{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHzY0pM//Bc7AKI3+gBK9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/File_00_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaaJ47Ee2VGS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o16Z8wP_6UDV"
      },
      "source": [
        "# **<h1 align=\"center\"><font color='#001ddd'> GLUCOSE PREDICTION DATASET**</font></h1>\n",
        "\n",
        "## **Dataset Description**\n",
        "The dataset is from a study that collected data from young adults in the UK with type 1 diabetes, who used a continuous glucose monitor (CGM), an insulin pump and a smartwatch. These devices collected blood glucose readings, insulin dosage, carbohydrate intake, and activity data. The data collected was aggregated to five-minute intervals and formatted into samples. Each sample represents a point in time and includes the aggregated five-minute intervals from the previous six hours. The aim is to predict the blood glucose reading an hour into the future, for each of these samples.\n",
        "\n",
        "The training set takes samples from the first three months of study data from nine of the participants and includes the future blood glucose value. These training samples appear in chronological order and overlap. The testing set takes samples from the remainder of the study period from fifteen of the participants (so unseen participants appear in the testing set). These testing samples do not overlap and are in a random order to avoid data leakage.\n",
        "\n",
        "**Complexities to be aware of:**\n",
        "\n",
        "This is medical data so there are missing values and noise in the data\n",
        "the participants did not all use the same device models (CGM, insulin pump and smartwatch) so there may be differences in the collection method of the data\n",
        "some participants in the test set do not appear in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--PrNXB8Ylys"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:#\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install category-encoders\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "#!pip install scikit-learn==1.4\n",
        "!pip install catboost\n",
        "!pip install deeptables\n",
        "\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install keras-nlp\n",
        "!pip install BorutaShap\n",
        "!pip install scikit-lego\n",
        "!!pip install --no-index -U --find-links=/kaggle/input/deeptables-v0-2-5/deeptables-0.2.5 deeptables==0.2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho3nCji3fPqQ"
      },
      "outputs": [],
      "source": [
        "folder_script = models_folders = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose\"\n",
        "os.chdir(folder_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syKhpAm8jJZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "013359ec-4787-45a6-9cf6-0b1079b2e46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x660 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from category_encoders.cat_boost import CatBoostEncoder\n",
        "from category_encoders.wrapper import PolynomialWrapper\n",
        "from category_encoders.count import CountEncoder\n",
        "\n",
        "# Setup notebook\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "import json\n",
        "import joblib\n",
        "#import calplot as cal\n",
        "import missingno as msno\n",
        "import category_encoders as ce\n",
        "\n",
        "# Graphic Libraries:\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "\n",
        "# Bloomberg\n",
        "#from xbbg import blp\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "# Time Management\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BMonthEnd, QuarterEnd\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay # BDay is business day, not birthday...\n",
        "import datetime as dt\n",
        "import click\n",
        "import glob\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import string\n",
        "\n",
        "from ipywidgets import AppLayout\n",
        "from ipywidgets import Dropdown, Layout, HTML, AppLayout, VBox, Label, HBox, BoundedFloatText, interact, Output\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "\n",
        "from keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
        "\n",
        "from keras.utils import FeatureSpace, plot_model\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate, GroupKFold, GridSearchCV, RepeatedStratifiedKFold, cross_val_predict\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "# metrics\n",
        "import sklearn\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             root_mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss,\n",
        "                             make_scorer)\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  HuberRegressor,\n",
        "                                  TweedieRegressor,\n",
        "                                  QuantileRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  TheilSenRegressor,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              AdaBoostClassifier,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              HistGradientBoostingRegressor,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "import logging\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "import scipy.stats as ss\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Setting rc parameters in seaborn for plots and graphs-\n",
        "# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n",
        "# To alter this, refer to matplotlib.rcParams.keys()\n",
        "\n",
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.5,\n",
        "         'grid.alpha'           :0.5,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : 'black',\n",
        "         'axes.titlesize'       : 12,\n",
        "         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "# Set Style\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "pd.set_option('display.max_columns', 100);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "G8YvvLtMYTBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6551321e-a25e-4c78-9525-b28007a59255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install graphviz\n",
        "import os\n",
        "os.environ[\"PATH\"] += os.pathsep + '/usr/bin/dot'"
      ],
      "metadata": {
        "id": "gxySMoesORTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73790705-3422-44df-e1dc-8d0b645a3c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Upload Data"
      ],
      "metadata": {
        "id": "eIq4n5QIJtVc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMB0Ku9izBm"
      },
      "source": [
        "## 1.1 Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXVCNFXEiysu"
      },
      "outputs": [],
      "source": [
        "def encode_target(y_train, y_test, encoder_type='label', enc_strategy=False):\n",
        "    \"\"\"\n",
        "    Encodes the target columns in the training and testing data\n",
        "    using the specified encoder type.\n",
        "\n",
        "    Parameters:\n",
        "    y_train (pd.Series or pd.DataFrame): Training target data.\n",
        "    y_test (pd.Series or pd.DataFrame): Testing target data.\n",
        "\n",
        "    Returns:\n",
        "    y_train_encoded (pd.Series): Encoded training target data.\n",
        "    y_test_encoded (pd.Series): Encoded testing target data.\n",
        "    \"\"\"\n",
        "\n",
        "    if encoder_type == 'label':\n",
        "        encoder = LabelEncoder()\n",
        "        y_train_encoded = encoder.fit_transform(y_train)\n",
        "        y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "        y_train_encoded = pd.Series(y_train_encoded, index=y_train.index, name=\"Target\")\n",
        "        y_test_encoded = pd.Series(y_test_encoded, index=y_test.index, name=\"Target\")\n",
        "\n",
        "\n",
        "    elif encoder_type == 'onehot':\n",
        "        y_train_ = y_train.values.reshape(-1, 1)\n",
        "        y_test_ = y_test.values.reshape(-1, 1)\n",
        "\n",
        "        encoder = OneHotEncoder(sparse_output=False)\n",
        "        y_train_encoded = encoder.fit_transform(y_train_)\n",
        "        y_test_encoded = encoder.transform(y_test_)\n",
        "\n",
        "        y_train_encoded = pd.DataFrame(y_train_encoded, index=y_train.index)\n",
        "        y_test_encoded = pd.DataFrame(y_test_encoded, index=y_test.index)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label'.\")\n",
        "\n",
        "    if enc_strategy:\n",
        "        return y_train_encoded, y_test_encoded, encoder\n",
        "\n",
        "    else:\n",
        "        return y_train_encoded, y_test_encoded\n",
        "\n",
        "def encode_data(X_train, X_test, encoder_type='label', columns=None, map=None):\n",
        "    \"\"\"\n",
        "    Encodes the training and testing data using the specified encoder type.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (pd.DataFrame): Training data.\n",
        "    X_test (pd.DataFrame): Testing data.\n",
        "    encoder_type (str): Type of encoder ('label' or 'onehot'). Default is 'label'.\n",
        "    columns (list): List of columns to encode. If None, all object type columns are encoded.\n",
        "\n",
        "    Returns:\n",
        "    X_train_encoded (pd.DataFrame): Encoded training data.\n",
        "    X_test_encoded (pd.DataFrame): Encoded testing data.\n",
        "    \"\"\"\n",
        "\n",
        "    if columns is None:\n",
        "        # Default to all object type columns if no columns are specified\n",
        "        columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    X_train_encoded = X_train.copy()\n",
        "    X_test_encoded = X_test.copy()\n",
        "\n",
        "    if encoder_type == 'label':\n",
        "        for col in columns:\n",
        "            le = LabelEncoder()\n",
        "            X_train_encoded[col] = le.fit_transform(X_train[col])\n",
        "            X_test_encoded[col] = le.transform(X_test[col])\n",
        "\n",
        "    elif encoder_type == 'onehot':\n",
        "        for col in columns:\n",
        "            ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
        "            # Fit the encoder on the training data and transform both training and test data\n",
        "            encoded_train = ohe.fit_transform(X_train[[col]])\n",
        "            encoded_test = ohe.transform(X_test[[col]])\n",
        "\n",
        "            # Create a DataFrame with the encoded data\n",
        "            encoded_train_df = pd.DataFrame(encoded_train, columns=ohe.get_feature_names_out([col]))\n",
        "            encoded_test_df = pd.DataFrame(encoded_test, columns=ohe.get_feature_names_out([col]))\n",
        "\n",
        "            # Concatenate the new columns to the original dataframes and drop the original columns\n",
        "            X_train_encoded = pd.concat([X_train_encoded.drop(col, axis=1), encoded_train_df], axis=1)\n",
        "            X_test_encoded = pd.concat([X_test_encoded.drop(col, axis=1), encoded_test_df], axis=1)\n",
        "\n",
        "    elif encoder_type == 'count_encoder':\n",
        "\n",
        "          for col in columns:\n",
        "\n",
        "                target_encoder = CountEncoder(cols=columns)\n",
        "                X_train_encoded = target_encoder.fit_transform(X_train_encoded)\n",
        "                X_test_encoded = target_encoder.transform(X_test_encoded)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label', 'onehot', 'target_encoder'.\")\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "\n",
        "def plot_training_session(history):\n",
        "  # Plot training and validation loss scores\n",
        "  # against the number of epochs.\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(history.history['loss'], label='Train')\n",
        "  plt.plot(history.history['val_loss'], label='Validation')\n",
        "  plt.grid(linestyle='--')\n",
        "  plt.ylabel('val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Train-Validation Scores', pad=13)\n",
        "  plt.legend(loc='upper right');\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5NjoRTdyVHe"
      },
      "source": [
        "## **1.2 Importing the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYVvvGmeG2W"
      },
      "source": [
        "### **1.2.1 Files**\n",
        "* activities.txt - a list of activity names that appear in the activity-X:XX columns\n",
        "* sample_submission.csv - a sample submission file in the correct format\n",
        "* test.csv - the test set\n",
        "* train.csv - the training set\n",
        "\n",
        "## **Columns**\n",
        "* train.csv:\n",
        "    * **id - row id** consisting of participant number and a count for that participant\n",
        "    * **p_num** - participant number\n",
        "    * **time** - time of day in the format HH:MM:SS\n",
        "    * **bg-X:XX** - blood glucose reading in mmol/L, X:XX(H:SS) time in the past (e.g. bg-2:35, would be the blood glucose reading from 2 hours and 35 minutes before the time value for that row), recorded by the continuous glucose monitor\n",
        "    * **insulin-X:XX** - total insulin dose received in units in the last 5 minutes, X:XX(H:SS) time in the past (e.g. insulin-2:35, would be the total insulin dose received between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the insulin pump\n",
        "    * **carbs-X:XX** - total carbohydrate value consumed in grammes in the last 5 minutes, X:XX(H:SS) time in the past (e.g. carbs-2:35, would be the total carbohydrate value consumed between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the participant\n",
        "    * **hr-X:XX** - mean heart rate in beats per minute in the last 5 minutes, X:XX(H:SS) time in the past (e.g. hr-2:35, would be the mean heart rate between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the smartwatch\n",
        "    * **steps-X:XX** - total steps walked in the last 5 minutes, X:XX(H:SS) time in the past (e.g. * steps-2:35, would be the total steps walked between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the smartwatch\n",
        "    * **cals-X:XX** - total calories burnt in the last 5 minutes, X:XX(H:SS) time in the past (e.g. cals-2:35, would be the total calories burned between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), calculated by the smartwatch\n",
        "    * **activity-X:XX** - self-declared activity performed in the last 5 minutes, X:XX(H:SS) time in the past (e.g. activity-2:35, would show a string name of the activity performed between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), set on the smartwatch\n",
        "    * **bg+1:00** - blood glucose reading in mmol/L an hour in the future, this is the value you will be predicting (not provided in test.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fiLvkXQuzJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbd624e-9cad-4963-d4ab-3c6953d12f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3644, 669) (177024, 670)\n"
          ]
        }
      ],
      "source": [
        "ext_data=True\n",
        "\n",
        "if ext_data==False:\n",
        "  df_train=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/train_cluster.csv\", index_col=0)\n",
        "  df_test=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/test_cluster.csv\", index_col=0)\n",
        "\n",
        "  df_train_scaled=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/X_train_scaled.csv\", index_col=0)\n",
        "  df_test.shape\n",
        "\n",
        "if ext_data==True:\n",
        "  df_train = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/train_cluster_enc_final.csv\", index_col=0)\n",
        "  df_test = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/test_cluster_enc_final.csv\", index_col=0)\n",
        "\n",
        "  df_train_scaled=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/X_train_scaled.csv\", index_col=0)\n",
        "  print(df_test.shape,df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIdNSqVxOY7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "15e894da-710e-4d5b-c3bf-682997dc8206"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "p_num\n",
              "p03    26028\n",
              "p02    25872\n",
              "p10    25454\n",
              "p12    25299\n",
              "p04    24686\n",
              "p11    24555\n",
              "p01     8459\n",
              "p06     8383\n",
              "p05     8288\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p_num</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>p03</th>\n",
              "      <td>26028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p02</th>\n",
              "      <td>25872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p10</th>\n",
              "      <td>25454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12</th>\n",
              "      <td>25299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p04</th>\n",
              "      <td>24686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p11</th>\n",
              "      <td>24555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p01</th>\n",
              "      <td>8459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p06</th>\n",
              "      <td>8383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p05</th>\n",
              "      <td>8288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_train.p_num.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.p_num = df_train.p_num.astype(\"str\")\n",
        "df_test.p_num = df_test.p_num.astype(\"str\")"
      ],
      "metadata": {
        "id": "7CM4Y6Mr5CuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train.groupby([\"cluster\"])[\"p_num\"].count()"
      ],
      "metadata": {
        "id": "azNdRmatWeUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8OmmGKk8KPX"
      },
      "outputs": [],
      "source": [
        "#df_train.groupby([\"cluster\",\"p_num\"])[\"p_num\"].count()[8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nJ0_v3bl0_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538f46b0-2ed1-447e-89aa-10d48594ea59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['p_num', 'hour', 'minute', 'obv_n', 'brake-5:55', 'brake-5:50',\n",
              "       'brake-5:45', 'brake-5:40', 'brake-5:35', 'brake-5:30',\n",
              "       ...\n",
              "       'enc_07_v7', 'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7',\n",
              "       'enc_06_v6', 'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6'],\n",
              "      dtype='object', length=670)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_train.head()\n",
        "df_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z8CiYrCCuNQ"
      },
      "outputs": [],
      "source": [
        "#df_all = pd.concat([df_train,df_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FXSnbRYnNg9"
      },
      "source": [
        "Sub-dataset are created for each main set of features to inpute missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHV_d6Ar-TX2"
      },
      "outputs": [],
      "source": [
        "# # Select columns containing the word \"bg\"\n",
        "# bg_col_train = df_train.filter(regex='bg|time|p_num|hour|minute')\n",
        "# bg_col_test = df_test.filter(regex='bg|time|p_num|hour|minute')\n",
        "\n",
        "# insulin_col_train = df_train.filter(regex='insulin|time|p_num|bg+1:00|hour|minute')\n",
        "# insulin_col_test = df_test.filter(regex='insulin|time|p_num|bg+1:00|hour|minute')\n",
        "# insulin_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# carb_col_train = df_train.filter(regex='carbs|time|p_num|bg+1:00|hour|minute')\n",
        "# carb_col_test = df_test.filter(regex='carbs|time|p_num|bg+1:00|hour|minute')\n",
        "# carb_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# hr_col_train = df_train.filter(regex='hr|time|p_num|bg+1:00|hour|minute')\n",
        "# hr_col_test = df_test.filter(regex='hr|time|p_num|bg+1:00|hour|minute')\n",
        "# hr_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# step_col_train = df_train.filter(regex='steps|time|p_num|bg+1:00|hour|minute')\n",
        "# step_col_test = df_test.filter(regex='steps|time|p_num|bg+1:00|hour|minute')\n",
        "# step_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# cal_col_train = df_train.filter(regex='cal|time|p_num|bg+1:00|hour|minute')\n",
        "# cal_col_test = df_test.filter(regex='cal|time|p_num|bg+1:00|hour|minute')\n",
        "# cal_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# act_col_train = df_train.filter(regex='activity|time|p_num|bg+1:00|hour|minute')\n",
        "# act_col_test = df_test.filter(regex='activity|time|p_num|bg+1:00|hour|minute')\n",
        "# act_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "display(dict(df_train.groupby(\"p_num\")[\"p_num\"].count()))\n",
        "display(dict(df_test.groupby(\"p_num\")[\"p_num\"].count()))\n",
        "#display(df_train[df_train[\"p_num\"]==\"p01\"].head())\n",
        "#display(df_train[df_train[\"p_num\"]==\"p02\"].head())"
      ],
      "metadata": {
        "id": "IYaD4UwO-dDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "1a709a4a-d7ed-47d8-d4c5-7dafb0ff7839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(177024, 670)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'p01': 8459,\n",
              " 'p02': 25872,\n",
              " 'p03': 26028,\n",
              " 'p04': 24686,\n",
              " 'p05': 8288,\n",
              " 'p06': 8383,\n",
              " 'p10': 25454,\n",
              " 'p11': 24555,\n",
              " 'p12': 25299}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'p01': 244,\n",
              " 'p02': 227,\n",
              " 'p04': 258,\n",
              " 'p05': 276,\n",
              " 'p06': 234,\n",
              " 'p10': 179,\n",
              " 'p11': 221,\n",
              " 'p12': 288,\n",
              " 'p15': 294,\n",
              " 'p16': 248,\n",
              " 'p18': 231,\n",
              " 'p19': 246,\n",
              " 'p21': 236,\n",
              " 'p22': 201,\n",
              " 'p24': 261}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Cross-Validation Strategy:**\n",
        "\n",
        "- *p03*: this individual is not among the test population. Therefore, it is heavily sampled by this observations. Total sampled: 25%/6028 obs.  \n",
        "- *Other*: About 5% of the onbs."
      ],
      "metadata": {
        "id": "V2TVKqQuHwES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### - Validation List 0"
      ],
      "metadata": {
        "id": "ue3pd5qk2Sw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ind = df_train.groupby(\"p_num\")[\"p_num\"].count().index.tolist()\n",
        "#display(df_train.groupby(\"p_num\")[\"p_num\"].count())\n",
        "#unique_ind.remove(\"p03\")\n",
        "print(df_train.shape)\n",
        "val_index = []\n",
        "# new_val_p01 = [f\"p01_{vali}\" for vali in range(8_000,8459)]\n",
        "# new_val_p02 = [f\"p02_{vali}\" for vali in range(24_000,25_872)]\n",
        "# new_val_p03 = [f\"p03_{vali}\" for vali in range(23_500,26_028)]\n",
        "# new_val_p04 = [f\"p04_{vali}\" for vali in range(23_500,24_686)]\n",
        "# new_val_p05 = [f\"p05_{vali}\" for vali in range(7800,8288)]\n",
        "# new_val_p06 = [f\"p06_{vali}\" for vali in range(7900,8383)]\n",
        "# new_val_p10 = [f\"p10_{vali}\" for vali in range(24_500,25454)]\n",
        "# new_val_p11 = [f\"p11_{vali}\" for vali in range(23_500,24555)]\n",
        "# new_val_p12 = [f\"p12_{vali}\" for vali in range(24_000,25299)]\n",
        "\n",
        "new_val_p01 = list(df_train[(df_train[\"p_num\"]==\"p01\")&(df_train[\"obv_n\"]>=7150)].index)\n",
        "new_val_p02 = list(df_train[(df_train[\"p_num\"]==\"p02\")&(df_train[\"obv_n\"]>=20500)].index)\n",
        "new_val_p03 = list(df_train[(df_train[\"p_num\"]==\"p03\")&(df_train[\"obv_n\"]>=21000)].index)\n",
        "new_val_p04 = list(df_train[(df_train[\"p_num\"]==\"p04\")&(df_train[\"obv_n\"]>=20500)].index)\n",
        "new_val_p05 = list(df_train[(df_train[\"p_num\"]==\"p05\")&(df_train[\"obv_n\"]>=7150)].index)\n",
        "new_val_p06 = list(df_train[(df_train[\"p_num\"]==\"p06\")&(df_train[\"obv_n\"]>=7150)].index)\n",
        "new_val_p10 = list(df_train[(df_train[\"p_num\"]==\"p10\")&(df_train[\"obv_n\"]>=20500)].index)\n",
        "new_val_p11 = list(df_train[(df_train[\"p_num\"]==\"p11\")&(df_train[\"obv_n\"]>=20500)].index)\n",
        "new_val_p12 = list(df_train[(df_train[\"p_num\"]==\"p12\")&(df_train[\"obv_n\"]>=20500)].index)\n",
        "\n",
        "val_index.append(new_val_p01)\n",
        "val_index.append(new_val_p02)\n",
        "val_index.append(new_val_p03)\n",
        "val_index.append(new_val_p04)\n",
        "val_index.append(new_val_p05)\n",
        "val_index.append(new_val_p06)\n",
        "val_index.append(new_val_p10)\n",
        "val_index.append(new_val_p11)\n",
        "val_index.append(new_val_p12)\n",
        "#unique_ind\n",
        "val_list_v0 = [item for row in val_index for item in row]\n",
        "print(len(val_list_v0)/float(df_train.shape[0]))"
      ],
      "metadata": {
        "id": "MhkcZsDVJAAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884f744f-1721-40e2-dbda-94bdab4d6211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(177024, 670)\n",
            "0.18118447216196673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### - Validation List 1"
      ],
      "metadata": {
        "id": "4hXGd8zK2Wa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ind = df_train.groupby(\"p_num\")[\"p_num\"].count().index.tolist()\n",
        "#display(df_train.groupby(\"p_num\")[\"p_num\"].count())\n",
        "#unique_ind.remove(\"p03\")\n",
        "print(df_train.shape)\n",
        "val_index = []\n",
        "new_val_p01 = [f\"p01_{vali}\" for vali in range(1200)]\n",
        "new_val_p02 = [f\"p02_{vali}\" for vali in range(4800)]\n",
        "new_val_p03 = [f\"p03_{vali}\" for vali in range(6500)]\n",
        "new_val_p04 = [f\"p04_{vali}\" for vali in range(3000)]\n",
        "new_val_p05 = [f\"p05_{vali}\" for vali in range(1270)]\n",
        "new_val_p06 = [f\"p06_{vali}\" for vali in range(1270)]\n",
        "new_val_p10 = [f\"p10_{vali}\" for vali in range(3000)]\n",
        "new_val_p11 = [f\"p11_{vali}\" for vali in range(3050)]\n",
        "new_val_p12 = [f\"p12_{vali}\" for vali in range(3600)]\n",
        "\n",
        "val_index.append(new_val_p01)\n",
        "val_index.append(new_val_p02)\n",
        "val_index.append(new_val_p03)\n",
        "val_index.append(new_val_p04)\n",
        "val_index.append(new_val_p05)\n",
        "val_index.append(new_val_p06)\n",
        "val_index.append(new_val_p10)\n",
        "val_index.append(new_val_p11)\n",
        "val_index.append(new_val_p12)\n",
        "#unique_ind\n",
        "val_list_v1 = [item for row in val_index for item in row]\n",
        "print(len(val_list_v1)/float(df_train.shape[0]))"
      ],
      "metadata": {
        "id": "E78phacmI_9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a506eb1c-86be-437c-f6de-cef0e3beb844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(177024, 670)\n",
            "0.15641946854663774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### - Validation List 2: it Removes \"p03\" from the training:"
      ],
      "metadata": {
        "id": "UA45B4Sz2bH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_index = []\n",
        "\n",
        "new_val_p03 = list(df_train[df_train[\"p_num\"]==\"p03\"].index)\n",
        "\n",
        "new_val_p01 = [f\"p01_{vali}\" for vali in range(8459,8459)]\n",
        "new_val_p02 = [f\"p02_{vali}\" for vali in range(24_000,25_872)]\n",
        "new_val_p04 = [f\"p04_{vali}\" for vali in range(23_500,24_686)]\n",
        "new_val_p05 = [f\"p05_{vali}\" for vali in range(7800,8288)]\n",
        "new_val_p06 = [f\"p06_{vali}\" for vali in range(7900,8383)]\n",
        "new_val_p10 = [f\"p10_{vali}\" for vali in range(24_500,25454)]\n",
        "new_val_p11 = [f\"p11_{vali}\" for vali in range(23_500,24555)]\n",
        "new_val_p12 = [f\"p12_{vali}\" for vali in range(24_000,25299)]\n",
        "\n",
        "val_index.append(new_val_p01)\n",
        "val_index.append(new_val_p02)\n",
        "val_index.append(new_val_p03)\n",
        "val_index.append(new_val_p04)\n",
        "val_index.append(new_val_p05)\n",
        "val_index.append(new_val_p06)\n",
        "val_index.append(new_val_p10)\n",
        "val_index.append(new_val_p11)\n",
        "val_index.append(new_val_p12)\n",
        "\n",
        "val_list_v2 = [item for row in val_index for item in row]\n",
        "print(len(val_list_v2)/float(df_train.shape[0]))"
      ],
      "metadata": {
        "id": "nSe2OTab2R-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5028711a-fdf1-4c62-93fa-542974332b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18847726861894432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### - Validation List 3"
      ],
      "metadata": {
        "id": "uhqBsTua6b9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, vld = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train[\"p_num\"], shuffle=True)\n",
        "val_list_v3 = vld.index.tolist()\n",
        "print(len(val_list_v3)/float(df_train.shape[0]))"
      ],
      "metadata": {
        "id": "j4-D2JoQ6fT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e7db3c-1f03-45fd-e02b-3a0bb9355ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20000112979031093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### - Validation List 4"
      ],
      "metadata": {
        "id": "vqTZG9OVYGwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ind = df_train.groupby(\"p_num\")[\"p_num\"].count().index.tolist()\n",
        "#display(df_train.groupby(\"p_num\")[\"p_num\"].count())\n",
        "#unique_ind.remove(\"p03\")\n",
        "print(df_train.shape)\n",
        "val_index = []\n",
        "# new_val_p01 = [f\"p01_{vali}\" for vali in range(8_000,8459)]\n",
        "# new_val_p02 = [f\"p02_{vali}\" for vali in range(24_000,25_872)]\n",
        "# new_val_p03 = [f\"p03_{vali}\" for vali in range(23_500,26_028)]\n",
        "# new_val_p04 = [f\"p04_{vali}\" for vali in range(23_500,24_686)]\n",
        "# new_val_p05 = [f\"p05_{vali}\" for vali in range(7800,8288)]\n",
        "# new_val_p06 = [f\"p06_{vali}\" for vali in range(7900,8383)]\n",
        "# new_val_p10 = [f\"p10_{vali}\" for vali in range(24_500,25454)]\n",
        "# new_val_p11 = [f\"p11_{vali}\" for vali in range(23_500,24555)]\n",
        "# new_val_p12 = [f\"p12_{vali}\" for vali in range(24_000,25299)]\n",
        "\n",
        "new_val_p01 = list(df_train[(df_train[\"p_num\"]==\"p01\")&(df_train[\"obv_n\"]>=6300)&(df_train[\"obv_n\"]<=7600)].index)\n",
        "new_val_p02 = list(df_train[(df_train[\"p_num\"]==\"p02\")&(df_train[\"obv_n\"]>=17100)&(df_train[\"obv_n\"]<=20500)].index)\n",
        "new_val_p03 = list(df_train[(df_train[\"p_num\"]==\"p03\")&(df_train[\"obv_n\"]>=16500)&(df_train[\"obv_n\"]<=21000)].index)\n",
        "new_val_p04 = list(df_train[(df_train[\"p_num\"]==\"p04\")&(df_train[\"obv_n\"]>=16500)&(df_train[\"obv_n\"]<=20000)].index)\n",
        "new_val_p05 = list(df_train[(df_train[\"p_num\"]==\"p05\")&(df_train[\"obv_n\"]>=5200)&(df_train[\"obv_n\"]<=6600)].index)\n",
        "new_val_p06 = list(df_train[(df_train[\"p_num\"]==\"p06\")&(df_train[\"obv_n\"]>=4800)&(df_train[\"obv_n\"]<=6000)].index)\n",
        "new_val_p10 = list(df_train[(df_train[\"p_num\"]==\"p10\")&(df_train[\"obv_n\"]>=16500)&(df_train[\"obv_n\"]<=20000)].index)\n",
        "new_val_p11 = list(df_train[(df_train[\"p_num\"]==\"p11\")&(df_train[\"obv_n\"]>=16500)&(df_train[\"obv_n\"]<=20000)].index)\n",
        "new_val_p12 = list(df_train[(df_train[\"p_num\"]==\"p12\")&(df_train[\"obv_n\"]>=14000)&(df_train[\"obv_n\"]<=17500)].index)\n",
        "\n",
        "val_index.append(new_val_p01)\n",
        "val_index.append(new_val_p02)\n",
        "val_index.append(new_val_p03)\n",
        "val_index.append(new_val_p04)\n",
        "val_index.append(new_val_p05)\n",
        "val_index.append(new_val_p06)\n",
        "val_index.append(new_val_p10)\n",
        "val_index.append(new_val_p11)\n",
        "val_index.append(new_val_p12)\n",
        "#unique_ind\n",
        "val_list_v4 = [item for row in val_index for item in row]\n",
        "print(len(val_list_v4)/float(df_train.shape[0]))"
      ],
      "metadata": {
        "id": "WICUOt1BYGwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab195b32-a7e4-4c5d-fc03-fc1242ae40bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(177024, 670)\n",
            "0.14579379067245118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_sets = [val_list_v0,val_list_v1,val_list_v2,val_list_v3,val_list_v4]"
      ],
      "metadata": {
        "id": "Ust85u7II_55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYNfgB1gObc"
      },
      "source": [
        "###  **1.2.2 Data Preparation:**\n",
        "\n",
        "Data are scaled in groups."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns[-20:],df_train.columns[:20]"
      ],
      "metadata": {
        "id": "H4JGcd0dyqOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa725af4-525b-41b8-9807-2f36b2ce8f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['activity-0:05', 'activity-0:00', 'bg+1:00', 'cluster', 'cluster_pca',\n",
              "        'PC_1', 'PC_2', 'PC_3', 'enc_04_v7', 'enc_01_v1', 'enc_07_v7',\n",
              "        'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7', 'enc_06_v6',\n",
              "        'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6'],\n",
              "       dtype='object'),\n",
              " Index(['p_num', 'hour', 'minute', 'obv_n', 'brake-5:55', 'brake-5:50',\n",
              "        'brake-5:45', 'brake-5:40', 'brake-5:35', 'brake-5:30', 'brake-5:25',\n",
              "        'brake-5:20', 'brake-5:15', 'brake-5:10', 'brake-5:05', 'brake-5:00',\n",
              "        'brake-4:55', 'brake-4:50', 'brake-4:45', 'brake-4:40'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(columns=[\"p_num\",\"obv_n\"]).copy()\n",
        "X_test = df_test.drop(columns=[\"p_num\",\"obv_n\"]).copy()\n",
        "\n",
        "#X_train = df_train.drop(columns=[\"obv_n\"]).copy()\n",
        "#X_test = df_test.drop(columns=[\"obv_n\"]).copy()"
      ],
      "metadata": {
        "id": "UUDy375o9DPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hr_col_train = list(df_train.filter(regex='hr').columns)\n",
        "print(len(hr_col_train))\n",
        "\n",
        "X_train = X_train.drop(columns=hr_col_train)\n",
        "X_test = X_test.drop(columns=hr_col_train)"
      ],
      "metadata": {
        "id": "xSm1LidRQjGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bb5bd6-3ded-4070-8fdf-17cd81d8025d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwLn5-lSY1g3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce3862b-9a98-4672-f8ba-8984bad32bb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "static_fields = [\"hour\",\"minute\", 'cluster', 'cluster_pca',\n",
        "       'PC_1', 'PC_2', 'PC_3', 'enc_04_v7', 'enc_01_v1', 'enc_07_v7',\n",
        "       'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7', 'enc_06_v6',\n",
        "       'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6'] #\"id\",\n",
        "target = [\"bg+1:00\"]\n",
        "ts_fields = list(X_train.drop(columns=static_fields+target))\n",
        "len(ts_fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale Continous Features"
      ],
      "metadata": {
        "id": "ruDkoEreUI4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Features:"
      ],
      "metadata": {
        "id": "2eTNy49rV95Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feat_to_scale = ['PC_1', 'PC_2', 'PC_3', 'enc_04_v7', 'enc_01_v1', 'enc_07_v7',\n",
        "                  'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7', 'enc_06_v6',\n",
        "                  'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6']\n",
        "\n",
        "target_scaler_cont = StandardScaler()\n",
        "\n",
        "X_train[feat_to_scale] = target_scaler_cont.fit_transform(X_train[feat_to_scale])\n",
        "X_test[feat_to_scale] = target_scaler_cont.transform(X_test[feat_to_scale])"
      ],
      "metadata": {
        "id": "50zsI_uJVUmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Target:"
      ],
      "metadata": {
        "id": "yrlalmJ8WBeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_scaler = StandardScaler()\n",
        "target_scaler.fit(df_train_scaled[target])\n",
        "\n",
        "X_train[target] = target_scaler.transform(df_train[target])"
      ],
      "metadata": {
        "id": "Nh2LRlxA3okI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[target]"
      ],
      "metadata": {
        "id": "XV2M7OD4GfId",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "d7a56004-b6cb-40c7-9aa5-dfa02ce8cc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            bg+1:00\n",
              "id                 \n",
              "p01_0      1.709709\n",
              "p01_1      1.509468\n",
              "p01_2      2.410552\n",
              "p01_3      2.176938\n",
              "p01_4      1.476095\n",
              "...             ...\n",
              "p12_25294  0.942119\n",
              "p12_25295  0.875372\n",
              "p12_25296  0.808625\n",
              "p12_25297  0.741878\n",
              "p12_25298  0.641757\n",
              "\n",
              "[177024 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ee3694f-fb22-4938-9568-c457badae2d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bg+1:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>p01_0</th>\n",
              "      <td>1.709709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p01_1</th>\n",
              "      <td>1.509468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p01_2</th>\n",
              "      <td>2.410552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p01_3</th>\n",
              "      <td>2.176938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p01_4</th>\n",
              "      <td>1.476095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12_25294</th>\n",
              "      <td>0.942119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12_25295</th>\n",
              "      <td>0.875372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12_25296</th>\n",
              "      <td>0.808625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12_25297</th>\n",
              "      <td>0.741878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12_25298</th>\n",
              "      <td>0.641757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177024 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ee3694f-fb22-4938-9568-c457badae2d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ee3694f-fb22-4938-9568-c457badae2d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ee3694f-fb22-4938-9568-c457badae2d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80bf11ba-f148-495c-ad44-15270abe890a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80bf11ba-f148-495c-ad44-15270abe890a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80bf11ba-f148-495c-ad44-15270abe890a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[target] = np.nan\n",
        "\n",
        "X_train = X_train[list(X_test.columns)]"
      ],
      "metadata": {
        "id": "ACo0DVA5PDvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train.columns==X_test.columns).all()"
      ],
      "metadata": {
        "id": "bm92GR08f5J4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d862c8-eebf-4706-dad1-07249b367d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define Features Datatypes:"
      ],
      "metadata": {
        "id": "LgeSuWl0YGQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odQB0ciycJWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3cd7c0-e5d9-48a4-c9c0-9c27dd00737a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['activity',\n",
              " 'bg',\n",
              " 'cals_av',\n",
              " 'steps_av',\n",
              " 'carbs_av',\n",
              " 'brake',\n",
              " 'insulin_av',\n",
              " 'intake']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "ts_fields_group = list({q[:-5] for q in ts_fields})\n",
        "ts_fields_group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[[\"cluster\",\"cluster_pca\"]] = X_train[[\"cluster\",\"cluster_pca\"]].astype(\"int32\")"
      ],
      "metadata": {
        "id": "NVHpE0PE32Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.copy()\n",
        "X_test = X_test.copy()"
      ],
      "metadata": {
        "id": "EY2S5D2R_QWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_cols = X_train.select_dtypes(include=['int']).columns.tolist()\n",
        "float_cols = X_train.select_dtypes(include=['float']).columns.tolist()\n",
        "obj_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "X_train[int_cols] = X_train[int_cols].astype(\"int32\")\n",
        "X_train[float_cols] = X_train[float_cols].astype(\"float32\")\n",
        "X_train[obj_cols] = X_train[obj_cols].astype(\"string\")\n",
        "\n",
        "X_test[int_cols] = X_test[int_cols].astype(\"int32\")\n",
        "X_test[float_cols] = X_test[float_cols].astype(\"float32\")\n",
        "X_test[obj_cols] = X_test[obj_cols].astype(\"string\")"
      ],
      "metadata": {
        "id": "ouO2Yf1qpNiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "2HEN6SUz_TL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b2b4f5-a15d-4b3e-d956-718b3a062582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((177024, 596), (3644, 596))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols"
      ],
      "metadata": {
        "id": "jrXU1fCX2xqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e3d12a-1d21-4a89-dfe7-fff28fd5d7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "yb2Obgb13vdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4d505a-1762-4264-cc78-70cae4ecb271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 177024 entries, p01_0 to p12_25298\n",
            "Columns: 596 entries, hour to bg+1:00\n",
            "dtypes: float32(592), int32(4)\n",
            "memory usage: 407.9+ MB\n"
          ]
        }
      ]
    }
  ]
}