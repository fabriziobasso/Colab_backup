{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/File_00_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o16Z8wP_6UDV"
      },
      "source": [
        "# **<h1 align=\"center\"><font color='#001ddd'> GLUCOSE PREDICTION DATASET**</font></h1>\n",
        "\n",
        "## **Dataset Description**\n",
        "The dataset is from a study that collected data from young adults in the UK with type 1 diabetes, who used a continuous glucose monitor (CGM), an insulin pump and a smartwatch. These devices collected blood glucose readings, insulin dosage, carbohydrate intake, and activity data. The data collected was aggregated to five-minute intervals and formatted into samples. Each sample represents a point in time and includes the aggregated five-minute intervals from the previous six hours. The aim is to predict the blood glucose reading an hour into the future, for each of these samples.\n",
        "\n",
        "The training set takes samples from the first three months of study data from nine of the participants and includes the future blood glucose value. These training samples appear in chronological order and overlap. The testing set takes samples from the remainder of the study period from fifteen of the participants (so unseen participants appear in the testing set). These testing samples do not overlap and are in a random order to avoid data leakage.\n",
        "\n",
        "**Complexities to be aware of:**\n",
        "\n",
        "This is medical data so there are missing values and noise in the data\n",
        "the participants did not all use the same device models (CGM, insulin pump and smartwatch) so there may be differences in the collection method of the data\n",
        "some participants in the test set do not appear in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--PrNXB8Ylys"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:#\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install category-encoders\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "#!pip install scikit-learn==1.4\n",
        "!pip install catboost\n",
        "!pip install deeptables\n",
        "\n",
        "!pip install BorutaShap\n",
        "!pip install scikit-lego\n",
        "!!pip install --no-index -U --find-links=/kaggle/input/deeptables-v0-2-5/deeptables-0.2.5 deeptables==0.2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho3nCji3fPqQ"
      },
      "outputs": [],
      "source": [
        "folder_script = models_folders = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose\"\n",
        "os.chdir(folder_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "syKhpAm8jJZe",
        "outputId": "ac09afd6-639d-4d54-adfc-24cfdf013ea3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 960x660 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from category_encoders.cat_boost import CatBoostEncoder\n",
        "from category_encoders.wrapper import PolynomialWrapper\n",
        "from category_encoders.count import CountEncoder\n",
        "\n",
        "# Setup notebook\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "import json\n",
        "import joblib\n",
        "#import calplot as cal\n",
        "import missingno as msno\n",
        "import category_encoders as ce\n",
        "\n",
        "# Graphic Libraries:\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "\n",
        "# Bloomberg\n",
        "#from xbbg import blp\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "# Time Management\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BMonthEnd, QuarterEnd\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay # BDay is business day, not birthday...\n",
        "import datetime as dt\n",
        "import click\n",
        "import glob\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import string\n",
        "\n",
        "from ipywidgets import AppLayout\n",
        "from ipywidgets import Dropdown, Layout, HTML, AppLayout, VBox, Label, HBox, BoundedFloatText, interact, Output\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "\n",
        "from keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
        "\n",
        "from keras.utils import FeatureSpace, plot_model\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, RepeatedKFold, cross_validate, GroupKFold, GridSearchCV, RepeatedStratifiedKFold, cross_val_predict\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "# metrics\n",
        "import sklearn\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             root_mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss,\n",
        "                             make_scorer)\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  HuberRegressor,\n",
        "                                  TweedieRegressor,\n",
        "                                  QuantileRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  TheilSenRegressor,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              AdaBoostClassifier,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              HistGradientBoostingRegressor,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "import logging\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "import scipy.stats as ss\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Setting rc parameters in seaborn for plots and graphs-\n",
        "# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n",
        "# To alter this, refer to matplotlib.rcParams.keys()\n",
        "\n",
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.5,\n",
        "         'grid.alpha'           :0.5,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : 'black',\n",
        "         'axes.titlesize'       : 12,\n",
        "         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "# Set Style\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "pd.set_option('display.max_columns', 100);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G8YvvLtMYTBK",
        "outputId": "7c68bcf4-6e49-44b0-92fb-e22d7979093b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.17.0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxySMoesORTH",
        "outputId": "9ac3bac4-b4eb-4e40-95d9-e1c634cda5da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install graphviz\n",
        "import os\n",
        "os.environ[\"PATH\"] += os.pathsep + '/usr/bin/dot'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIq4n5QIJtVc"
      },
      "source": [
        "# 1.0 Upload Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMB0Ku9izBm"
      },
      "source": [
        "## 1.1 Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXVCNFXEiysu"
      },
      "outputs": [],
      "source": [
        "def encode_target(y_train, y_test, encoder_type='label', enc_strategy=False):\n",
        "    \"\"\"\n",
        "    Encodes the target columns in the training and testing data\n",
        "    using the specified encoder type.\n",
        "\n",
        "    Parameters:\n",
        "    y_train (pd.Series or pd.DataFrame): Training target data.\n",
        "    y_test (pd.Series or pd.DataFrame): Testing target data.\n",
        "\n",
        "    Returns:\n",
        "    y_train_encoded (pd.Series): Encoded training target data.\n",
        "    y_test_encoded (pd.Series): Encoded testing target data.\n",
        "    \"\"\"\n",
        "\n",
        "    if encoder_type == 'label':\n",
        "        encoder = LabelEncoder()\n",
        "        y_train_encoded = encoder.fit_transform(y_train)\n",
        "        y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "        y_train_encoded = pd.Series(y_train_encoded, index=y_train.index, name=\"Target\")\n",
        "        y_test_encoded = pd.Series(y_test_encoded, index=y_test.index, name=\"Target\")\n",
        "\n",
        "\n",
        "    elif encoder_type == 'onehot':\n",
        "        y_train_ = y_train.values.reshape(-1, 1)\n",
        "        y_test_ = y_test.values.reshape(-1, 1)\n",
        "\n",
        "        encoder = OneHotEncoder(sparse_output=False)\n",
        "        y_train_encoded = encoder.fit_transform(y_train_)\n",
        "        y_test_encoded = encoder.transform(y_test_)\n",
        "\n",
        "        y_train_encoded = pd.DataFrame(y_train_encoded, index=y_train.index)\n",
        "        y_test_encoded = pd.DataFrame(y_test_encoded, index=y_test.index)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label'.\")\n",
        "\n",
        "    if enc_strategy:\n",
        "        return y_train_encoded, y_test_encoded, encoder\n",
        "\n",
        "    else:\n",
        "        return y_train_encoded, y_test_encoded\n",
        "\n",
        "def encode_data(X_train, X_test, encoder_type='label', columns=None, map=None):\n",
        "    \"\"\"\n",
        "    Encodes the training and testing data using the specified encoder type.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (pd.DataFrame): Training data.\n",
        "    X_test (pd.DataFrame): Testing data.\n",
        "    encoder_type (str): Type of encoder ('label' or 'onehot'). Default is 'label'.\n",
        "    columns (list): List of columns to encode. If None, all object type columns are encoded.\n",
        "\n",
        "    Returns:\n",
        "    X_train_encoded (pd.DataFrame): Encoded training data.\n",
        "    X_test_encoded (pd.DataFrame): Encoded testing data.\n",
        "    \"\"\"\n",
        "\n",
        "    if columns is None:\n",
        "        # Default to all object type columns if no columns are specified\n",
        "        columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    X_train_encoded = X_train.copy()\n",
        "    X_test_encoded = X_test.copy()\n",
        "\n",
        "    if encoder_type == 'label':\n",
        "        for col in columns:\n",
        "            le = LabelEncoder()\n",
        "            X_train_encoded[col] = le.fit_transform(X_train[col])\n",
        "            X_test_encoded[col] = le.transform(X_test[col])\n",
        "\n",
        "    elif encoder_type == 'onehot':\n",
        "        for col in columns:\n",
        "            ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
        "            # Fit the encoder on the training data and transform both training and test data\n",
        "            encoded_train = ohe.fit_transform(X_train[[col]])\n",
        "            encoded_test = ohe.transform(X_test[[col]])\n",
        "\n",
        "            # Create a DataFrame with the encoded data\n",
        "            encoded_train_df = pd.DataFrame(encoded_train, columns=ohe.get_feature_names_out([col]))\n",
        "            encoded_test_df = pd.DataFrame(encoded_test, columns=ohe.get_feature_names_out([col]))\n",
        "\n",
        "            # Concatenate the new columns to the original dataframes and drop the original columns\n",
        "            X_train_encoded = pd.concat([X_train_encoded.drop(col, axis=1), encoded_train_df], axis=1)\n",
        "            X_test_encoded = pd.concat([X_test_encoded.drop(col, axis=1), encoded_test_df], axis=1)\n",
        "\n",
        "    elif encoder_type == 'count_encoder':\n",
        "\n",
        "          for col in columns:\n",
        "\n",
        "                target_encoder = CountEncoder(cols=columns)\n",
        "                X_train_encoded = target_encoder.fit_transform(X_train_encoded)\n",
        "                X_test_encoded = target_encoder.transform(X_test_encoded)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label', 'onehot', 'target_encoder'.\")\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "\n",
        "def plot_training_session(history):\n",
        "  # Plot training and validation loss scores\n",
        "  # against the number of epochs.\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(history.history['loss'], label='Train')\n",
        "  plt.plot(history.history['val_loss'], label='Validation')\n",
        "  plt.grid(linestyle='--')\n",
        "  plt.ylabel('val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Train-Validation Scores', pad=13)\n",
        "  plt.legend(loc='upper right');\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5NjoRTdyVHe"
      },
      "source": [
        "## **1.2 Importing the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYVvvGmeG2W"
      },
      "source": [
        "### **1.2.1 Files**\n",
        "* activities.txt - a list of activity names that appear in the activity-X:XX columns\n",
        "* sample_submission.csv - a sample submission file in the correct format\n",
        "* test.csv - the test set\n",
        "* train.csv - the training set\n",
        "\n",
        "## **Columns**\n",
        "* train.csv:\n",
        "    * **id - row id** consisting of participant number and a count for that participant\n",
        "    * **p_num** - participant number\n",
        "    * **time** - time of day in the format HH:MM:SS\n",
        "    * **bg-X:XX** - blood glucose reading in mmol/L, X:XX(H:SS) time in the past (e.g. bg-2:35, would be the blood glucose reading from 2 hours and 35 minutes before the time value for that row), recorded by the continuous glucose monitor\n",
        "    * **insulin-X:XX** - total insulin dose received in units in the last 5 minutes, X:XX(H:SS) time in the past (e.g. insulin-2:35, would be the total insulin dose received between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the insulin pump\n",
        "    * **carbs-X:XX** - total carbohydrate value consumed in grammes in the last 5 minutes, X:XX(H:SS) time in the past (e.g. carbs-2:35, would be the total carbohydrate value consumed between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the participant\n",
        "    * **hr-X:XX** - mean heart rate in beats per minute in the last 5 minutes, X:XX(H:SS) time in the past (e.g. hr-2:35, would be the mean heart rate between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the smartwatch\n",
        "    * **steps-X:XX** - total steps walked in the last 5 minutes, X:XX(H:SS) time in the past (e.g. * steps-2:35, would be the total steps walked between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the smartwatch\n",
        "    * **cals-X:XX** - total calories burnt in the last 5 minutes, X:XX(H:SS) time in the past (e.g. cals-2:35, would be the total calories burned between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), calculated by the smartwatch\n",
        "    * **activity-X:XX** - self-declared activity performed in the last 5 minutes, X:XX(H:SS) time in the past (e.g. activity-2:35, would show a string name of the activity performed between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), set on the smartwatch\n",
        "    * **bg+1:00** - blood glucose reading in mmol/L an hour in the future, this is the value you will be predicting (not provided in test.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fiLvkXQuzJ3",
        "outputId": "77a8aac2-c42c-4dad-b2e3-0965cb11fb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3644, 669) (177024, 670)\n"
          ]
        }
      ],
      "source": [
        "ext_data=True\n",
        "\n",
        "if ext_data==False:\n",
        "  df_train=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/train_cluster.csv\", index_col=0)\n",
        "  df_test=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/test_cluster.csv\", index_col=0)\n",
        "\n",
        "  df_train_scaled=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/X_train_scaled.csv\", index_col=0)\n",
        "  df_test.shape\n",
        "\n",
        "if ext_data==True:\n",
        "  df_train = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/train_cluster_enc_final.csv\", index_col=0)\n",
        "  df_test = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/test_cluster_enc_final.csv\", index_col=0)\n",
        "\n",
        "  df_train_scaled=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/X_train_scaled.csv\", index_col=0)\n",
        "  print(df_test.shape,df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "UIdNSqVxOY7o",
        "outputId": "9d5bd550-3ed4-412b-d396-8f3ce08ed2ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p_num</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>p03</th>\n",
              "      <td>26028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p02</th>\n",
              "      <td>25872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p10</th>\n",
              "      <td>25454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p12</th>\n",
              "      <td>25299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p04</th>\n",
              "      <td>24686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p11</th>\n",
              "      <td>24555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p01</th>\n",
              "      <td>8459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p06</th>\n",
              "      <td>8383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p05</th>\n",
              "      <td>8288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "p_num\n",
              "p03    26028\n",
              "p02    25872\n",
              "p10    25454\n",
              "p12    25299\n",
              "p04    24686\n",
              "p11    24555\n",
              "p01     8459\n",
              "p06     8383\n",
              "p05     8288\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.p_num.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CM4Y6Mr5CuF"
      },
      "outputs": [],
      "source": [
        "df_train.p_num = df_train.p_num.astype(\"str\")\n",
        "df_test.p_num = df_test.p_num.astype(\"str\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nJ0_v3bl0_s",
        "outputId": "43b2b137-e93e-48d3-9aa1-81317abb0ab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['p_num', 'hour', 'minute', 'obv_n', 'brake-5:55', 'brake-5:50',\n",
              "       'brake-5:45', 'brake-5:40', 'brake-5:35', 'brake-5:30',\n",
              "       ...\n",
              "       'enc_07_v7', 'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7',\n",
              "       'enc_06_v6', 'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6'],\n",
              "      dtype='object', length=670)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()\n",
        "df_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "IYaD4UwO-dDQ",
        "outputId": "0729dbd6-c3db-4a8e-eb9b-4dd1c631f07f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(177024, 670)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'p01': 8459,\n",
              " 'p02': 25872,\n",
              " 'p03': 26028,\n",
              " 'p04': 24686,\n",
              " 'p05': 8288,\n",
              " 'p06': 8383,\n",
              " 'p10': 25454,\n",
              " 'p11': 24555,\n",
              " 'p12': 25299}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'p01': 244,\n",
              " 'p02': 227,\n",
              " 'p04': 258,\n",
              " 'p05': 276,\n",
              " 'p06': 234,\n",
              " 'p10': 179,\n",
              " 'p11': 221,\n",
              " 'p12': 288,\n",
              " 'p15': 294,\n",
              " 'p16': 248,\n",
              " 'p18': 231,\n",
              " 'p19': 246,\n",
              " 'p21': 236,\n",
              " 'p22': 201,\n",
              " 'p24': 261}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df_train.shape)\n",
        "display(dict(df_train.groupby(\"p_num\")[\"p_num\"].count()))\n",
        "display(dict(df_test.groupby(\"p_num\")[\"p_num\"].count()))\n",
        "#display(df_train[df_train[\"p_num\"]==\"p01\"].head())\n",
        "#display(df_train[df_train[\"p_num\"]==\"p02\"].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYNfgB1gObc"
      },
      "source": [
        "###  **1.2.2 Data Preparation:**\n",
        "\n",
        "Data are scaled in groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4JGcd0dyqOr",
        "outputId": "c78f059f-4dc9-49e2-b5e1-faf53d4d0fcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Index(['activity-0:05', 'activity-0:00', 'bg+1:00', 'cluster', 'cluster_pca',\n",
              "        'PC_1', 'PC_2', 'PC_3', 'enc_04_v7', 'enc_01_v1', 'enc_07_v7',\n",
              "        'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7', 'enc_06_v6',\n",
              "        'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6'],\n",
              "       dtype='object'),\n",
              " Index(['p_num', 'hour', 'minute', 'obv_n', 'brake-5:55', 'brake-5:50',\n",
              "        'brake-5:45', 'brake-5:40', 'brake-5:35', 'brake-5:30', 'brake-5:25',\n",
              "        'brake-5:20', 'brake-5:15', 'brake-5:10', 'brake-5:05', 'brake-5:00',\n",
              "        'brake-4:55', 'brake-4:50', 'brake-4:45', 'brake-4:40'],\n",
              "       dtype='object'))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.columns[-20:],df_train.columns[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUDy375o9DPX"
      },
      "outputs": [],
      "source": [
        "X_train = df_train.drop(columns=[\"p_num\",\"obv_n\"]).copy()\n",
        "X_test = df_test.drop(columns=[\"p_num\",\"obv_n\"]).copy()\n",
        "\n",
        "#X_train = df_train.drop(columns=[\"obv_n\"]).copy()\n",
        "#X_test = df_test.drop(columns=[\"obv_n\"]).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSm1LidRQjGE",
        "outputId": "187d20e4-1786-4ec7-d885-b264d7990739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72\n"
          ]
        }
      ],
      "source": [
        "hr_col_train = list(df_train.filter(regex='hr').columns)\n",
        "print(len(hr_col_train))\n",
        "\n",
        "X_train = X_train.drop(columns=hr_col_train)\n",
        "X_test = X_test.drop(columns=hr_col_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwLn5-lSY1g3",
        "outputId": "09579c7f-3371-493a-af0c-8df2107266f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "static_fields = [\"hour\",\"minute\", 'cluster', 'cluster_pca',\n",
        "       'PC_1', 'PC_2', 'PC_3', 'enc_04_v7', 'enc_01_v1', 'enc_07_v7',\n",
        "       'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7', 'enc_06_v6',\n",
        "       'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6'] #\"id\",\n",
        "target = [\"bg+1:00\"]\n",
        "ts_fields = list(X_train.drop(columns=static_fields+target))\n",
        "len(ts_fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruDkoEreUI4y"
      },
      "source": [
        "### Scale Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrlalmJ8WBeo"
      },
      "source": [
        "##### Target:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh2LRlxA3okI"
      },
      "outputs": [],
      "source": [
        "target_scaler = StandardScaler()\n",
        "target_scaler.fit(df_train_scaled[target])\n",
        "\n",
        "X_train[target] = target_scaler.transform(df_train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACo0DVA5PDvk"
      },
      "outputs": [],
      "source": [
        "X_test[target] = np.nan\n",
        "\n",
        "X_train = X_train[list(X_test.columns)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm92GR08f5J4",
        "outputId": "6c8989b7-4142-44f9-b1cc-b67bdbbf5c6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(X_train.columns==X_test.columns).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eTNy49rV95Z"
      },
      "source": [
        "##### Features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgeSuWl0YGQP"
      },
      "source": [
        "##### Define Features Datatypes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVHpE0PE32Uq"
      },
      "outputs": [],
      "source": [
        "X_train[[\"cluster\",\"cluster_pca\"]] = X_train[[\"cluster\",\"cluster_pca\"]].astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouO2Yf1qpNiT"
      },
      "outputs": [],
      "source": [
        "int_cols = X_train.select_dtypes(include=['int']).columns.tolist()\n",
        "float_cols = X_train.select_dtypes(include=['float']).columns.tolist()\n",
        "obj_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "X_train[int_cols] = X_train[int_cols].astype(\"int32\")\n",
        "X_train[float_cols] = X_train[float_cols].astype(\"float32\")\n",
        "X_train[obj_cols] = X_train[obj_cols].astype(\"string\")\n",
        "\n",
        "X_test[int_cols] = X_test[int_cols].astype(\"int32\")\n",
        "X_test[float_cols] = X_test[float_cols].astype(\"float32\")\n",
        "X_test[obj_cols] = X_test[obj_cols].astype(\"string\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNky4HBLo7Bf"
      },
      "source": [
        "##### Time Features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWJCbZc7o92H"
      },
      "outputs": [],
      "source": [
        "X_train['hour_sin'] = np.sin(2 * np.pi * X_train['hour'] / 24)\n",
        "X_train['hour_cos'] = np.cos(2 * np.pi * X_train['hour'] / 24)\n",
        "X_train['minute_sin'] = np.sin(2 * np.pi * X_train['minute'] / 60)\n",
        "X_train['minute_cos'] = np.cos(2 * np.pi * X_train['minute'] / 60)\n",
        "\n",
        "X_train = X_train.drop(['hour', 'minute'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJFenS75p0jf"
      },
      "outputs": [],
      "source": [
        "X_test['hour_sin'] = np.sin(2 * np.pi * X_test['hour'] / 24)\n",
        "X_test['hour_cos'] = np.cos(2 * np.pi * X_test['hour'] / 24)\n",
        "X_test['minute_sin'] = np.sin(2 * np.pi * X_test['minute'] / 60)\n",
        "X_test['minute_cos'] = np.cos(2 * np.pi * X_test['minute'] / 60)\n",
        "\n",
        "X_test = X_test.drop(['hour', 'minute'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odQB0ciycJWf",
        "outputId": "2dc411aa-7727-4263-cc98-8136514193b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cals_av',\n",
              " 'activity',\n",
              " 'insulin_av',\n",
              " 'bg',\n",
              " 'brake',\n",
              " 'carbs_av',\n",
              " 'intake',\n",
              " 'steps_av']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ts_fields_group = list({q[:-5] for q in ts_fields})\n",
        "ts_fields_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY2S5D2R_QWd"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.copy()\n",
        "X_test = X_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HEN6SUz_TL1",
        "outputId": "ad5caa2b-a94a-4588-9c44-815c6d87eeec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((177024, 598), (3644, 598))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb2Obgb13vdo",
        "outputId": "8f9b29cc-6bc8-4a4f-dc05-dc399c19913c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 177024 entries, p01_0 to p12_25298\n",
            "Columns: 598 entries, brake-5:55 to minute_cos\n",
            "dtypes: float32(592), float64(4), int32(2)\n",
            "memory usage: 407.9+ MB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZGHtpoHu5mW"
      },
      "source": [
        "## **DATASET SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjMVD7M5u5F4",
        "outputId": "37f2ad52-8636-4013-de82-4bb9ae605281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((177024, 598), (3644, 598))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dBe9s0_vDHI"
      },
      "outputs": [],
      "source": [
        "Xt = X_train[['hour_sin','hour_cos','minute_sin','minute_cos', 'cluster_pca','PC_1', 'PC_2', 'PC_3',\n",
        "              'enc_04_v7', 'enc_01_v1', 'enc_07_v7', 'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7',\n",
        "              'enc_06_v6', 'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6',\"bg-0:00\", \"insulin_av-0:00\",\n",
        "              \"brake-0:00\",\"intake-0:00\",'steps_av-0:00']]\n",
        "\n",
        "Xtest = X_test[['hour_sin','hour_cos','minute_sin','minute_cos', 'cluster_pca','PC_1', 'PC_2', 'PC_3',\n",
        "                'enc_04_v7', 'enc_01_v1', 'enc_07_v7', 'enc_01_v4', 'enc_05_v4', 'enc_03_v6', 'enc_05_v7',\n",
        "                'enc_06_v6', 'enc_01_v6', 'enc_06_v7', 'enc_08_v6', 'enc_04_v6',\"bg-0:00\", \"insulin_av-0:00\",\n",
        "                \"brake-0:00\",\"intake-0:00\",'steps_av-0:00']]\n",
        "\n",
        "y = X_train[target].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CznH8e__LlBo"
      },
      "source": [
        "## **TREE MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzr1S-lTsX2"
      },
      "source": [
        "#### **FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqjh6floL0ti"
      },
      "outputs": [],
      "source": [
        "def objective_xgb(trial, model_class, X, y, use_gpu=True, sc=target_scaler,n_splits=3,n_repeats=3):\n",
        "\n",
        "    model_class = XGBRegressor\n",
        "\n",
        "    categorical_features = []\n",
        "    cat_bin = ['cluster_pca']\n",
        "    tot_cat = categorical_features + cat_bin\n",
        "    numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "    params = {\n",
        "    'n_estimators': 851, #trial.suggest_int('n_estimators', 100, 400, step=1),\n",
        "    'learning_rate': 0.01, #trial.suggest_loguniform('learning_rate', 0.01, 0.03),\n",
        "    'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 25),\n",
        "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.50, 0.95, step=0.025),\n",
        "    'subsample' :trial.suggest_float('subsample', .50, 0.95, step=0.025),\n",
        "    'reg_lambda' : trial.suggest_float('reg_lambda', 1e-5, 1.0, log = True),\n",
        "    'reg_alpha' :  trial.suggest_float('reg_alpha', 1e-5, 1.0, log = True),\n",
        "    'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
        "    'random_state': 42,\n",
        "    'tree_method': 'gpu_hist' if use_gpu else 'hist'}\n",
        "\n",
        "    # Create the early stopping callback\n",
        "    early_stop = EarlyStopping(rounds=61, metric_name=\"rmse\")\n",
        "\n",
        "    model = model_class(**params, objective='reg:squarederror', eval_metric='rmse', callbacks=[early_stop], enable_categorical=\"True\")\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', ce.TargetEncoder(), categorical_features),\n",
        "            ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,handle_unknown=\"ignore\"), cat_bin),\n",
        "            ('num', StandardScaler(), numeric_features)\n",
        "        ])\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model)], verbose=False)\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for num, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        pipeline[:-1].fit(X_train, y_train)\n",
        "        X_val_ = pipeline[:-1].transform(X_val) # Transform X_val using the same steps as X\n",
        "        eval_set = [(X_val_, y_val)]\n",
        "        fit_params = {'model__eval_set': eval_set, 'model__verbose': False}\n",
        "\n",
        "        # Fit the pipeline with early stopping\n",
        "        pipeline.fit(X_train, y_train, **fit_params)\n",
        "\n",
        "        y_pred = pipeline.predict(X_val)\n",
        "\n",
        "        y_val_ = sc.inverse_transform(y_val)\n",
        "        y_pred_ = sc.inverse_transform(y_pred.reshape(-1, 1))\n",
        "\n",
        "        print(f\"Fold {num} RMSE: {np.sqrt(mean_squared_error(y_val_, y_pred_))}\")\n",
        "        rmse_scores.append(np.sqrt(mean_squared_error(y_val_, y_pred_)))\n",
        "        gc.collect()\n",
        "\n",
        "    return rmse_scores[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMALKP06dZZP"
      },
      "outputs": [],
      "source": [
        "def objective_xgb(trial, model_class, X, y, use_gpu=True, sc=target_scaler,n_splits=3,n_repeats=3):\n",
        "\n",
        "    model_class = XGBRegressor\n",
        "\n",
        "    categorical_features = []\n",
        "    cat_bin = ['cluster_pca']\n",
        "    tot_cat = categorical_features + cat_bin\n",
        "    numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "    params = {\n",
        "    'n_estimators': 501, #trial.suggest_int('n_estimators', 100, 400, step=1),\n",
        "    'learning_rate': 0.01, #trial.suggest_loguniform('learning_rate', 0.01, 0.03),\n",
        "    'max_depth': trial.suggest_int('max_depth', 12, 20),\n",
        "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 12),\n",
        "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.55, 0.975, step=0.025),\n",
        "    'subsample' :trial.suggest_float('subsample', .55, 0.975, step=0.025),\n",
        "    'reg_lambda' : trial.suggest_float('reg_lambda', 1e-5, 1.0, log = True),\n",
        "    'reg_alpha' :  trial.suggest_float('reg_alpha', 1e-5, 1.0, log = True),\n",
        "    'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
        "    'random_state': 42,\n",
        "    'tree_method': 'gpu_hist' if use_gpu else 'hist'}\n",
        "\n",
        "    # Create the early stopping callback\n",
        "    early_stop = EarlyStopping(rounds=61, metric_name=\"rmse\")\n",
        "\n",
        "    model = model_class(**params, objective='reg:squarederror', eval_metric='rmse', enable_categorical=\"True\")\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', ce.TargetEncoder(), categorical_features),\n",
        "            ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,handle_unknown=\"ignore\"), cat_bin),\n",
        "            ('num', StandardScaler(), numeric_features)\n",
        "        ])\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model)], verbose=False)\n",
        "\n",
        "    kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
        "    rmse_scores = []\n",
        "\n",
        "\n",
        "    fit_params = {'verbose': False}\n",
        "    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_root_mean_squared_error', n_jobs=-1, params=fit_params)\n",
        "    gc.collect()\n",
        "\n",
        "    return np.mean(np.abs(cv_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__BW9NxXLtsI"
      },
      "source": [
        "### A - XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaXKMIeZUS48"
      },
      "outputs": [],
      "source": [
        "# Step 3: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, use_gpu, n_splits = 1 ,n_repeats=1):\n",
        "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, model_class, Xt, y, use_gpu=use_gpu, n_splits=n_splits, n_repeats=n_splits), n_trials=n_trials)\n",
        "    return study  # Return the study object\n",
        "\n",
        "# Step 5: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zr26n5uLzUw"
      },
      "source": [
        "#### Optuna Hyperameter Optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRlVkiHgBVJe",
        "outputId": "17dd9c01-8825-4cb9-8795-a25ca1969314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-10-30 22:53:38,880] A new study created in memory with name: no-name-360d927c-f1c8-436e-8de0-092e351fd22b\n",
            "[I 2024-10-30 23:00:18,215] Trial 0 finished with value: 0.47783102922969395 and parameters: {'max_depth': 18, 'min_child_weight': 1, 'colsample_bytree': 0.55, 'subsample': 0.7000000000000001, 'reg_lambda': 0.23164830432062045, 'reg_alpha': 0.00694765739707545, 'gamma': 0.08905614267354793}. Best is trial 0 with value: 0.47783102922969395.\n",
            "[I 2024-10-30 23:03:13,796] Trial 1 finished with value: 0.47676679823133683 and parameters: {'max_depth': 14, 'min_child_weight': 5, 'colsample_bytree': 0.55, 'subsample': 0.875, 'reg_lambda': 0.003372245264215911, 'reg_alpha': 0.0002142866225420383, 'gamma': 2.9072499542044044e-05}. Best is trial 1 with value: 0.47676679823133683.\n",
            "[I 2024-10-30 23:06:01,572] Trial 2 finished with value: 0.4819345573584239 and parameters: {'max_depth': 13, 'min_child_weight': 4, 'colsample_bytree': 0.75, 'subsample': 0.875, 'reg_lambda': 0.000992859915640351, 'reg_alpha': 0.022109394503867025, 'gamma': 0.06162341636}. Best is trial 1 with value: 0.47676679823133683.\n",
            "[I 2024-10-30 23:10:19,092] Trial 3 finished with value: 0.47130776445070904 and parameters: {'max_depth': 15, 'min_child_weight': 5, 'colsample_bytree': 0.875, 'subsample': 0.7000000000000001, 'reg_lambda': 0.0002694134576494196, 'reg_alpha': 0.0005928943697035441, 'gamma': 9.981012745181623e-05}. Best is trial 3 with value: 0.47130776445070904.\n",
            "[I 2024-10-30 23:13:56,378] Trial 4 finished with value: 0.472882608572642 and parameters: {'max_depth': 15, 'min_child_weight': 6, 'colsample_bytree': 0.8250000000000001, 'subsample': 0.75, 'reg_lambda': 0.0010080566480146517, 'reg_alpha': 0.0031028342326852617, 'gamma': 0.11763542692340527}. Best is trial 3 with value: 0.47130776445070904.\n",
            "[I 2024-10-30 23:19:39,868] Trial 5 finished with value: 0.46471144093407524 and parameters: {'max_depth': 17, 'min_child_weight': 6, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.875, 'reg_lambda': 0.5608832235018384, 'reg_alpha': 0.03677217502734549, 'gamma': 0.000792690791461077}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:24:19,677] Trial 6 finished with value: 0.4659464226828681 and parameters: {'max_depth': 16, 'min_child_weight': 6, 'colsample_bytree': 0.625, 'subsample': 0.925, 'reg_lambda': 0.0047327179205384875, 'reg_alpha': 0.06787149625417148, 'gamma': 0.026290624767574915}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:28:14,295] Trial 7 finished with value: 0.46869039204385543 and parameters: {'max_depth': 18, 'min_child_weight': 11, 'colsample_bytree': 0.775, 'subsample': 0.75, 'reg_lambda': 0.005778690087825349, 'reg_alpha': 0.0011233405060173248, 'gamma': 0.021828289793531967}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:30:31,583] Trial 8 finished with value: 0.48231293426619637 and parameters: {'max_depth': 14, 'min_child_weight': 12, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.975, 'reg_lambda': 0.004288985737335825, 'reg_alpha': 8.076488705191069e-05, 'gamma': 0.018882123054853976}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:31:45,456] Trial 9 finished with value: 0.5136848820580376 and parameters: {'max_depth': 12, 'min_child_weight': 8, 'colsample_bytree': 0.55, 'subsample': 0.65, 'reg_lambda': 1.162638067297711e-05, 'reg_alpha': 0.0019112149734357702, 'gamma': 0.3172348232845625}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:36:17,742] Trial 10 finished with value: 0.4746307498878903 and parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.975, 'subsample': 0.55, 'reg_lambda': 0.6527197052153099, 'reg_alpha': 0.6197064351013605, 'gamma': 0.0006571863324685364}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:45:57,305] Trial 11 finished with value: 0.4673741294278039 and parameters: {'max_depth': 17, 'min_child_weight': 2, 'colsample_bytree': 0.675, 'subsample': 0.9000000000000001, 'reg_lambda': 0.059075706839176324, 'reg_alpha': 0.09506287159816774, 'gamma': 0.0022242394488115364}. Best is trial 5 with value: 0.46471144093407524.\n",
            "[I 2024-10-30 23:50:56,480] Trial 12 finished with value: 0.4641599092218611 and parameters: {'max_depth': 17, 'min_child_weight': 8, 'colsample_bytree': 0.675, 'subsample': 0.9500000000000001, 'reg_lambda': 0.034339700263569514, 'reg_alpha': 0.10302467048693201, 'gamma': 0.0007146465272116565}. Best is trial 12 with value: 0.4641599092218611.\n",
            "[I 2024-10-30 23:56:45,381] Trial 13 finished with value: 0.46060025029712254 and parameters: {'max_depth': 20, 'min_child_weight': 10, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.975, 'reg_lambda': 0.05077181773345433, 'reg_alpha': 1.1135652545373137e-05, 'gamma': 0.0002948353535429396}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:02:02,643] Trial 14 finished with value: 0.4670378201537662 and parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.8250000000000001, 'reg_lambda': 0.04150815076537246, 'reg_alpha': 0.7077326070183971, 'gamma': 0.00015326601936515994}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:07:17,498] Trial 15 finished with value: 0.4615412089559767 and parameters: {'max_depth': 19, 'min_child_weight': 10, 'colsample_bytree': 0.65, 'subsample': 0.975, 'reg_lambda': 0.03300658757151572, 'reg_alpha': 1.744424911544904e-05, 'gamma': 2.1186968364036588e-05}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:12:05,694] Trial 16 finished with value: 0.46292797724405926 and parameters: {'max_depth': 19, 'min_child_weight': 11, 'colsample_bytree': 0.625, 'subsample': 0.975, 'reg_lambda': 0.09152196694351829, 'reg_alpha': 1.1605763171955393e-05, 'gamma': 1.191666912018731e-05}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:16:57,144] Trial 17 finished with value: 0.4633820818530189 and parameters: {'max_depth': 19, 'min_child_weight': 10, 'colsample_bytree': 0.75, 'subsample': 0.8250000000000001, 'reg_lambda': 0.017017177696749184, 'reg_alpha': 1.2227222031162863e-05, 'gamma': 8.952870147856777e-05}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:21:42,368] Trial 18 finished with value: 0.46481241782506305 and parameters: {'max_depth': 20, 'min_child_weight': 12, 'colsample_bytree': 0.8500000000000001, 'subsample': 0.8250000000000001, 'reg_lambda': 0.1480136327691492, 'reg_alpha': 4.0481062486673754e-05, 'gamma': 2.729947172081652e-05}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:26:07,663] Trial 19 finished with value: 0.4690775341457791 and parameters: {'max_depth': 19, 'min_child_weight': 8, 'colsample_bytree': 0.8, 'subsample': 0.5750000000000001, 'reg_lambda': 0.014097640309484787, 'reg_alpha': 4.8138180602739915e-05, 'gamma': 0.0002295172678673247}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:31:33,117] Trial 20 finished with value: 0.4661126699712541 and parameters: {'max_depth': 18, 'min_child_weight': 10, 'colsample_bytree': 0.925, 'subsample': 0.925, 'reg_lambda': 2.0970991962898335e-05, 'reg_alpha': 0.0002529882974482169, 'gamma': 0.0022371703399392427}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:36:44,909] Trial 21 finished with value: 0.46230364508099026 and parameters: {'max_depth': 19, 'min_child_weight': 10, 'colsample_bytree': 0.625, 'subsample': 0.975, 'reg_lambda': 0.10658518538638265, 'reg_alpha': 1.0360456124779024e-05, 'gamma': 1.0216076869629948e-05}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:41:52,723] Trial 22 finished with value: 0.46211761236190796 and parameters: {'max_depth': 19, 'min_child_weight': 10, 'colsample_bytree': 0.625, 'subsample': 0.975, 'reg_lambda': 0.01780187565822144, 'reg_alpha': 2.254821248873702e-05, 'gamma': 1.3160236520219643e-05}. Best is trial 13 with value: 0.46060025029712254.\n",
            "[I 2024-10-31 00:48:02,465] Trial 23 finished with value: 0.4604025748040941 and parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.925, 'reg_lambda': 0.012376109100807844, 'reg_alpha': 2.957509681090659e-05, 'gamma': 3.977885964317904e-05}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 00:54:27,223] Trial 24 finished with value: 0.46077630917231244 and parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.7250000000000001, 'subsample': 0.925, 'reg_lambda': 0.0014224746434726475, 'reg_alpha': 0.00011579257943336237, 'gamma': 5.238523323313738e-05}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:02:19,054] Trial 25 finished with value: 0.4609963827662998 and parameters: {'max_depth': 20, 'min_child_weight': 7, 'colsample_bytree': 0.7250000000000001, 'subsample': 0.925, 'reg_lambda': 0.0008938039361067716, 'reg_alpha': 0.00012422656086226195, 'gamma': 5.5831133327817965e-05}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:08:01,990] Trial 26 finished with value: 0.4619835846953922 and parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.775, 'subsample': 0.8, 'reg_lambda': 0.00013547374396856497, 'reg_alpha': 0.0005343334854112165, 'gamma': 0.00029052191402471}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:14:09,346] Trial 27 finished with value: 0.46193278166982865 and parameters: {'max_depth': 18, 'min_child_weight': 7, 'colsample_bytree': 0.7250000000000001, 'subsample': 0.875, 'reg_lambda': 0.00028566297543301995, 'reg_alpha': 3.857279269007136e-05, 'gamma': 0.005421850009329198}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:19:14,167] Trial 28 finished with value: 0.46149962147076923 and parameters: {'max_depth': 20, 'min_child_weight': 11, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.9000000000000001, 'reg_lambda': 0.010037422104731733, 'reg_alpha': 0.00011503227448037387, 'gamma': 4.602181104918848e-05}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:25:17,512] Trial 29 finished with value: 0.46395061744583976 and parameters: {'max_depth': 18, 'min_child_weight': 8, 'colsample_bytree': 0.8, 'subsample': 0.925, 'reg_lambda': 0.29905185073315016, 'reg_alpha': 3.22470826132583e-05, 'gamma': 0.0004312109887976794}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:36:45,287] Trial 30 finished with value: 0.46630722284317017 and parameters: {'max_depth': 16, 'min_child_weight': 1, 'colsample_bytree': 0.7250000000000001, 'subsample': 0.8500000000000001, 'reg_lambda': 0.0021936881688663637, 'reg_alpha': 0.010401172903398611, 'gamma': 0.00010702573540331275}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:44:33,914] Trial 31 finished with value: 0.46099517080518937 and parameters: {'max_depth': 20, 'min_child_weight': 7, 'colsample_bytree': 0.7250000000000001, 'subsample': 0.925, 'reg_lambda': 0.0016926553169274213, 'reg_alpha': 0.0003457363031032708, 'gamma': 5.3829281579540984e-05}. Best is trial 23 with value: 0.4604025748040941.\n",
            "[I 2024-10-31 01:50:35,770] Trial 32 finished with value: 0.4603695107830895 and parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.675, 'subsample': 0.9500000000000001, 'reg_lambda': 0.0023578997094310383, 'reg_alpha': 0.0002511828751854158, 'gamma': 4.804072231366388e-05}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 01:56:13,998] Trial 33 finished with value: 0.46109972728623283 and parameters: {'max_depth': 19, 'min_child_weight': 9, 'colsample_bytree': 0.675, 'subsample': 0.9500000000000001, 'reg_lambda': 0.00039460720519809923, 'reg_alpha': 7.345140555105775e-05, 'gamma': 3.3861682990692295e-05}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 02:01:11,838] Trial 34 finished with value: 0.4618331293265025 and parameters: {'max_depth': 20, 'min_child_weight': 11, 'colsample_bytree': 0.65, 'subsample': 0.9000000000000001, 'reg_lambda': 0.0076813746127865476, 'reg_alpha': 0.00013964435961263033, 'gamma': 0.00015148961331708238}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 02:10:03,995] Trial 35 finished with value: 0.4651622441079881 and parameters: {'max_depth': 18, 'min_child_weight': 4, 'colsample_bytree': 0.5750000000000001, 'subsample': 0.9500000000000001, 'reg_lambda': 0.0001252199352386175, 'reg_alpha': 0.0007600220408143071, 'gamma': 7.52888108383939e-05}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 02:15:24,282] Trial 36 finished with value: 0.4621315466033088 and parameters: {'max_depth': 19, 'min_child_weight': 9, 'colsample_bytree': 0.75, 'subsample': 0.8500000000000001, 'reg_lambda': 0.0006410826729085303, 'reg_alpha': 0.00018417233778189723, 'gamma': 0.00028340728420526355}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 02:20:37,109] Trial 37 finished with value: 0.4630043970213996 and parameters: {'max_depth': 20, 'min_child_weight': 8, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.7000000000000001, 'reg_lambda': 0.00205568254076639, 'reg_alpha': 6.610512656417435e-05, 'gamma': 2.038271427357088e-05}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 02:27:06,225] Trial 38 finished with value: 0.46292394068506026 and parameters: {'max_depth': 17, 'min_child_weight': 5, 'colsample_bytree': 0.65, 'subsample': 0.9000000000000001, 'reg_lambda': 0.003082597500566277, 'reg_alpha': 0.006980190969576756, 'gamma': 0.00015745406268774994}. Best is trial 32 with value: 0.4603695107830895.\n",
            "[I 2024-10-31 02:29:22,133] Trial 39 finished with value: 0.48819306161668563 and parameters: {'max_depth': 14, 'min_child_weight': 12, 'colsample_bytree': 0.775, 'subsample': 0.775, 'reg_lambda': 0.20518613299508887, 'reg_alpha': 2.119884716696185e-05, 'gamma': 0.0009790651493129512}. Best is trial 32 with value: 0.4603695107830895.\n"
          ]
        }
      ],
      "source": [
        "# usage with XGBRegressor\n",
        "xgb_study = tune_hyperparameters(Xt, y, XGBRegressor, n_trials=51, use_gpu=False, n_splits = 3 ,n_repeats=3)\n",
        "save_results(xgb_study, XGBRegressor, \"XGBoost\")\n",
        "xgb_params = xgb_study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.675, 'subsample': 0.9500000000000001, 'reg_lambda': 0.0023578997094310383, 'reg_alpha': 0.0002511828751854158, 'gamma': 4.804072231366388e-05}. Best is trial 32 with value: 0.4603695107830895.\n",
        "\n",
        "parameters: {'max_depth': 20, 'min_child_weight': 9, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.925, 'reg_lambda': 0.012376109100807844, 'reg_alpha': 2.957509681090659e-05, 'gamma': 3.977885964317904e-05}. Best is trial 23 with value: 0.4604025748040941."
      ],
      "metadata": {
        "id": "8j12tjd4bgtY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okwvIJ8XDD6X"
      },
      "outputs": [],
      "source": [
        "print(xgb_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwkDZqOJZ05p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}