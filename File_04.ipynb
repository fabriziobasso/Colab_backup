{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2OXnmlVm3NO2G4Ab/ep8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/File_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<h1 align=\"center\"><font color='#DD4141'> S4E9 Regression of Used Car Prices**</font></h1>"
      ],
      "metadata": {
        "id": "Cz7xIYxxxiWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CNyTd31_Zz3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:#\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install category-encoders\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "!pip install scikit-learn==1.4\n",
        "!pip install catboost\n",
        "\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install keras-nlp\n",
        "!pip install BorutaShap\n",
        "!pip install scikit-lego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7mobEcm-SOt"
      },
      "outputs": [],
      "source": [
        "folder_script = models_folders = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S4E9_Cars\"\n",
        "os.chdir(folder_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87aeab45-bd08-4934-ae52-cf33027438f1"
      },
      "outputs": [],
      "source": [
        "# Setup feedback system\n",
        "#from learntools.core import binder\n",
        "#binder.bind(globals())\n",
        "#from learntools.time_series.ex6 import *\n",
        "\n",
        "# Setup notebook\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "import json\n",
        "import joblib\n",
        "#import calplot as cal\n",
        "\n",
        "# Graphic Libraries:\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "# Set Style\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5});\n",
        "sns.despine(left=True, bottom=True, top=False, right=False);\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "mpl.rc('axes', labelsize=12);\n",
        "plt.rc('xtick',labelsize=10);\n",
        "plt.rc('ytick',labelsize=10);\n",
        "\n",
        "mpl.rcParams['axes.spines.top'] = False;\n",
        "mpl.rcParams['axes.spines.right'] = False;\n",
        "mpl.rcParams['axes.spines.left'] = True;\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "# tool for Excel:\n",
        "from openpyxl import load_workbook, Workbook\n",
        "from openpyxl.drawing.image import Image\n",
        "from openpyxl.styles import Border, Side, PatternFill, Font, GradientFill, Alignment\n",
        "from openpyxl.worksheet.cell_range import CellRange\n",
        "\n",
        "from openpyxl.formatting import Rule\n",
        "from openpyxl.styles import Font, PatternFill, Border\n",
        "from openpyxl.styles.differential import DifferentialStyle\n",
        "\n",
        "# Bloomberg\n",
        "#from xbbg import blp\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "# Time Management\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BMonthEnd, QuarterEnd\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay # BDay is business day, not birthday...\n",
        "import datetime as dt\n",
        "import click\n",
        "import glob\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import string\n",
        "\n",
        "from ipywidgets import AppLayout\n",
        "from ipywidgets import Dropdown, Layout, HTML, AppLayout, VBox, Label, HBox, BoundedFloatText, interact, Output\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "\n",
        "from keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "\n",
        "from keras.utils import FeatureSpace, plot_model\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate, GroupKFold, GridSearchCV, RepeatedStratifiedKFold, cross_val_predict\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "# metrics\n",
        "import sklearn\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             root_mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss,\n",
        "                             make_scorer)\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  HuberRegressor,\n",
        "                                  TweedieRegressor,\n",
        "                                  QuantileRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  TheilSenRegressor,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              AdaBoostClassifier,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              HistGradientBoostingRegressor,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "import scipy.stats as ss\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqoneKos-SCn"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "print(xgboost.__version__)\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56ff77a1-0ac3-4b08-a017-e41e25805efe"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "# Setting rc parameters in seaborn for plots and graphs-\n",
        "# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n",
        "# To alter this, refer to matplotlib.rcParams.keys()\n",
        "\n",
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.75,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : 'black',\n",
        "         'axes.titlesize'       : 12,\n",
        "         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "pd.set_option('display.max_columns', 100);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "#sns.set_theme(style=\"ticks\", context=\"notebook\")\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_categorical_columns(df):\n",
        "    # Select only categorical columns\n",
        "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Loop through each categorical column and plot\n",
        "    for col in categorical_columns:\n",
        "        if len(set(df[col]))<150:\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            sns.countplot(y=df[col], palette=palette_9, order=df[col].value_counts().index)\n",
        "            plt.title(f'Distribution of {col}')\n",
        "            plt.xlabel('Count')\n",
        "            plt.ylabel(col)\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "ft8VGLRRQ74a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_categorical_columns(df_train)"
      ],
      "metadata": {
        "id": "Lb0DMFfTWLgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DL_M5KKx2nO"
      },
      "source": [
        "<div style=\"border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: white; font-size:100%; text-align:left\">\n",
        "\n",
        "**<h3 align=\"center\"><font color='#3455eb'> Used Cars Regression :</font></h3>**\n",
        "\n",
        "<div style=\"border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: white; font-size:100%; text-align:left\">\n",
        "\n",
        "<h3 align=\"center\"><font color='#3455eb'> About The Competition :</font></h3>\n",
        "    \n",
        "**Task**: To develop a model that can predict the prices of used cars based on a set of parameters relative to the cars. It is a **regression task**.\n",
        "\n",
        "**Dataset**: Training Dataset (train.csv): Contains features along with the target variable, indicating the car price.Test Dataset (test.csv): Contains the features but requires predictions for the price.\n",
        "\n",
        "Additional Information:\n",
        "    \n",
        "**Evaluation**: The performance of the model is evaluated using the RMSE. This metric penalizes the outliers prices.\n",
        "\n",
        "The dataset was generated from a deep learning model trained on the Used Car Price Prediction [Link]()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5NjoRTdyVHe"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fiLvkXQuzJ3"
      },
      "outputs": [],
      "source": [
        "df_sub=pd.read_csv(\"sample_submission.csv\",na_values=[\"–\", \"not supported\"])\n",
        "df_train=pd.read_csv(\"train.csv\",na_values=[\"–\", \"not supported\"])\n",
        "df_test=pd.read_csv(\"test.csv\",na_values=[\"–\", \"not supported\"])\n",
        "\n",
        "\n",
        "df_old=pd.read_csv(\"used_cars.csv\",na_values=[\"–\", \"not supported\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmdZWMKeyjMw"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An_acX5RXTxI"
      },
      "outputs": [],
      "source": [
        "df_old[['milage', 'price']] = df_old[['milage', 'price']].map(lambda x: int(''.join(re.findall(r'\\d+', x))))\n",
        "df_old[['milage', 'price']] = df_old[['milage', 'price']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHFaYxYaXHft"
      },
      "outputs": [],
      "source": [
        "df_old.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UPLOAD DATASET"
      ],
      "metadata": {
        "id": "f-YC7s3KkYf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ext= pd.read_csv(\"train_extended_ext_final_no_outliers.csv\")\n",
        "df_test_ext = pd.read_csv(\"test_extended_ext_final_no_outliers.csv\")\n",
        "\n",
        "df_test_ext[\"skew\"] = df_test_ext[\"skew\"].fillna(0)\n",
        "df_test_ext.index = df_test.id.values\n",
        "\n",
        "#df_train_ext= pd.read_csv(\"train_extended_ext_final_outliers.csv\")\n",
        "#df_test_ext = pd.read_csv(\"test_extended_ext_final_outliers.csv\")\n",
        "\n",
        "cols_to_drop = [\"skew\",\"Dummy_BLK\",\"Dummy_Nero\",\"Dummy_Poor_color\",\"Dummy_RED\",\"Dummy_mult\",\"Dummy_grey\",\"int_col_nan\"]\n",
        "df_train_ext = df_train_ext.drop(columns=cols_to_drop)\n",
        "df_test_ext = df_test_ext.drop(columns=cols_to_drop)\n",
        "\n",
        "df_test_ext.shape"
      ],
      "metadata": {
        "id": "4myDh33u5XwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bacpmm5VC7Kw"
      },
      "source": [
        "## Review: Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypuIXiLREm7A"
      },
      "source": [
        "Remove all the models and Brands that are not in the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ChcsK0C6Cq"
      },
      "outputs": [],
      "source": [
        "to_remove = list(set(df_train_ext.model.unique()) - set(df_test.model.unique()))\n",
        "print(to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4Zbc6gXP6fP"
      },
      "outputs": [],
      "source": [
        "for rem in to_remove:\n",
        "    index_rem = df_train_ext[df_train_ext.model==rem].index\n",
        "    df_train_ext = df_train_ext.drop(index_rem, axis=0)\n",
        "\n",
        "df_train_ext.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6cIES5NFQdU"
      },
      "outputs": [],
      "source": [
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ext.info()"
      ],
      "metadata": {
        "id": "T9W6_qXOrLM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTVer1dNWuN_"
      },
      "outputs": [],
      "source": [
        "cat_col = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', \"age\", \"clean_title\",\"turbo\", \"num_cylinders\",\"accident\",\"horsepower\"]\n",
        "\n",
        "# Target Encoder for XGBRegressor\n",
        "train_data_encoded = df_train_ext.copy()\n",
        "test_data_encoded = df_test_ext.copy()\n",
        "\n",
        "target_encoder = ce.TargetEncoder(cols=cat_col)\n",
        "train_data_encoded[cat_col] = target_encoder.fit_transform(train_data_encoded[cat_col], train_data_encoded[\"price\"])\n",
        "test_data_encoded[cat_col] = target_encoder.transform(test_data_encoded[cat_col])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Compute the correlation matrix\n",
        "correlation_matrix = train_data_encoded[train_data_encoded.select_dtypes([\"float\",\"int\"]).columns].corr()\n",
        "target_correlation = correlation_matrix['price']\n",
        "print(target_correlation)"
      ],
      "metadata": {
        "id": "xQvgAhV-VnCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ext.columns"
      ],
      "metadata": {
        "id": "FgIIVpMBTeiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZT19n7WTX-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVvAyacvduiN"
      },
      "outputs": [],
      "source": [
        "df_train_ext.describe(exclude=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5t8tyZia6Oh"
      },
      "outputs": [],
      "source": [
        "#train_data_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjW3WTrqa6Oi"
      },
      "outputs": [],
      "source": [
        "del train_data_encoded,correlation_matrix\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKeN97_7a6Oi"
      },
      "outputs": [],
      "source": [
        "#df_train_ext[['accident', 'clean_title',\"luxury_brand\",\"premium_brand\",\"turbo\"]].describe(include =\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train_ext.head(3)"
      ],
      "metadata": {
        "id": "lD5K39u_sDuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_test_ext.head(3)"
      ],
      "metadata": {
        "id": "sH5hdSHNsHkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKUM5Pe6a6Oj"
      },
      "source": [
        "## Tree Models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKOdX4QAa6Oj"
      },
      "source": [
        "### **Hyperparameter Tuning- Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train_ext.head()"
      ],
      "metadata": {
        "id": "qfm54J1puYVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otCgbBUva6Ok"
      },
      "outputs": [],
      "source": [
        "# Step 1: Data Preparation\n",
        "y = df_train_ext['price']\n",
        "X = df_train_ext.drop(columns=['price'])\n",
        "\n",
        "use_gpu = True  # Set to False if you want to use CPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[X.select_dtypes(include=['object']).columns]=X[X.select_dtypes(include=['object']).columns].astype(\"category\")\n",
        "df_test_ext[df_test_ext.select_dtypes(include=['object']).columns]=df_test_ext[df_test_ext.select_dtypes(include=['object']).columns].astype(\"category\")\n",
        "#X.info();df_test_ext.info()"
      ],
      "metadata": {
        "id": "b1QibEnJCpbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X.info()"
      ],
      "metadata": {
        "id": "fiSdlbu8_FOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['brand', 'model','horsepower','age','num_cylinders']\n",
        "cat_bin = [ \"turbo\",'fuel_type', 'transmission', 'ext_col', 'int_col', \"clean_title\", \"accident\"]\n",
        "#categorical_features_2 = ['clean_title'\n",
        "tot_cat = categorical_features + cat_bin"
      ],
      "metadata": {
        "id": "17lB-FbzuPyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSHHrLX9a6Ok"
      },
      "outputs": [],
      "source": [
        "# Step 2: Objective Function for Optuna\n",
        "def objective(trial, model_class, X, y, use_gpu=False):\n",
        "\n",
        "    categorical_features = ['brand', 'model','horsepower','age','num_cylinders']\n",
        "    cat_bin = [ \"turbo\",'fuel_type', 'transmission', 'ext_col', 'int_col', \"clean_title\", \"accident\"]\n",
        "    tot_cat = categorical_features + cat_bin\n",
        "    numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "#{'max_depth': 15, 'min_child_weight': 26, 'colsample_bytree': 0.35, 'subsample': 0.725, 'reg_lambda': 0.010582018457700314, 'reg_alpha': 0.002394780534514407}\n",
        "    if model_class == XGBRegressor:\n",
        "        params = {\n",
        "            'n_estimators': 851, #trial.suggest_int('n_estimators', 100, 400, step=1),\n",
        "            'learning_rate': 0.01, #trial.suggest_loguniform('learning_rate', 0.01, 0.03),\n",
        "            'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 20, 35),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.30, 0.80, step=0.025),\n",
        "            'subsample' :trial.suggest_float('subsample', .55, 0.90, step=0.025),\n",
        "            'reg_lambda' : trial.suggest_float('reg_lambda', 1e-3, 1.0, log = True),\n",
        "            'reg_alpha' :  trial.suggest_float('reg_alpha', 1e-3, 1.0, log = True),\n",
        "            'random_state': 42,\n",
        "            'tree_method': 'gpu_hist' if use_gpu else 'hist'\n",
        "        }\n",
        "\n",
        "        # Create the early stopping callback\n",
        "        early_stop = EarlyStopping(rounds=61, metric_name=\"rmse\")\n",
        "\n",
        "        model = model_class(**params, objective='reg:squarederror',callbacks=[early_stop], enable_categorical=\"True\")\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,handle_unknown=\"ignore\"), cat_bin),\n",
        "                ('num', 'passthrough', numeric_features)\n",
        "            ])\n",
        "\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model)\n",
        "        ], verbose=False)\n",
        "\n",
        "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        rmse_scores = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X, X[\"brand\"]):\n",
        "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            pipeline[:-1].fit(X_train, y_train)\n",
        "            X_val_ = pipeline[:-1].transform(X_val) # Transform X_val using the same steps as X\n",
        "            eval_set = [(X_val_, y_val)]\n",
        "            fit_params = {'model__eval_set': eval_set}\n",
        "\n",
        "            # Fit the pipeline with early stopping\n",
        "            pipeline.fit(X_train, y_train, **fit_params)\n",
        "\n",
        "            y_pred = pipeline.predict(X_val)\n",
        "            rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
        "\n",
        "        return np.mean(rmse_scores)\n",
        "\n",
        "    elif model_class == LGBMRegressor:\n",
        "#{'reg_alpha': 0.049314275998236345, 'reg_lambda': 9.876122564091135, 'max_depth': 5, 'colsample_bytree': 0.3, 'subsample': 0.5}\n",
        "        params = {\n",
        "        #'num_leaves':         trial.suggest_int('num_leaves', 100, 111, step=1),\n",
        "        'n_estimators': 1000, #trial.suggest_int('n_estimators', 250, 800),\n",
        "        'learning_rate':      0.015, #trial.suggest_loguniform('learning_rate', 0.01, 0.03),\n",
        "        #'min_child_samples':  trial.suggest_int('min_child_samples', 60, 70, step=1),\n",
        "        #'min_child_weight' :  trial.suggest_float(\"min_child_weight\", 1e-2, 0.1, log=True),\n",
        "        \"reg_alpha\" :         trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
        "        \"reg_lambda\" :        trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"max_depth\" :         trial.suggest_int('max_depth', 5, 25, step=1),\n",
        "        #'bagging_freq' :      trial.suggest_int('bagging_freq', 3, 9),\n",
        "        #'max_bin' :           trial.suggest_int('max_bin', 401, 501, step=5),\n",
        "        'colsample_bytree':   trial.suggest_float(\"colsample_bytree\", 0.30, 1.0, step=0.05),\n",
        "        'subsample':          trial.suggest_float(\"subsample\", 0.3, 1.00, step=0.025),\n",
        "        #\"learning_rate\" :     0.01,\n",
        "        'random_state':       42,\n",
        "        'force_col_wise':     True,\n",
        "        'device':             \"cpu\"\n",
        "        }\n",
        "\n",
        "        #if params[\"bagging_freq\"]>0:\n",
        "        #    params['bagging_fraction'] =  trial.suggest_float(\"bagging_fraction\", 0.75, 0.85, step=0.01)\n",
        "\n",
        "        model = model_class(**params, objective='regression')\n",
        "        # Use CPU to avoid GPU issues\n",
        "#         if use_gpu:\n",
        "#             model.set_params(device='cpu')\n",
        "\n",
        "        pipeline = Pipeline([('model', model)])\n",
        "\n",
        "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        rmse_scores = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X, X[\"brand\"]):\n",
        "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            pipeline.fit(X_train, y_train)\n",
        "            y_pred = pipeline.predict(X_val)\n",
        "            rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
        "\n",
        "        return np.mean(rmse_scores)\n",
        "\n",
        "    elif model_class == CatBoostRegressor:\n",
        "        params = {\n",
        "            'loss_function':       'RMSE',\n",
        "            'eval_metric':         'RMSE',\n",
        "            'bootstrap_type':      'Bernoulli',\n",
        "            'iterations':           4000, #: trial.suggest_int('iterations', 500, 4000),\n",
        "            'learning_rate':         0.015, #: trial.suggest_loguniform('learning_rate', 0.01, 0.03),\n",
        "            'depth'                 : trial.suggest_int('depth', 10, 16),\n",
        "            'l2_leaf_reg'           : trial.suggest_float(\"l2_leaf_reg\", 0.1, 10.0, log=True),\n",
        "            #\"bagging_temperature\"   : trial.suggest_float('bagging_temperature', 1, 10),\n",
        "             'subsample'             : trial.suggest_float(\"subsample\", 0.7, 1.0, step=0.025),\n",
        "            'random_seed': 42,\n",
        "            'task_type': 'GPU' if use_gpu else 'CPU'\n",
        "        }\n",
        "\n",
        "        model = model_class(**params, verbose=0)\n",
        "\n",
        "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        rmse_scores = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X, X[\"brand\"]):\n",
        "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            train_pool = Pool(X_train, y_train, cat_features=tot_cat)\n",
        "            val_pool = Pool(X_val, y_val, cat_features=tot_cat)\n",
        "\n",
        "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=200, verbose=0)\n",
        "            y_pred = model.predict(val_pool)\n",
        "            rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
        "\n",
        "        return np.mean(rmse_scores)\n",
        "\n",
        "    elif model_class == PoissonRegressor:\n",
        "\n",
        "        params = {\n",
        "            'max_iter':             1000,\n",
        "            'alpha':                trial.suggest_float(\"alpha\", 0.001, 10.0, log=True),\n",
        "                  }\n",
        "\n",
        "        model = model_class(**params)\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,handle_unknown=\"ignore\"), cat_bin),\n",
        "                ('num', 'passthrough', numeric_features)\n",
        "            ])\n",
        "\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model)\n",
        "        ], verbose=False)\n",
        "\n",
        "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        rmse_scores = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X, X[\"brand\"]):\n",
        "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            # Fit the pipeline with early stopping\n",
        "            pipeline.fit(X_train, y_train)\n",
        "\n",
        "            y_pred = pipeline.predict(X_val)\n",
        "            rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
        "\n",
        "        return np.mean(rmse_scores)\n",
        "\n",
        "\n",
        "# Step 3: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, use_gpu):\n",
        "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
        "    study.optimize(lambda trial: objective(trial, model_class, X, y, use_gpu=use_gpu), n_trials=n_trials)\n",
        "    numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "    return study  # Return the study object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYI1sDWNa6Ol"
      },
      "outputs": [],
      "source": [
        "# Step 4: Training and Evaluation\n",
        "def train_and_evaluate(model_class, params, X, y, use_gpu, X_val=None, y_val=None, es=51):\n",
        "    categorical_features = ['brand', 'model','horsepower','age','num_cylinders']\n",
        "    cat_bin = [ \"turbo\",'fuel_type', 'transmission', 'ext_col', 'int_col', \"clean_title\", \"accident\"]\n",
        "\n",
        "    tot_cat = categorical_features + cat_bin\n",
        "    numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "    if model_class == XGBRegressor:\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,handle_unknown=\"ignore\"), cat_bin),\n",
        "                ('num', 'passthrough', numeric_features)\n",
        "            ])\n",
        "\n",
        "\n",
        "        # Create the early stopping callback\n",
        "        early_stop = EarlyStopping(rounds=es, metric_name=\"rmse\")\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model_class(**params, objective='reg:squarederror', tree_method='gpu_hist' if use_gpu else 'auto',\n",
        "                                  callbacks=[early_stop], enable_categorical=\"True\",verbosity=0))\n",
        "        ])\n",
        "\n",
        "        # Prepare your eval_set for early stopping\n",
        "        pipeline[:-1].fit(X, y)\n",
        "        X_val_ = pipeline[:-1].transform(X_val) # Transform X_val using the same steps as X\n",
        "        eval_set = [(X_val_, y_val)]\n",
        "\n",
        "        # Define the fit parameters with the double underscore notation\n",
        "        fit_params = {\n",
        "            'model__eval_set': eval_set\n",
        "            }\n",
        "\n",
        "        pipeline.fit(X, y, **fit_params)\n",
        "        y_pred = pipeline.predict(X)\n",
        "\n",
        "    elif model_class == LGBMRegressor:\n",
        "#         # Set to CPU if GPU usage is specified\n",
        "#         if use_gpu:\n",
        "#             params['device'] = 'cpu'\n",
        "        if X_val is None and y_val is None:\n",
        "          model = model_class(**params, objective='regression', verbose=-1)\n",
        "          pipeline = Pipeline([('model',model)])\n",
        "          pipeline.fit(X, y)\n",
        "          y_pred = pipeline.predict(X)\n",
        "        else:\n",
        "          model = model_class(**params, objective='regression', verbose=-1)\n",
        "          model.fit(X, y, eval_set=(X_val, y_val), callbacks=[early_stopping(stopping_rounds=es)])\n",
        "          y_pred = model.predict(X)\n",
        "\n",
        "    elif model_class == CatBoostRegressor:\n",
        "        train_pool = Pool(X, y, cat_features=tot_cat)\n",
        "        val_pool = Pool(X_val, y_val, cat_features=tot_cat)\n",
        "\n",
        "        # Use GPU or CPU based on the flag\n",
        "        params['task_type'] = 'GPU' if use_gpu else 'CPU'\n",
        "        params['loss_function']='RMSE'\n",
        "        params['eval_metric']='RMSE'\n",
        "        params['bootstrap_type']='Bernoulli'\n",
        "        params['iterations']=4000\n",
        "        params['learning_rate']=0.015\n",
        "\n",
        "        model = model_class(**params, verbose=0)\n",
        "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=es)  # Apply early stopping\n",
        "        y_pred = model.predict(train_pool)\n",
        "\n",
        "    elif model_class == PoissonRegressor:\n",
        "        preprocessor = ColumnTransformer(\n",
        "                                          transformers=[\n",
        "                                              ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                                              ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,\n",
        "                                                                        handle_unknown=\"ignore\"), cat_bin),\n",
        "                                              ('num', 'passthrough', numeric_features)\n",
        "                                          ])\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model_class(**params))])\n",
        "\n",
        "\n",
        "        pipeline.fit(X, y)\n",
        "        y_pred = pipeline.predict(X)\n",
        "\n",
        "    elif model_class == GammaRegressor:\n",
        "        preprocessor = ColumnTransformer(\n",
        "                                          transformers=[\n",
        "                                              ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                                              ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,\n",
        "                                                                        handle_unknown=\"ignore\"), cat_bin),\n",
        "                                              ('num', 'passthrough', numeric_features)\n",
        "                                          ])\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model_class(**params))])\n",
        "\n",
        "\n",
        "        pipeline.fit(X, y)\n",
        "        y_pred = pipeline.predict(X)\n",
        "\n",
        "    elif model_class == TheilSenRegressor:\n",
        "        categorical_features = ['brand', 'model','horsepower','age','num_cylinders']\n",
        "        cat_bin = [ \"turbo\",'fuel_type', 'transmission', 'ext_col', 'int_col', \"clean_title\", \"accident\"]\n",
        "        tot_cat = categorical_features + cat_bin\n",
        "        numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "                                          transformers=[\n",
        "                                              ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                                              ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,\n",
        "                                                                        handle_unknown=\"ignore\"), cat_bin),\n",
        "                                              ('num', 'passthrough', numeric_features)\n",
        "                                          ])\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model_class(**params))])\n",
        "\n",
        "\n",
        "        pipeline.fit(X, y)\n",
        "        y_pred = pipeline.predict(X)\n",
        "\n",
        "    elif model_class == QuantileRegressor:\n",
        "        categorical_features = ['brand', 'model','horsepower','age','num_cylinders']\n",
        "        cat_bin = [ \"turbo\",'fuel_type', 'transmission', 'ext_col', 'int_col', \"clean_title\", \"accident\"]\n",
        "        tot_cat = categorical_features + cat_bin\n",
        "        numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "                                          transformers=[\n",
        "                                              ('cat', ce.TargetEncoder(), categorical_features),\n",
        "                                              ('cat_bin', OneHotEncoder(drop=\"first\",sparse_output=False,\n",
        "                                                                        handle_unknown=\"ignore\"), cat_bin),\n",
        "                                              ('num', 'passthrough', numeric_features)\n",
        "                                          ])\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model_class(**params))])\n",
        "\n",
        "\n",
        "        pipeline.fit(X, y)\n",
        "        y_pred = pipeline.predict(X)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "    print(f'RMSE on train data for {model_class.__name__}: {rmse}')\n",
        "\n",
        "    if model_class == CatBoostRegressor or model_class == LGBMRegressor:\n",
        "        return model  # Return the trained CatBoost model directly\n",
        "    else:\n",
        "        return pipeline  # Return the pipeline for other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdPs9SEha6Ol"
      },
      "outputs": [],
      "source": [
        "# Step 5: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost"
      ],
      "metadata": {
        "id": "v-RIdeCx34aL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6DIpjVBa6Om"
      },
      "outputs": [],
      "source": [
        "# usage with XGBRegressor\n",
        "xgb_study = tune_hyperparameters(X, y, XGBRegressor, n_trials=101, use_gpu=use_gpu)\n",
        "save_results(xgb_study, XGBRegressor, \"XGBoost\")\n",
        "xgb_params = xgb_study.best_params  # Extract best parameters\n",
        "#xgb_model = train_and_evaluate(XGBRegressor, xgb_params, X, y, use_gpu)\n",
        "#xgb_preds_ = xgb_model.predict(df_test_ext)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* {'max_depth': 29, 'min_child_weight': 5, 'colsample_bytree': 0.825, 'subsample': 0.925, 'reg_lambda': 0.07804926714639399, 'reg_alpha': 0.39224544026611263}. Best is trial 17 with value: 38839.10463443243.\n",
        "\n",
        "* **{'max_depth': 29, 'min_child_weight': 5, 'colsample_bytree': 0.85, 'subsample': 0.95, 'reg_lambda': 0.12276300120266487, 'reg_alpha': 0.12047181544967944}. Best is trial 25 with value: 38782.7465219681.**\n",
        "\n",
        "* {'max_depth': 28, 'min_child_weight': 5, 'colsample_bytree': 0.775, 'subsample': 0.9, 'reg_lambda': 0.11712195989066673, 'reg_alpha': 0.8788652828669352} Score: 39050.20411068065\n",
        "\n",
        "* {'max_depth': 29, 'min_child_weight': 5, 'colsample_bytree': 0.975, 'subsample': 0.825, 'reg_lambda': 0.006339328665482851, 'reg_alpha': 0.0536613112277456}. Best is trial 14 with value: 39050.21201562656.\n",
        "\n",
        "**INCLUDING OUTLIERS**\n",
        "\n",
        "- 1 RESULTS:\n",
        "    - MSE: 73002.22233658335\n",
        "    - Best hyperparameters: {'max_depth': 11, 'min_child_weight': 20, 'colsample_bytree': 0.5, 'subsample': 0.65, 'reg_lambda': 0.15991951720673386, 'reg_alpha': 0.03897467582642847}\n",
        "\n",
        "- 2 RESULTS:\n",
        "  - MSE: 72976.56952626754\n",
        "  - Best hyperparameters: {'max_depth': 20, 'min_child_weight': 29, 'colsample_bytree': 0.425, 'subsample': 0.325, 'reg_lambda': 0.10853520311330123, 'reg_alpha': 1.8035136371987968}\n",
        "\n",
        "**New Dataset NO Outliers**\n",
        "\n",
        "- 1 RESULTS:\n",
        "  - MSE: 46661.78083566207\n",
        "  - Best hyperparameters: {'max_depth': 15, 'min_child_weight': 26, 'colsample_bytree': 0.35, 'subsample': 0.725, 'reg_lambda': 0.010582018457700314, 'reg_alpha': 0.002394780534514407}"
      ],
      "metadata": {
        "id": "0B7GiegjKzh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Diagnostic:"
      ],
      "metadata": {
        "id": "kZTsDxnEEJa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trial = xgb_study.best_trial\n",
        "print('MSE: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "jw6q7Z2YEI5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh8aU2OYdIl0"
      },
      "outputs": [],
      "source": [
        "fig = optuna.visualization.plot_optimization_history(xgb_study)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KJQW0YNdIl1"
      },
      "outputs": [],
      "source": [
        "fig = optuna.visualization.plot_param_importances(xgb_study)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del xgb_study, xgb_model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "WOJu0D1UEPfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "3UueBLsCEQgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BufMbRSZa6Om"
      },
      "outputs": [],
      "source": [
        "xgb_params = {'n_estimators': 1200, 'learning_rate': 0.01,\n",
        "              'max_depth': 15, 'min_child_weight': 26, 'colsample_bytree': 0.35, 'subsample': 0.725,\n",
        "              'reg_lambda': 0.010582018457700314, 'reg_alpha': 0.002394780534514407}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "oof_pred_xgb = np.zeros(len(X))\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    xgb_model = train_and_evaluate(XGBRegressor, xgb_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val, es=61)\n",
        "    xgb_preds = xgb_model.predict(X_val)\n",
        "\n",
        "    oof_pred_xgb[val_index] = xgb_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, xgb_preds))\n",
        "    print(f'RMSE on validation data for XGBoost: {rmse}')\n",
        "\n",
        "    test_results[i] = xgb_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"XGBoost_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(valid_scores)\n",
        "valid_scores.RMSE.mean()"
      ],
      "metadata": {
        "id": "PWCuCZ8X_RA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_xgb_preds = pd.DataFrame(oof_pred_xgb, columns=[\"oof_xgb\"])\n",
        "df_xgb_preds.to_csv(\"oof/oof_xgb_preds_v10_no_outliers.csv\", index=False)\n",
        "df_xgb_preds.head()"
      ],
      "metadata": {
        "id": "ZEQsy1TqDZBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### XGBoost Forecast"
      ],
      "metadata": {
        "id": "QJvRbyN831Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_results[\"all_sample\"] = xgb_preds_\n",
        "\n",
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(10)"
      ],
      "metadata": {
        "id": "HJof_YlKvgkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "yJG4JilLxY4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_xgb_v10_no_outliers.csv\", index=False)"
      ],
      "metadata": {
        "id": "nfPjjHLV4MOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import auth\n",
        "# import google.auth\n",
        "# from googleapiclient.discovery import build\n",
        "# from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# from email.mime.text import MIMEText\n",
        "# from email.mime.multipart import MIMEMultipart\n",
        "# from email.mime.base import MIMEBase\n",
        "# from email import encoders\n",
        "\n",
        "# import base64\n",
        "# import mimetypes\n",
        "\n",
        "# # 1. Authenticate and get credentials\n",
        "# auth.authenticate_user()\n",
        "# creds, _ = google.auth.default()\n",
        "\n",
        "# # 2. Build the Gmail API service\n",
        "# service = build('gmail', 'v1', credentials=creds)\n",
        "\n",
        "# # 3. Compose the email\n",
        "# email_msg = MIMEMultipart()\n",
        "# email_msg['to'] = 'fabrizio.basso@invesco.com'\n",
        "# email_msg['subject'] = 'Car File'\n",
        "# email_msg.attach(MIMEText('Email body', 'plain'))\n",
        "\n",
        "# # 4. Attach the file from Google Drive\n",
        "# #file_id = 'YOUR_FILE_ID_FROM_GOOGLE_DRIVE' # Replace with the actual file ID\n",
        "# file_name = 'submission_xgb_v8_outliers.csv' # Replace with the actual file name\n",
        "# mime_type, _ = mimetypes.guess_type(file_name)\n",
        "\n",
        "# media = MediaFileUpload(f'/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S4E9_Cars/submissions/{file_name}', mimetype=mime_type)\n",
        "# attachment = MIMEBase('application', 'octet-stream')\n",
        "# attachment.set_payload(media.getbytes(0, media.size()))\n",
        "# encoders.encode_base64(attachment)\n",
        "# attachment.add_header('Content-Disposition', 'attachment', filename=file_name)\n",
        "# email_msg.attach(attachment)\n",
        "\n",
        "# # 5. Encode the email\n",
        "# encoded_message = base64.urlsafe_b64encode(email_msg.as_bytes()).decode()\n",
        "\n",
        "# # 6. Send the email\n",
        "# create_message = {'raw': encoded_message}\n",
        "# send_message = (service.users().messages().send(userId=\"me\", body=create_message).execute())\n",
        "\n",
        "# print(f'Message Id: {send_message[\"id\"]}')"
      ],
      "metadata": {
        "id": "mcSMn7q1RJU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LGBMRegressor**"
      ],
      "metadata": {
        "id": "rjXtqbJ1Sunl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[X.select_dtypes(include=['object']).columns]=X[X.select_dtypes(include=['object']).columns].astype(\"category\")\n",
        "df_test_ext[df_test_ext.select_dtypes(include=['object']).columns]=df_test_ext[df_test_ext.select_dtypes(include=['object']).columns].astype(\"category\")\n",
        "X.info();df_test_ext.info()"
      ],
      "metadata": {
        "id": "fEhMjA4j2LpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage with LGBMRegressor\n",
        "lgbm_study = tune_hyperparameters(X, y, LGBMRegressor, n_trials=150, use_gpu=use_gpu)\n",
        "save_results(lgbm_study, LGBMRegressor, \"LightGBM\")\n",
        "lgbm_params = lgbm_study.best_params\n",
        "lgbm_model = train_and_evaluate(LGBMRegressor, lgbm_params, X, y, use_gpu)\n",
        "# lgbm_preds = lgbm_model.predict(test_data)"
      ],
      "metadata": {
        "id": "Mkg_biz-4oCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lgbm_params)"
      ],
      "metadata": {
        "id": "1_DHZT5-jRwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New Dataset with Outliers**\n",
        "* Model 1:\n",
        "  - RMSE: 68111.35949925394:\n",
        "  - Param: {'learning_rate': 0.014924620627674447, 'reg_alpha': 0.2737441785534247, 'reg_lambda': 0.5444882158181196, 'max_depth': 12, 'colsample_bytree': 0.4, 'subsample': 0.95}\n",
        "\n",
        "* Model 2:  \n",
        "  - RMSE: 67919.2555001917\n",
        "  - Param: {'reg_alpha': 0.46744886322047696, 'reg_lambda': 8.064180196480073, 'max_depth': 5, 'colsample_bytree': 0.3, 'subsample': 0.85}\n",
        "\n",
        "**New Dataset *without* Outliers**\n",
        "\n",
        "* Model 1:\n",
        "\n",
        "  * RMSE: 39520.08354062245\n",
        "  * Best hyperparameters: {'reg_alpha': 0.049314275998236345, 'reg_lambda': 9.876122564091135, 'max_depth': 5, 'colsample_bytree': 0.3, 'subsample': 0.5}\n",
        "\n",
        "* Model 2:\n",
        "\n",
        "  * RMSE: 39438.52125799005\n",
        "  * Best hyperparameters: {'reg_alpha': 0.051295104792849454, 'reg_lambda': 0.05653495928350055, 'max_depth': 5, 'colsample_bytree': 0.2, 'subsample': 0.65}"
      ],
      "metadata": {
        "id": "4LGDrY5j0Efx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Diagnostic:"
      ],
      "metadata": {
        "id": "GJ1f80mfVl-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trial = lgbm_study.best_trial\n",
        "print('MSE: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "SfgJYl8TVl-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX73MHX7Vl-Z"
      },
      "outputs": [],
      "source": [
        "fig = optuna.visualization.plot_optimization_history(lgbm_study)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmvPdo76Vl-a"
      },
      "outputs": [],
      "source": [
        "fig = optuna.visualization.plot_param_importances(lgbm_study)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del lgbm_study\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "dsF2n943Vq_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "wx8hNpu60vaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NO EARLY STOPPING**"
      ],
      "metadata": {
        "id": "uG0phZ_SAxme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lgbm_params = {'n_estimators': 1200,\n",
        "#               'max_depth': 14,\n",
        "#               'learning_rate': 0.014,\n",
        "#                'reg_alpha': 0.2737441785534247,\n",
        "#                'reg_lambda': 0.5444882158181196,\n",
        "#                'max_depth': 12,\n",
        "#                'colsample_bytree': 0.4,\n",
        "#                'subsample': 0.95,\n",
        "#                \"learning_rate\" :     0.01,\n",
        "#                'random_state':       42,\n",
        "#                'device':\"cpu\"}\n",
        "\n",
        "# n_splits=3\n",
        "# n_repeats = 3\n",
        "\n",
        "# test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "# valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "# rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "# rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "# for i, (train_index, val_index) in enumerate(rskf.split(X, y)):\n",
        "#     X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#     y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "#     lgbm_model = train_and_evaluate(LGBMRegressor, lgbm_params, X_train, y_train, use_gpu)\n",
        "#     lgbm_preds = lgbm_model.predict(X_val)\n",
        "\n",
        "#     rmse = np.sqrt(mean_squared_error(y_val, lgbm_preds))\n",
        "#     print(f'RMSE on validation data for LightGBM: {rmse}')\n",
        "\n",
        "#     test_results[i] = lgbm_model.predict(df_test_ext)\n",
        "#     valid_scores.loc[i, \"Model\"] = f\"LightGBM_{i}\"\n",
        "#     valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "Nba8SA0SmdV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WITH EARLY-STOPPING**"
      ],
      "metadata": {
        "id": "kdtFPAphA293"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_params = {'n_estimators': 1300,\n",
        "               'learning_rate': 0.014,\n",
        "               'reg_alpha': 8.183585502155848,\n",
        "               'reg_lambda': 7.7576949696381385,\n",
        "               'max_depth': 5,\n",
        "               'colsample_bytree': 0.35,\n",
        "               'subsample': 0.9750000000000001,\n",
        "               'random_state': 42,\n",
        "               'device':\"cpu\"}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_lgbm = np.zeros(len(X))\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    lgbm_model = train_and_evaluate(LGBMRegressor, lgbm_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val,es=181)\n",
        "    lgbm_preds = lgbm_model.predict(X_val)\n",
        "\n",
        "    oof_preds_lgbm[val_index] = lgbm_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, lgbm_preds))\n",
        "    print(f'RMSE on validation data for LightGBM: {rmse}')\n",
        "\n",
        "    test_results[i] = lgbm_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"LightGBM_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "c0lTG6gp6Ow5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_scores.RMSE.mean()"
      ],
      "metadata": {
        "id": "Fijea9SFOQe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lgbm_preds = pd.DataFrame(oof_preds_lgbm, columns=[\"oof_lgbm\"])\n",
        "df_lgbm_preds.to_csv(\"oof/oof_lgbm_preds_v7_no_outliers.csv\", index=False)\n",
        "df_lgbm_preds.head()"
      ],
      "metadata": {
        "id": "LFwHkJLQFG2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### LGBM Forecast"
      ],
      "metadata": {
        "id": "u9xiVsakB6zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results[\"mean\"] = test_results.iloc[:,:-1].mean(axis=1)\n",
        "test_results.head(10)"
      ],
      "metadata": {
        "id": "LO1ypns_Ofqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "5ZfiYXezB6zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_lgbm_v7_no_outliers.csv\", index=False)"
      ],
      "metadata": {
        "id": "JNRg2hZyB6zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Catboost**"
      ],
      "metadata": {
        "id": "eE-4x0-5BMxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[X.select_dtypes(include=['object']).columns]=X[X.select_dtypes(include=['object']).columns].astype(\"category\")\n",
        "df_test_ext[df_test_ext.select_dtypes(include=['object']).columns]=df_test_ext[df_test_ext.select_dtypes(include=['object']).columns].astype(\"category\")\n",
        "#X.info();df_test_ext.info()"
      ],
      "metadata": {
        "id": "yTM0LcxBBMxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Usage with CatBoostRegressor\n",
        "#catboost_study = tune_hyperparameters(X, y, CatBoostRegressor, n_trials=25, use_gpu=use_gpu)\n",
        "#save_results(catboost_study, CatBoostRegressor, \"CatBoost\")\n",
        "#catboost_params = catboost_study.best_params\n",
        "catboost_model = train_and_evaluate(CatBoostRegressor, catboost_params, X, y, use_gpu)\n",
        "#catboost_preds = catboost_model.predict(test_data)"
      ],
      "metadata": {
        "id": "GpTC7GTW_lf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "parameters: {'learning_rate': 0.014921267420169311, 'depth': 13, 'l2_leaf_reg': 3.3634869818677156, 'subsample': 0.925}. Best is trial 23 with value: 39447.7526085777."
      ],
      "metadata": {
        "id": "H-sEb2CfMkCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Diagnostic:"
      ],
      "metadata": {
        "id": "ewnETDCeyeWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trial = catboost_study.best_trial\n",
        "print('MSE: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "bJ2SqQXEyeWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjgqLiLHyeWc"
      },
      "outputs": [],
      "source": [
        "fig = optuna.visualization.plot_optimization_history(catboost_study)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDGylT__yeWd"
      },
      "outputs": [],
      "source": [
        "fig = optuna.visualization.plot_param_importances(catboost_study)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del catboost_study, catboost_model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "JAXUeA6SyeWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "jYrRjNdPus0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_params = {'learning_rate': 0.014921267420169311, 'depth': 13, 'l2_leaf_reg': 3.3634869818677156, 'subsample': 0.925}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_cat = np.zeros(len(X))\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    cat_model = train_and_evaluate(CatBoostRegressor, cat_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val)\n",
        "    cat_preds = cat_model.predict(X_val)\n",
        "\n",
        "    oof_preds_cat[val_index] = cat_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, cat_preds))\n",
        "    print(f'RMSE on validation data for cat: {rmse}')\n",
        "\n",
        "    test_results[i] = cat_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"cat_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "suuFmSGxkD59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat_preds = pd.DataFrame(oof_preds_cat, columns=[\"oof_cat\"])\n",
        "df_cat_preds.to_csv(\"oof/oof_cat_preds_v1.csv\", index=False)\n",
        "df_cat_preds.head()"
      ],
      "metadata": {
        "id": "yU2_V9SNH_Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_scores"
      ],
      "metadata": {
        "id": "Rfw6C8xRPjm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CatBoost Forecast"
      ],
      "metadata": {
        "id": "DsXGx-ewu0eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(10)"
      ],
      "metadata": {
        "id": "hpvMWwJau0eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "ab3K6z0Lu0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_cat_v1.csv\", index=False)"
      ],
      "metadata": {
        "id": "xzl--DYhu0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Poisson Regression:"
      ],
      "metadata": {
        "id": "app3vgHj8Qus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu=False\n",
        "# usage with PoissonRegressor\n",
        "poi_study = tune_hyperparameters(X, y, PoissonRegressor, n_trials=51, use_gpu=use_gpu)\n",
        "save_results(poi_study, PoissonRegressor, \"Poi\")\n",
        "poi_params = poi_study.best_params  # Extract best parameters\n",
        "#xgb_model = train_and_evaluate(XGBRegressor, xgb_params, X, y, use_gpu)\n",
        "#xgb_preds_ = xgb_model.predict(df_test_ext)"
      ],
      "metadata": {
        "id": "kkHIJqQj8dTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "5yqBEKl_J4gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poi_params = {'alpha': 0.009}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_poi = np.zeros(len(X))\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    poi_model = train_and_evaluate(PoissonRegressor, poi_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val)\n",
        "    poi_preds = poi_model.predict(X_val)\n",
        "\n",
        "    oof_preds_poi[val_index] = poi_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, poi_preds))\n",
        "    print(f'RMSE on validation data for cat: {rmse}')\n",
        "\n",
        "    test_results[i] = poi_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"poi_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "-IAkdlyJJ4gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    RMSE on train data for PoissonRegressor: 40718.68957618613\n",
        "    RMSE on validation data for cat: 40010.07675057371\n",
        "    RMSE on train data for PoissonRegressor: 41015.09513266724\n",
        "    RMSE on validation data for cat: 39301.15707337416\n",
        "    RMSE on train data for PoissonRegressor: 39417.75920686562\n",
        "    RMSE on validation data for cat: 42690.84899097667\n",
        "    RMSE on train data for PoissonRegressor: 39562.80731892349\n",
        "    RMSE on validation data for cat: 42509.839722038436\n",
        "    RMSE on train data for PoissonRegressor: 40548.4530053571\n",
        "    RMSE on validation data for cat: 40253.386610255606\n",
        "    RMSE on train data for PoissonRegressor: 41045.61060024812\n",
        "    RMSE on validation data for cat: 39442.72515985904\n",
        "    RMSE on train data for PoissonRegressor: 41043.71165100683\n",
        "    RMSE on validation data for cat: 39555.77869769673\n",
        "    RMSE on train data for PoissonRegressor: 40671.30648408839\n",
        "    RMSE on validation data for cat: 40064.129487068865\n",
        "    RMSE on train data for PoissonRegressor: 39409.70186814949\n",
        "    RMSE on validation data for cat: 42471.25457782956"
      ],
      "metadata": {
        "id": "TKAC1g3fNUCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_poi_preds = pd.DataFrame(oof_preds_poi, columns=[\"oof_poi\"])\n",
        "df_poi_preds.to_csv(\"oof/oof_poi_preds_v2.csv\", index=False)\n",
        "df_poi_preds.head()"
      ],
      "metadata": {
        "id": "7muTG_ApLXpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_scores"
      ],
      "metadata": {
        "id": "R-rhwsAuLXp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### PoissonRegressor Forecast"
      ],
      "metadata": {
        "id": "hX-5mSSYLXp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(10)"
      ],
      "metadata": {
        "id": "gLt8bJVpLXp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "2j_IOnreLXp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_poi_v2_without_outliers.csv\", index=False)"
      ],
      "metadata": {
        "id": "1xlBXpKELXp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gamma Regressor:"
      ],
      "metadata": {
        "id": "Ur18JdV3QdCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "uSEpqH5wQlt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gam_params = {'alpha': 0.01}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_gam = pd.DataFrame(index = list(range(len(X))), columns=[\"oof_gam\"])\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    gam_model = train_and_evaluate(GammaRegressor, gam_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val)\n",
        "    gam_preds = gam_model.predict(X_val)\n",
        "\n",
        "    oof_preds_gam.loc[val_index,\"oof_gam\"] = gam_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, gam_preds))\n",
        "    print(f'RMSE on validation data for GammaReg: {rmse}')\n",
        "\n",
        "    test_results[i] = gam_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"poi_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "UyL-l5TiQlt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds_gam.head()"
      ],
      "metadata": {
        "id": "f-sxNlj0NLoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gam_preds = oof_preds_gam.copy()\n",
        "df_gam_preds.to_csv(\"oof/oof_gam_preds_v2_no_outliers.csv\", index=False)\n",
        "df_gam_preds.head()"
      ],
      "metadata": {
        "id": "bvbwOvapRx8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_scores"
      ],
      "metadata": {
        "id": "cwzVFtRfRx8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### GammaRegressor Forecast"
      ],
      "metadata": {
        "id": "DzrvTL2PRx8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(10)"
      ],
      "metadata": {
        "id": "VS0XBxCjRx8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "63cUawzMRx80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_gam_v2_no_outliers.csv\", index=False)"
      ],
      "metadata": {
        "id": "QE79b14BRx81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TheilSenRegressor Regressor:"
      ],
      "metadata": {
        "id": "YIGhTNOQwZRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "oYvzhm3WwZRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theil_params = {'max_subpopulation': 15_000}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_theil = pd.DataFrame(index = list(range(len(X))), columns=[\"oof_theil\"])\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    theil_model = train_and_evaluate(TheilSenRegressor, theil_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val)\n",
        "    theil_preds = theil_model.predict(X_val)\n",
        "    print(theil_model.coef_)\n",
        "\n",
        "    oof_preds_theil.loc[val_index,\"oof_theil\"] = theil_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, theil_preds))\n",
        "    print(f'RMSE on validation data for TheilSenRegressor: {rmse}')\n",
        "\n",
        "    test_results[i] = theil_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"TheilSenRegressor_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "0vgDK0EywZRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds_theil = oof_preds_theil.clip(lower=2_000)\n",
        "oof_preds_theil.head()"
      ],
      "metadata": {
        "id": "6bv08OTKwZRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_theil_preds = oof_preds_theil.copy()\n",
        "df_theil_preds.to_csv(\"oof/oof_theil_preds_v0_no_outliers.csv\", index=False)\n",
        "df_theil_preds.head()"
      ],
      "metadata": {
        "id": "A6vGIEGvwZRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_scores"
      ],
      "metadata": {
        "id": "tHd8YCNPwZRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TheilRegressor Forecast"
      ],
      "metadata": {
        "id": "Qd-pi5-WwZRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = test_results.clip(lower=2_000)\n",
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(5)"
      ],
      "metadata": {
        "id": "QAltvxUQwZRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "JzL2cp2CwZRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_theil_v0_no_outliers.csv\", index=False)"
      ],
      "metadata": {
        "id": "MqjBzn3qwZRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QuantileRegressor Regressor:"
      ],
      "metadata": {
        "id": "mrbH91ucwqDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "AhYwwfgHwqD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quant_params = {\"quantile\":0.9, \"alpha\":0.001}\n",
        "\n",
        "n_splits=3\n",
        "n_repeats = 3\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits*n_repeats)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits*n_repeats)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_quant = pd.DataFrame(index = list(range(len(X))), columns=[\"oof_quant\"])\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=36851234)\n",
        "\n",
        "rskf.get_n_splits(X, X[\"brand\"])\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(rskf.split(X, X[\"brand\"])):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    quant_model = train_and_evaluate(QuantileRegressor, quant_params, X_train, y_train, use_gpu, X_val=X_val, y_val=y_val)\n",
        "    quant_preds = quant_model.predict(X_val)\n",
        "    #print(quant_model.coef_)\n",
        "\n",
        "    oof_preds_quant.loc[val_index,\"oof_quant\"] = quant_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, quant_preds))\n",
        "    print(f'RMSE on validation data for QuantRegressor: {rmse}')\n",
        "\n",
        "    test_results[i] = quant_model.predict(df_test_ext)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"QuantRegressor_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "E7y_rrlGwqD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds_quant = oof_preds_quant.clip(lower=2_000)\n",
        "oof_preds_quant.head()"
      ],
      "metadata": {
        "id": "JJyA3b5SwqD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_quant_preds = oof_preds_quant.copy()\n",
        "df_quant_preds.to_csv(\"oof/oof_quant_preds_v0_no_outliers.csv\", index=False)\n",
        "df_quant_preds.head()"
      ],
      "metadata": {
        "id": "z-nvh8jzwqD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_scores"
      ],
      "metadata": {
        "id": "PDEhX9jywqD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Quantile Regressor Forecast"
      ],
      "metadata": {
        "id": "Bg1TQwwawqD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = test_results.clip(lower=2_000)\n",
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(5)"
      ],
      "metadata": {
        "id": "Wv0YBPg9wqD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "LT6n2BKmwqD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_quant_v0_no_outliers.csv\", index=False)"
      ],
      "metadata": {
        "id": "FYzwsyFMwqD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESEMBLING:"
      ],
      "metadata": {
        "id": "QsUUkluex8gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Mean:"
      ],
      "metadata": {
        "id": "meEXqx7imEHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_sub = pd.read_csv(\"submissions/submission_cat_v1.csv\")\n",
        "lgb_sub = pd.read_csv(\"submissions/submission_lgbm_v2.csv\")\n",
        "xgb_sub = pd.read_csv(\"submissions/submission_xgb_v7.csv\")\n",
        "poi_sub = pd.read_csv(\"submissions/submission_poi_v0.csv\")\n",
        "#poi_sub_v1 = pd.read_csv(\"submissions/submission_poi_v2_no_outliers.csv\")\n",
        "gam_sub = pd.read_csv(\"submissions/submission_gam_v1.csv\")\n",
        "#xgb_sub_out = pd.read_csv(\"submissions/submission_xgb_v9_outliers.csv\")\n",
        "#lgb_sub_out = pd.read_csv(\"submissions/submission_lgbm_v5_with_outliers.csv\")\n",
        "#lgb_sub_v1 = pd.read_csv(\"submissions/submission_lgbm_v7_no_outliers.csv\")\n",
        "xgb_sub_v1 = pd.read_csv(\"submissions/submission_xgb_v10_no_outliers.csv\")\n",
        "#theil = pd.read_csv(\"submissions/submission_theil_v0_no_outliers.csv\")\n",
        "#quant = pd.read_csv(\"submissions/submission_quant_v0_no_outliers.csv\")\n",
        "#ensemble_v0 = pd.read_csv(\"submissions/submission_ensemble_v0.csv\")\n",
        "\n",
        "all_sub = pd.DataFrame()\n",
        "all_sub[\"cat\"] = cat_sub[\"price\"]\n",
        "all_sub[\"lgb\"] = lgb_sub[\"price\"]\n",
        "all_sub[\"xgb\"] = xgb_sub[\"price\"]\n",
        "all_sub[\"poi\"] = poi_sub[\"price\"]\n",
        "#all_sub[\"poi_v1\"] = poi_sub_v1[\"price\"]\n",
        "all_sub[\"gam\"] = gam_sub[\"price\"]\n",
        "#all_sub[\"lgb_out\"] = lgb_sub_out[\"price\"]\n",
        "#all_sub[\"xgb_out\"] = xgb_sub_out[\"price\"]\n",
        "#all_sub[\"lgb_v1\"] = lgb_sub_v1[\"price\"]\n",
        "all_sub[\"xgb_v1\"] = xgb_sub_v1[\"price\"]\n",
        "#all_sub[\"theil\"] = theil[\"price\"]\n",
        "#all_sub[\"quant\"] = quant[\"price\"]\n",
        "\n",
        "all_sub[\"mean\"] = all_sub.mean(axis=1)\n",
        "all_sub.head()"
      ],
      "metadata": {
        "id": "7jh2Ss0FFyJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(3, 3, figsize=(15, 10))\n",
        "axs = np.ravel(axs)\n",
        "\n",
        "\n",
        "axs[0].scatter(lgb_sub[\"price\"],lgb_sub_out[\"price\"],alpha=0.5, color=\"firebrick\")\n",
        "axs[0].set_title(\"LightGBM vs LightGBM_w_Out\")\n",
        "axs[1].scatter(lgb_sub[\"price\"],lgb_sub_v1[\"price\"],alpha=0.5,color=\"darkslateblue\")\n",
        "axs[1].set_title(\"LightGBM vs LightGBM_v1\")\n",
        "axs[2].scatter(lgb_sub[\"price\"],theil[\"price\"],alpha=0.5,color=\"salmon\")\n",
        "axs[2].set_title(\"LightGBM vs theil\")\n",
        "axs[3].scatter(lgb_sub[\"price\"],cat_sub[\"price\"],alpha=0.5,color=\"royalblue\")\n",
        "axs[3].set_title(\"LightGBM vs CatBoost\")\n",
        "axs[4].scatter(lgb_sub[\"price\"],xgb_sub[\"price\"],alpha=0.5,color=\"seagreen\")\n",
        "axs[4].set_title(\"LightGBM vs XGBoost\")\n",
        "axs[5].scatter(xgb_sub_v1[\"price\"],xgb_sub[\"price\"],alpha=0.5,color=\"tomato\")\n",
        "axs[5].set_title(\"XGBoost v1 vs XGBoost\")\n",
        "axs[6].scatter(xgb_sub_out[\"price\"],xgb_sub[\"price\"],alpha=0.5,color=\"darkslateblue\")\n",
        "axs[6].set_title(\"XGBoost Out vs XGBoost\")\n",
        "axs[7].scatter(gam_sub[\"price\"],theil[\"price\"],alpha=0.5,color=\"darkslateblue\")\n",
        "axs[7].set_title(\"Gamma vs Theil\")\n",
        "axs[8].scatter(quant[\"price\"],lgb_sub[\"price\"],alpha=0.5,color=\"salmon\")\n",
        "axs[8].set_title(\"Quant vs Poisson v1\")\n",
        "\n",
        "#plt.legend()\n",
        "#axs[0].set_xlabel(\"LightGBM\")\n",
        "#axs[0].set_ylabel(\"CatBoost\")\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bSlMZ9jdlZ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = all_sub[\"mean\"]\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "PS5px2ZxRtkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submissions/submission_simplemean_v8.csv\", index=False)"
      ],
      "metadata": {
        "id": "UNt6ZEClR4wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VotingRegressor"
      ],
      "metadata": {
        "id": "oQK7kfa08Jva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.isna().sum()#.shape"
      ],
      "metadata": {
        "id": "X0GIm6iwqcpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_oof = pd.read_csv(\"oof/oof_cat_preds_v1.csv\")\n",
        "lgb_oof = pd.read_csv(\"oof/oof_lgbm_preds_v3.csv\")\n",
        "xgb_oof = pd.read_csv(\"oof/oof_xgb_preds_v7.csv\")\n",
        "#poi_oof = pd.read_csv(\"oof/oof_poi_preds_v0.csv\")\n",
        "gam_oof = pd.read_csv(\"oof/oof_gam_preds_v1.csv\")\n",
        "xgb_oof_v1 = pd.read_csv(\"oof/oof_xgb_preds_v10_no_outliers.csv\")\n",
        "lgb_oof_v1 = pd.read_csv(\"oof/oof_lgbm_preds_v7_no_outliers.csv\")\n",
        "xgb_oof_v2 = pd.read_csv(\"oof/oof_xgb_preds_v9_outliers.csv\")\n",
        "#quant_oof = pd.read_csv(\"oof/oof_quant_preds_v0_no_outliers.csv\")\n",
        "\n",
        "\n",
        "all_oof = pd.DataFrame()\n",
        "all_oof[\"cat\"] = cat_oof[\"oof_cat\"]\n",
        "all_oof[\"lgb\"] = lgb_oof[\"oof_lgbm\"]\n",
        "all_oof[\"xgb\"] = xgb_oof[\"oof_xgb\"]\n",
        "#all_oof[\"poi\"] = poi_oof[\"oof_poi\"]\n",
        "all_oof[\"gam\"] = gam_oof[\"oof_gam\"]\n",
        "all_oof[\"lgb_v1\"] = lgb_oof_v1[\"oof_lgbm\"]\n",
        "all_oof[\"xgb_v1\"] = xgb_oof_v1[\"oof_xgb\"]\n",
        "all_oof[\"xgb_v2\"] = xgb_oof_v2[\"oof_xgb\"]\n",
        "#all_oof[\"quant\"] = quant_oof[\"oof_quant\"]\n",
        "\n",
        "print(all_oof.shape)"
      ],
      "metadata": {
        "id": "FDiLljTKyatV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_oof[\"price\"] = y.values\n",
        "all_oof.isna().sum()\n",
        "#lgb_oof_v5"
      ],
      "metadata": {
        "id": "pNxtJn_Qq0qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_oof.corr()"
      ],
      "metadata": {
        "id": "wbcWJRebVLCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(all_oof[\"xgb_v1\"],all_oof[\"price\"])\n",
        "plt.xlabel(\"xgb_v1\")\n",
        "plt.ylabel(\"Target\")\n",
        "plt.title(\"Quant vs Target\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SVqZBxpULEAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_objective(trial):\n",
        "    params = {\n",
        "              'n_estimators' :      trial.suggest_int('n_estimators', 150, 500, step=5),\n",
        "              'max_depth' :         trial.suggest_int('max_depth', 4, 10, step=1),\n",
        "              'min_samples_split' : trial.suggest_int('min_samples_split', 6, 25, step=1),\n",
        "              'max_features':       trial.suggest_float('max_features', .40, 1.0, step=0.15),\n",
        "              'max_samples':        trial.suggest_float('max_samples', .30, 1.0, step=0.05),\n",
        "              }\n",
        "\n",
        "\n",
        "    optuna_model = RandomForestRegressor(**params)\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(all_oof.drop(columns=[\"price\"]), all_oof[\"price\"]):\n",
        "        X_train, X_val = all_oof.drop(columns=[\"price\"]).iloc[train_idx], all_oof.drop(columns=[\"price\"]).iloc[val_idx]\n",
        "        y_train, y_val = all_oof[[\"price\"]].iloc[train_idx], all_oof[[\"price\"]].iloc[val_idx]\n",
        "\n",
        "        optuna_model.fit(X_train, y_train)\n",
        "        y_pred = optuna_model.predict(X_val)\n",
        "        rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
        "\n",
        "    return np.mean(rmse_scores)"
      ],
      "metadata": {
        "id": "ePHaSPqkgE4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_study = optuna.create_study(direction = 'minimize', study_name=\"rf_opt\",\n",
        "                                sampler = optuna.samplers.TPESampler(seed=42),\n",
        "                                pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "                                )"
      ],
      "metadata": {
        "id": "95v4DGq3gE0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_study.optimize(rf_objective, 31, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "tWd8E_dHgEwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model:"
      ],
      "metadata": {
        "id": "Jzth8dNneCr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 9, 'max_features': 0.4, 'max_samples': 0.3}\n",
        "all_sub_ = all_sub.drop(\"mean\", axis=1)\n",
        "n_splits=5\n",
        "\n",
        "test_results = pd.DataFrame(columns=list(range(n_splits)))\n",
        "valid_scores = pd.DataFrame(index= list(range(n_splits)),columns=[\"Model\",\"RMSE\"])\n",
        "\n",
        "oof_preds_rf = np.zeros(len(X))\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_idx, val_idx) in enumerate(kf.split(all_oof.drop(columns=[\"price\"]), all_oof[\"price\"])):\n",
        "    X_train, X_val = all_oof.drop(columns=[\"price\"]).iloc[train_idx], all_oof.drop(columns=[\"price\"]).iloc[val_idx]\n",
        "    y_train, y_val = all_oof[[\"price\"]].iloc[train_idx], all_oof[[\"price\"]].iloc[val_idx]\n",
        "\n",
        "    rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    rf_preds = rf_model.predict(X_val)\n",
        "\n",
        "    oof_preds_rf[val_idx] = rf_preds\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, rf_preds))\n",
        "    print(f'RMSE on validation data for Ens: {rmse}')\n",
        "\n",
        "    test_results[i] = rf_model.predict(all_sub_)\n",
        "    valid_scores.loc[i, \"Model\"] = f\"rf_{i}\"\n",
        "    valid_scores.loc[i, \"RMSE\"] = rmse\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "1NfrUBCmeCr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results[\"mean\"] = test_results.mean(axis=1)\n",
        "test_results.head(10)"
      ],
      "metadata": {
        "id": "kTDqIMH8haHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub[\"price\"] = test_results[\"mean\"]\n",
        "\n",
        "df_sub.to_csv(\"submissions/submission_ensemble_v3.csv\", index=False)"
      ],
      "metadata": {
        "id": "wvRe6i4hiS_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.head()"
      ],
      "metadata": {
        "id": "SBjo9mDcig-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eUVAN6uhH7O"
      },
      "source": [
        "### **NEURAL NETWORK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik1EXI1eI10b"
      },
      "source": [
        "#### Training Function:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_session(history):\n",
        "  # Plot training and validation loss scores\n",
        "  # against the number of epochs.\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(history.history['loss'], label='Train')\n",
        "  plt.plot(history.history['val_loss'], label='Validation')\n",
        "  plt.grid(linestyle='--')\n",
        "  plt.ylabel('val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Train-Validation Scores', pad=13)\n",
        "  plt.legend(loc='upper right');\n",
        "  plt.show()\n",
        "  return None\n",
        "\n",
        "class dense_block(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, dropout_rate=0.25, activation=\"relu\", kr=0, name=\"drb\"):   #tf.keras.regularizers.L2(l2=0.01)\n",
        "        super(dense_block, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        self.linear_dense = tf.keras.layers.Dense(units, name=f\"lin_dense_0_{name}\")\n",
        "        self.project = tf.keras.layers.Dense(units, name=f\"lin_dense_prj_{name}\")\n",
        "\n",
        "        self.batchnorm_0 = tf.keras.layers.BatchNormalization(name=f\"bn_0_{name}\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate,name=f\"do_0_{name}\")\n",
        "\n",
        "        if activation==\"gelu\":\n",
        "          self.activation_0 = tf.keras.activations.gelu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"relu\":\n",
        "          self.activation_0 = tf.keras.activations.relu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"elu\":\n",
        "          self.activation_0 = tf.keras.activations.elu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"swish\":\n",
        "          self.activation_0 = tf.keras.activations.swish\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"selu\":\n",
        "          self.activation_0 = tf.keras.activations.selu\n",
        "#          self.dropout = tf.keras.layers.AlphaDropout(dropout_rate,name=f\"alphado_0_{name}\")\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"lecun_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"leaky_relu\":\n",
        "          self.activation_0 = tf.keras.layers.LeakyReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"prelu\":\n",
        "          self.activation_0 = tf.keras.layers.PReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        x = self.dense_0(inputs)\n",
        "        x = self.batchnorm_0(x)\n",
        "        x = self.activation_0(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class dense_residual_block(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, dropout_rate=0.25, activation=\"relu\", kr=0, attention=False, name=\"drb\", norm=\"batch\"):   #tf.keras.regularizers.L2(l2=0.01)\n",
        "        super(dense_residual_block, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        self.linear_dense = tf.keras.layers.Dense(units, name=f\"lin_dense_0_{name}\")\n",
        "        self.project = tf.keras.layers.Dense(units, name=f\"lin_dense_prj_{name}\")\n",
        "\n",
        "        if norm==\"batch\":\n",
        "          self.batchnorm_0 = tf.keras.layers.BatchNormalization(name=f\"bn_0_{name}\")\n",
        "          self.batchnorm_1 = tf.keras.layers.BatchNormalization(name=f\"bn_1_{name}\")\n",
        "          self.batchnorm_prj = tf.keras.layers.BatchNormalization(name=f\"bn_prj_{name}\")  #LayerNormalization()\n",
        "\n",
        "        if norm==\"layer\":\n",
        "          self.batchnorm_0 = tf.keras.layers.LayerNormalization(name=f\"bn_0_lr_{name}\")\n",
        "          self.batchnorm_1 = tf.keras.layers.LayerNormalization(name=f\"bn_1_lr_{name}\")\n",
        "          self.batchnorm_prj = tf.keras.layers.LayerNormalization(name=f\"bn_prj_lr_{name}\")  #LayerNormalization()\n",
        "\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.BatchNormalization(name=f\"bn_2_{name}\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate,name=f\"do_0_{name}\")\n",
        "        self.add_layer = tf.keras.layers.Add(name=f\"add_0_{name}\")\n",
        "\n",
        "        self.attention=attention\n",
        "        self.attention_layer = tf.keras.layers.Attention(name=f\"attention_{name}\")\n",
        "\n",
        "        if activation==\"gelu\":\n",
        "          self.activation_0 = tf.keras.activations.gelu\n",
        "          self.activation_1 = tf.keras.activations.gelu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "        if activation==\"relu\":\n",
        "          self.activation_0 = tf.keras.activations.relu\n",
        "          self.activation_1 = tf.keras.activations.relu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "        if activation==\"elu\":\n",
        "          self.activation_0 = tf.keras.activations.elu\n",
        "          self.activation_1 = tf.keras.activations.elu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "        if activation==\"swish\":\n",
        "          self.activation_0 = tf.keras.activations.swish\n",
        "          self.activation_1 = tf.keras.activations.swish\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "        if activation==\"selu\":\n",
        "          self.activation_0 = tf.keras.activations.selu\n",
        "          self.activation_1 = tf.keras.activations.selu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"lecun_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "        if activation==\"leaky_relu\":\n",
        "          self.activation_0 = tf.keras.layers.LeakyReLU()\n",
        "          self.activation_1 = tf.keras.layers.LeakyReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "        if activation==\"prelu\":\n",
        "          self.activation_0 = tf.keras.layers.PReLU()\n",
        "          self.activation_1 = tf.keras.layers.PReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\",\n",
        "                                               kernel_regularizer = tf.keras.regularizers.L2(l2=kr),\n",
        "                                               name=f\"dense_0_{name}\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        if self.attention==True:\n",
        "          attention = self.attention_layer([inputs, inputs])\n",
        "        else:\n",
        "          attention = inputs\n",
        "\n",
        "        x = self.dense_0(attention)\n",
        "        x = self.batchnorm_0(x)\n",
        "        x = self.activation_0(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.linear_dense(x)\n",
        "        x = self.batchnorm_1(x)\n",
        "\n",
        "        if attention.shape[-1] != self.units:\n",
        "            inputs = self.project(attention)\n",
        "            inputs = self.batchnorm_prj(inputs)\n",
        "\n",
        "        return self.add_layer([x, inputs])\n",
        "\n",
        "\n",
        "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
        "    mlp_layers = []\n",
        "    if activation==\"relu\":\n",
        "        activation_0 = tf.keras.activations.relu\n",
        "    if activation==\"prelu\":\n",
        "        activation_0 = tf.keras.layers.PReLU()\n",
        "    if activation==\"elu\":\n",
        "        activation_0 = tf.keras.activations.elu\n",
        "    if activation==\"swish\":\n",
        "        activation_0 = tf.keras.activations.swish\n",
        "    if activation==\"selu\":\n",
        "        activation_0 = tf.keras.activations.selu\n",
        "    if activation==\"leaky_relu\":\n",
        "        activation_0 = tf.keras.layers.LeakyReLU()\n",
        "    if activation==\"gelu\":\n",
        "        activation_0 = tf.keras.activations.gelu\n",
        "\n",
        "    for units in hidden_units:\n",
        "        mlp_layers.append(normalization_layer()),\n",
        "        if activation == \"selu\":\n",
        "          mlp_layers.append(layers.Dense(units, activation=activation_0, kernel_initializer=\"lecun_normal\"))\n",
        "          mlp_layers.append(layers.AlphaDropout(dropout_rate))\n",
        "        else:\n",
        "          if activation in [\"prelu\",\"leaky_relu\"]:\n",
        "            mlp_layers.append(layers.Dense(units))\n",
        "            mlp_layers.append(activation_0)\n",
        "            mlp_layers.append(layers.Dropout(dropout_rate))\n",
        "          else:\n",
        "            mlp_layers.append(layers.Dense(units,activation=activation_0))\n",
        "            mlp_layers.append(layers.Dropout(dropout_rate))\n",
        "\n",
        "    return keras.Sequential(mlp_layers, name=name)"
      ],
      "metadata": {
        "id": "sJ-GSta_tWmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Management:"
      ],
      "metadata": {
        "id": "iSKvxH8xta_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe, shuffle=False, batch_size=64):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe[\"FloodProbability\"]\n",
        "    dataframe = dataframe.drop(columns=[\"FloodProbability\"])\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "9dJxhdbbteAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_used = ['brand', 'model', 'milage', 'fuel_type', 'transmission', 'ext_col',\n",
        "       'int_col', 'accident', 'clean_title', 'price', 'ext_col_nan',\n",
        "       'Dummy_Special_color', 'Dummy_metal', 'Dummy_cus',\n",
        "       'Dummy_Special_color_int', 'horsepower', 'engine_capacity', 'turbo',\n",
        "       'num_cylinders', 'age', 'milage_per_year', 'premium_brand',\n",
        "       'luxury_brand', 'engine_eff', 'is_GT']\n",
        "\n",
        "cat_feat = [ \"turbo\",'fuel_type', 'ext_col', 'premium_brand','luxury_brand','int_col', \"clean_title\",\n",
        "           'accident','ext_col_nan','Dummy_Special_color', 'Dummy_metal', 'Dummy_cus',\n",
        "            'Dummy_Special_color_int','is_GT']\n",
        "\n",
        "num_feat = [col for col in feat_used if col not in cat_feat]"
      ],
      "metadata": {
        "id": "WTiYjSe7-A2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(func_model, train, test_data, best_params, experiment_name=\"baseline_nn\", splits=5, n_repeats=5, rs=42, target=\"FloodProbability\",\n",
        "                   batch_size=64, num_epochs=200, learning_rate=0.005):\n",
        "\n",
        "  skf = RepeatedStratifiedKFold(n_splits=splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "  test_predictions = np.zeros((len(test_data),1))\n",
        "  test_results_df = pd.DataFrame(index=test_data.index, columns=[target])\n",
        "\n",
        "  all_logloss = []\n",
        "  all_RMSE_pr = []\n",
        "  oof_results = np.empty(shape=(train.shape[0],1))\n",
        "\n",
        "  for i, (train_index, valid_index) in enumerate(skf.split(train,train[target])):\n",
        "\n",
        "    print(f\"\\nRunning CV {i}\\n\")\n",
        "    ########################################################################## Prepare the Dataset:\n",
        "    X_trn = train.iloc[train_index,:]\n",
        "    X_val = train.iloc[valid_index,:]\n",
        "\n",
        "    X = X_trn.drop(columns=[target]).copy()\n",
        "    y = X_trn[target].copy()\n",
        "\n",
        "    val_X = X_val.drop(columns=[target]).copy()\n",
        "    val_y = X_val[target].copy()\n",
        "\n",
        "    X_test = test_data.copy()\n",
        "    #################################################################### Prepare Datasets loaders:\n",
        "\n",
        "    train_dataset = dataframe_to_dataset(X_trn, batch_size=batch_size, shuffle=True)\n",
        "    valid_dataset = dataframe_to_dataset(X_val, batch_size=batch_size, shuffle=False)\n",
        "    test_dataset = dataframe_to_dataset(X_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    feature_space_dict = FeatureSpace(\n",
        "                                  features={**{a:FeatureSpace.integer_categorical(num_oov_indices=1, output_mode=\"one_hot\") for a in cat_feat},\n",
        "                                            **{a:FeatureSpace.float_normalized() for a in num_feat}},\n",
        "                                  output_mode=\"dict\"\n",
        "                                  )\n",
        "\n",
        "    train_ds_with_no_labels = train_dataset.map(lambda x, *_: x)\n",
        "    print(\"Adapting Features Space....\")\n",
        "    feature_space_dict.adapt(train_ds_with_no_labels)\n",
        "\n",
        "    preprocessed_train_ds = train_dataset.map(lambda x, y: (feature_space_dict(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "    preprocessed_valid_ds = valid_dataset.map(lambda x, y: (feature_space_dict(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "    preprocessed_test_ds = test_dataset.map(lambda x, y: (feature_space_dict(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    ##################################################################### Relevant Folders\n",
        "    folders_experiment = f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E9_Cars/neural_networks/{experiment_name}/\"\n",
        "    folders_experiment_cv1 = f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E9_Cars/neural_networks/\"\n",
        "    folders_experiment_cv2= f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E9_Cars/neural_networks/{experiment_name}\"\n",
        "    folders_experiment_cv3 = f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E9_Cars/neural_networks/{experiment_name}/cv_{i}/\"\n",
        "    folder_data = f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data//Data/S4E4_Abalone\"\n",
        "    list_directories = [folder_data,folders_experiment,folders_experiment_cv1,folders_experiment_cv2,folders_experiment_cv3]\n",
        "\n",
        "    for path in list_directories:\n",
        "      try:\n",
        "          os.mkdir(path)\n",
        "      except OSError as error:\n",
        "          print(f\"{path} already exists\")\n",
        "    ##################################################################### Generate and Fit Model\n",
        "    # Callbacks:\n",
        "    checkpoint_filepath = folders_experiment + f'checkpoint/{experiment_name}.weights.h5'\n",
        "\n",
        "    # Generate the Model:\n",
        "    model = func_model(feature_space_dict, name=experiment_name, learning_rate = learning_rate, **best_params)\n",
        "\n",
        "    print(\"Start training the model...\")\n",
        "    history = model.fit(preprocessed_train_ds,\n",
        "                        epochs=num_epochs,\n",
        "                        callbacks=[keras.callbacks.EarlyStopping(monitor='val_rmse', patience=21, mode=\"min\",\n",
        "                                                  start_from_epoch=5,restore_best_weights=True),\n",
        "                                   keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                    save_weights_only=True,\n",
        "                                                    monitor=\"val_rmse\",\n",
        "                                                    mode='min',\n",
        "                                                    save_best_only=True),\n",
        "                                   keras.callbacks.ReduceLROnPlateau(monitor='val_rmse', factor=0.5,\n",
        "                                                          patience=5, min_lr=0.0001, mode=\"min\")],\n",
        "                        validation_data=preprocessed_valid_ds)\n",
        "    print(\"Model training finished\")\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    model.evaluate(preprocessed_valid_ds, verbose=0)\n",
        "\n",
        "    plot_training_session(history)\n",
        "\n",
        "    oof_res = model.predict(preprocessed_valid_ds)\n",
        "    test_prob = model.predict(preprocessed_test_ds)\n",
        "\n",
        "    print(f\"Out-of-Fold Shapes: {oof_results[valid_index].shape},{oof_res.shape}\")\n",
        "\n",
        "    oof_results[valid_index] += oof_res/n_repeats\n",
        "    rmse_score = np.sqrt(mean_squared_error(y_val, quant_preds))\n",
        "\n",
        "    test_predictions += test_prob/skf.get_n_splits()\n",
        "\n",
        "    ##################################################################### Save the Model\n",
        "    model.save(f\"{folders_experiment_cv3}/model_{experiment_name}.keras\")\n",
        "    feature_space_dict.save(f\"{folders_experiment_cv3}/myfeaturespace_{experiment_name}.keras\")\n",
        "\n",
        "    print(f\"Test RMSE Score: {round(rmse_score, 3)}%\")\n",
        "    all_RMSE_pr.append(round(rmse_score, 3))\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "  ##################################################################### Create Model Output\n",
        "  test_results_df.loc[:,:] = test_predictions\n",
        "\n",
        "  print(f\"All Valuation RMSE: {all_RMSE_pr}\")\n",
        "\n",
        "  return test_results_df, oof_results"
      ],
      "metadata": {
        "id": "DxzbZ9x5uM6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN Data Preparation:"
      ],
      "metadata": {
        "id": "GVtI5ZZW_dJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ext.head()"
      ],
      "metadata": {
        "id": "PqA6hiysbF4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ext.describe(include =\"all\").T"
      ],
      "metadata": {
        "id": "Mirgzd3YesG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train_ext.drop(\"price\", axis=1)\n",
        "y = df_train_ext[\"price\"]\n",
        "\n",
        "log_transformer_y = FunctionTransformer(func=np.log,inverse_func=np.exp,check_inverse=True)\n",
        "\n",
        "ly = log_transformer_y.fit_transform(y.values.reshape(-1,1))\n",
        "oy = log_transformer_y.inverse_transform(ly)\n",
        "\n",
        "(oy==y.values).all()"
      ],
      "metadata": {
        "id": "d8Wgm2qrvKLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "categorical_features = ['brand', 'model','horsepower','age','num_cylinders',\"transmission\"]\n",
        "\n",
        "cat_bin = [ \"turbo\",'fuel_type', 'ext_col', 'premium_brand','luxury_brand','int_col', \"clean_title\",\n",
        "           'accident','ext_col_nan','Dummy_Special_color', 'Dummy_metal', 'Dummy_cus',\n",
        "            'Dummy_Special_color_int','is_GT']\n",
        "\n",
        "log_col = [\"milage_per_year\",\"engine_eff\"]\n",
        "\n",
        "rev_log_col = [\"milage\"]\n",
        "\n",
        "tot_cat = categorical_features + cat_bin + log_col + rev_log_col\n",
        "numeric_features = [col for col in X.columns if col not in tot_cat]\n",
        "\n",
        "log_transformer = FunctionTransformer(np.log1p)\n",
        "neg_log_transformer = FunctionTransformer(lambda x: -np.log1p(x))\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "                                  transformers=[\n",
        "                                      ('cat', ce.james_stein.JamesSteinEncoder(), categorical_features),\n",
        "                                      ('cat_bin', ce.ordinal.OrdinalEncoder(), cat_bin),\n",
        "                                      ('log', log_transformer, log_col),\n",
        "                                      ('neglog', neg_log_transformer, rev_log_col),\n",
        "                                      ('num', 'passthrough', numeric_features)]\n",
        "                                  )"
      ],
      "metadata": {
        "id": "Ys-8Oc0UeVTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X = pd.DataFrame(preprocessor.fit_transform(X,ly), columns=tot_cat+numeric_features)\n",
        "new_X_test = pd.DataFrame(preprocessor.transform(df_test_ext), columns=tot_cat+numeric_features)"
      ],
      "metadata": {
        "id": "H_dMkygUuKDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X.shape"
      ],
      "metadata": {
        "id": "ZjsLd8shvns6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X.describe(include =\"all\").T"
      ],
      "metadata": {
        "id": "r3NnMms8voUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(new_X.columns)\n",
        "\n",
        "fig, axs = plt.subplots(4, 6, figsize=(15, 6))\n",
        "axs = np.ravel(axs)\n",
        "\n",
        "for i, col in enumerate(cols):\n",
        "    sns.histplot(new_X[col], ax=axs[i], )\n",
        "    axs[i].set_title(col, fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "scw_-dcL7Yxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LABEL ENCODE CATEGORICAL FEATURES\n",
        "CAT_SIZE = []\n",
        "CAT_EMB = []\n",
        "\n",
        "for ctx in cat_bin:\n",
        "  mx = new_X[ctx].count_values().max\n",
        "  CAT_SIZE.append(mx+1) #ADD ONE FOR RARE\n",
        "  CAT_EMB.append( int(np.ceil( np.sqrt(mx+1))) ) # ADD ONE FOR RARE"
      ],
      "metadata": {
        "id": "ldtrg4V5uM3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywSI5ajuuM0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJ58480TuMw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCsz9V0_uMtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H5xPFSdmuMoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9JhExlNRU5f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}