{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/Chapter_IV_Baseline_Forecasts_using_NIXTLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter IV Baseline Forecasts using NIXTLA**"
      ],
      "metadata": {
        "id": "9sj1tF7rTVpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Importing holdout (test) and validation datasets"
      ],
      "metadata": {
        "id": "KRdlauxkTftT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M7BI02TY-xm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install statsforecast==1.7.8\n",
        "!pip install datasetsforecast==0.0.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ],
      "metadata": {
        "id": "0SfREjn8WTf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clone the repository\n",
        "!git clone https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-2E.git"
      ],
      "metadata": {
        "id": "thJeCVQoWTyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import os\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import missingno as msno\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from IPython.display import display, HTML\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "np.random.seed()\n",
        "tqdm.pandas()\n",
        "\n",
        "# Navigate to the repository's root directory\n",
        "%cd Modern-Time-Series-Forecasting-with-Python-2E\n",
        "\n",
        "from src.utils.data_utils import compact_to_expanded\n",
        "from src.imputation.interpolation import SeasonalInterpolation"
      ],
      "metadata": {
        "id": "d9q__r7fWr75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3Cu5YK6FR4CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd"
      ],
      "metadata": {
        "id": "1xUUV4hTZulN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/Books/Modern Time Series Forecasting/Chapter II/imgs/chapter_2\", exist_ok=True)\n",
        "preprocessed = Path(\"/content/drive/MyDrive/Books/Modern Time Series Forecasting/Data/data/london_smart_meters/data/london_smart_meters/preprocessed\")"
      ],
      "metadata": {
        "id": "dcEIKcoyWudv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert preprocessed.is_dir(), \"You have to run 02 - Preprocessing London Smart Meter Dataset.ipynb in Chapter02 before running this notebook\""
      ],
      "metadata": {
        "id": "BwTDEYiraK3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_plot(fig, legends = None, font_size=15, title_font_size=20):\n",
        "    if legends:\n",
        "        names = cycle(legends)\n",
        "        fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
        "    fig.update_layout(\n",
        "            autosize=False,\n",
        "            width=900,\n",
        "            height=500,\n",
        "            title={\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top'},\n",
        "            titlefont={\n",
        "                \"size\": title_font_size\n",
        "            },\n",
        "            legend_title = None,\n",
        "            legend=dict(\n",
        "                font=dict(size=font_size),\n",
        "                orientation=\"h\",\n",
        "                yanchor=\"bottom\",\n",
        "                y=0.98,\n",
        "                xanchor=\"right\",\n",
        "                x=1,\n",
        "            ),\n",
        "            yaxis=dict(\n",
        "                title_text=\"Value\",\n",
        "                titlefont=dict(size=font_size),\n",
        "                tickfont=dict(size=font_size),\n",
        "            ),\n",
        "            xaxis=dict(\n",
        "                title_text=\"Day\",\n",
        "                titlefont=dict(size=font_size),\n",
        "                tickfont=dict(size=font_size),\n",
        "            )\n",
        "        )\n",
        "    return fig"
      ],
      "metadata": {
        "id": "3mxraqG6afI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "from itertools import cycle\n",
        "\n",
        "pio.templates.default = \"plotly_white\"\n",
        "import warnings\n",
        "import humanize\n",
        "\n",
        "from functools import partial\n",
        "from statsforecast.core import StatsForecast\n",
        "from utilsforecast.plotting import plot_series\n",
        "from utilsforecast.evaluation import evaluate\n",
        "from statsforecast.models import (\n",
        "    Naive,\n",
        "    SeasonalNaive,\n",
        "    HistoricAverage,\n",
        "    WindowAverage,\n",
        "    SeasonalWindowAverage,\n",
        "    RandomWalkWithDrift,\n",
        "    HoltWinters,\n",
        "    ETS,\n",
        "    AutoETS,\n",
        "    AutoARIMA,\n",
        "    ARIMA,\n",
        "    AutoTheta,\n",
        "    DynamicTheta,\n",
        "    DynamicOptimizedTheta,\n",
        "    Theta,\n",
        "    OptimizedTheta,\n",
        "    TBATS,\n",
        "    AutoTBATS,\n",
        "    MSTL\n",
        "\n",
        ")\n",
        "from datasetsforecast.losses import *\n",
        "from src.utils.ts_utils import forecast_bias\n",
        "\n",
        "import time\n",
        "from src.utils import plotting_utils\n",
        "\n",
        "from tqdm import tqdm\n",
        "np.random.seed(42)\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "RUQg6hf3aKV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsforecast as stf\n",
        "stf.__version__"
      ],
      "metadata": {
        "id": "1by44eqWafQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this makes it so that the outputs of the predict methods have the id as a column\n",
        "# instead of as the index\n",
        "os.environ['NIXTLA_ID_AS_COL'] = '1'"
      ],
      "metadata": {
        "id": "-SUT8NIlbZ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Set up Folders**"
      ],
      "metadata": {
        "id": "9InPk747gTMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/Books/Modern Time Series Forecasting/Chapter IV/chapter_4\", exist_ok=True)\n",
        "preprocessed = Path(\"/content/drive/MyDrive/Books/Modern Time Series Forecasting/Data/data/london_smart_meters/data/london_smart_meters/preprocessed\")"
      ],
      "metadata": {
        "id": "z8JTcOcEf5Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Graph Functions and Formatting**"
      ],
      "metadata": {
        "id": "DqZJ-KTIgWdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_plot(fig, legends = None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
        "    if legends:\n",
        "        names = cycle(legends)\n",
        "        fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
        "    fig.update_layout(\n",
        "            autosize=False,\n",
        "            width=900,\n",
        "            height=500,\n",
        "            title_text=title,\n",
        "            title={\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top'},\n",
        "            titlefont={\n",
        "                \"size\": 20\n",
        "            },\n",
        "            legend_title = None,\n",
        "            legend=dict(\n",
        "                font=dict(size=font_size),\n",
        "                orientation=\"h\",\n",
        "                yanchor=\"bottom\",\n",
        "                y=0.98,\n",
        "                xanchor=\"right\",\n",
        "                x=1,\n",
        "            ),\n",
        "            yaxis=dict(\n",
        "                title_text=ylabel,\n",
        "                titlefont=dict(size=font_size),\n",
        "                tickfont=dict(size=font_size),\n",
        "            ),\n",
        "            xaxis=dict(\n",
        "                title_text=xlabel,\n",
        "                titlefont=dict(size=font_size),\n",
        "                tickfont=dict(size=font_size),\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def plot_forecast(pred_df, forecast_columns, timestamp_col, forecast_display_names=None):\n",
        "    if forecast_display_names is None:\n",
        "        forecast_display_names = forecast_columns\n",
        "    else:\n",
        "        assert len(forecast_columns) == len(forecast_display_names)\n",
        "\n",
        "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
        "    colors = [c.replace(\"rgb\", \"rgba\").replace(\")\", \", <alpha>)\") for c in px.colors.qualitative.Dark2]\n",
        "    act_color = colors[0]\n",
        "    colors = cycle(colors[1:])\n",
        "    dash_types = cycle([\"dash\", \"dot\", \"dashdot\"])\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=pred_df[mask][timestamp_col], y=pred_df[mask]['energy_consumption'],\n",
        "                             mode='lines', line=dict(color=act_color.replace(\"<alpha>\", \"0.3\")),\n",
        "                             name='Actual Consumption'))\n",
        "\n",
        "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
        "        fig.add_trace(go.Scatter(x=pred_df[mask][timestamp_col], y=pred_df.loc[mask, col],\n",
        "                                 mode='lines', line=dict(dash=next(dash_types), color=next(colors).replace(\"<alpha>\", \"1\")),\n",
        "                                 name=display_col))\n",
        "    return fig"
      ],
      "metadata": {
        "id": "38d-jaAXf5Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Load the Datasets**"
      ],
      "metadata": {
        "id": "HgHnJWoxghPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Readin the missing value imputed and train test split data\n",
        "try:\n",
        "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed.parquet\")\n",
        "    train_df = train_df[['LCLid',\"timestamp\",\"energy_consumption\",\"frequency\"]]\n",
        "    val_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed.parquet\")\n",
        "    val_df = val_df[['LCLid',\"timestamp\",\"energy_consumption\",\"frequency\"]]\n",
        "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed.parquet\")\n",
        "    test_df = test_df[['LCLid',\"timestamp\",\"energy_consumption\",\"frequency\"]]\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: File not found in {preprocessed}. Ensure you've run '01-Setting up Experiment Harness.ipynb' in Chapter 04 and that the file path is correct.\")"
      ],
      "metadata": {
        "id": "I7DhV6jMf4_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape, val_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "Mx8MV_NZg1ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Min train_df Date: \" , train_df.timestamp.min())\n",
        "print(\"Max train_df Date: \" , train_df.timestamp.max())\n",
        "print(\"Min val_df Date: \" , val_df.timestamp.min())\n",
        "print(\"Max val_df Date: \" , val_df.timestamp.max())\n",
        "print(\"Min test_df Date: \" , test_df.timestamp.min())\n",
        "print(\"Max test_df Date: \" , test_df.timestamp.max())"
      ],
      "metadata": {
        "id": "jMyZHqBDf41i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[train_df.timestamp >'2012-01-01']\n",
        "print(\"Min train_df Date: \" , train_df.timestamp.min())"
      ],
      "metadata": {
        "id": "kS4AH_1rglyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "5GUfuNZzgyRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#picking a single time series from the dataset for illustration\n",
        "freq = train_df.iloc[0]['frequency']\n",
        "ts_train = train_df.loc[train_df.LCLid==\"MAC000193\", ['LCLid',\"timestamp\",\"energy_consumption\"]]\n",
        "ts_val = val_df.loc[val_df.LCLid==\"MAC000193\", ['LCLid',\"timestamp\",\"energy_consumption\"]]\n",
        "ts_test = test_df.loc[test_df.LCLid==\"MAC000193\", ['LCLid',\"timestamp\",\"energy_consumption\"]]"
      ],
      "metadata": {
        "id": "VnoflyU4gqhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_train.shape"
      ],
      "metadata": {
        "id": "9_d7x5UtgtSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Baseline Forecasts"
      ],
      "metadata": {
        "id": "IzUBM0NdR2b8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Choosing an evaluation metric**\n",
        "\n",
        "In machine learning, we have a handful of metrics that can be used to measure continuous outputs,\n",
        "mainly Mean Absolute Error (MAE) and Mean Squared Error (MSE). But in the time series forecasting\n",
        "realm, there are scores of metrics with no real consensus on which ones to use. One of the reasons for\n",
        "this overwhelming number of metrics is that no one metric measures every characteristic of a forecast.\n",
        "Therefore, we have a whole chapter devoted to this topic (Chapter 18, Evaluating Forecasts – Forecast\n",
        "Metrics). For now, we will just review a few metrics, all of which we are going to use to measure the\n",
        "forecasts. We are just going to consider them at face value:\n",
        "* **Mean Absolute Error** (MAE): MAE is a very simple metric. It is the average of the unsigned\n",
        "error between the forecast at timestep() and the observed value at time ().\n",
        "Here, N is the number of time series, L is the length of time series (in this case, the length of\n",
        "the test period), and f and y are the forecast and observed values, respectively.\n",
        "* **Mean Squared Error** (MSE): MSE is the average of the squared error between the forecast ( )\n",
        "and observed ( ).\n",
        "* **Mean Absolute Scaled Error** (MASE): MASE is slightly more complicated than MSE or MAE\n",
        "but gives us a slightly better measure to overcome the scale-dependent nature of the previous\n",
        "two measures. If we have multiple time series with different average values, MAE and MSE\n",
        "will show higher errors for the high-value time series as opposed to the low-valued time series.\n",
        "MASE overcomes this by scaling the errors based on the in-sample MAE from the naïve\n",
        "forecasting method (which is one of the most basic forecasts possible; we will review it later\n",
        "in this chapter). Intuitively, MASE gives us the measure of how much better our forecast is as\n",
        "compared to the naïve forecast:\n",
        "* **Forecast Bias** (FB): This is a metric with slightly different aspects from the other metrics we’ve seen. While the other metrics help assess the correctness of the forecast, irrespective of the direction of the error, forecast bias lets us understand the overall bias in the model. Forecast\n",
        "bias is a metric that helps us understand whether the forecast is continuously over- or under forecasting. We calculate forecast bias as the difference between the sum of the forecast and the\n",
        "sum of the observed values, expressed as a percentage over the sum of all actuals:\n",
        "\n",
        "Now, our test harness is ready. We also know how to evaluate and compare forecasts that have been\n",
        "generated from different models on a single, fixed holdout dataset with a set of predetermined metrics. Now, it’s time to start forecasting."
      ],
      "metadata": {
        "id": "9SFMsTHISrK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.concat([ts_train, ts_val])"
      ],
      "metadata": {
        "id": "oC8d8VIkUTST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_performance(ts_train, ts_test, models, metrics, freq, level, id_col, time_col, target_col, h, metric_df=None):\n",
        "    if metric_df is None:\n",
        "        metric_df = pd.DataFrame()  # Initialize an empty DataFrame if not provided\n",
        "\n",
        "    results = ts_test.copy()\n",
        "\n",
        "    # Timing dictionary to store train and predict durations\n",
        "    timing = {}\n",
        "\n",
        "    for model in models:\n",
        "        model_name = model.__class__.__name__\n",
        "        evaluation = {}  # Reset the evaluation dictionary for each model\n",
        "\n",
        "        # Start the timer for fitting and prediction\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Instantiate StatsForecast class\n",
        "        sf = StatsForecast(\n",
        "            models=[model],\n",
        "            freq=freq,\n",
        "            n_jobs=-1,\n",
        "            fallback_model=Naive()\n",
        "        )\n",
        "\n",
        "        # Efficiently predict without storing memory\n",
        "        y_pred = sf.forecast(\n",
        "            h=h,\n",
        "            df=ts_train,\n",
        "            id_col=id_col,\n",
        "            time_col=time_col,\n",
        "            target_col=target_col,\n",
        "            level=level,\n",
        "        )\n",
        "\n",
        "        # Calculating the duration\n",
        "        duration = time.time() - start_time\n",
        "        timing[model_name] = duration\n",
        "\n",
        "        # Merge prediction results to the original dataframe\n",
        "        results = results.merge(y_pred, how='left', on=[id_col, time_col])\n",
        "\n",
        "        ids = ts_train[id_col].unique()\n",
        "        # Calculate metrics\n",
        "        for id in ids:\n",
        "            temp_results = results[results[id_col] == id]\n",
        "            temp_train = ts_train[ts_train[id_col] == id]\n",
        "            for metric in metrics:\n",
        "                metric_name = metric.__name__\n",
        "                #print(metric_name)\n",
        "                if metric_name == 'mase':\n",
        "                    evaluation[metric_name] = metric(temp_results[target_col].values,\n",
        "                                                    temp_results[model_name].values,\n",
        "                                                    temp_train[target_col].values, seasonality=48)\n",
        "                #elif metric_name == 'smape':\n",
        "                #    print(metric(temp_results[target_col].values, temp_results[model_name].values))\n",
        "\n",
        "                else:\n",
        "                    evaluation[metric_name] = metric(temp_results[target_col].values, temp_results[model_name].values)\n",
        "            evaluation[id_col] = id\n",
        "            evaluation['Time Elapsed'] = timing[model_name]\n",
        "\n",
        "            # Prepare and append this model's results to metric_df\n",
        "            temp_df = pd.DataFrame(evaluation, index=[0])\n",
        "            temp_df['Model'] = model_name\n",
        "            metric_df = pd.concat([metric_df, temp_df], ignore_index=True)\n",
        "\n",
        "    return results, metric_df"
      ],
      "metadata": {
        "id": "WFm2GMbKUWDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Naïve forecast**\n",
        "\n",
        "A naïve forecast is as simple as you can get. The forecast is just the last/most recent observation in a time series. If the latest observation in a time series is 10, then the forecast for all future timesteps is 10. This can be implemented as follows using the NaiveSeasonal class in darts:"
      ],
      "metadata": {
        "id": "Qaz8581xT4az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame()\n",
        "\n",
        "results, metrics = evaluate_performance(\n",
        "                                        ts_train=ts_train,\n",
        "                                        ts_test=ts_val,\n",
        "                                        models=[Naive()],\n",
        "                                        metrics=[mase, mae, mse, rmse, forecast_bias],\n",
        "                                        freq=freq,\n",
        "                                        level=[],  # Ensure this is correct or adjust as necessary\n",
        "                                        id_col='LCLid',\n",
        "                                        time_col='timestamp',\n",
        "                                        target_col='energy_consumption',\n",
        "                                        h=len(ts_val),\n",
        "                                        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "                                    )"
      ],
      "metadata": {
        "id": "UfRVyMMIgwTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "Dxd4XXO4R8zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['Naive']\n",
        "model_display_name = ['Naive']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/naive.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AwO2Njf0SG0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Moving average forecast**\n",
        "While a naïve forecast memorizes the most recent past, it also memorizes the noise at any timestep.\n",
        "A moving average forecast is another simple method that tries to overcome the pure memorization\n",
        "of the naïve method. Instead of taking the latest observation, it takes the mean of the latest n steps as the forecast. Moving average is not one of the models present in darts, but we have implemented a darts-compatible model in this book’s GitHub repository in the chapter04 folder:"
      ],
      "metadata": {
        "id": "JcVn3qxlo_Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [WindowAverage(window_size = 48)],\n",
        "        metrics = [mase, mae, mse, rmse,forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "6n3rGh-9k2ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "K6WRJbtZk3ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['WindowAverage']\n",
        "model_display_name = ['WindowAverage']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/window_average.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ruCfq9h-pS1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Seasonal naive forecast**\n",
        "A seasonal naive forecast is a twist on the simple naive method. Whereas in the naive method, we\n",
        "took the last observation (Yt−1), in seasonal naïve, we take the Yt−k observation. So, we look back k steps for each forecast. This enables the algorithm to mimic the last seasonality cycle. For instance, if we set k=48*7, we will be able to mimic the latest seasonal weekly cycle. This method is implemented in darts and we can use it like so:"
      ],
      "metadata": {
        "id": "uPf3IauWqs7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "                    evaluate_performance(\n",
        "                        ts_train=ts_train,\n",
        "                        ts_test=ts_val,\n",
        "                        models = [SeasonalNaive(season_length=48*7)],\n",
        "                        metrics = [mase, mae, mse, rmse, forecast_bias],\n",
        "                        freq = freq,\n",
        "                        level = [] ,\n",
        "                        id_col = 'LCLid',\n",
        "                        time_col = 'timestamp',\n",
        "                        target_col = 'energy_consumption',\n",
        "                        h = len(ts_val),\n",
        "                        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "                        )\n",
        "                    )"
      ],
      "metadata": {
        "id": "Px8gy0Gypd_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.head()"
      ],
      "metadata": {
        "id": "YPj7bqGlrJa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "kCPo8wMfrQUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['SeasonalNaive']\n",
        "model_display_name = ['SeasonalNaive']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/seasonal_naive.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ptV8ZeubrK2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exponential smoothing (ETS)**\n",
        "Exponential smoothing (ETS) is one of the most popular methods for generating forecasts. It has been around since the late 1950s and has proved its mettle and stood the test of time. There are a few different variants of ETS – **single exponential smoothing**, **double exponential smoothing**, **Holt-Winters’ seasonal smoothing**, and so on. But all of them have one key idea that has been used in different ways.\n",
        "In the naïve method, we were just using the latest observation, which is like saying only the most recent data point in history matters and no data point before that matters. On the other hand, the moving average method considers the last n observations to be equally important and takes the mean of them.\n",
        "ETS combines both these intuitions and says that all the history is important, but the recent history is more important. Therefore, the forecast is generated using a weighted average where the weights decrease exponentially as we move farther into the history"
      ],
      "metadata": {
        "id": "1Ret4i4lsWuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [ HoltWinters(error_type = 'A', season_length = 48)],\n",
        "        metrics = [mase, mae, mse, rmse,forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "wAP88iBJrSeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "3VsLjKfUtjLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['HoltWinters']\n",
        "model_display_name = ['HoltWinters']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/ets.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "OGOw7wKGue-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [ AutoETS(model = 'AAA',season_length = 48)],\n",
        "        metrics = [mase, mae, mse, rmse,forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "UOmws9pluvof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "c_OpA160u5F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['AutoETS']\n",
        "model_display_name = ['AutoETS']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/ets.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "zqFqdrVXu7Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ARIMA**\n",
        "Autoregressive Integrated Moving Average (ARIMA) models are the other class of methods that, like\n",
        "ETS, have stood the test of time and are one of the most popular classical methods of forecasting. The\n",
        "ETS family of methods is modeled around trend and seasonality, while ARIMA relies on autocorrelation\n",
        "(the correlation of with −1, −2, and so on)"
      ],
      "metadata": {
        "id": "lUDoma3hvY5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [ ARIMA(order = (2,1,1), seasonal_order = (1,1,1), season_length = 48)],\n",
        "#        models = [ ARIMA(order = (0,1,2), seasonal_order = (0,0,2), season_length = 48)],\n",
        "        metrics = [mase, mae, mse, rmse, forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "Y_QhwURCu9r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "9DnNU6zR91au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "Yp4hgBgRviRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['ARIMA']\n",
        "model_display_name = ['ARIMA']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/ARIMA.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "qKaV5EU0vkCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sample Auto ARIMA**\n",
        "\n",
        "Note: This may take a long time to run.\n",
        "\n",
        "To get a better understanding of what parameters to use, you can run AutoARIMA and output the fitted parameters. AutoARIMA however is very slow, so I have includedd a sample output from AutoARIMA."
      ],
      "metadata": {
        "id": "SxzPTsv5v7eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'arma': (0, 2, 0, 2, 48, 1, 0)"
      ],
      "metadata": {
        "id": "3apcjMXD9YGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sf = StatsForecast(\n",
        "#     models=[AutoARIMA( max_p = 2, max_d=1, max_q = 2, max_P=2, max_D = 1, max_Q = 2,\n",
        "#                       start_p = 1, start_q = 1, start_P = 1, start_Q = 1, stepwise = True, season_length=48)],\n",
        "#     freq=freq,\n",
        "#     n_jobs=-1,\n",
        "#     fallback_model = Naive()\n",
        "# )\n",
        "\n",
        "# y_pred = sf.fit(\n",
        "\n",
        "#                     df=ts_train,\n",
        "#                     id_col = 'LCLid',\n",
        "#                     time_col = 'timestamp',\n",
        "#                     target_col = 'energy_consumption',\n",
        "\n",
        "#                     )\n",
        "\n",
        "# sf.fitted_[0,0].model_"
      ],
      "metadata": {
        "id": "IQHUaMn4vl7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Theta Forecast**\n",
        "The Theta Forecast was the top-performing submission in the M3 forecasting competition that was\n",
        "held in 2002. The method relies on a parameter, θ, that amplifies or smooths the local curvature of a time series, depending on the value chosen. Using θ, we smooth or amplify the original time series.\n",
        "\n",
        "These smoothed lines are called theta lines. V. Assimakopoulos and K. Nikolopoulos proposed this\n",
        "method as a decomposition approach to forecasting. Although in theory any number of theta lines\n",
        "can be used, the originally proposed method used two theta lines, =0 and =2, and took an average\n",
        "of the forecast of the two theta lines as the final forecast."
      ],
      "metadata": {
        "id": "ZH4l39NC5NeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [ Theta(season_length =48, decomposition_type = 'additive' )],\n",
        "        metrics = [mase, mae, mse, rmse, forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "yuhGNzhmwjv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "7XcPkqQD6Tso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['Theta']\n",
        "model_display_name = ['Theta']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/auto_theta.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "R_fsBLko6Vmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TBATS**\n",
        "\n",
        "NIXTLA again offers TBATS and AutoTBATS. AutoTBATS can be slow, so here we will just do TBATS. Similar to AutoARIMA, you can run a model using AutoTBATS to get a recommendation of good parameters to use."
      ],
      "metadata": {
        "id": "17yl-HDn7SvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sf = StatsForecast(\n",
        "    models=[TBATS(seasonal_periods  = 48, use_trend=True, use_damped_trend=True)],\n",
        "    freq=freq,\n",
        "    n_jobs=2\n",
        ")\n",
        "\n",
        "y_pred = sf.fit(\n",
        "\n",
        "                    df=ts_train,\n",
        "                    id_col = 'LCLid',\n",
        "                    time_col = 'timestamp',\n",
        "                    target_col = 'energy_consumption',\n",
        "\n",
        "                    )\n",
        "#sf.fitted_[0,0].model_"
      ],
      "metadata": {
        "id": "8DL06POr6Vj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [ TBATS(seasonal_periods = [48])],\n",
        "        metrics = [mase, mae, mse, rmse,forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "0RB0sZQD6Vg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "s37Kxm_--PPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MSTL**"
      ],
      "metadata": {
        "id": "EzY4RQ8EAl2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, metrics = (\n",
        "    evaluate_performance(\n",
        "        ts_train,\n",
        "        ts_val,\n",
        "        models = [ MSTL(season_length = 48)],\n",
        "        metrics = [mase, mae, mse, rmse, forecast_bias],\n",
        "        freq = freq,\n",
        "        level = [] ,\n",
        "        id_col = 'LCLid',\n",
        "        time_col = 'timestamp',\n",
        "        target_col = 'energy_consumption',\n",
        "        h = len(ts_val),\n",
        "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "id": "WT2guB0F6VeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ['MSTL']\n",
        "model_display_name = ['MSTL']\n",
        "\n",
        "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
        "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
        "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
        "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
        "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
        "#fig.write_image(\"imgs/chapter_4/auto_tbats.png\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Ec-VqkuP6VbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_styled = metrics.reset_index(drop=True).style.format({\n",
        "            \"mae\": \"{:.3f}\",\n",
        "            \"mse\": \"{:.3f}\",\n",
        "            \"mase\": \"{:.3f}\",\n",
        "            \"rmse\": \"{:.3f}\",\n",
        "            \"forecast_bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"mae\",\"mse\",\"mase\",\"rmse\",\"Time Elapsed\"])\n",
        "display(metric_styled)"
      ],
      "metadata": {
        "id": "S9FJk1hc6VV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on this sample test, the best performing models are (HoltWinters, and ETS), ARIMA, and TBATS. Lets build that for all models using AutoETS and TBATS. ARIMA gives similar performance to TBATS, but TBATS is faster."
      ],
      "metadata": {
        "id": "llqkicREA_1p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84gzaBeo6VSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}