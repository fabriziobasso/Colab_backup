{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 82611,
          "databundleVersionId": 9553358,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/brist1d_ricopue_conv2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import plot_model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import gc,os,random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:04:57.743472Z",
          "iopub.execute_input": "2024-11-19T11:04:57.743867Z",
          "iopub.status.idle": "2024-11-19T11:05:17.570321Z",
          "shell.execute_reply.started": "2024-11-19T11:04:57.743832Z",
          "shell.execute_reply": "2024-11-19T11:05:17.569171Z"
        },
        "id": "8uCtjrfnMQVI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seeds(seed=2024)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:05:17.572269Z",
          "iopub.execute_input": "2024-11-19T11:05:17.5729Z",
          "iopub.status.idle": "2024-11-19T11:05:17.579612Z",
          "shell.execute_reply.started": "2024-11-19T11:05:17.572846Z",
          "shell.execute_reply": "2024-11-19T11:05:17.578502Z"
        },
        "id": "1gTGAsfFMQVL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('/kaggle/input/brist1d/train.csv')\n",
        "test=pd.read_csv('/kaggle/input/brist1d/test.csv')\n",
        "\n",
        "train.columns = train.columns.str.replace(':', '_')\n",
        "train.columns = train.columns.str.replace('-', '_')\n",
        "test.columns = test.columns.str.replace(':', '_')\n",
        "test.columns = test.columns.str.replace('-', '_')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:05:17.581263Z",
          "iopub.execute_input": "2024-11-19T11:05:17.58175Z",
          "iopub.status.idle": "2024-11-19T11:05:30.635902Z",
          "shell.execute_reply.started": "2024-11-19T11:05:17.581701Z",
          "shell.execute_reply": "2024-11-19T11:05:30.634691Z"
        },
        "id": "rsLItrdfMQVM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_cols=train.columns.tolist()\n",
        "bg_cols   = [col for col in train_cols if \"bg_\" in col ]\n",
        "insu_cols = [col for col in train_cols if \"insulin_\" in col ]\n",
        "carb_cols = [col for col in train_cols if \"carbs_\" in col ]\n",
        "hr_cols   = [col for col in train_cols if \"hr_\" in col ]\n",
        "step_cols = [col for col in train_cols if \"steps_\" in col ]\n",
        "cals_cols = [col for col in train_cols if \"cals_\" in col ]\n",
        "\n",
        "actv_cols = [col for col in train_cols if \"activity_\" in col ] # --> 98% of nan values\n",
        "train.drop(columns=actv_cols,inplace=True)\n",
        "test.drop(columns=actv_cols,inplace=True)\n",
        "\n",
        "print(len(bg_cols),len(insu_cols),len(carb_cols),len(hr_cols),len(step_cols),len(cals_cols), len(actv_cols))\n",
        "feature_cols =  carb_cols + hr_cols + bg_cols + insu_cols + step_cols + cals_cols\n",
        "print([col for col in train.columns.tolist() if col not in feature_cols])\n",
        "\n",
        "#target\n",
        "train.columns = train.columns.str.replace('bg+1_00', 'target')\n",
        "test['target']=0\n",
        "\n",
        "#feature to create validation groups\n",
        "print(train.p_num.unique())\n",
        "print(test.p_num.unique())\n",
        "\n",
        "#Time feature no used\n",
        "train.drop(columns=['id','time',],inplace=True)\n",
        "test.drop(columns=['id','time'],inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:05:30.638215Z",
          "iopub.execute_input": "2024-11-19T11:05:30.638604Z",
          "iopub.status.idle": "2024-11-19T11:05:31.125555Z",
          "shell.execute_reply.started": "2024-11-19T11:05:30.638569Z",
          "shell.execute_reply": "2024-11-19T11:05:31.124353Z"
        },
        "id": "XPC56-NiMQVM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#impute missing --> from https://www.kaggle.com/code/greysky/brist1d-blood-glucose-prediction-tabnet\n",
        "for colset in [bg_cols, insu_cols, carb_cols, hr_cols, step_cols, cals_cols]:\n",
        "    train[colset] = train[colset].interpolate(axis=1)\n",
        "    test[colset] = test[colset].interpolate(axis=1)\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "train[feature_cols] = imputer.fit_transform(train[feature_cols])\n",
        "test[feature_cols] = imputer.transform(test[feature_cols])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:05:31.126825Z",
          "iopub.execute_input": "2024-11-19T11:05:31.127153Z",
          "iopub.status.idle": "2024-11-19T11:06:00.145656Z",
          "shell.execute_reply.started": "2024-11-19T11:05:31.127122Z",
          "shell.execute_reply": "2024-11-19T11:06:00.144362Z"
        },
        "id": "pu7oW73KMQVN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale features\n",
        "df_tmp=pd.concat([train,test])\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "df_tmp[feature_cols]=scaler.fit_transform(df_tmp[feature_cols])\n",
        "\n",
        "train=df_tmp[:len(train)]\n",
        "test=df_tmp[len(train):]\n",
        "del df_tmp\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-19T11:06:00.14693Z",
          "iopub.execute_input": "2024-11-19T11:06:00.147265Z",
          "iopub.status.idle": "2024-11-19T11:06:02.835519Z",
          "shell.execute_reply.started": "2024-11-19T11:06:00.147231Z",
          "shell.execute_reply": "2024-11-19T11:06:02.834374Z"
        },
        "trusted": true,
        "id": "piV6bEz2MQVN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,data,target,data_index,train_features,batch_size=1024*10,shuffle=False,mode='train',*args, **kwargs):\n",
        "\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.data=data\n",
        "        self.target=target\n",
        "        self.features=train_features\n",
        "        self.data_index = data_index\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.mode = mode\n",
        "        self.n = 0\n",
        "        self.max = self.__len__()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        ct = int( np.ceil( len(self.data_index) / self.batch_size ) )\n",
        "        return ct\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X,y = self.__data_generation(indexes)\n",
        "        return X,y\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.n >= self.max:\n",
        "            self.n = 0\n",
        "        result = self.__getitem__(self.n)\n",
        "        self.n += 1\n",
        "        return result\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = self.data_index\n",
        "        if self.shuffle: np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        X = self.data.iloc[indexes][self.features]\n",
        "        X = X.values.reshape(len(indexes),6,int(len(feature_cols)/6))\n",
        "        y = self.data.iloc[indexes][self.target].values\n",
        "\n",
        "        return X,y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:06:02.837049Z",
          "iopub.execute_input": "2024-11-19T11:06:02.837418Z",
          "iopub.status.idle": "2024-11-19T11:06:02.85075Z",
          "shell.execute_reply.started": "2024-11-19T11:06:02.837371Z",
          "shell.execute_reply": "2024-11-19T11:06:02.849386Z"
        },
        "id": "wLcfLrL2MQVN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = DataGenerator(train,'target',train.head(1024).index,feature_cols,shuffle=False, batch_size=1024,mode='train')\n",
        "X,y=next(gen)\n",
        "\n",
        "for i in range(0,1024,300):\n",
        "    print(X[i].shape,y[i])\n",
        "    print(X.shape)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(X[i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:06:02.85219Z",
          "iopub.execute_input": "2024-11-19T11:06:02.852705Z",
          "iopub.status.idle": "2024-11-19T11:06:03.616966Z",
          "shell.execute_reply.started": "2024-11-19T11:06:02.852664Z",
          "shell.execute_reply": "2024-11-19T11:06:03.615647Z"
        },
        "id": "U_V5YCAKMQVO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "def make_model(img_rows,img_cols,channnels):\n",
        "\n",
        "    input_model = tf.keras.layers.Input(shape=(img_rows,img_cols,channnels))\n",
        "\n",
        "    ########################################################\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(6,3), activation='relu')(input_model)\n",
        "    conv1 = tf.keras.layers.Conv2D(64, kernel_size=(1,3),padding='same', activation='relu')(conv1)\n",
        "    conv1 = tf.keras.layers.MaxPooling2D(1,2)(conv1)\n",
        "    conv1 = tf.keras.layers.Conv2D(128, kernel_size=(1,3),padding='same', activation='relu')(conv1)\n",
        "    conv1 = tf.keras.layers.Flatten()(conv1)\n",
        "\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(conv1)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_model, outputs=output)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss = 'mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "img_rows=6\n",
        "img_cols=72\n",
        "channnels=1\n",
        "model=make_model(img_rows,img_cols,channnels)\n",
        "model.summary()\n",
        "#plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "#from IPython.display import Image\n",
        "#Image(retina=True, filename='model.png')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:06:03.618639Z",
          "iopub.execute_input": "2024-11-19T11:06:03.619135Z",
          "iopub.status.idle": "2024-11-19T11:06:03.821069Z",
          "shell.execute_reply.started": "2024-11-19T11:06:03.619086Z",
          "shell.execute_reply": "2024-11-19T11:06:03.820018Z"
        },
        "id": "1yTACX9_MQVO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cv = GroupKFold(5)\n",
        "K.clear_session()\n",
        "test_gen=DataGenerator(test,'target',test.index,feature_cols,shuffle=False, batch_size=256,mode='test')\n",
        "train_oof= np.zeros((len(train)))\n",
        "test_preds= np.zeros((len(test)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in cv.split(train, train.target, groups=train['p_num']):\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min', baseline=None, restore_best_weights=True)\n",
        "    rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3,  mode='min', verbose=0)\n",
        "\n",
        "    print('train_p_num:',train.iloc[train_index]['p_num'].unique(),'*********  valid_p_num:',train.iloc[valid_index]['p_num'].unique())\n",
        "\n",
        "    train_gen=DataGenerator(train,'target',train_index,feature_cols,shuffle=False, batch_size=256,mode='train')\n",
        "    valid_gen=DataGenerator(train,'target',valid_index,feature_cols,shuffle=False, batch_size=256,mode='train')\n",
        "    print(len(train_index),len(valid_index))\n",
        "    model=make_model(img_rows,img_cols,channnels)\n",
        "    model.fit(train_gen,validation_data =valid_gen, verbose=1, epochs=50,callbacks = [rlr,es] )\n",
        "\n",
        "    test_preds += model.predict(test_gen,verbose=0).ravel()/5\n",
        "\n",
        "    oof_preds = model.predict(valid_gen,verbose=0).ravel()\n",
        "    train_oof[valid_index] = oof_preds\n",
        "    rmse = np.sqrt(mean_squared_error(train.iloc[valid_index].target, oof_preds))\n",
        "    print(f\"RMSE oof Score: {rmse}\")\n",
        "\n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(train.target, train_oof))\n",
        "print(f\"RMSE Score: {rmse}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T11:06:03.823644Z",
          "iopub.execute_input": "2024-11-19T11:06:03.823996Z",
          "iopub.status.idle": "2024-11-19T14:00:17.326008Z",
          "shell.execute_reply.started": "2024-11-19T11:06:03.823962Z",
          "shell.execute_reply": "2024-11-19T14:00:17.324696Z"
        },
        "id": "zN6aSCeoMQVP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission=pd.read_csv('/kaggle/input/brist1d/sample_submission.csv')\n",
        "submission['bg+1:00']=test_preds\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "submission.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-19T14:00:17.356405Z",
          "iopub.status.idle": "2024-11-19T14:00:17.35705Z",
          "shell.execute_reply.started": "2024-11-19T14:00:17.356793Z",
          "shell.execute_reply": "2024-11-19T14:00:17.356834Z"
        },
        "id": "5wrTYkoCMQVP"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}