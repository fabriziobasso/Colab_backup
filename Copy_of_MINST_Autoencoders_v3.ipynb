{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/Copy_of_MINST_Autoencoders_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcOHxLaaQMzu"
      },
      "source": [
        "# **AUTOENCODERS for DIMENSION REDUCTION: A STUDY**\n",
        "\n",
        "There are so many practical applications of autoencoders. Dimensionality reduction is one of them.\n",
        "\n",
        "There are so many techniques for dimensionality reduction. Autoencoders (AEs) and Principal Component Analysis (PCA) are popular among them.\n",
        "\n",
        "PCA is not suitable for dimensionality reduction in non-linear data. In contrast, autoencoders work really well with non-linear data in dimensionality reduction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05njbizeaM4B"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# adabelief\n",
        "!pip install adabelief-tf --no-cache-di\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwUe2neLj69S"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "# Connect to Colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "old_wd = os.getcwd()\n",
        "os.chdir(\"/content/drive/MyDrive/Exercises/Autoencoders\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgS4VpZURQZH"
      },
      "outputs": [],
      "source": [
        "# Acquire MNIST data\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, KFold\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import MultiHeadAttention, Attention\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Add, Concatenate, Dropout, BatchNormalization, Conv1D, Reshape, Flatten, AveragePooling1D, MaxPool1D\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow_addons.activations import sparsemax\n",
        "from tensorflow_addons.metrics import FBetaScore, F1Score\n",
        "from adabelief_tf import AdaBeliefOptimizer\n",
        "from keras import layers\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxEeEzK2VblR"
      },
      "source": [
        "**Objectives**\n",
        "\n",
        "At the end of this article, youâ€™ll be able to\n",
        "\n",
        "* Use Autoencoders to reduce the dimensionality of the input data\n",
        "* Use PCA to reduce the dimensionality of the input data\n",
        "* Compare the performance of PCA and Autoencoders in dimensionality reduction\n",
        "* See how Autoencoders outperform PCA in dimensionality reduction\n",
        "* Learn key differences between PCA and Autoencoders\n",
        "* Learn when to use which method for dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMwDPH8TR-4K"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx6Gp_ozSAIX"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq4bXXIQQGMl"
      },
      "outputs": [],
      "source": [
        "# Reshape data\n",
        "train_images = np.reshape(train_images, (-1, 784))\n",
        "test_images = np.reshape(test_images, (-1, 784))\n",
        "\n",
        "# Normalize data\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXbhvG37lcq_"
      },
      "source": [
        "### TRAIN VALIDATION SPLIT:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aSGrSHAlopN"
      },
      "outputs": [],
      "source": [
        "X_t, X_v, y_t, y_v = train_test_split(train_images, train_labels, stratify=train_labels, test_size=0.16, random_state=1978)\n",
        "\n",
        "print(\"Test-Validation Split Sizes: {}, {}, {}. and {}\".format(X_t.shape, y_t.shape, X_v.shape, y_v.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_a3EzTDQ6vf"
      },
      "source": [
        "## 1.0 Traditional Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test PCA:"
      ],
      "metadata": {
        "id": "-J6WwtmPQnKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBwApBd2QNaV"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca.fit(train_images)\n",
        "compressed_images = pca.transform(test_images)\n",
        "recovered_images = pca.inverse_transform(compressed_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IOc6oEvRBD5"
      },
      "outputs": [],
      "source": [
        "# Visualize compressed MNIST digits after PCA\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(recovered_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuohoL20RXmK"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2, whiten=True)\n",
        "pca.fit(train_images)\n",
        "compressed_images = pca.transform(test_images)\n",
        "recovered_images = pca.inverse_transform(compressed_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcq-HzpERjd0"
      },
      "outputs": [],
      "source": [
        "# Visualize compressed MNIST digits after PCA\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(recovered_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rWwSc_dRlul"
      },
      "outputs": [],
      "source": [
        "# Visualize compressed MNIST digits after PCA\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(test_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wFNdPvNR3ws"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=compressed_images[:,0],\n",
        "                y=compressed_images[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"First principal component\")\n",
        "plt.ylabel(\"Second principal component\")\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LinearDiscriminantAnalysis"
      ],
      "metadata": {
        "id": "X4WYG95SRyjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.manifold import Isomap"
      ],
      "metadata": {
        "id": "14RbVdOkRyYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "#embedding = Isomap(n_neighbors=30, n_components=2)\n",
        "#X_transformed = embedding.fit(train_images)"
      ],
      "metadata": {
        "id": "kA2PfhbDjKGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **DEFINE CALLBACKS**"
      ],
      "metadata": {
        "id": "D-vgPzYJgZ6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuPIrRzwa3dJ"
      },
      "outputs": [],
      "source": [
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                        factor=0.75,\n",
        "                        patience=10,\n",
        "                        verbose=1,\n",
        "                        mode=\"min\")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                            patience=25,\n",
        "                            verbose=1,\n",
        "                            mode=\"min\",\n",
        "                            restore_best_weights=True)\n",
        "\n",
        "\n",
        "checkpoint_filepath = '/checkpoint/'\n",
        "\n",
        "Checkpoint = tf.keras.callbacks.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor=\"val_loss\",\n",
        "                                                 mode='min',\n",
        "                                                 restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orUqX6jiYmIN"
      },
      "source": [
        "## **2.0 Perform dimensionality reduction with Autoencoder**\n",
        "Now, weâ€™ll build a deep autoencoder to apply dimensionality reduction to the same MNIST data. We also keep the dimensionality of the latent vector two-dimensional so that it is easy to compare the output with the previous output returned by PCA.\n",
        "\n",
        "- Step 1: Acquire and prepare the MNIST dataset as previously.\n",
        "- Step 2: Define the autoencoder architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ-NxiZniR4a"
      },
      "outputs": [],
      "source": [
        "def model_autoencoder(act_1='sigmoid',act_lat='tanh'):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, activation=act_1)(input_layer)\n",
        "  enc_layer_2 = Dense(300, activation=act_1)(enc_layer_1)\n",
        "  enc_layer_3 = Dense(100, activation=act_1)(enc_layer_2)\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation=act_lat)(enc_layer_3)\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, activation=act_1)(encoder)\n",
        "  dec_layer_2 = Dense(300, activation=act_1)(dec_layer_1)\n",
        "  dec_layer_3 = Dense(500, activation=act_1)(dec_layer_2)\n",
        "  dec_layer_4 = Dense(input_dim, activation=act_1)(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxmt3FfljPD3"
      },
      "outputs": [],
      "source": [
        "input_dim = 28*28\n",
        "latent_vec_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "# First build the encoder\n",
        "enc_layer_1 = Dense(500, activation='sigmoid')(input_layer)\n",
        "enc_layer_2 = Dense(300, activation='sigmoid')(enc_layer_1)\n",
        "enc_layer_3 = Dense(100, activation='sigmoid')(enc_layer_2)\n",
        "enc_layer_4 = Dense(latent_vec_dim, activation='tanh')(enc_layer_3)\n",
        "encoder = enc_layer_4\n",
        "\n",
        "# Then build the decoder\n",
        "dec_layer_1 = Dense(100, activation='sigmoid')(encoder)\n",
        "dec_layer_2 = Dense(300, activation='sigmoid')(dec_layer_1)\n",
        "dec_layer_3 = Dense(500, activation='sigmoid')(dec_layer_2)\n",
        "dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "decoder = dec_layer_4\n",
        "\n",
        "# Connect both encoder and decoder\n",
        "autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "# Latent representation (Optional)\n",
        "latent_model = Model(input_layer, encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTm0rxhHnZQd"
      },
      "outputs": [],
      "source": [
        "X_t.shape, y_t.shape, X_v.shape, y_v.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCDDiJwzoYNb"
      },
      "source": [
        "### 2.1 Optimizing Alogrithm: ADAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6WcmRkXXVcb"
      },
      "outputs": [],
      "source": [
        "autoencoder_adam_lr, latent_model_adam_lr = model_autoencoder(act_1='sigmoid',act_lat='tanh')\n",
        "\n",
        "# Get summary\n",
        "autoencoder_adam_lr.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNbmoAArYz7T"
      },
      "outputs": [],
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_adam_lr.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_lr = autoencoder_adam_lr.fit(X_t, X_t, epochs=250, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                          shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_adam_lr.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/adam/autoencoder')\n",
        "latent_model_adam_lr.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/adam/encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foiNdMQQZWCq"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_lr.history['loss'], label='Train')\n",
        "plt.plot(history_lr.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV8ENGvtZ7-W"
      },
      "outputs": [],
      "source": [
        "compressed_images = autoencoder_adam_lr.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4ftrGomhqkm"
      },
      "outputs": [],
      "source": [
        "latent_representation = latent_model_adam_lr.predict(test_images)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cJgEwd5UxnL"
      },
      "source": [
        "#### Adam with no LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4N3JTTaUlwC"
      },
      "outputs": [],
      "source": [
        "autoencoder_adam, latent_model_adam = model_autoencoder(act_1='sigmoid',act_lat='tanh')\n",
        "\n",
        "# Get summary\n",
        "autoencoder_adam.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4WJHaThUwCf"
      },
      "outputs": [],
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_adam.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_nolr = autoencoder_adam.fit(X_t, X_t, epochs=100, batch_size=128, callbacks = [early_stop, Checkpoint],\n",
        "                          shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_adam.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/adam_nolr/autoencoder')\n",
        "latent_model_adam.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/adam_nolr/encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2exAaxgUwCg"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.plot(history_nolr.history['loss'], label='Train')\n",
        "plt.plot(history_nolr.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dexW5v4RUwCg"
      },
      "outputs": [],
      "source": [
        "compressed_images = autoencoder_adam.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEM1e50DUwCg"
      },
      "outputs": [],
      "source": [
        "latent_representation = latent_model_adam.predict(test_images)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5-OwvD-UrR6"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_lr.history['val_loss'], label='Validation Adam_lr')\n",
        "plt.plot(history_nolr.history['val_loss'], label='Validation Adam_nolr')\n",
        "\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - ADAM lr vs ADAM nolr', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJnD3Nk7UrNT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea3OffC4UrJh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgJI7R0KUrE_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC7h6AjUonWd"
      },
      "source": [
        "### 2.2 Optimizing Algo: NADAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKAZldVPhu_C"
      },
      "outputs": [],
      "source": [
        "autoencoder_nadam, latent_model_nadam = model_autoencoder(act_1='sigmoid',act_lat='tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlb47K5sow2q"
      },
      "outputs": [],
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Nadam()\n",
        "loss = 'mse'\n",
        "autoencoder_nadam.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_nadam = autoencoder_nadam.fit(X_t, X_t, epochs=100, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                      shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_nadam.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/nadam/autoencoder')\n",
        "latent_model_nadam.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/nadam/encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EHtNrnFpE4V"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.plot(history_nadam.history['loss'], label='Train')\n",
        "plt.plot(history_nadam.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Binary Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYZPKAdKp-KN"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_lr.history['val_loss'], label='Validation Adam lr')\n",
        "plt.plot(history_nolr.history['val_loss'], label='Validation Adam nolr')\n",
        "plt.plot(history_nadam.history['val_loss'], label='Validation Nadam')\n",
        "plt.ylabel('Binary Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam vs ADAM', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_AB4c3E9I1d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l66ruzot2tEs"
      },
      "outputs": [],
      "source": [
        "compressed_images = autoencoder_nadam.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyQR1oji233w"
      },
      "outputs": [],
      "source": [
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(test_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_nadam.predict(test_images)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "fvqwZTB2tXNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NO0arbkqWrw"
      },
      "source": [
        "### 2.2 Optimizing Algo: ADAMBelief"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OH7mDrLq8f9"
      },
      "outputs": [],
      "source": [
        "autoencoder_adam_b, latent_model_adam_b = model_autoencoder(act_1='sigmoid',act_lat='tanh')\n",
        "\n",
        "# Get summary\n",
        "#autoencoder_adam_b.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0jcJhkJrFOd"
      },
      "outputs": [],
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = AdaBeliefOptimizer(learning_rate=0.025,\n",
        "                               weight_decay = 1e-5,\n",
        "                               epsilon = 1e-7,\n",
        "                               print_change_log = False)\n",
        "loss = 'mse'\n",
        "\n",
        "autoencoder_adam_b.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_ab = autoencoder_adam_b.fit(X_t, X_t, epochs=140, batch_size=128, callbacks = [early_stop, Checkpoint],\n",
        "                                   shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_adam_b.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/adabelief/autoencoder')\n",
        "latent_model_adam_b.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/adabelief/encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB4S5vGMrrfP"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.plot(history_ab.history['loss'], label='Train')\n",
        "plt.plot(history_ab.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Binary Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - AdaBelief', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9_YaYq6r2L7"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.plot(history_lr.history['val_loss'], label='Validation Adam')\n",
        "plt.plot(history_ab.history['val_loss'], label='Validation Nadam')\n",
        "plt.ylabel('Binary Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam vs ADAM', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yupn0O-Mso-z"
      },
      "source": [
        "### 2.2 Optimizing Algo: SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwHDGFe3so-8"
      },
      "outputs": [],
      "source": [
        "autoencoder_sgdnest, latent_model_sgdnest = model_autoencoder(act_1='sigmoid',act_lat='tanh')\n",
        "\n",
        "# Get summary\n",
        "#autoencoder_adam_b.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoxavEz-so-8"
      },
      "outputs": [],
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
        "loss = 'mse'\n",
        "\n",
        "autoencoder_sgdnest.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_ab = autoencoder_sgdnest.fit(X_t, X_t, epochs=250, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                   shuffle=True, validation_data=(X_v, X_v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3rNeL0vso-8"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.plot(history_ab.history['loss'], label='Train')\n",
        "plt.plot(history_ab.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Binary Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXruH-8uso-8"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.plot(history_nolr.history['val_loss'], label='Validation Adam')\n",
        "plt.plot(history_ab.history['val_loss'], label='Validation SGD')\n",
        "plt.ylabel('Binary Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - SGD vs ADAM', pad=13)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjEplp9oySbV"
      },
      "outputs": [],
      "source": [
        "compressed_images = autoencoder_sgdnest.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Variational Autoencoders:"
      ],
      "metadata": {
        "id": "jge-JezAcanG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "xvQcHU0Fcg2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28*28\n",
        "latent_vec_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "# First build the encoder\n",
        "enc_layer_1 = Dense(500, activation='sigmoid')(input_layer)\n",
        "enc_layer_2 = Dense(300, activation='sigmoid')(enc_layer_1)\n",
        "enc_layer_3 = Dense(100, activation='sigmoid')(enc_layer_2)\n",
        "enc_layer_4 = Dense(32, activation='sigmoid')(enc_layer_3)\n",
        "z_mean = layers.Dense(latent_vec_dim, name=\"z_mean\")(enc_layer_4)\n",
        "z_log_var = layers.Dense(latent_vec_dim, name=\"z_log_var\")(enc_layer_4)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "id": "YP_FVa0icgzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then build the decoder\n",
        "latent_inputs = keras.Input(shape=(latent_vec_dim,))\n",
        "dec_layer_0 = Dense(32, activation='sigmoid')(latent_inputs)\n",
        "dec_layer_1 = Dense(100, activation='sigmoid')(dec_layer_0)\n",
        "dec_layer_2 = Dense(300, activation='sigmoid')(dec_layer_1)\n",
        "dec_layer_3 = Dense(500, activation='sigmoid')(dec_layer_2)\n",
        "dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, dec_layer_4, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "lpPVogi7cgwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(input_layer)[2])\n",
        "vae = keras.Model(input_layer, outputs, name='vae_mlp')"
      ],
      "metadata": {
        "id": "zOGoby_OcgtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we've done so far allows us to instantiate 3 models:\n",
        "\n",
        "* an end-to-end autoencoder mapping inputs to reconstructions\n",
        "* an encoder mapping inputs to the latent space\n",
        "* a generator that can take points on the latent space and will output the corresponding reconstructed samples.\n",
        "\n",
        "We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term."
      ],
      "metadata": {
        "id": "nngCVeWBn5Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction_loss = keras.losses.binary_crossentropy(input_layer, outputs)\n",
        "reconstruction_loss *= input_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "U9hVksEen5Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vae = vae.fit(X_t, X_t,\n",
        "                      epochs=100,\n",
        "                      batch_size=128,\n",
        "                      callbacks = [early_stop, Checkpoint, lr],\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_v, X_v))"
      ],
      "metadata": {
        "id": "dwfGEb12prkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = encoder.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[2][:,0],\n",
        "                y=latent_representation[2][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "vIucu_TxtPVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[1][:,0],\n",
        "                y=latent_representation[1][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "pTyyG7hbt637"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_vae.history['loss'], label='Train')\n",
        "plt.plot(history_vae.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Customized Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "yM1QICobxfyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = vae.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W04SllNUxBQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 20  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-3, 3, n)\n",
        "grid_y = np.linspace(-3, 3, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y9IJgwR1xBE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/vae/autoencoder')\n",
        "encoder.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_tanh/vae/encoder')"
      ],
      "metadata": {
        "id": "HhHExWit4d2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Exploring Different Activation Functions:"
      ],
      "metadata": {
        "id": "5QhPDf7ycNz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1 Linear for Latent Dimension:"
      ],
      "metadata": {
        "id": "JrouJiLV39cI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxC6gBfDzfu4"
      },
      "outputs": [],
      "source": [
        "autoencoder_siglin, latent_model_siglin = model_autoencoder(act_1='sigmoid',act_lat='linear')\n",
        "\n",
        "# Get summary\n",
        "autoencoder_siglin.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_siglin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_siglin = autoencoder_siglin.fit(X_t, X_t, epochs=100, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                    shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_siglin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_lin/enc/autoencoder')\n",
        "latent_model_siglin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/sig_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "jZALfs3l4H4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_siglin.history['loss'], label='Train')\n",
        "plt.plot(history_siglin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "WjagsxCD5wf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_siglin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bQ26MZOA6at3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_siglin.predict(test_images)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "wt3R2u0n6qwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 Hidden Layers: Relu - Latent Space: Linear"
      ],
      "metadata": {
        "id": "7YIDeAAd8Jj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(act_1='relu',act_lat='tanh',kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, activation=act_1, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_2 = Dense(300, activation=act_1, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_3 = Dense(100, activation=act_1, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation=act_lat)(enc_layer_3)\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, activation=act_1, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_2 = Dense(300, activation=act_1, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_3 = Dense(500, activation=act_1, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "76rv2CAa9w8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_rellin, latent_model_rellin = model_autoencoder(act_1='relu',act_lat='linear')\n",
        "\n",
        "# Get summary\n",
        "autoencoder_rellin.summary()"
      ],
      "metadata": {
        "id": "sA65pgqe69Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_rellin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_rellin = autoencoder_rellin.fit(X_t, X_t, epochs=100, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_rellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/rel_lin/enc/autoencoder')\n",
        "latent_model_rellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/rel_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "-roGhhyR692c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_rellin.history['loss'], label='Train')\n",
        "plt.plot(history_rellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "NiVNbDzA-eJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_rellin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "peRgIfPt_GDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_rellin.predict(test_images)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "otAl4G9__PHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 Hidden Layers: PRelu - Latent Space: Linear"
      ],
      "metadata": {
        "id": "-gEs53Su_7nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "vmproHM-CRlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "PKizhwpq_YJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_prellin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, X_t, epochs=100, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "OsMKRP5dAJ0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "wezGS6e1Ag0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_rellin.history['val_loss'], label='Relu_Lin')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Prelu_lin')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "nj8HHjTBBL4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KreHh1abFSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "hhUnUoReFeRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3 Hidden Layers: PRelu - Latent Space: Linear + Regularization L1"
      ],
      "metadata": {
        "id": "ZZDsASPyLo_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.001))(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "2gmgAOGZLo_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "bIxp3vjfLo_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_prellin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_l1/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_l1/enc/encoder')"
      ],
      "metadata": {
        "id": "noCJKsKeLo_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "x1zgRfoNLo_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y9NWP4hNLo_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "f62hMAWtLo_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.1 Hidden Layers: PRelu - Latent Space: Linear + BatchNorm"
      ],
      "metadata": {
        "id": "ASlETdF7SNPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "tVrmVDg_SNPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "17Hs2PtGSNPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_prellin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn/enc/encoder')"
      ],
      "metadata": {
        "id": "pwGIzws1SNPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "NigaFQfLSNPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "78HDFv3-SNPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "PeCbOrHaSNPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4 Hidden: Swish - Latent Linear"
      ],
      "metadata": {
        "id": "MK6VtrIpGOwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.swish(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.swish(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.swish(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.swish(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.swish(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.swish(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "o-kd6C5gFl6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_swilin, latent_model_swilin = model_autoencoder()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_swilin.summary()"
      ],
      "metadata": {
        "id": "OM80VKzAGzbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_swilin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_swilin = autoencoder_swilin.fit(X_t, X_t, epochs=100, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_swilin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin/enc/autoencoder')\n",
        "latent_model_swilin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "TBdGPx_4G9CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_swilin.history['loss'], label='Train')\n",
        "plt.plot(history_swilin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "w-4-hjrxH8j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_swilin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bHVTZljKIvKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_swilin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "Fi5QpBefI2tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_rellin.history['val_loss'], label='Relu_Lin')\n",
        "plt.plot(history_swilin.history['val_loss'], label='Swish_lin')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "Tlebpgz9I__C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.5 Hidden: Swish - Latent: Sig"
      ],
      "metadata": {
        "id": "Hd7neNuMLWR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.swish(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.swish(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.swish(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='sigmoid')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.swish(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.swish(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.swish(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "ObBiFp5wJiyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_swisig, latent_model_swisig = model_autoencoder()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_swisig.summary()"
      ],
      "metadata": {
        "id": "9pHTTOajLhJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_swisig.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_swisig = autoencoder_swisig.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_swisig.save(f'/content/drive/MyDrive/Exercises/Autoencoders/swi_sig/enc/autoencoder')\n",
        "latent_model_swisig.save(f'/content/drive/MyDrive/Exercises/Autoencoders/swi_sig/enc/encoder')"
      ],
      "metadata": {
        "id": "yFCHy1TTLmAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_swisig.history['loss'], label='Train')\n",
        "plt.plot(history_swisig.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "zg9xUIZeL0Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_swisig.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t_HqObRQMnBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_swisig.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "2YrRATlwMtLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.6 Hidden: Selu - Latent: Linear"
      ],
      "metadata": {
        "id": "yTnQGFjPQHYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"lecun_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.selu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.selu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.selu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.selu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.selu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.selu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "tufCrnxYM1pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_selulin, latent_model_selulin = model_autoencoder()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_selulin.summary()"
      ],
      "metadata": {
        "id": "s08DC5hSQzg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_selulin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_selulin = autoencoder_selulin.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_selulin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin/enc/autoencoder')\n",
        "latent_model_selulin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "wf1tOGEoQ8VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_selulin.history['loss'], label='Train')\n",
        "plt.plot(history_selulin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Selu-Lin Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "eUMFSW_3RiO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_selulin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EWqol95BUNXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_selulin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "CmRcSueJUXY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.7 Hidden: Selu - Latent: Linear + regulatization\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IJeQ6sHWU6B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder(kernel=\"lecun_normal\", l1=0.01):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.selu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.selu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.selu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=l1))(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.selu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.selu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.selu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "GI8MC1AdVEeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_selulin_r, latent_model_selulin_r = model_autoencoder(l1=0.001)\n",
        "\n",
        "# Get summary\n",
        "autoencoder_selulin_r.summary()"
      ],
      "metadata": {
        "id": "OaHl2ax_VEeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_selulin_r.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_selulin_r = autoencoder_selulin_r.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_selulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin_reg/enc/autoencoder')\n",
        "latent_model_selulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin_reg/enc/encoder')"
      ],
      "metadata": {
        "id": "0VfXE8tPUd7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_selulin.history['loss'], label='Train')\n",
        "plt.plot(history_selulin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Selu-Lin Combo-with Regual', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "vgwUfbX-WRhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_selulin_r.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2UiTbm4WoUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_selulin_r.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "okh8eFtdXBnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.5 Hidden: Elu - Latent: Sig"
      ],
      "metadata": {
        "id": "linXPrF6bB9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='sigmoid')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "4aFXVCfubIHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elusig, latent_model_elusig = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elusig.summary()"
      ],
      "metadata": {
        "id": "-iTz68EYbRzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elusig.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elusig = autoencoder_elusig.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elusig.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_sig/enc/autoencoder')\n",
        "latent_model_elusig.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_sig/enc/encoder')"
      ],
      "metadata": {
        "id": "_0ZfFOo5bRwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elusig.history['loss'], label='Train')\n",
        "plt.plot(history_elusig.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "vwKUAh0ybRtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elusig.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nOuL54uXcL5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elusig.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "pwmdDmpccQ5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.5 Hidden: Elu - Latent: Lin"
      ],
      "metadata": {
        "id": "M_q39JA4c3Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "avei2Rwvc3Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin, latent_model_elulin = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin.summary()"
      ],
      "metadata": {
        "id": "66PQEl46c3Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin = autoencoder_elulin.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin/enc/autoencoder')\n",
        "latent_model_elulin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "Ly0iusUvc3Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin.history['loss'], label='Train')\n",
        "plt.plot(history_elulin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "ff1p_cDmc3Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GabwcCbQc3Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "dkENcSYwc3Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.6 Hidden: Elu - Latent: Lin + BN"
      ],
      "metadata": {
        "id": "3DQkfbQcWUgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "qari_T-xWUgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin, latent_model_elulin = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin.summary()"
      ],
      "metadata": {
        "id": "tK80v4wOWUgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin = autoencoder_elulin.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_bn/enc/autoencoder')\n",
        "latent_model_elulin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_bn/enc/encoder')"
      ],
      "metadata": {
        "id": "AbxzYCwFWUgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin.history['loss'], label='Train')\n",
        "plt.plot(history_elulin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "fu_pHFdOWUgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ExE0X9BNWUgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "6NNfWEccWUgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.7 Hidden: Elu - Latent: Lin + Reg L1"
      ],
      "metadata": {
        "id": "4Nd8-nkofRup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.01))(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "EhryBpPifRuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin_r, latent_model_elulin_r = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin_r.summary()"
      ],
      "metadata": {
        "id": "Ddf0JYumfRuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin_r.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin_r = autoencoder_elulin_r.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin/enc/autoencoder')\n",
        "latent_model_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "bF30E1kbfRur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin_r.history['loss'], label='Train')\n",
        "plt.plot(history_elulin_r.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "IpFfIi6VfRur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin_r.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VdYzGAvfRur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin_r.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "XraxFB3rfRur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.8 Hidden: Elu - Latent: Lin + Reg L2"
      ],
      "metadata": {
        "id": "_HBWJnhFBDqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L2(l2=0.01))(enc_layer_3)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "MgDJl0Q6BDqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin_r, latent_model_elulin_r = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin_r.summary()"
      ],
      "metadata": {
        "id": "-8VIbmgZBDqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin_r.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin_r = autoencoder_elulin_r.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_rl2/enc/autoencoder')\n",
        "latent_model_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_rl2/enc/encoder')"
      ],
      "metadata": {
        "id": "N2r5umshBDqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin_r.history['loss'], label='Train')\n",
        "plt.plot(history_elulin_r.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "PnVJX2ppBDqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin_r.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GPHfZJdvBDqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin_r.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "24mV4vv1BDqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.9 Hidden: Gelu - Latent: Lin"
      ],
      "metadata": {
        "id": "M9srdok_-bHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.gelu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.gelu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.gelu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', )(enc_layer_3) #kernel_regularizer = tf.keras.regularizers.L2(l2=0.01)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.gelu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.gelu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.gelu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='linear')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "jrFcGlCK-bHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin_r, latent_model_elulin_r = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin_r.summary()"
      ],
      "metadata": {
        "id": "Ojw0hfa0-bHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin_r.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin_r = autoencoder_elulin_r.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin/enc/autoencoder')\n",
        "latent_model_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin/enc/encoder')"
      ],
      "metadata": {
        "id": "UV2N9dpn-bHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin_r.history['loss'], label='Train')\n",
        "plt.plot(history_elulin_r.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "H1zqMXPv-bHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin_r.predict(test_images)\n",
        "n = 15\n",
        "plt.figure(figsize=(26, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mlGnxVd2-bHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin_r.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "-jbCdkqQ-bHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.10 Hidden: Gelu - Latent: Tanh"
      ],
      "metadata": {
        "id": "4Equaw6G_MIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.gelu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.gelu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.gelu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='tanh', )(enc_layer_3) #kernel_regularizer = tf.keras.regularizers.L2(l2=0.01)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.gelu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.gelu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.gelu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='linear')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "YwrxujNd_MIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin_r, latent_model_elulin_r = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin_r.summary()"
      ],
      "metadata": {
        "id": "GgEHy10e_MIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin_r.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin_r = autoencoder_elulin_r.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_tahn/enc/autoencoder')\n",
        "latent_model_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_tahn/enc/encoder')"
      ],
      "metadata": {
        "id": "ssRJNdyb_MIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin_r.history['loss'], label='Train')\n",
        "plt.plot(history_elulin_r.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "LGDOfeEA_MIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin_r.predict(test_images)\n",
        "n = 15\n",
        "plt.figure(figsize=(26, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EKifdfDo_MIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin_r.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "iSXUcUb4_MIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.11 Hidden: Gelu - Latent: Lin - L1 Reg"
      ],
      "metadata": {
        "id": "jCeOXDDpAxqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.activations.gelu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.activations.gelu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.activations.gelu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.01))(enc_layer_3) #kernel_regularizer = tf.keras.regularizers.L2(l2=0.01)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.activations.gelu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.activations.gelu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.activations.gelu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='linear')(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder, latent_model"
      ],
      "metadata": {
        "id": "jkGeyiqwAxqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_elulin_r, latent_model_elulin_r = model_autoencoder_()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_elulin_r.summary()"
      ],
      "metadata": {
        "id": "PmlDuJSpAxqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = 'mse'\n",
        "autoencoder_elulin_r.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_elulin_r = autoencoder_elulin_r.fit(X_t, X_t, epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, X_v))\n",
        "\n",
        "autoencoder_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_l1/enc/autoencoder')\n",
        "latent_model_elulin_r.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_l1/enc/encoder')"
      ],
      "metadata": {
        "id": "fCwbM24kAxqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_elulin_r.history['loss'], label='Train')\n",
        "plt.plot(history_elulin_r.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Elu-Sig Combo', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "ELUhwpFdAxqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_elulin_r.predict(test_images)\n",
        "n = 15\n",
        "plt.figure(figsize=(26, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_fC46OQYAxqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_elulin_r.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "ySPpW7VeAxqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.0 Variational Autoencoders Relu-Activation:"
      ],
      "metadata": {
        "id": "NYVN2gUNMPUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "odqvZgUeMPUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28*28\n",
        "latent_vec_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "# First build the encoder\n",
        "enc_layer_1 = Dense(500, activation='relu')(input_layer)\n",
        "enc_layer_2 = Dense(300, activation='relu')(enc_layer_1)\n",
        "enc_layer_3 = Dense(100, activation='relu')(enc_layer_2)\n",
        "enc_layer_4 = Dense(32, activation='relu')(enc_layer_3)\n",
        "z_mean = layers.Dense(latent_vec_dim, name=\"z_mean\")(enc_layer_4)\n",
        "z_log_var = layers.Dense(latent_vec_dim, name=\"z_log_var\")(enc_layer_4)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "id": "WQ1UcQw0MPUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then build the decoder\n",
        "latent_inputs = keras.Input(shape=(latent_vec_dim,))\n",
        "dec_layer_0 = Dense(32, activation='relu')(latent_inputs)\n",
        "dec_layer_1 = Dense(100, activation='relu')(dec_layer_0)\n",
        "dec_layer_2 = Dense(300, activation='relu')(dec_layer_1)\n",
        "dec_layer_3 = Dense(500, activation='relu')(dec_layer_2)\n",
        "dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, dec_layer_4, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "77E4ap-GMTLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(input_layer)[2])\n",
        "vae = keras.Model(input_layer, outputs, name='vae_mlp')"
      ],
      "metadata": {
        "id": "OvjL_EI0MTLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we've done so far allows us to instantiate 3 models:\n",
        "\n",
        "* an end-to-end autoencoder mapping inputs to reconstructions\n",
        "* an encoder mapping inputs to the latent space\n",
        "* a generator that can take points on the latent space and will output the corresponding reconstructed samples.\n",
        "\n",
        "We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term."
      ],
      "metadata": {
        "id": "jERqRpQ4MTLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction_loss = keras.losses.binary_crossentropy(input_layer, outputs)\n",
        "reconstruction_loss *= input_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "EPToAzm3MTLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vae = vae.fit(X_t, X_t,\n",
        "                      epochs=120,\n",
        "                      batch_size=128,\n",
        "                      callbacks = [early_stop, Checkpoint, lr],\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_v, X_v))"
      ],
      "metadata": {
        "id": "d6dUJLEfMTLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = encoder.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[2][:,0],\n",
        "                y=latent_representation[2][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "-DkTPo39NRqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[1][:,0],\n",
        "                y=latent_representation[1][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "_orKqXCINRqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_vae.history['loss'], label='Train')\n",
        "plt.plot(history_vae.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Customized Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "4mxFEKQlNRqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = vae.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D0kbFTiBNRqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 20  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-3, 3, n)\n",
        "grid_y = np.linspace(-3, 3, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6QMDN6g1NRqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae/autoencoder')\n",
        "encoder.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae/encoder')"
      ],
      "metadata": {
        "id": "dTZ8pkgONRqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.0 Variational Autoencoders Prelu-Activation:"
      ],
      "metadata": {
        "id": "1odFAgR0739L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "rGmft9cp739N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28*28\n",
        "latent_vec_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "# First build the encoder\n",
        "enc_layer_1 = Dense(500, kernel_initializer='he_normal')(input_layer)\n",
        "enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "enc_layer_2 = Dense(300, kernel_initializer='he_normal')(enc_layer_1)\n",
        "enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "enc_layer_3 = Dense(100, kernel_initializer='he_normal')(enc_layer_2)\n",
        "enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "enc_layer_4 = Dense(32, kernel_initializer='he_normal')(enc_layer_3)\n",
        "enc_layer_4 = tf.keras.layers.PReLU()(enc_layer_4)\n",
        "\n",
        "z_mean = layers.Dense(latent_vec_dim, name=\"z_mean\")(enc_layer_4)\n",
        "z_log_var = layers.Dense(latent_vec_dim, name=\"z_log_var\")(enc_layer_4)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "id": "W_5WdRHW739O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then build the decoder\n",
        "latent_inputs = keras.Input(shape=(latent_vec_dim,))\n",
        "\n",
        "dec_layer_0 = Dense(32, kernel_initializer='he_normal')(latent_inputs)\n",
        "dec_layer_0 = tf.keras.layers.PReLU()(dec_layer_0)\n",
        "\n",
        "dec_layer_1 = Dense(100, kernel_initializer='he_normal')(dec_layer_0)\n",
        "dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "\n",
        "dec_layer_2 = Dense(300, kernel_initializer='he_normal')(dec_layer_1)\n",
        "dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "dec_layer_3 = Dense(500, kernel_initializer='he_normal')(dec_layer_2)\n",
        "dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, dec_layer_4, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "jQQAybWU739O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(input_layer)[2])\n",
        "vae = keras.Model(input_layer, outputs, name='vae_mlp')"
      ],
      "metadata": {
        "id": "BwrbiV-D739P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we've done so far allows us to instantiate 3 models:\n",
        "\n",
        "* an end-to-end autoencoder mapping inputs to reconstructions\n",
        "* an encoder mapping inputs to the latent space\n",
        "* a generator that can take points on the latent space and will output the corresponding reconstructed samples.\n",
        "\n",
        "We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term."
      ],
      "metadata": {
        "id": "kpYg5NFE739Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction_loss = keras.losses.binary_crossentropy(input_layer, outputs)\n",
        "reconstruction_loss *= input_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "snqbyFA3739Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vae = vae.fit(X_t, X_t,\n",
        "                      epochs=120,\n",
        "                      batch_size=128,\n",
        "                      callbacks = [early_stop, Checkpoint, lr],\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_v, X_v))"
      ],
      "metadata": {
        "id": "Tg2thiTp739R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = encoder.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(15, 9))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[2][:,0],\n",
        "                y=latent_representation[2][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "e72MTBon739R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[1][:,0],\n",
        "                y=latent_representation[1][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "hTPPRbQ-739S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_vae.history['loss'], label='Train')\n",
        "plt.plot(history_vae.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Customized Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "giF-hRRl739T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = vae.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CoSnKHox739T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 20  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-3, 3, n)\n",
        "grid_y = np.linspace(-3, 3, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tmYaneI8739U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae_prelu/autoencoder')\n",
        "encoder.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae_prelu/encoder')"
      ],
      "metadata": {
        "id": "tH8bntsM739U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.0 Variational Autoencoders Elu-Activation:"
      ],
      "metadata": {
        "id": "9EuwMZppI0VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "OxReN0veI0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28*28\n",
        "latent_vec_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "# First build the encoder\n",
        "enc_layer_1 = Dense(500, kernel_initializer='he_normal')(input_layer)\n",
        "enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "enc_layer_2 = Dense(300, kernel_initializer='he_normal')(enc_layer_1)\n",
        "enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "enc_layer_3 = Dense(100, kernel_initializer='he_normal')(enc_layer_2)\n",
        "enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "enc_layer_4 = Dense(32, kernel_initializer='he_normal')(enc_layer_3)\n",
        "enc_layer_4 = tf.keras.activations.elu(enc_layer_4)\n",
        "\n",
        "z_mean = layers.Dense(latent_vec_dim, name=\"z_mean\")(enc_layer_4)\n",
        "z_log_var = layers.Dense(latent_vec_dim, name=\"z_log_var\")(enc_layer_4)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "id": "CxNfUKGdI0VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then build the decoder\n",
        "latent_inputs = keras.Input(shape=(latent_vec_dim,))\n",
        "\n",
        "dec_layer_0 = Dense(32, kernel_initializer='he_normal')(latent_inputs)\n",
        "dec_layer_0 = tf.keras.activations.elu(dec_layer_0)\n",
        "\n",
        "dec_layer_1 = Dense(100, kernel_initializer='he_normal')(dec_layer_0)\n",
        "dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "\n",
        "dec_layer_2 = Dense(300, kernel_initializer='he_normal')(dec_layer_1)\n",
        "dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "dec_layer_3 = Dense(500, kernel_initializer='he_normal')(dec_layer_2)\n",
        "dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, dec_layer_4, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "nHbkZpqJI0VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(input_layer)[2])\n",
        "vae = keras.Model(input_layer, outputs, name='vae_mlp')"
      ],
      "metadata": {
        "id": "lFmSgv8cI0VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we've done so far allows us to instantiate 3 models:\n",
        "\n",
        "* an end-to-end autoencoder mapping inputs to reconstructions\n",
        "* an encoder mapping inputs to the latent space\n",
        "* a generator that can take points on the latent space and will output the corresponding reconstructed samples.\n",
        "\n",
        "We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term."
      ],
      "metadata": {
        "id": "la9h5FK8I0VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction_loss = keras.losses.binary_crossentropy(input_layer, outputs)\n",
        "reconstruction_loss *= input_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "s2v7H0HdI0VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vae = vae.fit(X_t, X_t,\n",
        "                      epochs=120,\n",
        "                      batch_size=128,\n",
        "                      callbacks = [early_stop, Checkpoint, lr],\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_v, X_v))"
      ],
      "metadata": {
        "id": "yjN85WOBI0VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = encoder.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(15, 9))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[2][:,0],\n",
        "                y=latent_representation[2][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "Jm-juj4tI0VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[1][:,0],\n",
        "                y=latent_representation[1][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "UU3xtXq2I0VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_vae.history['loss'], label='Train')\n",
        "plt.plot(history_vae.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Customized Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "Cd4nC-SXI0VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = vae.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v9r9hpkOI0VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 20  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-3, 3, n)\n",
        "grid_y = np.linspace(-3, 3, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XoEGgkrEI0VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae_elu/autoencoder')\n",
        "encoder.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae_elu/encoder')"
      ],
      "metadata": {
        "id": "IgtSc2dNI0VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.0 Hidden Layers: PRelu - Latent Space: Linear + BatchNorm: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "gTdDKGOHZMx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "OCQwuXsxZ5rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric. Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "qoZBLKdPZMx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "OTzyxG4EZMx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "Hn36dTJ3ZMx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "S1cRiuaeZMx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJysyKr3eR6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_2c_Wm6VZMx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "EfabInZ4ZMx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=np.argmax(y_t, axis=1), palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "bY6sQxXEL4MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=np.argmax(y_v, axis=1), palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "ajPAIw7TgUBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Hidden Layers: PRelu - Latent Space: Linear + BatchNorm + Regularization: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "TmqzorrBgC3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "1j_iAAgCgC3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L2(l2=1.0))(enc_layer_3)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = tf.keras.Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = tf.keras.Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "ZFLrijMEgC3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "f-_eQEl1gC3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn_mo_reg_l2_v2/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn_mo_reg_l2_v2/enc/encoder')"
      ],
      "metadata": {
        "id": "_P-hqnTcgC3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "DvonqdRhgC3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0RwKRQ84gC3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "AOD6vr5LgC3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "lqL054wCgC3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "bJ4h_HrJgC3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Hidden Layers: PRelu - Latent Space: Linear + BatchNorm + Regularization: MULTIPLE OUTPUT test 2"
      ],
      "metadata": {
        "id": "ZK4zSQVejnU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "T8bEsAjKjnU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.01))(enc_layer_3)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "fi7EjwzcjnU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "5_DCi-2MjnU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn_mo_reg_l1/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/prel_lin_bn_mo_reg_l1/enc/encoder')"
      ],
      "metadata": {
        "id": "CtTq2EyujnU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "U0tfRAqSjnU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qGDZ6LJTjnU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "_2_7ijZujnU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "BDHbOoPpjnU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "T3ynm44DjnU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Hidden Layers: Selu - Latent Space: Linear + BatchNorm + Regularization: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "uB_DnDLswUwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "tAzKHUs7wUwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"lecun_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.activations.selu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.selu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.selu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L2(l2=0.01))(enc_layer_3)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.selu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.selu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.selu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "61jN5P56wUwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "PNihECc3wUwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin_bn_mo_bn/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin_bn_mo_bn/enc/encoder')"
      ],
      "metadata": {
        "id": "c6X_dwnhwUwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "E62w-clvwUwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "16viYrehwUwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "pDaVB7rOwUwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "sAyCHBn4wUwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "PegFb7PzwUwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4 Hidden Layers: Selu - Latent Space: Linear + BatchNorm + Regularization L1: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "MLFJaJuXK74J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "jJlLwlFoK74K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"lecun_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1)\n",
        "  enc_layer_1 = tf.keras.activations.selu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.selu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.selu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.01))(enc_layer_3)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.selu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.selu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.selu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "MBXp-6V7K74L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "v84i5unBK74L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin_bn_mo_l1/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/selu_lin_bn_mo_l1/enc/encoder')"
      ],
      "metadata": {
        "id": "eXLiUNTkK74L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "_C-o_yWMK74M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OMqj0sSwK74M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "oinCLUekK74M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "5X66Z8vFK74M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "cjt5DNl_K74N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5 Hidden Layers: Elu - Latent Space: Linear: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "tjdnQzhsM-b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "Ctnqpu0IM-b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  #enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  #enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  #enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  #dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  #dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  #dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "xZ_0bf27M-b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "SxjMkZDLM-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "Fr5SoDMgM-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "7_5o59OTM-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cn6bblC6M-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "uNN4UWs4M-b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "d_BAbd2cM-b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "mbLJngvMM-b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6 Hidden Layers: Elu - Latent Space: Linear: MULTIPLE OUTPUT and L1 reg"
      ],
      "metadata": {
        "id": "_yliHpiIHI5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "g7LPnKIZHI5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  #enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.elu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  #enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.elu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  #enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.elu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.01))(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  #dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.elu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  #dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.elu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  #dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.elu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "klCRxT3oHI5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "HXtcf9HCHI5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_l1_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/elu_lin_l1_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "sm5nvfzsHI5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "LS2PupjeHI5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MwzSTahTHI5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "hTwvV15jHI5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "9QvyRdkHHI5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "mH9AKvJOHI5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.7 Hidden Layers: Relu - Latent Space: Linear: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "rvIOKAqeLkL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "kK21B6EFLkL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.relu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.relu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.relu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear')(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.relu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.relu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.relu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "GQ8pjm-dLkL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "skhLJUS9LkL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "7lMpYflELkL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "D7S9FywTLkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zdhnFvTLLkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "njOXXrwXLkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "bDjsmhINLkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "_mf-qB3aLkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.8 Hidden Layers: Relu - Latent Space: Linear: MULTIPLE OUTPUT and L1 reg"
      ],
      "metadata": {
        "id": "0LGjaAB5NZRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "yEzBktOsNZRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.relu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.relu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.relu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.01))(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.relu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.relu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.relu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "7Nzu4-xeNZRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "aFpus3aoNZRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "3ABGpgM7NZRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "NH3Pi-e_NZRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xuJbUJ7RNZRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "9tzZuNAsNZRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "NH6ced_gNZRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "s4ViHyhtNZRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.9 Hidden Layers: Relu - Latent Space: Linear: MULTIPLE OUTPUT and L2 reg"
      ],
      "metadata": {
        "id": "vkelmr7EPh3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "eu8hTBnSPh3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.relu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.relu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.relu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L2(l2=0.1))(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.relu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.relu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.relu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "__GbantePh3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "_LIlsdyZPh3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_l2_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_l2_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "PmUI0QJ5Ph3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "Fk4VhZb2Ph3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T7SNyY2sPh3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "nvVSVvHEPh3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "2D0PvE1jPh3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "5gng3OW1Ph3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.10 Hidden Layers: Relu - Latent Space: Linear: MULTIPLE OUTPUT and L2 reg v2"
      ],
      "metadata": {
        "id": "WsHamQnVd_1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "rsryGDY3d_1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.relu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.relu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.relu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L2(l2=1.0))(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.relu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.relu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.relu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "lFmGOP-Id_1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "RfFs3aROd_1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_l2_mo_v2/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/relu_lin_bn_l2_mo_v2/enc/encoder')"
      ],
      "metadata": {
        "id": "JpZbv5Ycd_1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "CpYZWYNEd_1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8RX6nRuKd_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "mtNqcFcTd_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "FNfrPT6rd_11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "8mufQrA3d_11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.11 Hidden Layers: Gelu - Latent Space: Linear: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "HpvUHsE3CjW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "Nzn3WpGRCjW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  #enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.gelu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  #enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.gelu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  #enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.gelu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear',)(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  #dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.gelu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  #dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.gelu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  #dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.gelu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "aX3i9VoACjW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "Y-xsxpWFCjW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_mo/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_mo/enc/encoder')"
      ],
      "metadata": {
        "id": "G8UyoGjwCjW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "WZVlWi_FCjW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ge_s8DziCjW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "xfkFYpQGCjW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "29BHx-6KCjW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "fhdZtxIRCjW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Hidden Layers: Gelu - Latent Space: Linear: MULTIPLE OUTPUT + L1 reg"
      ],
      "metadata": {
        "id": "ZHUY0G8YD4cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "3gAOZAfUD4cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  #enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.gelu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  #enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.gelu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  #enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.gelu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L1(l1=0.1))(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  #dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.gelu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  #dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.gelu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  #dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.gelu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "IaomkXHFD4cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "NoZkol_ID4cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_mo_l1/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_mo_l1/enc/encoder')"
      ],
      "metadata": {
        "id": "kCIdRWziD4cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "3Zzoq9oxD4cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tERH_qK-D4c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "xuqxBnwjD4c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "V9mlnRurD4c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "f9MLAktwD4c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Hidden Layers: Gelu - Latent Space: Linear: MULTIPLE OUTPUT + L2 reg"
      ],
      "metadata": {
        "id": "_8TI__y2Fuqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "cpKY8LOKFuqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_autoencoder_mult(kernel=\"he_normal\"):\n",
        "  input_dim = 28*28\n",
        "  latent_vec_dim = 2\n",
        "\n",
        "  input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "  # Define the autoencoder architecture\n",
        "  # First build the encoder\n",
        "  enc_layer_1 = Dense(500, kernel_initializer=kernel)(input_layer)\n",
        "  #enc_layer_1 = tf.keras.layers.BatchNormalization()(enc_layer_1) #bn worsen the\n",
        "  enc_layer_1 = tf.keras.activations.gelu(enc_layer_1)\n",
        "\n",
        "  enc_layer_2 = Dense(300, kernel_initializer=kernel)(enc_layer_1)\n",
        "  #enc_layer_2 = tf.keras.layers.BatchNormalization()(enc_layer_2)\n",
        "  enc_layer_2 = tf.keras.activations.gelu(enc_layer_2)\n",
        "\n",
        "  enc_layer_3 = Dense(100, kernel_initializer=kernel)(enc_layer_2)\n",
        "  #enc_layer_3 = tf.keras.layers.BatchNormalization()(enc_layer_3)\n",
        "  enc_layer_3 = tf.keras.activations.gelu(enc_layer_3)\n",
        "\n",
        "  enc_layer_4 = Dense(latent_vec_dim, activation='linear', kernel_regularizer = tf.keras.regularizers.L2(l2=0.01))(enc_layer_3) #, kernel_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
        "  #enc_layer_4 = tf.keras.layers.BatchNormalization()(enc_layer_4)\n",
        "\n",
        "  output_1 = Dense(10, activation='softmax', name=\"Class_Output\")(enc_layer_4)\n",
        "\n",
        "  encoder = enc_layer_4\n",
        "\n",
        "  # Then build the decoder\n",
        "  dec_layer_1 = Dense(100, kernel_initializer=kernel)(encoder)\n",
        "  #dec_layer_1 = tf.keras.layers.BatchNormalization()(dec_layer_1)\n",
        "  dec_layer_1 = tf.keras.activations.gelu(dec_layer_1)\n",
        "\n",
        "  dec_layer_2 = Dense(300, kernel_initializer=kernel)(dec_layer_1)\n",
        "  #dec_layer_2 = tf.keras.layers.BatchNormalization()(dec_layer_2)\n",
        "  dec_layer_2 = tf.keras.activations.gelu(dec_layer_2)\n",
        "\n",
        "  dec_layer_3 = Dense(500, kernel_initializer=kernel)(dec_layer_2)\n",
        "  #dec_layer_3 = tf.keras.layers.BatchNormalization()(dec_layer_3)\n",
        "  dec_layer_3 = tf.keras.activations.gelu(dec_layer_3)\n",
        "\n",
        "  dec_layer_4 = Dense(input_dim, activation='sigmoid', name=\"Ric_Output\")(dec_layer_3)\n",
        "  decoder = dec_layer_4\n",
        "\n",
        "  # Connect both encoder and decoder\n",
        "  autoencoder_mult = Model(inputs = input_layer, outputs = [decoder, output_1], name=\"Deep_Autoencoder\")\n",
        "\n",
        "  # Latent representation (Optional)\n",
        "  latent_model = Model(input_layer, encoder)\n",
        "\n",
        "  return autoencoder_mult, latent_model"
      ],
      "metadata": {
        "id": "KuC1RHtgFuqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_prellin, latent_model_prellin = model_autoencoder_mult()\n",
        "\n",
        "# Get summary\n",
        "autoencoder_prellin.summary()"
      ],
      "metadata": {
        "id": "sp9NzSB2Fuq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = 'mse'\n",
        "loss_1 = 'categorical_crossentropy'#\n",
        "\n",
        "autoencoder_prellin.compile(loss=[loss_0, loss_1], loss_weights=[0.75,0.25], optimizer=optimizer)\n",
        "\n",
        "# Train the autoencoder with MNIST data\n",
        "history_prellin = autoencoder_prellin.fit(X_t, [X_t, y_t_], epochs=120, batch_size=128, callbacks = [early_stop, Checkpoint, lr],\n",
        "                                       shuffle=True, validation_data=(X_v, [X_v, y_v_]))\n",
        "\n",
        "autoencoder_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_mo_l2/enc/autoencoder')\n",
        "latent_model_prellin.save(f'/content/drive/MyDrive/Exercises/Autoencoders/gelu_lin_mo_l2/enc/encoder')"
      ],
      "metadata": {
        "id": "yrLtQW7fFuq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_prellin.history['loss'], label='Train')\n",
        "plt.plot(history_prellin.history['val_loss'], label='Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "aiVWG0PKFuq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = autoencoder_prellin.predict(test_images)[0]\n",
        "n = 18\n",
        "plt.figure(figsize=(25, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5-K_fovTFuq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "8rY6wznBFuq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_t)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_t, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "on0Z4yfPFuq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = latent_model_prellin.predict(X_v)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[:,0],\n",
        "                y=latent_representation[:,1],\n",
        "                hue=y_v, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "8-SftE37Fuq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.10 VAE: MULTIPLE OUTPUT"
      ],
      "metadata": {
        "id": "kl2YahjEQ8jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_t_ = to_categorical(y_t)\n",
        "y_v_ = to_categorical(y_v)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "print(y_t.shape, y_v.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "09YsjNoK5MHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "pjJUiOSP4_jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28*28\n",
        "latent_vec_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "# First build the encoder\n",
        "enc_layer_1 = Dense(500, kernel_initializer='he_normal')(input_layer)\n",
        "enc_layer_1 = tf.keras.layers.PReLU()(enc_layer_1)\n",
        "\n",
        "enc_layer_2 = Dense(300, kernel_initializer='he_normal')(enc_layer_1)\n",
        "enc_layer_2 = tf.keras.layers.PReLU()(enc_layer_2)\n",
        "\n",
        "enc_layer_3 = Dense(100, kernel_initializer='he_normal')(enc_layer_2)\n",
        "enc_layer_3 = tf.keras.layers.PReLU()(enc_layer_3)\n",
        "\n",
        "enc_layer_4 = Dense(32, kernel_initializer='he_normal')(enc_layer_3)\n",
        "enc_layer_4 = tf.keras.layers.PReLU()(enc_layer_4)\n",
        "\n",
        "z_mean = layers.Dense(latent_vec_dim, name=\"z_mean\")(enc_layer_4)\n",
        "z_log_var = layers.Dense(latent_vec_dim, name=\"z_log_var\")(enc_layer_4)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "id": "EuWQrYVg4_jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then build the decoder\n",
        "latent_inputs = keras.Input(shape=(latent_vec_dim,))\n",
        "\n",
        "dec_layer_0 = Dense(32, kernel_initializer='he_normal')(latent_inputs)\n",
        "dec_layer_0 = tf.keras.layers.PReLU()(dec_layer_0)\n",
        "\n",
        "dec_layer_1 = Dense(100, kernel_initializer='he_normal')(dec_layer_0)\n",
        "dec_layer_1 = tf.keras.layers.PReLU()(dec_layer_1)\n",
        "\n",
        "\n",
        "dec_layer_2 = Dense(300, kernel_initializer='he_normal')(dec_layer_1)\n",
        "dec_layer_2 = tf.keras.layers.PReLU()(dec_layer_2)\n",
        "\n",
        "dec_layer_3 = Dense(500, kernel_initializer='he_normal')(dec_layer_2)\n",
        "dec_layer_3 = tf.keras.layers.PReLU()(dec_layer_3)\n",
        "\n",
        "output_1 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
        "output_2 = Dense(10, activation='softmax', name=\"Class_Output\")(latent_inputs)\n",
        "\n",
        "\n",
        "decoder = keras.Model(latent_inputs, [output_1,output_2], name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "VwVrqDo84_jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(input_layer)[2])\n",
        "vae = keras.Model(input_layer, outputs, name='vae_mlp')"
      ],
      "metadata": {
        "id": "DLDZAClo4_jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we've done so far allows us to instantiate 3 models:\n",
        "\n",
        "* an end-to-end autoencoder mapping inputs to reconstructions\n",
        "* an encoder mapping inputs to the latent space\n",
        "* a generator that can take points on the latent space and will output the corresponding reconstructed samples.\n",
        "\n",
        "We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term."
      ],
      "metadata": {
        "id": "RMYVJEQq4_jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reconstruction_loss = keras.losses.binary_crossentropy(input_layer, outputs[0])\n",
        "#reconstruction_loss *= input_dim\n",
        "#kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "#kl_loss = K.sum(kl_loss, axis=-1)\n",
        "#kl_loss *= -0.5\n",
        "#vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "#vae.add_loss(vae_loss)\n",
        "#vae.compile(optimizer='adam')\n",
        "\n",
        "def vae_loss(x, z_decoded):\n",
        "        # Reconstruction loss\n",
        "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "        # KL divergence\n",
        "        kl_loss = -5e-4 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)"
      ],
      "metadata": {
        "id": "5nYXeRv34_jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_0 = vae_loss\n",
        "loss_1 = 'categorical_crossentropy'\n",
        "\n",
        "vae.compile(optimizer=optimizer,loss=[vae_loss, loss_1],loss_weights=[0.75,0.25],)"
      ],
      "metadata": {
        "id": "l4YmyXDc7QGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vae = vae.fit(X_t, [X_t, y_t_],\n",
        "                      epochs=120,\n",
        "                      batch_size=128,\n",
        "                      callbacks = [early_stop, Checkpoint, lr],\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_v, [X_v, y_v_]))"
      ],
      "metadata": {
        "id": "Rwru1nRn4_jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_representation = encoder.predict(test_images)\n",
        "\n",
        "plt.figure(figsize=(15, 9))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[2][:,0],\n",
        "                y=latent_representation[2][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "MOVYtEpD4_jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "sns.scatterplot(x=latent_representation[1][:,0],\n",
        "                y=latent_representation[1][:,1],\n",
        "                hue=test_labels, palette='tab10')\n",
        "\n",
        "plt.xlabel(\"Encoder first dimension\")\n",
        "plt.ylabel(\"Encoder second dimension\")\n",
        "\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.01, 1),\n",
        "           borderaxespad=0);"
      ],
      "metadata": {
        "id": "wcN-zD2k4_jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss scores\n",
        "# against the number of epochs.\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history_vae.history['loss'], label='Train')\n",
        "plt.plot(history_vae.history['val_loss'], label='Validation')\n",
        "plt.ylabel('Customized Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Autoencoder Reconstruction Loss - Nadam', pad=13)\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "SNubkmS64_jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = vae.predict(test_images)\n",
        "n = 5\n",
        "plt.figure(figsize=(9, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "\n",
        "  plt.title(test_labels[i])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Jhpd1KU4_jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 20  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-3, 3, n)\n",
        "grid_y = np.linspace(-3, 3, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tt9Z5e_M4_jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae_prelu/autoencoder')\n",
        "encoder.save(f'/content/drive/MyDrive/Exercises/Autoencoders/vae_prelu/encoder')"
      ],
      "metadata": {
        "id": "Go6ReAt34_jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = vae.predict(test_images)[0]\n",
        "n = 15\n",
        "plt.figure(figsize=(22, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L6mUJm0uQ8jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "Q3jESRXR5WTz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iCSkpOGw5Xla"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}