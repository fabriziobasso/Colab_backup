{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/File_02_EDA_ext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o16Z8wP_6UDV"
      },
      "source": [
        "# **<h1 align=\"center\"><font color='#001ddd'> GLUCOSE PREDICTION DATASET**</font></h1>\n",
        "\n",
        "## **Dataset Description**\n",
        "The dataset is from a study that collected data from young adults in the UK with type 1 diabetes, who used a continuous glucose monitor (CGM), an insulin pump and a smartwatch. These devices collected blood glucose readings, insulin dosage, carbohydrate intake, and activity data. The data collected was aggregated to five-minute intervals and formatted into samples. Each sample represents a point in time and includes the aggregated five-minute intervals from the previous six hours. The aim is to predict the blood glucose reading an hour into the future, for each of these samples.\n",
        "\n",
        "The training set takes samples from the first three months of study data from nine of the participants and includes the future blood glucose value. These training samples appear in chronological order and overlap. The testing set takes samples from the remainder of the study period from fifteen of the participants (so unseen participants appear in the testing set). These testing samples do not overlap and are in a random order to avoid data leakage.\n",
        "\n",
        "**Complexities to be aware of:**\n",
        "\n",
        "This is medical data so there are missing values and noise in the data\n",
        "the participants did not all use the same device models (CGM, insulin pump and smartwatch) so there may be differences in the collection method of the data\n",
        "some participants in the test set do not appear in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--PrNXB8Ylys"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:#\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install category-encoders\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "#!pip install scikit-learn==1.4\n",
        "!pip install catboost\n",
        "!pip install deeptables\n",
        "\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install keras-nlp\n",
        "!pip install BorutaShap\n",
        "!pip install scikit-lego\n",
        "!!pip install --no-index -U --find-links=/kaggle/input/deeptables-v0-2-5/deeptables-0.2.5 deeptables==0.2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho3nCji3fPqQ"
      },
      "outputs": [],
      "source": [
        "folder_script = models_folders = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose\"\n",
        "os.chdir(folder_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syKhpAm8jJZe"
      },
      "outputs": [],
      "source": [
        "from category_encoders.cat_boost import CatBoostEncoder\n",
        "from category_encoders.wrapper import PolynomialWrapper\n",
        "from category_encoders.count import CountEncoder\n",
        "\n",
        "# Setup notebook\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "import json\n",
        "import joblib\n",
        "#import calplot as cal\n",
        "import missingno as msno\n",
        "import category_encoders as ce\n",
        "\n",
        "# Graphic Libraries:\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "\n",
        "# Bloomberg\n",
        "#from xbbg import blp\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "# Time Management\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BMonthEnd, QuarterEnd\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay # BDay is business day, not birthday...\n",
        "import datetime as dt\n",
        "import click\n",
        "import glob\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import string\n",
        "\n",
        "from ipywidgets import AppLayout\n",
        "from ipywidgets import Dropdown, Layout, HTML, AppLayout, VBox, Label, HBox, BoundedFloatText, interact, Output\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "\n",
        "from keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "\n",
        "from keras.utils import FeatureSpace, plot_model\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate, GroupKFold, GridSearchCV, RepeatedStratifiedKFold, cross_val_predict\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "# metrics\n",
        "import sklearn\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             root_mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss,\n",
        "                             make_scorer)\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  HuberRegressor,\n",
        "                                  TweedieRegressor,\n",
        "                                  QuantileRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  TheilSenRegressor,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              AdaBoostClassifier,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              HistGradientBoostingRegressor,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "import logging\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "import scipy.stats as ss\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Setting rc parameters in seaborn for plots and graphs-\n",
        "# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n",
        "# To alter this, refer to matplotlib.rcParams.keys()\n",
        "\n",
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.5,\n",
        "         'grid.alpha'           :0.5,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : 'black',\n",
        "         'axes.titlesize'       : 12,\n",
        "         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "# Set Style\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "pd.set_option('display.max_columns', 100);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMB0Ku9izBm"
      },
      "source": [
        "## 1.0 Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXVCNFXEiysu"
      },
      "outputs": [],
      "source": [
        "def encode_target(y_train, y_test, encoder_type='label', enc_strategy=False):\n",
        "    \"\"\"\n",
        "    Encodes the target columns in the training and testing data\n",
        "    using the specified encoder type.\n",
        "\n",
        "    Parameters:\n",
        "    y_train (pd.Series or pd.DataFrame): Training target data.\n",
        "    y_test (pd.Series or pd.DataFrame): Testing target data.\n",
        "\n",
        "    Returns:\n",
        "    y_train_encoded (pd.Series): Encoded training target data.\n",
        "    y_test_encoded (pd.Series): Encoded testing target data.\n",
        "    \"\"\"\n",
        "\n",
        "    if encoder_type == 'label':\n",
        "        encoder = LabelEncoder()\n",
        "        y_train_encoded = encoder.fit_transform(y_train)\n",
        "        y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "        y_train_encoded = pd.Series(y_train_encoded, index=y_train.index, name=\"Target\")\n",
        "        y_test_encoded = pd.Series(y_test_encoded, index=y_test.index, name=\"Target\")\n",
        "\n",
        "\n",
        "    elif encoder_type == 'onehot':\n",
        "        y_train_ = y_train.values.reshape(-1, 1)\n",
        "        y_test_ = y_test.values.reshape(-1, 1)\n",
        "\n",
        "        encoder = OneHotEncoder(sparse_output=False)\n",
        "        y_train_encoded = encoder.fit_transform(y_train_)\n",
        "        y_test_encoded = encoder.transform(y_test_)\n",
        "\n",
        "        y_train_encoded = pd.DataFrame(y_train_encoded, index=y_train.index)\n",
        "        y_test_encoded = pd.DataFrame(y_test_encoded, index=y_test.index)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label'.\")\n",
        "\n",
        "    if enc_strategy:\n",
        "        return y_train_encoded, y_test_encoded, encoder\n",
        "\n",
        "    else:\n",
        "        return y_train_encoded, y_test_encoded\n",
        "\n",
        "def encode_data(X_train, X_test, encoder_type='label', columns=None, map=None):\n",
        "    \"\"\"\n",
        "    Encodes the training and testing data using the specified encoder type.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (pd.DataFrame): Training data.\n",
        "    X_test (pd.DataFrame): Testing data.\n",
        "    encoder_type (str): Type of encoder ('label' or 'onehot'). Default is 'label'.\n",
        "    columns (list): List of columns to encode. If None, all object type columns are encoded.\n",
        "\n",
        "    Returns:\n",
        "    X_train_encoded (pd.DataFrame): Encoded training data.\n",
        "    X_test_encoded (pd.DataFrame): Encoded testing data.\n",
        "    \"\"\"\n",
        "\n",
        "    if columns is None:\n",
        "        # Default to all object type columns if no columns are specified\n",
        "        columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    X_train_encoded = X_train.copy()\n",
        "    X_test_encoded = X_test.copy()\n",
        "\n",
        "    if encoder_type == 'label':\n",
        "        for col in columns:\n",
        "            le = LabelEncoder()\n",
        "            X_train_encoded[col] = le.fit_transform(X_train[col])\n",
        "            X_test_encoded[col] = le.transform(X_test[col])\n",
        "\n",
        "    elif encoder_type == 'onehot':\n",
        "        for col in columns:\n",
        "            ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
        "            # Fit the encoder on the training data and transform both training and test data\n",
        "            encoded_train = ohe.fit_transform(X_train[[col]])\n",
        "            encoded_test = ohe.transform(X_test[[col]])\n",
        "\n",
        "            # Create a DataFrame with the encoded data\n",
        "            encoded_train_df = pd.DataFrame(encoded_train, columns=ohe.get_feature_names_out([col]))\n",
        "            encoded_test_df = pd.DataFrame(encoded_test, columns=ohe.get_feature_names_out([col]))\n",
        "\n",
        "            # Concatenate the new columns to the original dataframes and drop the original columns\n",
        "            X_train_encoded = pd.concat([X_train_encoded.drop(col, axis=1), encoded_train_df], axis=1)\n",
        "            X_test_encoded = pd.concat([X_test_encoded.drop(col, axis=1), encoded_test_df], axis=1)\n",
        "\n",
        "    elif encoder_type == 'count_encoder':\n",
        "\n",
        "          for col in columns:\n",
        "\n",
        "                target_encoder = CountEncoder(cols=columns)\n",
        "                X_train_encoded = target_encoder.fit_transform(X_train_encoded)\n",
        "                X_test_encoded = target_encoder.transform(X_test_encoded)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label', 'onehot', 'target_encoder'.\")\n",
        "\n",
        "    return X_train_encoded, X_test_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5NjoRTdyVHe"
      },
      "source": [
        "## **Importing the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGpj7GRz7V8b"
      },
      "source": [
        "## **Files**\n",
        "* activities.txt - a list of activity names that appear in the activity-X:XX columns\n",
        "* sample_submission.csv - a sample submission file in the correct format\n",
        "* test.csv - the test set\n",
        "* train.csv - the training set\n",
        "\n",
        "## **Columns**\n",
        "* train.csv:\n",
        "    * **id - row id** consisting of participant number and a count for that participant\n",
        "    * **p_num** - participant number\n",
        "    * **time** - time of day in the format HH:MM:SS\n",
        "    * **bg-X:XX** - blood glucose reading in mmol/L, X:XX(H:SS) time in the past (e.g. bg-2:35, would be the blood glucose reading from 2 hours and 35 minutes before the time value for that row), recorded by the continuous glucose monitor\n",
        "    * **insulin-X:XX** - total insulin dose received in units in the last 5 minutes, X:XX(H:SS) time in the past (e.g. insulin-2:35, would be the total insulin dose received between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the insulin pump\n",
        "    * **carbs-X:XX** - total carbohydrate value consumed in grammes in the last 5 minutes, X:XX(H:SS) time in the past (e.g. carbs-2:35, would be the total carbohydrate value consumed between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the participant\n",
        "    * **hr-X:XX** - mean heart rate in beats per minute in the last 5 minutes, X:XX(H:SS) time in the past (e.g. hr-2:35, would be the mean heart rate between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the smartwatch\n",
        "    * **steps-X:XX** - total steps walked in the last 5 minutes, X:XX(H:SS) time in the past (e.g. * steps-2:35, would be the total steps walked between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), recorded by the smartwatch\n",
        "    * **cals-X:XX** - total calories burnt in the last 5 minutes, X:XX(H:SS) time in the past (e.g. cals-2:35, would be the total calories burned between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), calculated by the smartwatch\n",
        "    * **activity-X:XX** - self-declared activity performed in the last 5 minutes, X:XX(H:SS) time in the past (e.g. activity-2:35, would show a string name of the activity performed between 2 hours and 40 minutes and 2 hours and 35 minutes before the time value for that row), set on the smartwatch\n",
        "    * **bg+1:00** - blood glucose reading in mmol/L an hour in the future, this is the value you will be predicting (not provided in test.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fiLvkXQuzJ3"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/final_train.csv\")\n",
        "df_test=pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/Glucose/final_test.csv\", index_col=0)\n",
        "\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIdNSqVxOY7o"
      },
      "outputs": [],
      "source": [
        "df_train.p_num.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8OmmGKk8KPX"
      },
      "outputs": [],
      "source": [
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(5)"
      ],
      "metadata": {
        "id": "Sb2zhG-O3K4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nJ0_v3bl0_s"
      },
      "outputs": [],
      "source": [
        "df_train.head()\n",
        "df_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z8CiYrCCuNQ"
      },
      "outputs": [],
      "source": [
        "df_all = pd.concat([df_train,df_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FXSnbRYnNg9"
      },
      "source": [
        "Sub-dataset are created for each main set of features to inpute missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHV_d6Ar-TX2"
      },
      "outputs": [],
      "source": [
        "# # Select columns containing the word \"bg\"\n",
        "# bg_col_train = df_train.filter(regex='bg|time|p_num|hour|minute')\n",
        "# bg_col_test = df_test.filter(regex='bg|time|p_num|hour|minute')\n",
        "\n",
        "# insulin_col_train = df_train.filter(regex='insulin|bg+1:00')\n",
        "# insulin_col_test = df_test.filter(regex='insulin|bg+1:00')\n",
        "# insulin_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# carb_col_train = df_train.filter(regex='carbs|time|p_num|bg+1:00|hour|minute')\n",
        "# carb_col_test = df_test.filter(regex='carbs|time|p_num|bg+1:00|hour|minute')\n",
        "# carb_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# hr_col_train = df_train.filter(regex='hr|time|p_num|bg+1:00|hour|minute')\n",
        "# hr_col_test = df_test.filter(regex='hr|time|p_num|bg+1:00|hour|minute')\n",
        "# hr_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# cal_col_train = df_train.filter(regex='cal|time|p_num|bg+1:00|hour|minute')\n",
        "# cal_col_test = df_test.filter(regex='cal|time|p_num|bg+1:00|hour|minute')\n",
        "# cal_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "\n",
        "# act_col_train = df_train.filter(regex='activity|time|p_num|bg+1:00|hour|minute')\n",
        "# act_col_test = df_test.filter(regex='activity|time|p_num|bg+1:00|hour|minute')\n",
        "# act_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Outliers**"
      ],
      "metadata": {
        "id": "RTpydJ3JfkKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------\n",
        "### Insulin"
      ],
      "metadata": {
        "id": "0LnpZ94eEYJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train.min().min(),insulin_col_test.min().min()"
      ],
      "metadata": {
        "id": "rsYZGDeGxbNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_test.clip(upper=10.0, inplace=True)\n",
        "# insulin_col_train.clip(upper=10.0, inplace=True)\n",
        "#insulin_col_train"
      ],
      "metadata": {
        "id": "flOHT1WGxCpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insulin_col_train"
      ],
      "metadata": {
        "id": "FDDYbqAQVqSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train.plot(kind=\"scatter\", x=\"insulin_av31\", y=\"insulin_av30\", alpha=0.6)\n",
        "# plt.xlabel(\"Insulin 0:00\")\n",
        "# plt.ylabel(\"Insulin 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "2p9zITNAvtoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(insulin_col_train)\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "KqH4_WJeg2rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# insulin_col_train.corr()[\"bg+1:00\"][:-1].plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "pnQnzAvqnGRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train.drop(columns=\"bg+1:00\", inplace=True)"
      ],
      "metadata": {
        "id": "q6YbHKbxnYtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_test.plot(kind=\"scatter\", x=\"insulin_av31\", y=\"insulin_av20\", alpha=0.6)\n",
        "# plt.xlabel(\"Insulin 0:00\")\n",
        "# plt.ylabel(\"Insulin 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "aJ5l50gZwgDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_test.head()"
      ],
      "metadata": {
        "id": "BXrsnBZ1tb8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_ins_col = list(insulin_col_test.columns)\n",
        "\n",
        "# obs_index = set()\n",
        "\n",
        "# for c in all_ins_col:\n",
        "#   susp = insulin_col_train[insulin_col_train[c]>10]\n",
        "#   new_ind = set(susp.index)\n",
        "#   obs_index = obs_index.union(new_ind)\n",
        "\n",
        "# obs_index = list(obs_index)\n",
        "# print(len(obs_index))"
      ],
      "metadata": {
        "id": "FB7faXGMf_pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------\n",
        "### Steps"
      ],
      "metadata": {
        "id": "-WWquyvcJs1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train = df_train.filter(regex='steps')\n",
        "# step_col_test = df_test.filter(regex='steps')\n",
        "# step_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# step_col_train.min().min(),step_col_train.min().min()"
      ],
      "metadata": {
        "id": "ZelWaWyjJs1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_test.clip(upper=10.0, inplace=True)\n",
        "# insulin_col_train.clip(upper=10.0, inplace=True)\n",
        "#insulin_col_train"
      ],
      "metadata": {
        "id": "Qyyc7NtfJs1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insulin_col_train"
      ],
      "metadata": {
        "id": "YwPNnoG0Js1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train.plot(kind=\"scatter\", x=\"steps_av31\", y=\"steps_av19\", alpha=0.6)\n",
        "# plt.xlabel(\"steps 0:00\")\n",
        "# plt.ylabel(\"steps 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "sbbYqp8IJs1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(step_col_train)\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "toffJ1xQJs1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_test.plot(kind=\"scatter\", x=\"steps_av31\", y=\"steps_av19\", alpha=0.6)\n",
        "# plt.xlabel(\"Steps 0:00\")\n",
        "# plt.ylabel(\"Steps 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "HhsLrqFjJs1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brake"
      ],
      "metadata": {
        "id": "_fQHHaCpny0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# brake_col_train = df_train.filter(regex='brake')\n",
        "# brake_col_test = df_test.filter(regex='brake')\n",
        "# #step_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# display(brake_col_train.sample(3))\n",
        "# brake_col_train.min().min(),brake_col_test.min().min()"
      ],
      "metadata": {
        "id": "4f-okzTon1Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# brake_col_train.plot(kind=\"scatter\", x=\"brake31\", y=\"brake30\", alpha=0.6)\n",
        "# plt.xlabel(\"brake 0:00\")\n",
        "# plt.ylabel(\"brake 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "M1AabXbVn1Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(brake_col_train)\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "x6c_yJW0n1BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# brake_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# brake_col_train.corr()[\"bg+1:00\"][:-1].plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "wsTtU8Nen07d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# brake_col_train.drop(columns=\"bg+1:00\", inplace=True)"
      ],
      "metadata": {
        "id": "_LUd61chn04W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "3N6jK9rwSZrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYNfgB1gObc"
      },
      "source": [
        "## Scale the Data:\n",
        "\n",
        "Data are scaled in groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwLn5-lSY1g3"
      },
      "outputs": [],
      "source": [
        "static_fields = [\"p_num\"] #\"id\",\n",
        "target = [\"bg+1:00\"]\n",
        "ts_fields = list(df_train.drop(columns=static_fields+target))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(columns=target).copy()\n",
        "y_train = df_train[target].copy()\n",
        "\n",
        "X_test = df_test.drop(columns=target).copy()"
      ],
      "metadata": {
        "id": "ACo0DVA5PDvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odQB0ciycJWf"
      },
      "outputs": [],
      "source": [
        "ts_fields_group = list({q[:-2] for q in ts_fields})\n",
        "ts_fields_group = ['steps_av','insulin_av','activity','cals_av', 'brake', 'carbs_av','bg','hr','intake']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.filter(regex=\"bg\")"
      ],
      "metadata": {
        "id": "PC2X06bmIjsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgrdNhb2cJTC"
      },
      "outputs": [],
      "source": [
        "scaling_groups = {group: X_train.filter(regex=group) for group in ts_fields_group}\n",
        "scaling_groups_test = {group: X_test.filter(regex=group) for group in ts_fields_group}\n",
        "\n",
        "scaled_groups = {group: X_train.filter(regex=group) for group in ts_fields_group}\n",
        "scaled_groups_test = {group: X_test.filter(regex=group) for group in ts_fields_group}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQQpzqFpggTX"
      },
      "outputs": [],
      "source": [
        "# Create the function for the transformation\n",
        "def log_transform(x, c=1):  # 'c' is the constant to add\n",
        "    return np.log1p(x + c)\n",
        "\n",
        "scaling_strat = {group: QuantileTransformer(output_distribution='normal', subsample=None, random_state=42) for group in ts_fields_group}\n",
        "scaling_strat[\"steps_av\"] = StandardScaler() #Pipeline([('log_trans', FunctionTransformer(func=log_transform, kw_args={'c': 0})), ('quantile', QuantileTransformer(output_distribution='normal', subsample=None))])\n",
        "scaling_strat[\"carbs_av\"] = MinMaxScaler()\n",
        "scaling_strat[\"activity\"] = MinMaxScaler()\n",
        "scaling_strat['bg'] = StandardScaler()\n",
        "#scaling_strat['intake'] = QuantileTransformer(output_distribution='normal', subsample=25000, random_state=42) #FunctionTransformer(func=log_transform, kw_args={'c': 10})\n",
        "#scaling_strat['carbs_av'] = PowerTransformer() #QuantileTransformer(output_distribution='normal', subsample=25000, random_state=42) #FunctionTransformer(func=log_transform, kw_args={'c': 10})\n",
        "#scaling_strat['insulin_av'] = QuantileTransformer(output_distribution='normal', subsample=None, random_state=42) #PowerTransformer() #FunctionTransformer(func=log_transform, kw_args={'c': 10})\n",
        "\n",
        "scaling_strat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqVFJs1SQkFo"
      },
      "outputs": [],
      "source": [
        "# log_features = []\n",
        "\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('log', FunctionTransformer(func=np.log1p), log_features),\n",
        "#         ('minmax', MinMaxScaler(), minmax_features)\n",
        "#     ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRKbTOh5ggPr"
      },
      "outputs": [],
      "source": [
        "# n_bins=30\n",
        "# for group in ts_fields_group:\n",
        "\n",
        "#   stand_scaler = StandardScaler()\n",
        "\n",
        "#   data_train_ = scaling_groups[group].values.reshape(-1,1)\n",
        "#   data_train = scaling_strat[group].fit_transform(data_train_)\n",
        "\n",
        "#   data_train_s = pd.DataFrame(data_train.reshape(-1,32),index=scaling_groups[group].index, columns=scaling_groups[group].columns)\n",
        "#   data_train_s = pd.DataFrame(stand_scaler.fit_transform(data_train_s),index=data_train_s.index, columns=data_train_s.columns)\n",
        "\n",
        "#   scaled_groups[group] = data_train_s\n",
        "\n",
        "#   data_test_ = scaling_groups_test[group].values.reshape(-1,1)\n",
        "#   data_test = scaling_strat[group].transform(data_test_)\n",
        "#   data_test_s = pd.DataFrame(data_test.reshape(-1,32),index=scaling_groups_test[group].index, columns=scaling_groups_test[group].columns)\n",
        "#   data_test_s = pd.DataFrame(stand_scaler.transform(data_test_s),index=data_test_s.index, columns=data_test_s.columns)\n",
        "#   scaled_groups_test[group] = data_test_s\n",
        "\n",
        "#   fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True, figsize=(6, 3))\n",
        "\n",
        "#   # We can set the number of bins with the *bins* keyword argument.\n",
        "#   axs[0].hist(data_train_, bins=n_bins)\n",
        "#   axs[1].hist(data_train, bins=n_bins)\n",
        "#   axs[0].set_title(\"Unscaled\", fontsize=8)\n",
        "#   axs[1].set_title(\"Scaled\", fontsize=8)\n",
        "#   plt.suptitle(group, fontsize=12)\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_p0xXeRgf6o"
      },
      "outputs": [],
      "source": [
        "X_train_scaled_ = X_train[static_fields].copy()\n",
        "X_test_scaled_ = X_test[static_fields].copy()\n",
        "\n",
        "X_train_scaled = pd.concat([scaled_groups[group] for group in ts_fields_group], axis=1)\n",
        "X_train_scaled = pd.concat([X_train_scaled_,X_train_scaled], axis=1)\n",
        "\n",
        "X_test_scaled = pd.concat([scaled_groups_test[group] for group in ts_fields_group], axis=1)\n",
        "X_test_scaled = pd.concat([X_test_scaled_,X_test_scaled], axis=1)\n",
        "\n",
        "print(X_train.shape,X_train_scaled.shape)\n",
        "print(X_test.shape,X_test_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "8gNSkH3USdQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Scaling Analysis:"
      ],
      "metadata": {
        "id": "Gef0uPjNo_gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insulin"
      ],
      "metadata": {
        "id": "OJ6EROA0sVsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train = X_train_scaled.filter(regex='insulin').copy()\n",
        "# insulin_col_test = X_test_scaled.filter(regex='insulin').copy()\n",
        "\n",
        "# insulin_col_train.min().min()"
      ],
      "metadata": {
        "id": "6nN-52lz4tg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train.plot(kind=\"scatter\", x=\"insulin_av31\", y=\"insulin_av30\", alpha=0.6)\n",
        "# plt.xlabel(\"Insulin 0:00\")\n",
        "# plt.ylabel(\"Insulin 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0k9MvYEJzuTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(insulin_col_train)\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "fQYoRrqLgnUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# insulin_col_train.corr()[\"bg+1:00\"][:-1].plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "eobF8fBnpvDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train.drop(columns=\"bg+1:00\", inplace=True)\n",
        "# scaler=StandardScaler()\n",
        "\n",
        "# insulin_col_train = pd.DataFrame(scaler.fit_transform(insulin_col_train),index=insulin_col_train.index, columns=insulin_col_train.columns)"
      ],
      "metadata": {
        "id": "Dgdfb_KMpu-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(insulin_col_train)\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "ApbDIHUdpu76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# insulin_col_train.corr()[\"bg+1:00\"][:-1].plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "cRsiWHFWpu4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------\n",
        "### Steps"
      ],
      "metadata": {
        "id": "fPDbUwvwscZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train = X_train_scaled.filter(regex='steps')\n",
        "# step_col_test = X_test_scaled.filter(regex='steps')\n",
        "# #step_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "\n",
        "# step_col_train.min().min(),step_col_test.min().min()"
      ],
      "metadata": {
        "id": "hiHe8q1rscZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insulin_col_test.clip(upper=10.0, inplace=True)\n",
        "# insulin_col_train.clip(upper=10.0, inplace=True)\n",
        "#insulin_col_train"
      ],
      "metadata": {
        "id": "-pVHL8phscZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insulin_col_train"
      ],
      "metadata": {
        "id": "BXFHT9R3scZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train.plot(kind=\"scatter\", x=\"steps_av31\", y=\"steps_av19\", alpha=0.6)\n",
        "# plt.xlabel(\"steps 0:00\")\n",
        "# plt.ylabel(\"steps 1:00\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "jtsyOTHjscZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(step_col_train)\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "gwGy3vpvscZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# step_col_train.corr()[\"bg+1:00\"][:-1].plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "qEgM48z0pu1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train.drop(columns=\"bg+1:00\", inplace=True)\n",
        "# scaler=StandardScaler()\n",
        "\n",
        "# step_col_train = pd.DataFrame(scaler.fit_transform(step_col_train),index=step_col_train.index, columns=step_col_train.columns)"
      ],
      "metadata": {
        "id": "CMP62FtSs7DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax =  plt.subplots(figsize=(15,5))\n",
        "# ax.boxplot(step_col_train.iloc[:,:-1])\n",
        "# #plt.yscale('log')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "N_04ZBbAs7DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step_col_train[\"bg+1:00\"] = df_train[\"bg+1:00\"]\n",
        "# step_col_train.corr()[\"bg+1:00\"][:-1].plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "g2vyEan_s7DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add back Target:"
      ],
      "metadata": {
        "id": "2BjTNbZ8TXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[\"bg+1:00\"] = y_train.values\n",
        "X_test_scaled[\"bg+1:00\"] = np.nan\n",
        "print(X_train.shape,X_train_scaled.shape)\n",
        "print(X_test.shape,X_test_scaled.shape)"
      ],
      "metadata": {
        "id": "F3l0JPjwzkPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(y_train, bins=30, color=\"salmon\")\n",
        "plt.xlabel(\"bg+1:00\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Target Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U8xum8WMbXaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Data"
      ],
      "metadata": {
        "id": "zNi17EWFddRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.reset_index().to_csv(\"X_train_scaled.csv\",index=False)\n",
        "X_test_scaled.reset_index().to_csv(\"X_test_scaled.csv\",index=False)"
      ],
      "metadata": {
        "id": "6uMRl3baVuVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X_train_scaled.select_dtypes(include=\"float\").columns\n",
        "\n",
        "X_train_scaled[num_cols] = X_train_scaled[num_cols].astype(\"float32\")\n",
        "X_test_scaled[num_cols] = X_test_scaled[num_cols].astype(\"float32\")"
      ],
      "metadata": {
        "id": "1gKkwn-rcYLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "284dsQlnUJaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.reset_index().to_csv(\"X_train_scaled_smaller.csv\",index=False)\n",
        "X_test_scaled.reset_index().to_csv(\"X_test_scaled_smaller.csv\",index=False)"
      ],
      "metadata": {
        "id": "OjVncvqqULxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgqnAYyaUSHP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}