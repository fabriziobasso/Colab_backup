{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/File_02_Calories_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTING CALOORIES BURNED\n",
        "\n",
        "## RMSLE Metric and Competition Context\n",
        "\n",
        "This notebook is developed for a data science competition focused on predicting **Calories burned** during exercise. The evaluation metric for this competition is the **Root Mean Squared Logarithmic Error (RMSLE)**, which measures the square root of the mean squared difference between the logarithms of predicted and actual values. RMSLE is ideal for datasets with a wide range of target values, as it emphasizes **relative errors**, ensuring balanced performance across small and large calorie values.\n",
        "\n",
        "The RMSLE formula is:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*AUzyQ1rc6mpQVYfn)\n",
        "\n",
        "### Why RMSLE?\n",
        "- **Handles Wide Ranges**: RMSLE penalizes relative errors proportionally, making it robust for calorie values ranging from small (e.g., 10 calories) to large (e.g., 1000 calories).\n",
        "- **Balanced Evaluation**: Ensures models perform well across the entire spectrum of calorie burn.\n",
        "- **Competition Goal**: A lower RMSLE score indicates a precise and generalizable model, critical for ranking high on the leaderboard.\n",
        "\n",
        "---\n",
        "\n",
        "## Potential Effects of Features on Calorie Burn\n",
        "\n",
        "The dataset includes the following features to predict calorie burn: **Sex**, **Age**, **Height**, **Weight**, **Duration**, **Heart_Rate**, and **Body_Temp**. Below, we explore how each feature might influence calorie burn:\n",
        "\n",
        "### 1. Sex\n",
        "- **Impact**: Differences in metabolic rates and muscle mass between males and females affect calorie burn. Males often have higher muscle mass, leading to greater calorie expenditure for the same exercise.\n",
        "- **Example**: A male running at the same pace and duration as a female may burn more calories due to higher energy demands.\n",
        "\n",
        "### 2. Age\n",
        "- **Impact**: Basal metabolic rate (BMR) decreases with age, reducing calorie burn in older individuals due to lower metabolic rates and muscle mass (sarcopenia).\n",
        "- **Example**: A 20-year-old may burn more calories than a 50-year-old during identical workouts.\n",
        "\n",
        "### 3. Height\n",
        "- **Impact**: Taller individuals have more body mass or muscle, requiring more energy for movement, thus burning more calories. Height’s effect is often linked to weight and exercise intensity.\n",
        "- **Example**: A taller person may expend more energy covering the same distance.\n",
        "\n",
        "### 4. Weight\n",
        "- **Impact**: Heavier individuals burn more calories due to the energy required to move greater body mass. Body composition (fat vs. muscle) also influences calorie burn.\n",
        "- **Example**: A 90 kg individual burns more calories walking the same distance as a 60 kg individual.\n",
        "\n",
        "### 5. Duration\n",
        "- **Impact**: Longer exercise sessions directly increase total calorie expenditure, though intensity and exercise type also matter.\n",
        "- **Example**: Running for 30 minutes burns more calories than running for 15 minutes.\n",
        "\n",
        "### 6. Heart_Rate\n",
        "- **Impact**: Higher heart rates indicate greater exercise intensity and metabolic effort, leading to increased calorie burn. Fitness levels can modulate heart rate responses.\n",
        "- **Example**: High heart rate during a HIIT workout correlates with higher calorie burn.\n",
        "\n",
        "### 7. Body_Temp\n",
        "- **Impact**: Rising body temperature during exercise reflects increased metabolic activity and thermoregulation, potentially increasing calorie burn. Environmental factors (e.g., heat) also play a role.\n",
        "- **Example**: Exercising in a hot environment may increase calorie expenditure due to thermoregulation.\n",
        "\n",
        "---\n",
        "\n",
        "## Transition to Analysis\n",
        "\n",
        "Understanding the relationships between these features and calorie burn is key to building a predictive model. In this notebook, we will:\n",
        "\n",
        "1. **Explore Data**: Analyze the distribution of the target variable (**Calories**) and features using visualizations (e.g., histograms, boxplots).\n",
        "2. **Correlation Analysis**: Identify relationships between features and the target using correlation matrices and polar plots.\n",
        "3. **Outlier Detection**: Address anomalies that could skew model performance.\n",
        "4. **Feature Engineering**: Apply techniques like quantile and equal-width binning to enhance model input.\n",
        "5. **Model Development**: Build and evaluate models to minimize RMSLE, aligning with competition objectives.\n",
        "\n",
        "### Visualization Strategy\n",
        "We will use:\n",
        "- **Histograms** and **boxplots** to examine feature distributions.\n",
        "- **Correlation matrices** to uncover feature relationships.\n",
        "- **Polar plots** for creative visualization of feature impacts.\n",
        "- **Pair plots** to explore pairwise relationships.\n",
        "\n",
        "By systematically analyzing the data, we aim to develop a robust model that accurately predicts calorie burn and excels in the competition.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0plw_SZl679v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.0 Setting"
      ],
      "metadata": {
        "id": "Q4e2HGJH8zTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Import Libraries:"
      ],
      "metadata": {
        "id": "boXswaUo7Uvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall scikit-learn\n",
        "# !pip install scikit-learn==1.4"
      ],
      "metadata": {
        "id": "8fOwAMLAw7Co"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6rYYQgW0Rmxv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!pip install -qq pytorch_tabnet\n",
        "!pip install optuna\n",
        "!pip install --upgrade catboost\n",
        "#!pip install optuna-integration-pytorch-tabnet\n",
        "\n",
        "#from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "!pip install --upgrade category-encoders\n",
        "!pip install optuna-integration\n",
        "!pip install colorama\n",
        "#!pip install pyfiglet\n",
        "#!pip install keras-tuner --upgrade\n",
        "#!pip install keras-nlp\n",
        "#!pip install BorutaShap\n",
        "#!pip install scikit-learn==1.2.2\n",
        "#!pip install scikit-lego\n",
        "!pip install skops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import lightgbm, xgboost, catboost\n",
        "sklearn.__version__, lightgbm.__version__, xgboost.__version__, catboost.__version__"
      ],
      "metadata": {
        "id": "crKlzXJctRD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568285cb-5a45-424b-ac5c-27068ddee9d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.6.1', '4.5.0', '2.1.4', '1.2.8')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vIS1habP8JGi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4104357-dbcd-422d-a9b6-af158273c400"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Setup notebook\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "import json\n",
        "import joblib\n",
        "#from joblib import dump, load\n",
        "#import calplot as cal\n",
        "\n",
        "# Graphic Libraries:\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "from termcolor import colored\n",
        "# Set Style\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5});\n",
        "sns.despine(left=True, bottom=True, top=False, right=False);\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "mpl.rc('axes', labelsize=12);\n",
        "plt.rc('xtick',labelsize=10);\n",
        "plt.rc('ytick',labelsize=10);\n",
        "\n",
        "mpl.rcParams['axes.spines.top'] = False;\n",
        "mpl.rcParams['axes.spines.right'] = False;\n",
        "mpl.rcParams['axes.spines.left'] = True;\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "# tool for Excel:\n",
        "from openpyxl import load_workbook, Workbook\n",
        "from openpyxl.drawing.image import Image\n",
        "from openpyxl.styles import Border, Side, PatternFill, Font, GradientFill, Alignment\n",
        "from openpyxl.worksheet.cell_range import CellRange\n",
        "\n",
        "from openpyxl.formatting import Rule\n",
        "from openpyxl.styles import Font, PatternFill, Border\n",
        "from openpyxl.styles.differential import DifferentialStyle\n",
        "\n",
        "# Bloomberg\n",
        "#from xbbg import blp\n",
        "from catboost import CatBoostRegressor, Pool, CatBoostClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "# Time Management\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BMonthEnd, QuarterEnd\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay # BDay is business day, not birthday...\n",
        "import datetime as dt\n",
        "import click\n",
        "import glob\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import string\n",
        "\n",
        "from ipywidgets import AppLayout\n",
        "from ipywidgets import Dropdown, Layout, HTML, AppLayout, VBox, Label, HBox, BoundedFloatText, interact, Output\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "\n",
        "from keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "\n",
        "from keras.utils import FeatureSpace, plot_model\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "#import keras_tuner as kt\n",
        "#from keras_tuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedKFold, cross_val_score, cross_validate, GroupKFold, GridSearchCV, RepeatedStratifiedKFold, cross_val_predict\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures,\n",
        "                                   FunctionTransformer)\n",
        "\n",
        "# metrics\n",
        "import sklearn\n",
        "#import skops.io as sio\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             root_mean_squared_error,\n",
        "                             root_mean_squared_log_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss,\n",
        "                             make_scorer)\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  HuberRegressor,\n",
        "                                  TweedieRegressor,\n",
        "                                  QuantileRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  TheilSenRegressor,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              AdaBoostClassifier,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              StackingClassifier,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              HistGradientBoostingRegressor,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.base import clone\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from category_encoders import TargetEncoder, CatBoostEncoder, LeaveOneOutEncoder, OrdinalEncoder, CountEncoder\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "from sklearn.multioutput import RegressorChain\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "import scipy.stats as ss\n",
        "\n",
        "#from category_encoders.cat_boost import CatBoostEncoder\n",
        "#from category_encoders.wrapper import PolynomialWrapper\n",
        "#from category_encoders.count import CountEncoder\n",
        "#from category_encoders import TargetEncoder\n",
        "\n",
        "import skops.io as sio\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#import pyfiglet\n",
        "#plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Formatting and Settings:**"
      ],
      "metadata": {
        "id": "yQhbcUmY8EXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pkkRPWKZCkYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2be5ab86-acb9-47dd-8206-ea8cb461c8d7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x660 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.5,\n",
        "         'grid.alpha'           :0.5,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : 'black',\n",
        "         'axes.titlesize'       : 12,\n",
        "#         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "# Set Style\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "\n",
        "# import font colors\n",
        "from colorama import Fore, Style, init\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "pd.set_option('display.max_columns', 100);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True\n",
        "\n",
        "init(autoreset=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NU7oWpLHRmxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16c461e-a047-4840-c77d-33f5356fe06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from itertools import product\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "import torch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Connect to Colab:#\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Functions:"
      ],
      "metadata": {
        "id": "cVSGNoaQB8fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Plotting Functiss**"
      ],
      "metadata": {
        "id": "3uNczPcrH4iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_scatter(df, x=\"feat1\", y=\"feat2\", color_feature=None, cmap='viridis'):\n",
        "    \"\"\"\n",
        "    Generates a scatter plot with points colored based on a third feature.\n",
        "\n",
        "    Args:\n",
        "        df: Pandas DataFrame containing the data.\n",
        "        x: Name of the column to use for the x-axis.\n",
        "        y: Name of the column to use for the y-axis.\n",
        "        color_feature: Name of the column to use for coloring the points.\n",
        "                       If None, points will be a single color.\n",
        "        cmap: Colormap to use for coloring the points (e.g., 'viridis', 'plasma', 'magma', 'inferno', 'cividis').\n",
        "              See matplotlib documentation for available colormaps.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    if color_feature is not None:\n",
        "        # Ensure the color feature exists\n",
        "        if color_feature not in df.columns:\n",
        "            raise ValueError(f\"Color feature '{color_feature}' not found in DataFrame.\")\n",
        "\n",
        "        # Scatter plot with colors\n",
        "        scatter = plt.scatter(df[x], df[y], c=df[color_feature], cmap=cmap)\n",
        "\n",
        "        # Add a colorbar\n",
        "        cbar = plt.colorbar(scatter)\n",
        "        cbar.set_label(color_feature)  # Label the colorbar\n",
        "\n",
        "    else:\n",
        "        # Simple scatter plot (single color)\n",
        "        plt.scatter(df[x], df[y],color=\"royalblue\",alpha=0.6)\n",
        "\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel(y)\n",
        "    plt.title(\"Scatter Plot\")  # Add a title for better visualization\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RjO42zM1B8FU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Dataset Management Functions**:"
      ],
      "metadata": {
        "id": "rVeb3ga2HynB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "\n",
        "    state = 42\n",
        "    n_splits = 10\n",
        "    early_stop = 200\n",
        "\n",
        "    target = 'Calories'\n",
        "    train = pd.read_csv('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/test.csv')\n",
        "    submission = pd.read_csv( \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\")\n",
        "    #train_org = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/original.csv\")\n",
        "\n",
        "    original_data = 'N'\n",
        "    outliers = 'N'\n",
        "    log_trf = 'Y'\n",
        "    scaler_trf = 'Y'\n",
        "    feature_eng = 'N'\n",
        "    missing = 'Y'\n",
        "    sqrt_normalization=\"Y\"\n",
        "    impose_normalization=\"N\"\n",
        "    trg_enc = \"N\"\n",
        "    problem = \"Regression\"\n",
        "    metric_goal=\"LRMSE\"\n",
        "    direction_=\"minimize\"\n",
        "    log_trans_cols = [\"Body_Temp\"]\n",
        "    sqrt_norm_cols = [\"Age\"]\n",
        "    impose_norm_cols = []\n",
        "    trg_enc_feat = []\n",
        "\n",
        "class Preprocessing():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.train = Config.train\n",
        "        self.test = Config.test\n",
        "        self.targets = Config.target\n",
        "\n",
        "        self.prp_data()\n",
        "\n",
        "    def prp_data(self):\n",
        "\n",
        "        if Config.original_data == 'Y':\n",
        "            self.train = pd.concat([self.train, Config.train_org], ignore_index=True).drop_duplicates(ignore_index=True)\n",
        "\n",
        "        self.train = self.train.drop(['id'], axis=1)\n",
        "        self.test = self.test.drop(['id'], axis=1)\n",
        "\n",
        "        self.cat_features = self.train.drop(self.targets, axis=1).select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "        self.num_features = self.train.drop(self.targets, axis=1).select_dtypes(exclude=['object', 'bool']).columns.tolist()\n",
        "\n",
        "        self.train = self.reduce_mem(self.train)\n",
        "        self.test = self.reduce_mem(self.test)\n",
        "        return self\n",
        "\n",
        "    def reduce_mem(self, df):\n",
        "\n",
        "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', \"uint16\", \"uint32\", \"uint64\"]\n",
        "\n",
        "        for col in df.columns:\n",
        "            col_type = df[col].dtypes\n",
        "\n",
        "            if col_type in numerics:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "\n",
        "                if \"int\" in str(col_type):\n",
        "                    if c_min >= np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min >= np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min >= np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min >= np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "                else:\n",
        "                    if c_min >= np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    if c_min >= np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float64)\n",
        "\n",
        "        return df\n",
        "\n",
        "class EDA(Config, Preprocessing):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_info()\n",
        "        self.heatmap()\n",
        "        self.dist_plots()\n",
        "        self.cat_feature_plots()\n",
        "        if Config.problem == 'Classification':\n",
        "          self.target_pie()\n",
        "        else:\n",
        "          self.target_dist()\n",
        "\n",
        "    def data_info(self):\n",
        "\n",
        "        for data, label in zip([self.train, self.test], ['Train', 'Test']):\n",
        "            table_style = [{'selector': 'th:not(.index_name)',\n",
        "                            'props': [('background-color', 'slategrey'),\n",
        "                                      ('color', '#FFFFFF'),\n",
        "                                      ('font-weight', 'bold'),\n",
        "                                      ('border', '1px solid #DCDCDC'),\n",
        "                                      ('text-align', 'center')]\n",
        "                            },\n",
        "                            {'selector': 'tbody td',\n",
        "                             'props': [('border', '1px solid #DCDCDC'),\n",
        "                                       ('font-weight', 'normal')]\n",
        "                            }]\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} head\\n')\n",
        "            display(data.head().style.set_table_styles(table_style))\n",
        "\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} info\\n'+Style.RESET_ALL)\n",
        "            display(data.info())\n",
        "\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} describe\\n')\n",
        "            display(data.describe().drop(index='count', columns=self.targets, errors = 'ignore').T\n",
        "                    .style.set_table_styles(table_style).format('{:.3f}'))\n",
        "\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} missing values\\n'+Style.RESET_ALL)\n",
        "            display(data.isnull().sum())\n",
        "        return self\n",
        "\n",
        "    def heatmap(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f'\\nCorrelation Heatmap\\n')\n",
        "        plt.figure(figsize=(7,7))\n",
        "        corr = self.train.select_dtypes(exclude='object').corr(method='pearson')\n",
        "        sns.heatmap(corr, fmt = '0.2f', cmap = 'Blues', annot=True, cbar=False)\n",
        "        plt.show()\n",
        "\n",
        "    def dist_plots(self):\n",
        "\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nDistribution analysis - Numerical\\n\")\n",
        "        df = pd.concat([self.train[self.num_features].assign(Source = 'Train'),\n",
        "                        self.test[self.num_features].assign(Source = 'Test'),],\n",
        "                        axis=0, ignore_index = True)\n",
        "\n",
        "        fig, axes = plt.subplots(len(self.num_features), 2 ,figsize = (13, len(self.num_features) * 4),\n",
        "                                 gridspec_kw = {'hspace': 0.3,\n",
        "                                                'wspace': 0.2,\n",
        "                                                'width_ratios': [0.70, 0.30]\n",
        "                                               }\n",
        "                                )\n",
        "        for i,col in enumerate(self.num_features):\n",
        "            try:\n",
        "                ax = axes[i,0]\n",
        "            except:\n",
        "                ax = axes[i]\n",
        "            sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source',\n",
        "                        palette = ['royalblue', 'tomato'], ax = ax, alpha=0.7, linewidth = 2\n",
        "                       )\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.set_title(f\"\\n{col}\")\n",
        "            ax.grid('--',alpha=0.7)\n",
        "\n",
        "            try:\n",
        "                ax = axes[i,1]\n",
        "            except:\n",
        "                ax = axes[1]\n",
        "            sns.boxplot(data = df, y = col, x=df.Source, width = 0.5,\n",
        "                        linewidth = 1, fliersize= 1,\n",
        "                        ax = ax, palette=['royalblue', 'tomato']\n",
        "                       )\n",
        "            ax.set_title(f\"\\n{col}\")\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.tick_params(axis='both', which='major')\n",
        "            ax.set_xticklabels(['Train', 'Test'])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def cat_feature_plots(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nDistribution analysis - Categorical\\n\")\n",
        "        fig, axes = plt.subplots(len(self.cat_features), 2 ,figsize = (18, len(self.cat_features) * 6),\n",
        "                                 gridspec_kw = {'hspace': 0.5,\n",
        "                                                'wspace': 0.2,\n",
        "                                               }\n",
        "                                )\n",
        "\n",
        "        for i, col in enumerate(self.cat_features):\n",
        "            try:\n",
        "                ax = axes[i,0]\n",
        "            except:\n",
        "                ax = axes[i]\n",
        "            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='royalblue', alpha=0.7)\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.set_title(f\"\\n{col} Train\")\n",
        "\n",
        "            try:\n",
        "                ax = axes[i,1]\n",
        "            except:\n",
        "                ax = axes[i+1]\n",
        "            sns.barplot(data=self.test[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='tomato', alpha=0.7)\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.set_title(f\"\\n{col} Test\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def target_pie(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nTarget feature distribution\\n\")\n",
        "        targets = self.train[self.targets]\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(targets.value_counts(), labels=targets.value_counts().index, autopct='%1.2f%%', colors=palette_9)\n",
        "        plt.show()\n",
        "\n",
        "    def target_dist(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nTarget feature distribution\\n\")\n",
        "        fig, axes = plt.subplots(1, 1, figsize=(7, 5))\n",
        "        sns.histplot(self.train[self.targets], kde=True, ax=axes)\n",
        "        axes.set_title('Distribution of Price')\n",
        "        axes.set_xlabel(self.targets)\n",
        "        axes.set_ylabel('Frequency')"
      ],
      "metadata": {
        "id": "0595jA_qHZuK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 EDA"
      ],
      "metadata": {
        "id": "49q4hFif9abF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Experiment Area:"
      ],
      "metadata": {
        "id": "tTS6MhPt9dWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    SEED    = 333\n",
        "    CV      = KFold(n_splits=15, shuffle=True, random_state=SEED)\n",
        "    VERSION = '1'\n",
        "\n",
        "class Data:\n",
        "    path       = False\n",
        "    or_path    = ''\n",
        "    to_drop    = False\n",
        "    target     = 'Calories'\n",
        "    drop_duplicates = False\n",
        "\n",
        "    def __init__(self):\n",
        "        self.train      = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_train_01.csv\",index_col=0).drop(columns=self.to_drop) if self.to_drop else pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_train_01.csv\",index_col=0)\n",
        "        self.test       = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_test_01.csv\",index_col=0).drop(columns=self.to_drop) if self.to_drop else pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_test_01.csv\",index_col=0)\n",
        "        self.submission = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "        self.original   = pd.read_csv(self.or_path) if self.or_path else pd.DataFrame()\n",
        "\n",
        "        self.train.loc[:,\"BMI\"] = np.clip(self.train.BMI, a_min=-5.0, a_max=5.0)\n",
        "        self.test.loc[:,\"BMI\"] = np.clip(self.test.BMI, a_min=-5.0, a_max=5.0)\n",
        "\n",
        "    @property\n",
        "    def X(self):\n",
        "        return self.train.drop(columns=self.target)\n",
        "    @property\n",
        "    def y(self):\n",
        "        return self.train[[self.target]]\n",
        "    @property\n",
        "    def X_test(self):\n",
        "        return self.test\n",
        "    @property\n",
        "    def X_original(self):\n",
        "        if len(self.original) != 0:\n",
        "            return self.original.drop(columns=self.target)\n",
        "        return pd.DataFrame()\n",
        "    @property\n",
        "    def y_original(self):\n",
        "        if len(self.original) != 0:\n",
        "            return self.original[[self.target]]\n",
        "        return pd.DataFrame()\n",
        "    @property\n",
        "    def cat_features(self):\n",
        "        return self.X.select_dtypes(include=['category', 'bool', 'category','int']).columns.to_list()\n",
        "    @property\n",
        "    def num_features(self):\n",
        "        return self.X.select_dtypes(exclude=['category', 'bool', 'category','int']).columns.to_list()\n",
        "\n",
        "    def submit(self, sub: np.ndarray, desc: str):\n",
        "        '''Submit the predictions in the adequate format'''\n",
        "        self.submission[self.target] = sub\n",
        "        self.submission.to_csv(f'SUB_{CFG.VERSION}_{desc}.csv', index=False)\n",
        "        print(colored('Submission has been made.', color='green', attrs=['bold', 'dark']))\n",
        "\n",
        "    @staticmethod\n",
        "    def sep_line():\n",
        "        print(colored(f'{\"_____\"*14}', color='black'))\n",
        "        print('')\n",
        "\n",
        "    @staticmethod\n",
        "    def head(head_text):\n",
        "        print(colored(f'{\"    \"} ➩ {head_text} ', color='green', attrs=['dark']))\n",
        "\n",
        "    def display_data(self):\n",
        "        self.head(f'𝐃𝐚𝐭𝐚𝐬𝐞𝐭 𝐬𝐡𝐚𝐩𝐞𝐬 — 𝐓𝐫𝐚𝐢𝐧 | 𝐓𝐞𝐬𝐭: {self.train.shape} | {self.test.shape}')\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐓𝐫𝐚𝐢𝐧 𝐡𝐞𝐚𝐝')\n",
        "        display(self.train.head(5))\n",
        "        self.head('𝐓𝐞𝐬𝐭 𝐡𝐞𝐚𝐝')\n",
        "        display(self.test.head(5))\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐓𝐫𝐚𝐢𝐧 𝐢𝐧𝐟𝐨')\n",
        "        display(self.train.info())\n",
        "        self.head('𝐓𝐞𝐬𝐭 𝐢𝐧𝐟𝐨')\n",
        "        display(self.test.info())\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐓𝐫𝐚𝐢𝐧 𝐬𝐮𝐦𝐦𝐚𝐫𝐲 𝐬𝐭𝐚𝐭𝐬')\n",
        "        display(self.train.describe().T)\n",
        "        self.head('𝐓𝐞𝐬𝐭 𝐬𝐮𝐦𝐦𝐚𝐫𝐲 𝐬𝐭𝐚𝐭𝐬')\n",
        "        display(self.test.describe().T)\n",
        "        self.sep_line()\n",
        "\n",
        "        def nunique_null(train, test):\n",
        "            nunique_train, nunique_test = {}, {}\n",
        "            nulls_train, nulls_test = {}, {}\n",
        "\n",
        "            for col in test.columns:\n",
        "                nunique_train[col], nunique_test[col] = train[col].nunique(), test[col].nunique()\n",
        "                nulls_train[col], nulls_test[col] = train[col].isna().sum(), test[col].isna().sum()\n",
        "\n",
        "            df = pd.DataFrame([nunique_train, nunique_test,\n",
        "                               nulls_train, nulls_test],\n",
        "                              index=['Train nunique', 'Test nunique',\n",
        "                                     'Train null', 'Test null'])\n",
        "            return df\n",
        "\n",
        "        self.head('𝐍𝐮𝐧𝐢𝐪𝐮𝐞 𝐚𝐧𝐝 𝐧𝐮𝐥𝐥𝐬')\n",
        "        display(nunique_null(self.train, self.test))\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞𝐬')\n",
        "        display(f'Train duplicated: {self.train.duplicated().sum()}')\n",
        "        display(f'Test duplicated: {self.test.duplicated().sum()}')\n",
        "\n",
        "        if self.drop_duplicates==True:\n",
        "          if self.train.duplicated().sum() > 0:\n",
        "              self.train = self.train.drop_duplicates()\n",
        "              print('Train duplicates dropped.')\n",
        "          if self.test.duplicated().sum() > 0:\n",
        "              #self.test = self.test.drop_duplicates()\n",
        "              print('Test duplicates dropped.')\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐍𝐮𝐧𝐢𝐪𝐮𝐞 𝐢𝐧 𝐭𝐫𝐚𝐢𝐧 𝐧𝐨𝐭 𝐢𝐧 𝐭𝐞𝐬𝐭/𝐢𝐧 𝐭𝐞𝐬𝐭 𝐧𝐨𝐭 𝐢𝐧 𝐭𝐫𝐚𝐢𝐧')\n",
        "        cat_cols = [c for c in self.test.columns if self.train[c].nunique() <= 40 or\n",
        "                    c in self.test.select_dtypes(include=['object', 'category']).columns]\n",
        "\n",
        "        def compare_unique_categories(train, test, cat_cols):\n",
        "            unique_train_dic, unique_test_dic = {}, {}\n",
        "\n",
        "            for c in cat_cols:\n",
        "                unique_train_c = train[c].unique()\n",
        "                unique_test_c = test[c].unique()\n",
        "\n",
        "                count_tr = sum(1 for cat in unique_train_c if cat not in unique_test_c and not pd.isna(cat))\n",
        "                count_te = sum(1 for cat in unique_test_c if (cat not in unique_train_c and not pd.isna(cat)))\n",
        "\n",
        "                unique_train_dic[c] = count_tr\n",
        "                unique_test_dic[c] = count_te\n",
        "\n",
        "            result_df = pd.DataFrame([unique_train_dic, unique_test_dic],\n",
        "                                     index=['in train not in test', 'in test not in train'])\n",
        "\n",
        "            return result_df\n",
        "\n",
        "        display(compare_unique_categories(self.train, self.test, cat_cols))\n",
        "\n",
        "data = Data()\n",
        "data.display_data()"
      ],
      "metadata": {
        "id": "YGfCDVNy67x7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f38d48a-6a46-4f40-b0bb-9a0328b01b41"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ➩ 𝐃𝐚𝐭𝐚𝐬𝐞𝐭 𝐬𝐡𝐚𝐩𝐞𝐬 — 𝐓𝐫𝐚𝐢𝐧 | 𝐓𝐞𝐬𝐭: (765000, 13) | (250000, 12) \n",
            "______________________________________________________________________\n",
            "\n",
            "     ➩ 𝐓𝐫𝐚𝐢𝐧 𝐡𝐞𝐚𝐝 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Sex    Height    Weight  Heart_Rate  Body_Temp       BMI  Intensity  \\\n",
              "0    1  1.113015  0.489702    0.583480   1.236062 -0.938031   1.183180   \n",
              "1    0 -0.909676 -1.081265   -1.109199  -0.430898 -1.184666  -0.923712   \n",
              "2    0 -1.065268 -0.795635   -1.214992  -0.302671  0.209075  -1.017567   \n",
              "3    1  1.346402  1.060962    1.006650   0.851379  0.026339   1.161541   \n",
              "4    0 -0.676289 -1.009858    0.689273   0.723151 -1.479569   1.075158   \n",
              "\n",
              "   Heart_Duration  Weight_Duration_Heart  Outliers_Duration_Heart_Temp  \\\n",
              "0       -0.952799               1.338352                             0   \n",
              "1        0.431582              -1.004625                             0   \n",
              "2        0.610071              -1.047153                             0   \n",
              "3       -0.852901               1.619162                             0   \n",
              "4       -0.890178               0.535818                             0   \n",
              "\n",
              "    BMI_Age  Age_Group  Calories  \n",
              "0  0.899410          3     150.0  \n",
              "1 -0.783423          6      34.0  \n",
              "2 -0.920441          5      29.0  \n",
              "3  0.610264          1     140.0  \n",
              "4  0.794743          3     146.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31b70c54-f0f3-41f6-8c4b-3556f15f0416\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Heart_Rate</th>\n",
              "      <th>Body_Temp</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>Heart_Duration</th>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <th>BMI_Age</th>\n",
              "      <th>Age_Group</th>\n",
              "      <th>Calories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.113015</td>\n",
              "      <td>0.489702</td>\n",
              "      <td>0.583480</td>\n",
              "      <td>1.236062</td>\n",
              "      <td>-0.938031</td>\n",
              "      <td>1.183180</td>\n",
              "      <td>-0.952799</td>\n",
              "      <td>1.338352</td>\n",
              "      <td>0</td>\n",
              "      <td>0.899410</td>\n",
              "      <td>3</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.909676</td>\n",
              "      <td>-1.081265</td>\n",
              "      <td>-1.109199</td>\n",
              "      <td>-0.430898</td>\n",
              "      <td>-1.184666</td>\n",
              "      <td>-0.923712</td>\n",
              "      <td>0.431582</td>\n",
              "      <td>-1.004625</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.783423</td>\n",
              "      <td>6</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.065268</td>\n",
              "      <td>-0.795635</td>\n",
              "      <td>-1.214992</td>\n",
              "      <td>-0.302671</td>\n",
              "      <td>0.209075</td>\n",
              "      <td>-1.017567</td>\n",
              "      <td>0.610071</td>\n",
              "      <td>-1.047153</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.920441</td>\n",
              "      <td>5</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.346402</td>\n",
              "      <td>1.060962</td>\n",
              "      <td>1.006650</td>\n",
              "      <td>0.851379</td>\n",
              "      <td>0.026339</td>\n",
              "      <td>1.161541</td>\n",
              "      <td>-0.852901</td>\n",
              "      <td>1.619162</td>\n",
              "      <td>0</td>\n",
              "      <td>0.610264</td>\n",
              "      <td>1</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.676289</td>\n",
              "      <td>-1.009858</td>\n",
              "      <td>0.689273</td>\n",
              "      <td>0.723151</td>\n",
              "      <td>-1.479569</td>\n",
              "      <td>1.075158</td>\n",
              "      <td>-0.890178</td>\n",
              "      <td>0.535818</td>\n",
              "      <td>0</td>\n",
              "      <td>0.794743</td>\n",
              "      <td>3</td>\n",
              "      <td>146.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b70c54-f0f3-41f6-8c4b-3556f15f0416')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31b70c54-f0f3-41f6-8c4b-3556f15f0416 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31b70c54-f0f3-41f6-8c4b-3556f15f0416');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4884385d-5463-4e02-9d73-e4794b012920\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4884385d-5463-4e02-9d73-e4794b012920')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4884385d-5463-4e02-9d73-e4794b012920 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.168750816056408,\n        \"min\": -1.0652676534121075,\n        \"max\": 1.346402126739124,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.9096760546926732,\n          -0.6762886566135219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9785706603690901,\n        \"min\": -1.0812653537820445,\n        \"max\": 1.0609624481289703,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.0812653537820445,\n          -1.0098577603850107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0647789066057443,\n        \"min\": -1.2149916926185682,\n        \"max\": 1.0066499700235418,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.109199232492753,\n          0.6892725896460976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7399530547704812,\n        \"min\": -0.4308983794101588,\n        \"max\": 1.236062481396348,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.4308983794101588,\n          0.7231514473020388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7499545582553401,\n        \"min\": -1.4795687676941394,\n        \"max\": 0.209074627099514,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.1846658978984863,\n          -1.4795687676941394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1572048872856004,\n        \"min\": -1.017567477816385,\n        \"max\": 1.1831795261555886,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.923711952613644,\n          1.0751579176742505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7808393405806044,\n        \"min\": -0.952799106288478,\n        \"max\": 0.6100706037007835,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4315817341670164,\n          -0.8901783646387891\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight_Duration_Heart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2639380737405015,\n        \"min\": -1.047153323068602,\n        \"max\": 1.6191619689980792,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.0046250182560108,\n          0.535817840722791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outliers_Duration_Heart_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8946798485909927,\n        \"min\": -0.9204414238211772,\n        \"max\": 0.8994097113393933,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.783423385813749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age_Group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Calories\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62.47559523525967,\n        \"min\": 29.0,\n        \"max\": 150.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ➩ 𝐓𝐞𝐬𝐭 𝐡𝐞𝐚𝐝 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Sex    Height    Weight  Heart_Rate  Body_Temp       BMI  Intensity  \\\n",
              "750000    1  0.179465  0.418294   -0.897614  -0.302671  0.978939  -0.995739   \n",
              "750001    1  1.968769  1.560816    0.583480   0.594924 -0.082149   0.507888   \n",
              "750002    0  1.035219  0.703924    0.689273   0.466696 -0.214836   0.093216   \n",
              "750003    0 -0.209514 -0.152967    1.218235   0.723151  0.199218   0.640408   \n",
              "750004    0 -0.131718 -0.581412   -0.157067   0.594924 -1.314534  -0.037914   \n",
              "\n",
              "        Heart_Duration  Weight_Duration_Heart  Outliers_Duration_Heart_Temp  \\\n",
              "750000        0.661858              -0.890129                             0   \n",
              "750001       -0.611173               1.078027                             0   \n",
              "750002       -0.294981               0.309886                             0   \n",
              "750003       -0.533902               0.544812                             0   \n",
              "750004       -0.407071              -0.199594                             0   \n",
              "\n",
              "         BMI_Age  Age_Group  \n",
              "750000 -0.910919          4  \n",
              "750001  0.200535          2  \n",
              "750002 -0.106216          2  \n",
              "750003  0.579460          3  \n",
              "750004 -0.269589          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80f7ed25-f00c-441d-9010-16925dde61c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Heart_Rate</th>\n",
              "      <th>Body_Temp</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>Heart_Duration</th>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <th>BMI_Age</th>\n",
              "      <th>Age_Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>750000</th>\n",
              "      <td>1</td>\n",
              "      <td>0.179465</td>\n",
              "      <td>0.418294</td>\n",
              "      <td>-0.897614</td>\n",
              "      <td>-0.302671</td>\n",
              "      <td>0.978939</td>\n",
              "      <td>-0.995739</td>\n",
              "      <td>0.661858</td>\n",
              "      <td>-0.890129</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.910919</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750001</th>\n",
              "      <td>1</td>\n",
              "      <td>1.968769</td>\n",
              "      <td>1.560816</td>\n",
              "      <td>0.583480</td>\n",
              "      <td>0.594924</td>\n",
              "      <td>-0.082149</td>\n",
              "      <td>0.507888</td>\n",
              "      <td>-0.611173</td>\n",
              "      <td>1.078027</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200535</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750002</th>\n",
              "      <td>0</td>\n",
              "      <td>1.035219</td>\n",
              "      <td>0.703924</td>\n",
              "      <td>0.689273</td>\n",
              "      <td>0.466696</td>\n",
              "      <td>-0.214836</td>\n",
              "      <td>0.093216</td>\n",
              "      <td>-0.294981</td>\n",
              "      <td>0.309886</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.106216</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750003</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.209514</td>\n",
              "      <td>-0.152967</td>\n",
              "      <td>1.218235</td>\n",
              "      <td>0.723151</td>\n",
              "      <td>0.199218</td>\n",
              "      <td>0.640408</td>\n",
              "      <td>-0.533902</td>\n",
              "      <td>0.544812</td>\n",
              "      <td>0</td>\n",
              "      <td>0.579460</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750004</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.131718</td>\n",
              "      <td>-0.581412</td>\n",
              "      <td>-0.157067</td>\n",
              "      <td>0.594924</td>\n",
              "      <td>-1.314534</td>\n",
              "      <td>-0.037914</td>\n",
              "      <td>-0.407071</td>\n",
              "      <td>-0.199594</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.269589</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80f7ed25-f00c-441d-9010-16925dde61c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80f7ed25-f00c-441d-9010-16925dde61c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80f7ed25-f00c-441d-9010-16925dde61c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-477c3837-9071-4d57-9f89-d100eb537ff7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-477c3837-9071-4d57-9f89-d100eb537ff7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-477c3837-9071-4d57-9f89-d100eb537ff7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9254103821113405,\n        \"min\": -0.209513860455219,\n        \"max\": 1.968768521616861,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.968768521616861,\n          -0.1317180610955018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8228931252742432,\n        \"min\": -0.5814122000028078,\n        \"max\": 1.5608156019082071,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.5608156019082071,\n          -0.5814122000028078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8242312226565776,\n        \"min\": -0.8976143122411238,\n        \"max\": 1.2182348902751714,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5834801295202828,\n          -0.1570670913604204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41152920671151083,\n        \"min\": -0.3026706208865884,\n        \"max\": 0.7231514473020388,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5949236887784592,\n          0.7231514473020388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8278515213007824,\n        \"min\": -1.3145344779297474,\n        \"max\": 0.9789389219887332,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0821489916265427,\n          -1.3145344779297474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6444091637358313,\n        \"min\": -0.9957385463926176,\n        \"max\": 0.6404075079111087,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5078877686861787,\n          -0.0379138691385319\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5168140810053241,\n        \"min\": -0.6111730504613958,\n        \"max\": 0.6618575514632249,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.6111730504613958,\n          -0.4070711897878227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight_Duration_Heart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7491709408256775,\n        \"min\": -0.8901288339925667,\n        \"max\": 1.0780268784060487,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0780268784060487,\n          -0.1995942786722129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outliers_Duration_Heart_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5564097276691058,\n        \"min\": -0.9109191970341604,\n        \"max\": 0.5794598525114797,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2005352581172527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age_Group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______________________________________________________________________\n",
            "\n",
            "     ➩ 𝐓𝐫𝐚𝐢𝐧 𝐢𝐧𝐟𝐨 \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 765000 entries, 0 to 1014999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   Sex                           765000 non-null  int64  \n",
            " 1   Height                        765000 non-null  float64\n",
            " 2   Weight                        765000 non-null  float64\n",
            " 3   Heart_Rate                    765000 non-null  float64\n",
            " 4   Body_Temp                     765000 non-null  float64\n",
            " 5   BMI                           765000 non-null  float64\n",
            " 6   Intensity                     765000 non-null  float64\n",
            " 7   Heart_Duration                765000 non-null  float64\n",
            " 8   Weight_Duration_Heart         765000 non-null  float64\n",
            " 9   Outliers_Duration_Heart_Temp  765000 non-null  int64  \n",
            " 10  BMI_Age                       765000 non-null  float64\n",
            " 11  Age_Group                     765000 non-null  int64  \n",
            " 12  Calories                      765000 non-null  float64\n",
            "dtypes: float64(10), int64(3)\n",
            "memory usage: 81.7 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ➩ 𝐓𝐞𝐬𝐭 𝐢𝐧𝐟𝐨 \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 250000 entries, 750000 to 999999\n",
            "Data columns (total 12 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   Sex                           250000 non-null  int64  \n",
            " 1   Height                        250000 non-null  float64\n",
            " 2   Weight                        250000 non-null  float64\n",
            " 3   Heart_Rate                    250000 non-null  float64\n",
            " 4   Body_Temp                     250000 non-null  float64\n",
            " 5   BMI                           250000 non-null  float64\n",
            " 6   Intensity                     250000 non-null  float64\n",
            " 7   Heart_Duration                250000 non-null  float64\n",
            " 8   Weight_Duration_Heart         250000 non-null  float64\n",
            " 9   Outliers_Duration_Heart_Temp  250000 non-null  int64  \n",
            " 10  BMI_Age                       250000 non-null  float64\n",
            " 11  Age_Group                     250000 non-null  int64  \n",
            "dtypes: float64(9), int64(3)\n",
            "memory usage: 24.8 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______________________________________________________________________\n",
            "\n",
            "     ➩ 𝐓𝐫𝐚𝐢𝐧 𝐬𝐮𝐦𝐦𝐚𝐫𝐲 𝐬𝐭𝐚𝐭𝐬 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 count          mean        std       min  \\\n",
              "Sex                           765000.0  4.989882e-01   0.499999  0.000000   \n",
              "Height                        765000.0  5.077641e-16   1.000001 -4.021508   \n",
              "Weight                        765000.0  1.343297e-16   1.000001 -2.795048   \n",
              "Heart_Rate                    765000.0  6.856041e-16   1.000001 -3.013464   \n",
              "Body_Temp                     765000.0  1.793228e-14   1.000001 -3.764820   \n",
              "BMI                           765000.0 -1.325152e-04   0.998632 -5.000000   \n",
              "Intensity                     765000.0  3.098059e-17   1.000001 -1.563858   \n",
              "Heart_Duration                765000.0  1.517255e-15   1.000001 -1.390121   \n",
              "Weight_Duration_Heart         765000.0  1.852636e-16   1.000001 -1.507367   \n",
              "Outliers_Duration_Heart_Temp  765000.0  3.921569e-05   0.006262  0.000000   \n",
              "BMI_Age                       765000.0  1.750443e-16   1.000001 -1.511686   \n",
              "Age_Group                     765000.0  3.623880e+00   1.541745  1.000000   \n",
              "Calories                      765000.0  8.830742e+01  62.396760  1.000000   \n",
              "\n",
              "                                    25%        50%         75%         max  \n",
              "Sex                            0.000000   0.000000    1.000000    1.000000  \n",
              "Height                        -0.831880  -0.053922    0.801832    3.680276  \n",
              "Weight                        -0.867043  -0.081559    0.846740    4.060081  \n",
              "Heart_Rate                    -0.791822  -0.051275    0.795065    3.439877  \n",
              "Body_Temp                     -0.559126   0.338468    0.851379    1.877201  \n",
              "BMI                           -0.740093   0.011128    0.736294    5.000000  \n",
              "Intensity                     -0.875844  -0.105610    0.840522    2.483148  \n",
              "Heart_Duration                -0.757049  -0.333324    0.443798    4.005130  \n",
              "Weight_Duration_Heart         -0.837452  -0.131506    0.702951    4.344034  \n",
              "Outliers_Duration_Heart_Temp   0.000000   0.000000    0.000000    1.000000  \n",
              "BMI_Age                       -0.850150  -0.126144    0.736107    4.030577  \n",
              "Age_Group                      2.000000   3.000000    5.000000    7.000000  \n",
              "Calories                      34.000000  77.000000  136.000000  314.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd7dede1-686a-48e0-a8b0-5ddb4a3dd77b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>4.989882e-01</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>5.077641e-16</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-4.021508</td>\n",
              "      <td>-0.831880</td>\n",
              "      <td>-0.053922</td>\n",
              "      <td>0.801832</td>\n",
              "      <td>3.680276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>1.343297e-16</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-2.795048</td>\n",
              "      <td>-0.867043</td>\n",
              "      <td>-0.081559</td>\n",
              "      <td>0.846740</td>\n",
              "      <td>4.060081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Rate</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>6.856041e-16</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-3.013464</td>\n",
              "      <td>-0.791822</td>\n",
              "      <td>-0.051275</td>\n",
              "      <td>0.795065</td>\n",
              "      <td>3.439877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Body_Temp</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>1.793228e-14</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-3.764820</td>\n",
              "      <td>-0.559126</td>\n",
              "      <td>0.338468</td>\n",
              "      <td>0.851379</td>\n",
              "      <td>1.877201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>-1.325152e-04</td>\n",
              "      <td>0.998632</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>-0.740093</td>\n",
              "      <td>0.011128</td>\n",
              "      <td>0.736294</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intensity</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>3.098059e-17</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-1.563858</td>\n",
              "      <td>-0.875844</td>\n",
              "      <td>-0.105610</td>\n",
              "      <td>0.840522</td>\n",
              "      <td>2.483148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Duration</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>1.517255e-15</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-1.390121</td>\n",
              "      <td>-0.757049</td>\n",
              "      <td>-0.333324</td>\n",
              "      <td>0.443798</td>\n",
              "      <td>4.005130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>1.852636e-16</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-1.507367</td>\n",
              "      <td>-0.837452</td>\n",
              "      <td>-0.131506</td>\n",
              "      <td>0.702951</td>\n",
              "      <td>4.344034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>3.921569e-05</td>\n",
              "      <td>0.006262</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI_Age</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>1.750443e-16</td>\n",
              "      <td>1.000001</td>\n",
              "      <td>-1.511686</td>\n",
              "      <td>-0.850150</td>\n",
              "      <td>-0.126144</td>\n",
              "      <td>0.736107</td>\n",
              "      <td>4.030577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Group</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>3.623880e+00</td>\n",
              "      <td>1.541745</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calories</th>\n",
              "      <td>765000.0</td>\n",
              "      <td>8.830742e+01</td>\n",
              "      <td>62.396760</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>314.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd7dede1-686a-48e0-a8b0-5ddb4a3dd77b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd7dede1-686a-48e0-a8b0-5ddb4a3dd77b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd7dede1-686a-48e0-a8b0-5ddb4a3dd77b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8dc56f2e-acc5-4623-9cd4-b1b4fc5303ee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dc56f2e-acc5-4623-9cd4-b1b4fc5303ee')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8dc56f2e-acc5-4623-9cd4-b1b4fc5303ee button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 765000.0,\n        \"max\": 765000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          765000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.417211186614555,\n        \"min\": -0.0001325152491667629,\n        \"max\": 88.30742352941176,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          3.6238797385620916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.053987900216377,\n        \"min\": 0.006262124213478731,\n        \"max\": 62.3967604613897,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1.5417452727894405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9147995601797518,\n        \"min\": -5.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.58077503684998,\n        \"min\": -0.875843963245995,\n        \"max\": 34.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.316116525525697,\n        \"min\": -0.3333241017308226,\n        \"max\": 77.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.444456547720165,\n        \"min\": 0.0,\n        \"max\": 136.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.13465660756,\n        \"min\": 1.0,\n        \"max\": 314.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ➩ 𝐓𝐞𝐬𝐭 𝐬𝐮𝐦𝐦𝐚𝐫𝐲 𝐬𝐭𝐚𝐭𝐬 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 count      mean       std       min  \\\n",
              "Sex                           250000.0  0.498876  0.500000  0.000000   \n",
              "Height                        250000.0  0.002528  0.997501 -3.710325   \n",
              "Weight                        250000.0  0.000396  0.998243 -2.580825   \n",
              "Heart_Rate                    250000.0 -0.000591  0.999756 -3.013464   \n",
              "Body_Temp                     250000.0  0.000066  0.998186 -3.764820   \n",
              "BMI                           250000.0 -0.004466  0.998080 -5.000000   \n",
              "Intensity                     250000.0 -0.000928  0.999746 -1.563333   \n",
              "Heart_Duration                250000.0 -0.000380  0.997461 -1.312222   \n",
              "Weight_Duration_Heart         250000.0 -0.000767  0.999786 -1.505219   \n",
              "Outliers_Duration_Heart_Temp  250000.0  0.000028  0.005291  0.000000   \n",
              "BMI_Age                       250000.0 -0.001029  0.999830 -1.508818   \n",
              "Age_Group                     250000.0  3.623832  1.538621  1.000000   \n",
              "\n",
              "                                   25%       50%       75%       max  \n",
              "Sex                           0.000000  0.000000  1.000000  1.000000  \n",
              "Height                       -0.831880 -0.053922  0.801832  3.446889  \n",
              "Weight                       -0.867043 -0.081559  0.846740  3.631636  \n",
              "Heart_Rate                   -0.791822 -0.051275  0.795065  3.439877  \n",
              "Body_Temp                    -0.559126  0.338468  0.723151  1.877201  \n",
              "BMI                          -0.740093  0.008131  0.728037  5.000000  \n",
              "Intensity                    -0.876596 -0.107700  0.834455  2.493177  \n",
              "Heart_Duration               -0.757049 -0.326515  0.437294  3.835281  \n",
              "Weight_Duration_Heart        -0.837925 -0.134480  0.699004  4.053276  \n",
              "Outliers_Duration_Heart_Temp  0.000000  0.000000  0.000000  1.000000  \n",
              "BMI_Age                      -0.850105 -0.127124  0.732317  3.487105  \n",
              "Age_Group                     2.000000  3.000000  5.000000  7.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c5f474e-5a40-4746-ab63-be4cf375a77f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>0.498876</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>0.997501</td>\n",
              "      <td>-3.710325</td>\n",
              "      <td>-0.831880</td>\n",
              "      <td>-0.053922</td>\n",
              "      <td>0.801832</td>\n",
              "      <td>3.446889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.998243</td>\n",
              "      <td>-2.580825</td>\n",
              "      <td>-0.867043</td>\n",
              "      <td>-0.081559</td>\n",
              "      <td>0.846740</td>\n",
              "      <td>3.631636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Rate</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>-0.000591</td>\n",
              "      <td>0.999756</td>\n",
              "      <td>-3.013464</td>\n",
              "      <td>-0.791822</td>\n",
              "      <td>-0.051275</td>\n",
              "      <td>0.795065</td>\n",
              "      <td>3.439877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Body_Temp</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.998186</td>\n",
              "      <td>-3.764820</td>\n",
              "      <td>-0.559126</td>\n",
              "      <td>0.338468</td>\n",
              "      <td>0.723151</td>\n",
              "      <td>1.877201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>-0.004466</td>\n",
              "      <td>0.998080</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>-0.740093</td>\n",
              "      <td>0.008131</td>\n",
              "      <td>0.728037</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intensity</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>-0.000928</td>\n",
              "      <td>0.999746</td>\n",
              "      <td>-1.563333</td>\n",
              "      <td>-0.876596</td>\n",
              "      <td>-0.107700</td>\n",
              "      <td>0.834455</td>\n",
              "      <td>2.493177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Duration</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.997461</td>\n",
              "      <td>-1.312222</td>\n",
              "      <td>-0.757049</td>\n",
              "      <td>-0.326515</td>\n",
              "      <td>0.437294</td>\n",
              "      <td>3.835281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>-0.000767</td>\n",
              "      <td>0.999786</td>\n",
              "      <td>-1.505219</td>\n",
              "      <td>-0.837925</td>\n",
              "      <td>-0.134480</td>\n",
              "      <td>0.699004</td>\n",
              "      <td>4.053276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.005291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI_Age</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>-0.001029</td>\n",
              "      <td>0.999830</td>\n",
              "      <td>-1.508818</td>\n",
              "      <td>-0.850105</td>\n",
              "      <td>-0.127124</td>\n",
              "      <td>0.732317</td>\n",
              "      <td>3.487105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Group</th>\n",
              "      <td>250000.0</td>\n",
              "      <td>3.623832</td>\n",
              "      <td>1.538621</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c5f474e-5a40-4746-ab63-be4cf375a77f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c5f474e-5a40-4746-ab63-be4cf375a77f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c5f474e-5a40-4746-ab63-be4cf375a77f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-be78a895-874a-4641-a6ef-238a62c75a47\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be78a895-874a-4641-a6ef-238a62c75a47')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-be78a895-874a-4641-a6ef-238a62c75a47 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 250000.0,\n        \"max\": 250000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          250000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.043081239440903,\n        \"min\": -0.00446569712445531,\n        \"max\": 3.623832,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          -0.0010292838867875763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3632650732490894,\n        \"min\": 0.005291439123472267,\n        \"max\": 1.5386211701386616,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.9998298177086934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7700475229777473,\n        \"min\": -5.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8268266573517176,\n        \"min\": -0.8765961446590179,\n        \"max\": 2.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -0.740092857566932\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8930703460373253,\n        \"min\": -0.3265154592246458,\n        \"max\": 3.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.008130826579319\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2696410670034421,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.7323170868983471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6743686230477384,\n        \"min\": 1.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______________________________________________________________________\n",
            "\n",
            "     ➩ 𝐍𝐮𝐧𝐢𝐪𝐮𝐞 𝐚𝐧𝐝 𝐧𝐮𝐥𝐥𝐬 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Sex  Height  Weight  Heart_Rate  Body_Temp   BMI  Intensity  \\\n",
              "Train nunique    2      92      92          63         75  2201      11378   \n",
              "Test nunique     2      85      84          61         51  1812       9097   \n",
              "Train null       0       0       0           0          0     0          0   \n",
              "Test null        0       0       0           0          0     0          0   \n",
              "\n",
              "               Heart_Duration  Weight_Duration_Heart  \\\n",
              "Train nunique            1102                  21630   \n",
              "Test nunique              973                  19010   \n",
              "Train null                  0                      0   \n",
              "Test null                   0                      0   \n",
              "\n",
              "               Outliers_Duration_Heart_Temp  BMI_Age  Age_Group  \n",
              "Train nunique                             2   755720          7  \n",
              "Test nunique                              2   248943          7  \n",
              "Train null                                0        0          0  \n",
              "Test null                                 0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-210fca45-c124-49f6-9d62-ddd6f5de962d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Heart_Rate</th>\n",
              "      <th>Body_Temp</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>Heart_Duration</th>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <th>BMI_Age</th>\n",
              "      <th>Age_Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train nunique</th>\n",
              "      <td>2</td>\n",
              "      <td>92</td>\n",
              "      <td>92</td>\n",
              "      <td>63</td>\n",
              "      <td>75</td>\n",
              "      <td>2201</td>\n",
              "      <td>11378</td>\n",
              "      <td>1102</td>\n",
              "      <td>21630</td>\n",
              "      <td>2</td>\n",
              "      <td>755720</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test nunique</th>\n",
              "      <td>2</td>\n",
              "      <td>85</td>\n",
              "      <td>84</td>\n",
              "      <td>61</td>\n",
              "      <td>51</td>\n",
              "      <td>1812</td>\n",
              "      <td>9097</td>\n",
              "      <td>973</td>\n",
              "      <td>19010</td>\n",
              "      <td>2</td>\n",
              "      <td>248943</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Train null</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test null</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-210fca45-c124-49f6-9d62-ddd6f5de962d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-210fca45-c124-49f6-9d62-ddd6f5de962d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-210fca45-c124-49f6-9d62-ddd6f5de962d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ffb4123a-1bff-43d1-97bd-28396d429f30\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ffb4123a-1bff-43d1-97bd-28396d429f30')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ffb4123a-1bff-43d1-97bd-28396d429f30 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 0,\n        \"max\": 92,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          92,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 0,\n        \"max\": 92,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          92,\n          84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 0,\n        \"max\": 63,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          63,\n          61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 0,\n        \"max\": 75,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          75,\n          51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1169,\n        \"min\": 0,\n        \"max\": 2201,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2201,\n          1812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5983,\n        \"min\": 0,\n        \"max\": 11378,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          11378,\n          9097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 601,\n        \"min\": 0,\n        \"max\": 1102,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1102,\n          973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight_Duration_Heart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11780,\n        \"min\": 0,\n        \"max\": 21630,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          21630,\n          19010\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outliers_Duration_Heart_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 356252,\n        \"min\": 0,\n        \"max\": 755720,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          755720,\n          248943\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age_Group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______________________________________________________________________\n",
            "\n",
            "     ➩ 𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞𝐬 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Train duplicated: 2893'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Test duplicated: 918'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______________________________________________________________________\n",
            "\n",
            "     ➩ 𝐍𝐮𝐧𝐢𝐪𝐮𝐞 𝐢𝐧 𝐭𝐫𝐚𝐢𝐧 𝐧𝐨𝐭 𝐢𝐧 𝐭𝐞𝐬𝐭/𝐢𝐧 𝐭𝐞𝐬𝐭 𝐧𝐨𝐭 𝐢𝐧 𝐭𝐫𝐚𝐢𝐧 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Sex  Outliers_Duration_Heart_Temp  Age_Group\n",
              "in train not in test    0                             0          0\n",
              "in test not in train    0                             0          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa873ab4-8a33-42cb-af44-21edf6918b36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <th>Age_Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>in train not in test</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in test not in train</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa873ab4-8a33-42cb-af44-21edf6918b36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa873ab4-8a33-42cb-af44-21edf6918b36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa873ab4-8a33-42cb-af44-21edf6918b36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c4196897-53bd-431c-9b0f-6cc36abd7b51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4196897-53bd-431c-9b0f-6cc36abd7b51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c4196897-53bd-431c-9b0f-6cc36abd7b51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outliers_Duration_Heart_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age_Group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.shape, data.y.shape, data.X_test.shape"
      ],
      "metadata": {
        "id": "4-BfljxHg43C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80854673-872d-474c-8a50-fd22f1b6c523"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((765000, 12), (765000, 1), (250000, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.cat_features)"
      ],
      "metadata": {
        "id": "kEtWXl_ThCwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0646d85b-f376-495c-c567-aae8e5572331"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sex', 'Outliers_Duration_Heart_Temp', 'Age_Group']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_scatter(pd.concat([data.X,data.y],axis=1), x=\"BMI\", y=\"Intensity\", color_feature=\"Calories\")"
      ],
      "metadata": {
        "id": "uuFOKAjRPsMb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.info(),data.X_test.info()"
      ],
      "metadata": {
        "id": "73sGT_yqY8G2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f15ddd7-1ba3-440e-d902-a6ac9287a94d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 765000 entries, 0 to 1014999\n",
            "Data columns (total 12 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   Sex                           765000 non-null  int64  \n",
            " 1   Height                        765000 non-null  float64\n",
            " 2   Weight                        765000 non-null  float64\n",
            " 3   Heart_Rate                    765000 non-null  float64\n",
            " 4   Body_Temp                     765000 non-null  float64\n",
            " 5   BMI                           765000 non-null  float64\n",
            " 6   Intensity                     765000 non-null  float64\n",
            " 7   Heart_Duration                765000 non-null  float64\n",
            " 8   Weight_Duration_Heart         765000 non-null  float64\n",
            " 9   Outliers_Duration_Heart_Temp  765000 non-null  int64  \n",
            " 10  BMI_Age                       765000 non-null  float64\n",
            " 11  Age_Group                     765000 non-null  int64  \n",
            "dtypes: float64(9), int64(3)\n",
            "memory usage: 75.9 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 250000 entries, 750000 to 999999\n",
            "Data columns (total 12 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   Sex                           250000 non-null  int64  \n",
            " 1   Height                        250000 non-null  float64\n",
            " 2   Weight                        250000 non-null  float64\n",
            " 3   Heart_Rate                    250000 non-null  float64\n",
            " 4   Body_Temp                     250000 non-null  float64\n",
            " 5   BMI                           250000 non-null  float64\n",
            " 6   Intensity                     250000 non-null  float64\n",
            " 7   Heart_Duration                250000 non-null  float64\n",
            " 8   Weight_Duration_Heart         250000 non-null  float64\n",
            " 9   Outliers_Duration_Heart_Temp  250000 non-null  int64  \n",
            " 10  BMI_Age                       250000 non-null  float64\n",
            " 11  Age_Group                     250000 non-null  int64  \n",
            "dtypes: float64(9), int64(3)\n",
            "memory usage: 24.8 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X_test.shape, data.y.shape\n",
        "\n",
        "y_test_fic = data.y[:len(data.X_test)].copy()\n",
        "y_test_fic[\"Calories\"]=np.nan"
      ],
      "metadata": {
        "id": "K8cT8NgpwQin"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Neural Networks:\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014189,
          "end_time": "2024-10-26T19:32:03.237017",
          "exception": false,
          "start_time": "2024-10-26T19:32:03.222828",
          "status": "completed"
        },
        "tags": [],
        "id": "7OZ_SPtJ1KTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe, target, categorical_features, numerical_features, shuffle=False, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((dataframe[categorical_features].values,  # First input\n",
        "                                              dataframe[numerical_features].values),\n",
        "                                              target))\n",
        "\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "\n",
        "    return ds\n",
        "\n",
        "def dataframe_to_dataset_test(dataframe, target_finc, categorical_features, numerical_features, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((dataframe[categorical_features].values,  # First input\n",
        "                                              dataframe[numerical_features].values),\n",
        "                                              target_finc))\n",
        "\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "xv1gjhxRLK0I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_session(history):\n",
        "  # Plot training and validation loss scores\n",
        "  # against the number of epochs.\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(history.history['loss'], label='Train')\n",
        "  plt.plot(history.history['val_loss'], label='Validation')\n",
        "  plt.grid(linestyle='--')\n",
        "  plt.ylabel('val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Train-Validation Scores', pad=13)\n",
        "  plt.legend(loc='upper right');\n",
        "  plt.show()\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Root Mean Squared Logarithmic Error (RMSLE)\n",
        "    \"\"\"\n",
        "    # Ensure y_pred is non-negative and add a small constant to avoid log(0) errors\n",
        "    y_pred = K.maximum(K.cast(y_pred, tf.float32), K.epsilon()) # Corrected: K.maximum\n",
        "\n",
        "    first_log = K.log(K.maximum(K.cast(y_pred, tf.float32), K.epsilon()) + 1.) # Corrected: K.maximum\n",
        "    second_log = K.log(K.maximum(K.cast(y_true, tf.float32), K.epsilon()) + 1.) # Corrected: K.maximum\n",
        "\n",
        "    return K.sqrt(K.mean(K.square(first_log - second_log)))\n",
        "\n",
        "# def rmsle(y_true, y_pred):\n",
        "#     \"\"\"\n",
        "#     Root Mean Squared Logarithm Error\n",
        "#     Args:\n",
        "#         y_true ([np.array]): test samples\n",
        "#         y_pred ([np.array]): predicted samples\n",
        "#     Returns:\n",
        "#         [float]: root mean squared logarithm error\n",
        "#     \"\"\"\n",
        "#     first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
        "#     second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
        "#     return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))"
      ],
      "metadata": {
        "id": "1NQnrDo9ten6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    SEED    = 333\n",
        "    CV      = KFold(n_splits=11, shuffle=True, random_state=SEED)\n",
        "    VERSION = '1'\n",
        "\n",
        "class TrainModels:\n",
        "    def __init__(self, X, y, X_test, test_finc_target, X_original, y_original, model_, parameters):\n",
        "        self.model     = model_\n",
        "        self.parameters = parameters\n",
        "        self.X          = X\n",
        "        self.y          = y\n",
        "        self.test_finc_target = test_finc_target\n",
        "        self.X_test     = X_test\n",
        "        self._OOF_train = pd.DataFrame()\n",
        "        self._OOF_test  = pd.DataFrame()\n",
        "        self.categorical_features = X.select_dtypes(include=['category', 'bool', 'category','int']).columns.to_list()\n",
        "        self.numerical_features = X.select_dtypes(exclude=['category', 'bool', 'category','int']).columns.to_list()\n",
        "\n",
        "    def fit_model(self, name=\"Base_model\"):\n",
        "        oof_train = np.zeros(self.X.shape[0])\n",
        "        oof_test  = np.zeros(self.X_test.shape[0])\n",
        "        scores_train = []\n",
        "        scores_val   = []\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S5E5/layers_3_staked_models')\n",
        "\n",
        "        train_start = 0\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(CFG.CV.split(self.X, self.y)):\n",
        "            x_train, y_train = self.X.iloc[train_idx], self.y.iloc[train_idx]\n",
        "            x_val,   y_val   = self.X.iloc[val_idx],   self.y.iloc[val_idx]\n",
        "\n",
        "\n",
        "            train_ds = dataframe_to_dataset(x_train, y_train, self.categorical_features, self.numerical_features, shuffle=True, batch_size=1024)\n",
        "            val_ds = dataframe_to_dataset(x_val, y_val, self.categorical_features, self.numerical_features, shuffle=False, batch_size=1024)\n",
        "            test_ds = dataframe_to_dataset_test(self.X_test, self.test_finc_target, self.categorical_features, self.numerical_features, batch_size=1024)\n",
        "\n",
        "            model = self.model(**self.parameters)\n",
        "\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "            model.compile(optimizer=optimizer,\n",
        "                          loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                          metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "            checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5'\n",
        "            model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "                                                                        filepath=checkpoint_filepath,\n",
        "                                                                        save_weights_only=True,\n",
        "                                                                        monitor='val_rmsle',\n",
        "                                                                        mode='min',\n",
        "                                                                        save_best_only=True\n",
        "                                                                        )\n",
        "            if fold >= train_start:\n",
        "              # Fit the model\n",
        "              history = model.fit(train_ds,\n",
        "                                  validation_data=val_ds,\n",
        "                                  epochs=151,\n",
        "                                  batch_size=1024,\n",
        "                                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                                            keras.callbacks.EarlyStopping(patience=21, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                                            start_from_epoch=3, mode=\"min\"),\n",
        "                                              model_checkpoint_callback])\n",
        "\n",
        "              model.load_weights(checkpoint_filepath)\n",
        "              model.save(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S5E5/keras_models/{name}_{fold}.keras\")\n",
        "              plot_training_session(history)\n",
        "\n",
        "            else:\n",
        "              model = tf.keras.models.load_model(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S5E5/keras_models/{name}_{fold}.keras\",\n",
        "                                                custom_objects={'rmsle': rmsle})\n",
        "\n",
        "            model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred_train = model.predict(train_ds)\n",
        "            y_pred_val   = model.predict(val_ds)\n",
        "            y_pred_test  = model.predict(test_ds)\n",
        "\n",
        "            # Correct Ranges:\n",
        "\n",
        "            y_pred_train = np.maximum(y_pred_train, 1.0)\n",
        "            y_pred_train = np.minimum(y_pred_train, 315.0)\n",
        "\n",
        "            y_pred_val = np.maximum(y_pred_val, 1.0)\n",
        "            y_pred_val = np.minimum(y_pred_val, 315.0)\n",
        "\n",
        "            y_pred_test = np.maximum(y_pred_test, 1.0)\n",
        "            y_pred_test = np.minimum(y_pred_test, 315.0)\n",
        "\n",
        "            # Store Results\n",
        "            oof_train[val_idx] = y_pred_val.reshape(-1)\n",
        "            oof_test   += (y_pred_test/CFG.CV.get_n_splits()).reshape(-1)\n",
        "\n",
        "            train_score = root_mean_squared_log_error(y_train, y_pred_train)\n",
        "            val_score   = root_mean_squared_log_error(y_val, y_pred_val)\n",
        "\n",
        "            print(f'Fold {fold+1} → Training set Score: {train_score:.5f} | Validation set Score: {val_score:.5f}')\n",
        "\n",
        "            scores_train.append(train_score)\n",
        "            scores_val.append(val_score)\n",
        "\n",
        "        self._OOF_train[name] = oof_train\n",
        "        self._OOF_test[name]  = oof_test\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5')\n",
        "\n",
        "        print(colored(f'Overall → Training set Score: {np.mean(scores_train):.5f}±{np.std(scores_train):.7f} | Validation set Score: {np.mean(scores_val):.5f}±{np.std(scores_val):.7f}',\n",
        "              color='green', attrs=['bold', 'dark']))\n",
        "\n",
        "    @property\n",
        "    def OOF_train(self):\n",
        "        return self._OOF_train\n",
        "    @property\n",
        "    def OOF_test(self):\n",
        "        return self._OOF_test\n",
        "\n",
        "    def save_predictions(self):\n",
        "        self._OOF_train.to_csv('OOF_train_many_models.csv', index=False)\n",
        "        self._OOF_test.to_csv('OOF_test_many_models.csv', index=False)"
      ],
      "metadata": {
        "id": "31P8f6EBmOwG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41K1txKVzFhu"
      },
      "source": [
        "### **2.1.0 NeuralNetwork: Dense**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGyFvBNgzFh2"
      },
      "outputs": [],
      "source": [
        "data.X.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.max(axis=0)"
      ],
      "metadata": {
        "id": "grc-F6yEIltY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.min(axis=0)"
      ],
      "metadata": {
        "id": "a5TlsDYEKspq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = data.cat_features\n",
        "num_features = data.num_features\n",
        "\n",
        "cat_features_card = [2,2,8]\n",
        "cat_features_out = [2, 2, 4]\n",
        "\n",
        "print(cat_features,cat_features_card)\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "AbaJACP3minK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ceil(np.sqrt(cat_features_card[1]))"
      ],
      "metadata": {
        "id": "mZqePRWLqJFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(units=512,last_layer = 1, activation=\"relu\", do_rate=0.25, reg=0.001):\n",
        "\n",
        "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
        "    embs = []\n",
        "    for j in range(len(cat_features)):\n",
        "        e = layers.Embedding(cat_features_card[j], cat_features_out[j]) #np.ceil(np.sqrt(cat_features_card[1]))\n",
        "        x = e(x_input_cats[:,j])\n",
        "        x = layers.Flatten()(x)\n",
        "        embs.append(x)\n",
        "\n",
        "    x_input_nums = layers.Input(shape=(len(num_features),))\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
        "    x = layers.Dense(units, activation=activation, kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(do_rate)(x)\n",
        "    x = layers.Dense(units, activation=activation, kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(do_rate)(x)\n",
        "    x = layers.Dense(int(units/last_layer), activation=activation, kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(do_rate)(x)\n",
        "    x_final = layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x_final)\n",
        "    return model"
      ],
      "metadata": {
        "id": "VF6Qd4eziUd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_test = build_model(units=512)\n",
        "mod_test.summary()"
      ],
      "metadata": {
        "id": "HPhVCKp9mOzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ceVtzBwQlNg"
      },
      "source": [
        "#### 2.1.1 Optuna Optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ9CoxtaQlNg"
      },
      "outputs": [],
      "source": [
        "X_fin = data.X\n",
        "X_test_fin = data.X_test\n",
        "\n",
        "X_train_cat = data.X[cat_features]\n",
        "X_train_num = data.X[num_features]\n",
        "\n",
        "X_test_cat = data.X_test[cat_features]\n",
        "X_test_num = data.X_test[num_features]\n",
        "\n",
        "X_train_cat.info()\n",
        "X_train_num.info()\n",
        "\n",
        "y_fin = data.y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fin.isna().sum()"
      ],
      "metadata": {
        "id": "dw84O6QuLEK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMIZATION SECTION**"
      ],
      "metadata": {
        "id": "fqMh80e9vD0H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tObj5kq1QlNg"
      },
      "outputs": [],
      "source": [
        "def objective_nn(trial, X, y, n_splits, n_repeats, model=build_model, use_gpu=True, rs=42, fit_scaling=False, cv_strategy=\"KFold\"):\n",
        "\n",
        "    model_class = model\n",
        "\n",
        "    categorical_features = cat_features.copy()\n",
        "\n",
        "    num_cols = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "    params = {'units': trial.suggest_categorical('units', [128,256,512,1024]),\n",
        "              'last_layer': trial.suggest_int('last_layer', 1,2),\n",
        "              'activation': trial.suggest_categorical('activation', [\"relu\",\"selu\",\"gelu\",\"silu\"]), #, reg=0.001, dropout_rate=0.33)\n",
        "              'reg': trial.suggest_float('reg', 1e-4, 0.1, log=True),\n",
        "              'do_rate': trial.suggest_float('do_rate', 0.30, 0.50)\n",
        "              }\n",
        "\n",
        "    if cv_strategy == 'RepKFold':\n",
        "        kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "    elif cv_strategy == 'KFold':\n",
        "        kf = KFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"StratKFold\":\n",
        "        kf = StratifiedKFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"RepStratKFold\":\n",
        "        kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "    rmsle_scores = []\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    iteration_n=0\n",
        "\n",
        "    for idx_train, idx_valid in kf.split(X, y):\n",
        "        print(f\"Running Fold: {iteration_n}\")\n",
        "        # Split the data into training and validation sets for the current fold\n",
        "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train].to_numpy()#.reshape(-1, 1)\n",
        "        X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid].to_numpy()#.reshape(-1, 1)\n",
        "\n",
        "        X_train_cat = X_train[cat_features]\n",
        "        X_train_num = X_train[num_features]\n",
        "\n",
        "        X_valid_cat = X_valid[cat_features]\n",
        "        X_valid_num = X_valid[num_features]\n",
        "\n",
        "        # Create the model\n",
        "        keras.utils.set_random_seed(rs)\n",
        "        model = model_class(**params)\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "        model.compile(optimizer=optimizer,\n",
        "                      loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                      metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "        checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5'\n",
        "        model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_filepath,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_rmsle',\n",
        "            mode='min',\n",
        "            save_best_only=True)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit([X_train_cat,X_train_num], y_train,\n",
        "                  validation_data=([X_valid_cat, X_valid_num], y_valid),\n",
        "                  epochs=31,\n",
        "                  batch_size=1024,\n",
        "                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                            start_from_epoch=3, mode=\"min\"),\n",
        "                             model_checkpoint_callback])\n",
        "\n",
        "        model.load_weights(checkpoint_filepath)\n",
        "\n",
        "        # Make predictions on the validation set\n",
        "        y_pred = model.predict([X_valid_cat, X_valid_num], batch_size=1024)\n",
        "        y_pred = np.maximum(y_pred, 1.0)\n",
        "        y_pred = np.minimum(y_pred, 315.0)\n",
        "\n",
        "        print(\"Pred Min: {}\".format(y_pred.min()))\n",
        "        print(\"Pred Max: {}\".format(y_pred.max()))\n",
        "\n",
        "        # Calculate the RMSE for the current fold\n",
        "        rmsle_score = root_mean_squared_log_error(y_valid, y_pred)\n",
        "        print(f\"Fold {iteration_n} RMSLE: {rmsle_score}\")\n",
        "\n",
        "        rmsle_scores.append(rmsle_score)\n",
        "        iteration_n+=1\n",
        "\n",
        "    # Calculate the mean RMSLE score across all folds\n",
        "    key_metric = np.mean(rmsle_scores)\n",
        "\n",
        "    return key_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sux1Xc6ZQlNh"
      },
      "outputs": [],
      "source": [
        "# Step 2: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, n_splits_ ,n_repeats_, use_gpu=True):  #use_gpu\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
        "    study.optimize(lambda trial: objective_nn(trial, X, y, n_splits=n_splits_, n_repeats=n_repeats_, model=build_model, use_gpu=use_gpu, cv_strategy=\"KFold\"), n_trials=n_trials)\n",
        "    return study  # Return the study object\n",
        "\n",
        "# Step 3: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")# usage with XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fin.isna().sum(), y_fin.min()"
      ],
      "metadata": {
        "id": "_G7uNJwgKXOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1. Trial 4 finished with value: 0.06326587167991321 and parameters: {'units': 512, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012466698516071345, 'do_rate': 0.32329936440008156}.\n",
        "\n",
        "  2. Trial 12 finished with value: 0.0644081979735794 and parameters: {'units': 256, 'last_layer': 1, 'activation': 'relu', 'reg': 0.0006106006869707281, 'do_rate': 0.3494656732997632}.\n",
        "\n",
        "  3.  Trial 14 finished with value: 0.06490268403547308 and parameters: {'units': 256, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012000706329704339, 'do_rate': 0.3032266090954228}."
      ],
      "metadata": {
        "id": "4gD8te2nDso2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW_aoIIBQlNh"
      },
      "outputs": [],
      "source": [
        "nn0_study = tune_hyperparameters(X_fin, y_fin, model_class=build_model, n_trials=31, n_splits_ = 5 ,n_repeats_=3, use_gpu=True)\n",
        "\n",
        "cat_params = nn0_study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 Train Model:"
      ],
      "metadata": {
        "id": "lIkzAb-rGNGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'units': 512, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012466698516071345, 'do_rate': 0.32329936440008156}\n",
        "TM = TrainModels(X=data.X, y=data.y, X_test=data.X_test, test_finc_target=y_test_fic, X_original=None, y_original=None, model_=build_model, parameters=param)"
      ],
      "metadata": {
        "id": "xGuhYBvImOti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM.fit_model(name=\"NN_exp_00\")"
      ],
      "metadata": {
        "id": "NafO4kd5mOqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 Store Results:"
      ],
      "metadata": {
        "id": "4n5hBAAw8gPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = TM.OOF_train\n",
        "test_pred = TM.OOF_test\n",
        "train_pred = pd.DataFrame(data = train_pred, columns = [\"NN_exp_00\"])\n",
        "\n",
        "\n",
        "sub = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "\n",
        "sub[\"Calories\"] =  test_pred.values\n",
        "\n",
        "sub.to_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/submission_NN_exp_00.csv\")\n",
        "train_pred.to_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train_pred_NN_exp_00.csv\")"
      ],
      "metadata": {
        "id": "crsVb2JXmOns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.min(), test_pred.max()"
      ],
      "metadata": {
        "id": "FkWb5A0jmOkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred"
      ],
      "metadata": {
        "id": "MnoThd5GRKfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvKi8GKnOMjO"
      },
      "source": [
        "### **2.2.0 NeuralNetwork: Wide and Deep Model v0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciGJJnKjOMjP"
      },
      "outputs": [],
      "source": [
        "data.X.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.max(axis=0)"
      ],
      "metadata": {
        "id": "nOTFfHx9OMjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "ax[0].hist(data.X.BMI, bins=31)\n",
        "ax[1].hist(data.X_test.BMI, bins=31, color=\"salmon\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s7OEZdd9PQNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = data.cat_features\n",
        "num_features = data.num_features\n",
        "\n",
        "cat_features_card = [2,2,8]\n",
        "cat_features_out = [2, 2, 4]\n",
        "\n",
        "\n",
        "print(cat_features,cat_features_card)\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "9j6EMW2yOMjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wide_deep(units=512, activation=\"relu\", do_rate=0.25, reg=0.001, hidden_layers=3):\n",
        "    '''\n",
        "    In this model embedding is performed for the data feeding into both the Deep and and wide layers:\n",
        "    '''\n",
        "\n",
        "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
        "    embs = []\n",
        "    for j in range(len(cat_features)):\n",
        "        e = layers.Embedding(cat_features_card[j], cat_features_out[j]) #np.ceil(np.sqrt(cat_features_card[1]))\n",
        "        x = e(x_input_cats[:,j])\n",
        "        x = layers.Flatten()(x)\n",
        "        embs.append(x)\n",
        "\n",
        "    x_input_nums = layers.Input(shape=(len(num_features),))\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
        "\n",
        "    wide = layers.BatchNormalization()(x)\n",
        "    deep = x\n",
        "\n",
        "    for lay in range(hidden_layers):\n",
        "        deep = layers.Dense(units,kernel_regularizer=keras.regularizers.l2(reg), name=f\"dense_deep_{lay}\")(deep)\n",
        "        deep = layers.BatchNormalization(name=f\"bn_deep_{lay}\")(deep)\n",
        "        if activation == \"relu\":\n",
        "            deep = layers.ReLU(name=f\"relu_deep_{lay}\")(deep)\n",
        "        elif activation == \"prelu\":\n",
        "            deep = layers.PReLU(name=f\"prelu_deep_{lay}\")(deep)\n",
        "        elif activation == \"gelu \":\n",
        "            deep = activations.gelu(deep)\n",
        "        elif activation == \"silu\":\n",
        "            deep = activations.silu(deep)\n",
        "        elif activation == \"mish\":\n",
        "            deep = layers.Lambda(lambda x: keras.activations.mish(x), name=f\"mish_deep_{lay}\")(deep)\n",
        "        elif activation == \"celu\":\n",
        "            deep = activations.celu(deep)\n",
        "\n",
        "        deep = layers.Dropout(do_rate, name=f\"do_deep_{lay}\")(deep)\n",
        "\n",
        "    merged = layers.concatenate([wide, deep])\n",
        "\n",
        "    x_final = layers.Dense(1, activation='linear')(merged)\n",
        "\n",
        "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x_final)\n",
        "    return model"
      ],
      "metadata": {
        "id": "2XhwdLzZOMjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_test = wide_deep(units=512, activation=\"celu\")\n",
        "mod_test.summary()"
      ],
      "metadata": {
        "id": "0proQYO0OMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keras.utils.plot_model(mod_test, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "G8RnyWJH4oRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYIuPRrOMjQ"
      },
      "source": [
        "#### 2.2.1 Optuna Optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8kcen4hOMjQ"
      },
      "outputs": [],
      "source": [
        "X_fin = data.X\n",
        "X_test_fin = data.X_test\n",
        "\n",
        "X_train_cat = data.X[cat_features]\n",
        "X_train_num = data.X[num_features]\n",
        "\n",
        "X_test_cat = data.X_test[cat_features]\n",
        "X_test_num = data.X_test[num_features]\n",
        "\n",
        "X_train_cat.info()\n",
        "X_train_num.info()\n",
        "\n",
        "y_fin = data.y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fin.isna().sum()"
      ],
      "metadata": {
        "id": "jCYAFlZfOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMIZATION SECTION**"
      ],
      "metadata": {
        "id": "BtRpVIqfOMjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGA_0vWHOMjQ"
      },
      "outputs": [],
      "source": [
        "def objective_nn(trial, X, y, n_splits, n_repeats, model=wide_deep, use_gpu=True, rs=42, fit_scaling=False, cv_strategy=\"KFold\"):\n",
        "\n",
        "    model_class = model\n",
        "\n",
        "    categorical_features = cat_features.copy()\n",
        "\n",
        "    num_cols = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "    params = {\n",
        "              'units': trial.suggest_categorical('units', [128,256,512,1024]),\n",
        "              'last_layer': trial.suggest_int('last_layer', 1,2),\n",
        "              'activation': trial.suggest_categorical('activation', [\"relu\",\"prelu\",\"gelu\",\"silu\",\"mish\",\"celu\"]), #, reg=0.001, dropout_rate=0.33)\n",
        "              'reg': trial.suggest_float('reg', 1e-4, 0.1, log=True),\n",
        "              'do_rate': trial.suggest_float('do_rate', 0.30, 0.50),\n",
        "              'hidden_layers': trial.suggest_int('hidden_layers', 1,4)\n",
        "              }\n",
        "\n",
        "    if cv_strategy == 'RepKFold':\n",
        "        kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "    elif cv_strategy == 'KFold':\n",
        "        kf = KFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"StratKFold\":\n",
        "        kf = StratifiedKFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"RepStratKFold\":\n",
        "        kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "    rmsle_scores = []\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    iteration_n=0\n",
        "\n",
        "    for idx_train, idx_valid in kf.split(X, y):\n",
        "        print(f\"Running Fold: {iteration_n}\")\n",
        "        # Split the data into training and validation sets for the current fold\n",
        "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train].to_numpy()#.reshape(-1, 1)\n",
        "        X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid].to_numpy()#.reshape(-1, 1)\n",
        "\n",
        "        X_train_cat = X_train[cat_features]\n",
        "        X_train_num = X_train[num_features]\n",
        "\n",
        "        X_valid_cat = X_valid[cat_features]\n",
        "        X_valid_num = X_valid[num_features]\n",
        "\n",
        "        # Create the model\n",
        "        keras.utils.set_random_seed(rs)\n",
        "        model = model_class(**params)\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "        model.compile(optimizer=optimizer,\n",
        "                      loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                      metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "        checkpoint_filepath = '/tmp/ckpt/checkpoint_dw.weights.h5'\n",
        "        model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_filepath,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_rmsle',\n",
        "            mode='min',\n",
        "            save_best_only=True)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit([X_train_cat,X_train_num], y_train,\n",
        "                  validation_data=([X_valid_cat, X_valid_num], y_valid),\n",
        "                  epochs=31,\n",
        "                  batch_size=1024,\n",
        "                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                            start_from_epoch=3, mode=\"min\"),\n",
        "                             model_checkpoint_callback])\n",
        "\n",
        "        model.load_weights(checkpoint_filepath)\n",
        "\n",
        "        # Make predictions on the validation set\n",
        "        y_pred = model.predict([X_valid_cat, X_valid_num], batch_size=1024)\n",
        "        y_pred = np.maximum(y_pred, 1.0)\n",
        "        y_pred = np.minimum(y_pred, 315.0)\n",
        "\n",
        "        print(\"Pred Min: {}\".format(y_pred.min()))\n",
        "        print(\"Pred Max: {}\".format(y_pred.max()))\n",
        "\n",
        "        # Calculate the RMSE for the current fold\n",
        "        rmsle_score = root_mean_squared_log_error(y_valid, y_pred)\n",
        "        print(f\"Fold {iteration_n} RMSLE: {rmsle_score}\")\n",
        "\n",
        "        rmsle_scores.append(rmsle_score)\n",
        "        iteration_n+=1\n",
        "\n",
        "    # Calculate the mean RMSLE score across all folds\n",
        "    key_metric = np.mean(rmsle_scores)\n",
        "\n",
        "    return key_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvbmcziROMjQ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, n_splits_ ,n_repeats_, use_gpu=True):  #use_gpu\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
        "    study.optimize(lambda trial: objective_nn(trial, X, y, n_splits=n_splits_, n_repeats=n_repeats_, model=model_class, use_gpu=use_gpu, cv_strategy=\"KFold\"), n_trials=n_trials)\n",
        "    return study  # Return the study object\n",
        "\n",
        "# Step 3: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")# usage with XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fin.isna().sum(), y_fin.min()"
      ],
      "metadata": {
        "id": "EGOg0uogOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1. Trial 32 finished with value: 0.06224817614285113 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.000103427172893175, 'do_rate': 0.40056000512858025, 'hidden_layers': 2}\n",
        "\n",
        "  2. Trial 18 finished with value: 0.06211038027842043 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0001004170129215336, 'do_rate': 0.41356627172269655, 'hidden_layers': 3} Best\n",
        "\n",
        "  3.  Trial 23 finished with value: 0.06239891244956206 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00010001356287977584, 'do_rate': 0.4642367345915417, 'hidden_layers': 2}."
      ],
      "metadata": {
        "id": "4T2eke9wOMjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxPZBhabOMjQ"
      },
      "outputs": [],
      "source": [
        "nn0_study = tune_hyperparameters(X_fin, y_fin, model_class=wide_deep, n_trials=51, n_splits_ = 5 ,n_repeats_=3, use_gpu=True)\n",
        "\n",
        "cat_params = nn0_study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 Train Model:"
      ],
      "metadata": {
        "id": "oUmQ2LeBOMjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'units': 512, 'activation': 'silu', 'reg': 0.0001004170129215336, 'do_rate': 0.41356627172269655, 'hidden_layers': 3}"
      ],
      "metadata": {
        "id": "RCXgnVWW7_0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM = TrainModels(X=data.X, y=data.y, X_test=data.X_test, test_finc_target=y_test_fic, X_original=None, y_original=None, model_=wide_deep, parameters=param)"
      ],
      "metadata": {
        "id": "P0TZ7C9ZOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM.fit_model(name=\"NN_widedeep_00\")"
      ],
      "metadata": {
        "id": "4NQhOfOpOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 Store Results:"
      ],
      "metadata": {
        "id": "O2653MGROMjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_experiment = \"NN_widedeep_00\"\n",
        "\n",
        "train_pred = TM.OOF_train\n",
        "test_pred = TM.OOF_test\n",
        "train_pred = pd.DataFrame(data = train_pred, columns = [f\"{name_experiment}\"])\n",
        "\n",
        "sub = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "\n",
        "sub[\"Calories\"] =  test_pred.values"
      ],
      "metadata": {
        "id": "P-llnneROMjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.min(), test_pred.max()"
      ],
      "metadata": {
        "id": "fAkI6ulSOMjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.head()"
      ],
      "metadata": {
        "id": "9dYagSFaOMjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.head()"
      ],
      "metadata": {
        "id": "E3GQeR2Nn09P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred.head()"
      ],
      "metadata": {
        "id": "hao3UZR_n6TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "ax[0].hist(train_pred, bins=31)\n",
        "ax[1].hist(sub, bins=31, color=\"salmon\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7GFmuKS_oACd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/submission_{name_experiment}.csv\")\n",
        "train_pred.to_csv(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train_pred_{name_experiment}.csv\")"
      ],
      "metadata": {
        "id": "-yK4JpzuhMKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLZXE-JMog_7"
      },
      "source": [
        "### **2.3.0 NeuralNetwork: Wide and Deep Model v1**\n",
        "\n",
        "This version of the model includes a Cross Layers within the Wide Branch of the NN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oTZ-tkxVog_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "d9129937-dbb3-4d23-e9b8-8991be339c44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Sex    Height    Weight  Heart_Rate  Body_Temp       BMI  Intensity  \\\n",
              "741143    0 -1.065268 -1.009858    1.641405   1.492518 -0.556246   1.596106   \n",
              "667890    0  1.035219  0.489702   -1.003407   0.466696 -0.776115  -0.267643   \n",
              "400283    0 -1.454247 -1.652526    0.689273   1.107835 -1.988224   0.550355   \n",
              "\n",
              "        Heart_Duration  Weight_Duration_Heart  Outliers_Duration_Heart_Temp  \\\n",
              "741143       -0.880430               0.901859                             0   \n",
              "667890       -0.440315              -0.132311                             0   \n",
              "400283       -0.598032              -0.128284                             0   \n",
              "\n",
              "         BMI_Age  Age_Group  \n",
              "741143  1.145505          2  \n",
              "667890 -0.495884          2  \n",
              "400283  0.750211          6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5620a62-25b7-42d3-afb5-0d4dc147049e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Heart_Rate</th>\n",
              "      <th>Body_Temp</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>Heart_Duration</th>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <th>BMI_Age</th>\n",
              "      <th>Age_Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>741143</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.065268</td>\n",
              "      <td>-1.009858</td>\n",
              "      <td>1.641405</td>\n",
              "      <td>1.492518</td>\n",
              "      <td>-0.556246</td>\n",
              "      <td>1.596106</td>\n",
              "      <td>-0.880430</td>\n",
              "      <td>0.901859</td>\n",
              "      <td>0</td>\n",
              "      <td>1.145505</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667890</th>\n",
              "      <td>0</td>\n",
              "      <td>1.035219</td>\n",
              "      <td>0.489702</td>\n",
              "      <td>-1.003407</td>\n",
              "      <td>0.466696</td>\n",
              "      <td>-0.776115</td>\n",
              "      <td>-0.267643</td>\n",
              "      <td>-0.440315</td>\n",
              "      <td>-0.132311</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.495884</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400283</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.454247</td>\n",
              "      <td>-1.652526</td>\n",
              "      <td>0.689273</td>\n",
              "      <td>1.107835</td>\n",
              "      <td>-1.988224</td>\n",
              "      <td>0.550355</td>\n",
              "      <td>-0.598032</td>\n",
              "      <td>-0.128284</td>\n",
              "      <td>0</td>\n",
              "      <td>0.750211</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5620a62-25b7-42d3-afb5-0d4dc147049e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5620a62-25b7-42d3-afb5-0d4dc147049e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5620a62-25b7-42d3-afb5-0d4dc147049e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b6ba74e3-d8cf-4d88-8a24-2b40cfbd425e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6ba74e3-d8cf-4d88-8a24-2b40cfbd425e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b6ba74e3-d8cf-4d88-8a24-2b40cfbd425e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3392029604504114,\n        \"min\": -1.4542466502106934,\n        \"max\": 1.0352189293002554,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1.0652676534121075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0993059271909698,\n        \"min\": -1.6525261009583152,\n        \"max\": 0.4897017009526996,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1.0098577603850107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3395737458816372,\n        \"min\": -1.0034067723669386,\n        \"max\": 1.6414047307784303,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.6414047307784303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5182263163081919,\n        \"min\": 0.4666959302548797,\n        \"max\": 1.4925179984435069,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.4925179984435069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7711583343516011,\n        \"min\": -1.9882240275832972,\n        \"max\": -0.5562459660968821,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.5562459660968821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9341908792724716,\n        \"min\": -0.2676426090325963,\n        \"max\": 1.5961062279769975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.5961062279769975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Heart_Duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22298152964471243,\n        \"min\": -0.8804300833861397,\n        \"max\": -0.4403150266533678,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.8804300833861397\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight_Duration_Heart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5959195961253947,\n        \"min\": -0.1323114934068383,\n        \"max\": 0.9018592824288914,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9018592824288914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outliers_Duration_Heart_Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8566570452403535,\n        \"min\": -0.4958839770607871,\n        \"max\": 1.1455050763689365,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.1455050763689365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age_Group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data.X.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.max(axis=0)"
      ],
      "metadata": {
        "id": "T01DFbRoog_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "8f02969b-e670-466a-8e13-d76b07e6cfa1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sex                             1.000000\n",
              "Height                          3.680276\n",
              "Weight                          4.060081\n",
              "Heart_Rate                      3.439877\n",
              "Body_Temp                       1.877201\n",
              "BMI                             5.000000\n",
              "Intensity                       2.483148\n",
              "Heart_Duration                  4.005130\n",
              "Weight_Duration_Heart           4.344034\n",
              "Outliers_Duration_Heart_Temp    1.000000\n",
              "BMI_Age                         4.030577\n",
              "Age_Group                       7.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height</th>\n",
              "      <td>3.680276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>4.060081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Rate</th>\n",
              "      <td>3.439877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Body_Temp</th>\n",
              "      <td>1.877201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intensity</th>\n",
              "      <td>2.483148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Duration</th>\n",
              "      <td>4.005130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight_Duration_Heart</th>\n",
              "      <td>4.344034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outliers_Duration_Heart_Temp</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI_Age</th>\n",
              "      <td>4.030577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Group</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "ax[0].hist(data.X.Age_Group, bins=31)\n",
        "ax[1].hist(data.X_test.Age_Group, bins=31, color=\"salmon\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gB0uT1u4og_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "52614913-ca50-43a8-8448-3df7b8dcb3a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = data.cat_features\n",
        "num_features = data.num_features\n",
        "\n",
        "cat_features_card = [2,2,8]\n",
        "cat_features_out = [2, 2, 4]\n",
        "\n",
        "\n",
        "print(cat_features,cat_features_card)\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "35EqV75Oog_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9de4a76-0070-4230-a0d2-b37a06319539"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sex', 'Outliers_Duration_Heart_Temp', 'Age_Group'] [2, 2, 8]\n",
            "['Height', 'Weight', 'Heart_Rate', 'Body_Temp', 'BMI', 'Intensity', 'Heart_Duration', 'Weight_Duration_Heart', 'BMI_Age']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wide_deep_cross(units=512, activation=\"relu\", do_rate=0.25, reg=0.001, hidden_layers=3, num_cross_layers=2):\n",
        "    '''\n",
        "    In this model embedding is performed for the data feeding into both the Deep and and wide layers:\n",
        "    '''\n",
        "\n",
        "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
        "    embs = []\n",
        "    for j in range(len(cat_features)):\n",
        "        e = layers.Embedding(cat_features_card[j], cat_features_out[j]) #np.ceil(np.sqrt(cat_features_card[1]))\n",
        "        x = e(x_input_cats[:,j])\n",
        "        x = layers.Flatten()(x)\n",
        "        embs.append(x)\n",
        "\n",
        "    x_input_nums = layers.Input(shape=(len(num_features),))\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
        "\n",
        "    deep = x\n",
        "    wide = x  # Both Branches start with the concatenated features\n",
        "\n",
        "    # Wide Branch with Cross Layers:\n",
        "    for _ in range(num_cross_layers):\n",
        "        xl = layers.Dense(units=x.shape[-1],  # Output dimension same as input\n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         bias_initializer='zeros',\n",
        "                         activation=None)(wide)  # Linear activation\n",
        "        # Cross Layer Calculation:\n",
        "        cross = layers.Multiply()([x, xl])  # Element-wise multiplication\n",
        "        # Concatenate instead of Add:\n",
        "        wide = layers.Concatenate(axis=-1)([wide, cross])\n",
        "\n",
        "    # Deep Branch:\n",
        "    for lay in range(hidden_layers):\n",
        "        deep = layers.Dense(units,kernel_regularizer=keras.regularizers.l2(reg), name=f\"dense_deep_{lay}\")(deep)\n",
        "        deep = layers.BatchNormalization(name=f\"bn_deep_{lay}\")(deep)\n",
        "        if activation == \"relu\":\n",
        "            deep = layers.ReLU(name=f\"relu_deep_{lay}\")(deep)\n",
        "        elif activation == \"prelu\":\n",
        "            deep = layers.PReLU(name=f\"prelu_deep_{lay}\")(deep)\n",
        "        elif activation == \"gelu \":\n",
        "            deep = activations.gelu(deep)\n",
        "        elif activation == \"silu\":\n",
        "            deep = activations.silu(deep)\n",
        "        elif activation == \"mish\":\n",
        "            deep = layers.Lambda(lambda x: keras.activations.mish(x), name=f\"mish_deep_{lay}\")(deep)\n",
        "        elif activation == \"celu\":\n",
        "            deep = activations.celu(deep)\n",
        "\n",
        "        deep = layers.Dropout(do_rate, name=f\"do_deep_{lay}\")(deep)\n",
        "\n",
        "    merged = layers.concatenate([wide, deep])\n",
        "\n",
        "    x_final = layers.Dense(1, activation='linear')(merged)\n",
        "\n",
        "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x_final)\n",
        "    return model"
      ],
      "metadata": {
        "id": "wokXPvl4og_9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_test = wide_deep_cross(units=512, activation=\"celu\")\n",
        "mod_test.summary()"
      ],
      "metadata": {
        "id": "f-aeH3Lkog_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c8134b4-a047-41da-ae0c-977ebe9e0835"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item_2          │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m32\u001b[0m │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_deep_0        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m9,216\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_deep_0           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_deep_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ celu (\u001b[38;5;33mCelu\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bn_deep_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ do_deep_0 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ celu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_deep_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ do_deep_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_deep_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_deep_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │        \u001b[38;5;34m306\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ celu_1 (\u001b[38;5;33mCelu\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bn_deep_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ do_deep_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ celu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_deep_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ do_deep_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │        \u001b[38;5;34m595\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_deep_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_deep_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ celu_2 (\u001b[38;5;33mCelu\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bn_deep_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ do_deep_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ celu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m563\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ do_deep_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m564\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_deep_0        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_deep_0           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_deep_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ celu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Celu</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn_deep_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ do_deep_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ celu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_deep_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ do_deep_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_deep_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_deep_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">306</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ celu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Celu</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn_deep_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ do_deep_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ celu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_deep_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ do_deep_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">595</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_deep_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_deep_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ celu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Celu</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn_deep_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ do_deep_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ celu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">563</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ do_deep_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">564</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m542,177\u001b[0m (2.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,177</span> (2.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m539,105\u001b[0m (2.06 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">539,105</span> (2.06 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keras.utils.plot_model(mod_test, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "3k0CIB6Zog_9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6wkA7pZog_9"
      },
      "source": [
        "#### 2.3.1 Optuna Optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CmrU-X6gog_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4333d65-442f-469b-82b2-6a7a428c9d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 765000 entries, 0 to 1014999\n",
            "Data columns (total 3 columns):\n",
            " #   Column                        Non-Null Count   Dtype\n",
            "---  ------                        --------------   -----\n",
            " 0   Sex                           765000 non-null  int64\n",
            " 1   Outliers_Duration_Heart_Temp  765000 non-null  int64\n",
            " 2   Age_Group                     765000 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.3 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 765000 entries, 0 to 1014999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   Height                 765000 non-null  float64\n",
            " 1   Weight                 765000 non-null  float64\n",
            " 2   Heart_Rate             765000 non-null  float64\n",
            " 3   Body_Temp              765000 non-null  float64\n",
            " 4   BMI                    765000 non-null  float64\n",
            " 5   Intensity              765000 non-null  float64\n",
            " 6   Heart_Duration         765000 non-null  float64\n",
            " 7   Weight_Duration_Heart  765000 non-null  float64\n",
            " 8   BMI_Age                765000 non-null  float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 58.4 MB\n"
          ]
        }
      ],
      "source": [
        "X_fin = data.X\n",
        "X_test_fin = data.X_test\n",
        "\n",
        "X_train_cat = data.X[cat_features]\n",
        "X_train_num = data.X[num_features]\n",
        "\n",
        "X_test_cat = data.X_test[cat_features]\n",
        "X_test_num = data.X_test[num_features]\n",
        "\n",
        "X_train_cat.info()\n",
        "X_train_num.info()\n",
        "\n",
        "y_fin = data.y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fin.isna().sum()"
      ],
      "metadata": {
        "id": "7jcHcp1xog_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "ec460260-9df9-4112-f06e-4c8e9e05dc45"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Calories    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Calories</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMIZATION SECTION**"
      ],
      "metadata": {
        "id": "A3GfQaRzog_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iRvvGBIrog__"
      },
      "outputs": [],
      "source": [
        "def objective_nn(trial, X, y, n_splits, n_repeats, model=wide_deep_cross, use_gpu=True, rs=42, fit_scaling=False, cv_strategy=\"KFold\"):\n",
        "\n",
        "    model_class = model\n",
        "\n",
        "    categorical_features = cat_features.copy()\n",
        "\n",
        "    num_cols = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "    params = {\n",
        "              'units': trial.suggest_categorical('units', [128,256,512,1024]),\n",
        "              'num_cross_layers': trial.suggest_int('num_cross_layers', 1, 3),\n",
        "              'activation': trial.suggest_categorical('activation', [\"relu\",\"prelu\",\"silu\"]),\n",
        "              'reg': trial.suggest_float('reg', 1e-4, 0.01, log=True),\n",
        "              'do_rate': trial.suggest_float('do_rate', 0.25, 0.45),\n",
        "              'hidden_layers': trial.suggest_int('hidden_layers', 1,3)\n",
        "              }\n",
        "\n",
        "    if cv_strategy == 'RepKFold':\n",
        "        kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "    elif cv_strategy == 'KFold':\n",
        "        kf = KFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"StratKFold\":\n",
        "        kf = StratifiedKFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"RepStratKFold\":\n",
        "        kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "    rmsle_scores = []\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    iteration_n=0\n",
        "\n",
        "    for idx_train, idx_valid in kf.split(X, y):\n",
        "        print(f\"Running Fold: {iteration_n}\")\n",
        "        # Split the data into training and validation sets for the current fold\n",
        "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train].to_numpy()#.reshape(-1, 1)\n",
        "        X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid].to_numpy()#.reshape(-1, 1)\n",
        "\n",
        "        X_train_cat = X_train[cat_features]\n",
        "        X_train_num = X_train[num_features]\n",
        "\n",
        "        X_valid_cat = X_valid[cat_features]\n",
        "        X_valid_num = X_valid[num_features]\n",
        "\n",
        "        # Create the model\n",
        "        keras.utils.set_random_seed(rs)\n",
        "        model = model_class(**params)\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "        model.compile(optimizer=optimizer,\n",
        "                      loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                      metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "        checkpoint_filepath = '/tmp/ckpt/checkpoint_dwc.weights.h5'\n",
        "        model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_filepath,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_rmsle',\n",
        "            mode='min',\n",
        "            save_best_only=True)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit([X_train_cat,X_train_num], y_train,\n",
        "                  validation_data=([X_valid_cat, X_valid_num], y_valid),\n",
        "                  epochs=31,\n",
        "                  batch_size=1024,\n",
        "                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                            start_from_epoch=3, mode=\"min\"),\n",
        "                             model_checkpoint_callback])\n",
        "\n",
        "        model.load_weights(checkpoint_filepath)\n",
        "\n",
        "        # Make predictions on the validation set\n",
        "        y_pred = model.predict([X_valid_cat, X_valid_num], batch_size=1024)\n",
        "        y_pred = np.maximum(y_pred, 1.0)\n",
        "        y_pred = np.minimum(y_pred, 315.0)\n",
        "\n",
        "        print(\"Pred Min: {}\".format(y_pred.min()))\n",
        "        print(\"Pred Max: {}\".format(y_pred.max()))\n",
        "\n",
        "        # Calculate the RMSE for the current fold\n",
        "        rmsle_score = root_mean_squared_log_error(y_valid, y_pred)\n",
        "        print(f\"Fold {iteration_n} RMSLE: {rmsle_score}\")\n",
        "\n",
        "        rmsle_scores.append(rmsle_score)\n",
        "        iteration_n+=1\n",
        "\n",
        "    # Calculate the mean RMSLE score across all folds\n",
        "    key_metric = np.mean(rmsle_scores)\n",
        "\n",
        "    return key_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sik0OEQgog__"
      },
      "outputs": [],
      "source": [
        "# Step 2: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, n_splits_ ,n_repeats_, use_gpu=True):  #use_gpu\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
        "    study.optimize(lambda trial: objective_nn(trial, X, y, n_splits=n_splits_, n_repeats=n_repeats_, model=model_class, use_gpu=use_gpu, cv_strategy=\"KFold\"), n_trials=n_trials)\n",
        "    return study  # Return the study object\n",
        "\n",
        "# Step 3: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")# usage with XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fin.isna().sum(), y_fin.min()"
      ],
      "metadata": {
        "id": "bslCtqumog__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d24f8d3-ac93-457d-ddf0-d0079593ac6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Sex                             0\n",
              " Height                          0\n",
              " Weight                          0\n",
              " Heart_Rate                      0\n",
              " Body_Temp                       0\n",
              " BMI                             0\n",
              " Intensity                       0\n",
              " Heart_Duration                  0\n",
              " Weight_Duration_Heart           0\n",
              " Outliers_Duration_Heart_Temp    0\n",
              " BMI_Age                         0\n",
              " Age_Group                       0\n",
              " dtype: int64,\n",
              " Calories    1.0\n",
              " dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1. Trial 1 finished with value: 0.061372210432322494 and parameters: {'units': 512, 'num_cross_layers': 1, 'activation': 'relu', 'reg': 0.0007600657726479304, 'do_rate': 0.4197061058874465, 'hidden_layers': 2}.\n",
        "\n",
        "  2. Trial 6 finished with value: 0.061261933879490194 and parameters: {'units': 256, 'num_cross_layers': 1, 'activation': 'silu', 'reg': 0.0001002990796038959, 'do_rate': 0.39009941717483704, 'hidden_layers': 2}. Best\n",
        "\n",
        "  3.  Trial"
      ],
      "metadata": {
        "id": "ODFyJYEIog__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WDm9HvJSog__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd83b11-1ebb-44aa-f158-8476c611cd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 16:23:01,197] A new study created in memory with name: no-name-5a47d9c9-9da7-47a3-802e-60ba97dbf9c7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_3_loss: 0.0000e+00 - loss: 2.4092 - msle: 81.1970 - rmsle: 1.9016 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1139 - val_msle: 7.2276 - val_rmsle: 0.0976 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0890 - msle: 5.9968 - rmsle: 0.0774 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 5.3360 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0763 - msle: 4.9862 - rmsle: 0.0710 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.9597 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0725 - msle: 4.6348 - rmsle: 0.0687 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.8672 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.4579 - rmsle: 0.0677 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 5.9796 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.3403 - rmsle: 0.0668 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 5.0638 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.2555 - rmsle: 0.0662 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 5.1479 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1113 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.2271 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0810 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.4653 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0160 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.5133 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9993 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.2576 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9253 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9508 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9179 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0153 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9014 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0308 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8963 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9757 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8754 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 4.0126 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8726 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0318 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8529 - rmsle: 0.0627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9523 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8445 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8669 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8276 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8404 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8170 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8517 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8146 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8376 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8158 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8645 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7983 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8029 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7959 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7990 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7926 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8018 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7880 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7939 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7958 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7960 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7968 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7947 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7913 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7875 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7824 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7828 - val_rmsle: 0.0607 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06169323280115478\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 2.4059 - msle: 81.1560 - rmsle: 1.8986 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1146 - val_msle: 7.2584 - val_rmsle: 0.0979 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0892 - msle: 6.0431 - rmsle: 0.0775 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 5.7100 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0765 - msle: 5.0449 - rmsle: 0.0712 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0866 - val_msle: 6.0887 - val_rmsle: 0.0825 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0727 - msle: 4.6754 - rmsle: 0.0690 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.0167 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.5040 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.6335 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.3816 - rmsle: 0.0667 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6733 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.2759 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6847 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.2253 - rmsle: 0.0656 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.3147 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1267 - rmsle: 0.0649 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3935 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.0879 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2681 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0702 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1615 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0268 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1155 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9785 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1037 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9539 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0773 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9413 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9867 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9053 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0065 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9131 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9388 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8805 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9870 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8634 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8805 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8239 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8433 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8005 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8845 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8032 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8665 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8075 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8444 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7640 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8257 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7719 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8212 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7643 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8148 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7627 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8231 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7631 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8290 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7604 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8312 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7476 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7821 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7347 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7848 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.061503850992725255\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.4112 - msle: 81.2303 - rmsle: 1.9041 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1210 - val_msle: 7.1514 - val_rmsle: 0.1053 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0878 - msle: 6.0025 - rmsle: 0.0767 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 5.0835 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0756 - msle: 5.0140 - rmsle: 0.0705 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.4464 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0720 - msle: 4.6683 - rmsle: 0.0682 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.3466 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.5011 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1642 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.3536 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.4419 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.2918 - rmsle: 0.0656 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9954 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1864 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.1055 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1407 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9330 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0734 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0206 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0480 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.4811 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9826 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8688 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9531 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7372 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9362 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7788 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8959 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8477 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9149 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7959 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8747 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9036 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8802 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7809 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8958 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7209 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8217 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7263 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8341 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7124 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8036 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7696 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8103 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7352 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8144 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6901 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7628 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6904 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7660 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6543 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7750 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6661 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7629 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6386 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7506 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6395 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7258 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6337 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7201 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6285 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.3164066076278687\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.062107637027917384\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 2.4076 - msle: 81.2205 - rmsle: 1.9004 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1159 - val_msle: 7.2893 - val_rmsle: 0.1000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0883 - msle: 5.9745 - rmsle: 0.0771 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 5.7399 - val_rmsle: 0.0807 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0762 - msle: 5.0183 - rmsle: 0.0709 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 5.6073 - val_rmsle: 0.0877 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0730 - msle: 4.6738 - rmsle: 0.0692 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 5.2919 - val_rmsle: 0.0807 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.4684 - rmsle: 0.0675 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0870 - val_msle: 5.6985 - val_rmsle: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.3781 - rmsle: 0.0669 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.9969 - val_rmsle: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.2604 - rmsle: 0.0663 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 5.3714 - val_rmsle: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1856 - rmsle: 0.0655 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 4.6372 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1404 - rmsle: 0.0653 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1678 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0796 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.3851 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0314 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1094 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9941 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.4272 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9816 - rmsle: 0.0640 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1064 - val_msle: 6.2894 - val_rmsle: 0.1048 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9470 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2504 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8819 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8396 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8709 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8239 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8537 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8312 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8331 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8023 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8139 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7165 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7946 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7331 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7942 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7110 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7966 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7027 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7815 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6798 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7830 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6755 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7709 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6787 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7629 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6740 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7686 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6701 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7703 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6690 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7586 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6658 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7535 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6666 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7607 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6596 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06199537444142156\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 2.4072 - msle: 81.2841 - rmsle: 1.9010 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1145 - val_msle: 7.2060 - val_rmsle: 0.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0883 - msle: 6.0102 - rmsle: 0.0772 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 5.4023 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0760 - msle: 5.0292 - rmsle: 0.0708 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 5.0974 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.6795 - rmsle: 0.0688 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 5.0694 - val_rmsle: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.4624 - rmsle: 0.0674 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.8106 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.3700 - rmsle: 0.0667 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.1470 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.2801 - rmsle: 0.0663 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.5032 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.2002 - rmsle: 0.0654 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.1072 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1166 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1791 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0384 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2820 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0076 - rmsle: 0.0641 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9341 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0079 - rmsle: 0.0641 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9313 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9637 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8454 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8975 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9370 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8999 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8072 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8541 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7956 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8636 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7937 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8369 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8218 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8748 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7587 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8044 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7444 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7997 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7696 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7870 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8053 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7917 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7679 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7636 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7134 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7583 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7490 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7504 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7187 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7716 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7915 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7289 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 4.0364 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7469 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7808 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7064 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6665 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7011 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6596 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060979437874367416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 16:29:50,713] Trial 0 finished with value: 0.06165590662751728 and parameters: {'units': 128, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.006691033072861796, 'do_rate': 0.4209976258319959, 'hidden_layers': 2}. Best is trial 0 with value: 0.06165590662751728.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 17ms/step - dense_3_loss: 0.0000e+00 - loss: 2.3827 - msle: 79.6962 - rmsle: 1.6030 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2137 - val_msle: 9.1562 - val_rmsle: 0.1906 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0929 - msle: 5.2429 - rmsle: 0.0742 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1249 - val_msle: 6.2696 - val_rmsle: 0.1133 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0802 - msle: 4.5867 - rmsle: 0.0698 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1365 - val_msle: 7.3366 - val_rmsle: 0.1289 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.3746 - rmsle: 0.0683 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0931 - val_msle: 5.3515 - val_rmsle: 0.0865 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0735 - msle: 4.2762 - rmsle: 0.0674 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 4.5742 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.1555 - rmsle: 0.0664 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 4.9580 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.1155 - rmsle: 0.0658 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.4158 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.0890 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.6651 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.0445 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.4703 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0307 - rmsle: 0.0647 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.3664 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0145 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.4781 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9702 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.5588 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9197 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.3255 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8775 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.2417 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8725 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.2889 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8396 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9548 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8141 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9088 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8132 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8395 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7976 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0127 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7878 - rmsle: 0.0627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8714 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7407 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0626 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7292 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.1121 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7203 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9797 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7149 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.9494 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7100 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8853 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7139 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 4.0338 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7195 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8625 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6975 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8877 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7056 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 4.0919 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7090 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8938 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6927 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7663 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06208022190664309\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 2.3756 - msle: 79.5462 - rmsle: 1.6032 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.2454 - val_msle: 10.4298 - val_rmsle: 0.2227 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0928 - msle: 5.2741 - rmsle: 0.0743 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1515 - val_msle: 9.1935 - val_rmsle: 0.1392 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0801 - msle: 4.6275 - rmsle: 0.0699 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1097 - val_msle: 6.7339 - val_rmsle: 0.1010 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.4312 - rmsle: 0.0683 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0851 - val_msle: 6.0858 - val_rmsle: 0.0779 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.3056 - rmsle: 0.0674 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 6.4783 - val_rmsle: 0.0791 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.2220 - rmsle: 0.0666 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 5.9846 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.1795 - rmsle: 0.0659 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.3190 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.1177 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 6.1878 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.0971 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.3142 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0453 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.5816 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0217 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1588 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0055 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.6921 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9634 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.3093 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9410 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0067 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9106 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1090 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8826 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2510 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8645 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0158 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8361 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9882 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8396 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0339 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8241 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0456 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8212 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0458 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7802 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8640 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7540 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8868 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7476 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8131 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7577 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.8217 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7499 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8556 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7559 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8198 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7486 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8317 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7250 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7861 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7237 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7660 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7131 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7861 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.061400589609775735\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.3820 - msle: 79.5737 - rmsle: 1.6031 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.2154 - val_msle: 8.6366 - val_rmsle: 0.1917 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0935 - msle: 5.3325 - rmsle: 0.0743 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1134 - val_msle: 5.1097 - val_rmsle: 0.1019 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0800 - msle: 4.6501 - rmsle: 0.0693 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1030 - val_msle: 5.1718 - val_rmsle: 0.0952 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0753 - msle: 4.4132 - rmsle: 0.0677 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.4313 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.2875 - rmsle: 0.0664 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.1923 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.2135 - rmsle: 0.0661 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 4.2651 - val_rmsle: 0.0780 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1252 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.2510 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1201 - rmsle: 0.0650 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.0319 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0692 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.3909 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0453 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8604 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0102 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0996 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9823 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8503 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9519 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8812 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9684 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9109 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9166 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8404 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8721 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1578 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8139 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6560 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7909 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6584 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7774 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7178 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7714 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7347 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7659 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6487 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7626 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6470 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7532 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6619 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7686 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6463 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7270 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6055 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7120 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5944 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7248 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6204 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7140 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6348 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6895 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5783 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6875 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5774 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6971 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5791 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06115001596774129\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 2.3728 - msle: 79.7047 - rmsle: 1.5951 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.2685 - val_msle: 10.7555 - val_rmsle: 0.2454 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0931 - msle: 5.3354 - rmsle: 0.0744 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1777 - val_msle: 10.6191 - val_rmsle: 0.1667 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0803 - msle: 4.6326 - rmsle: 0.0699 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1565 - val_msle: 10.4834 - val_rmsle: 0.1487 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0766 - msle: 4.4527 - rmsle: 0.0687 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1700 - val_msle: 11.2984 - val_rmsle: 0.1631 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.3275 - rmsle: 0.0677 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1652 - val_msle: 12.7083 - val_rmsle: 0.1593 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.2111 - rmsle: 0.0667 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1181 - val_msle: 7.9739 - val_rmsle: 0.1132 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.1537 - rmsle: 0.0661 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1256 - val_msle: 9.6767 - val_rmsle: 0.1210 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.1253 - rmsle: 0.0656 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1136 - val_msle: 7.7427 - val_rmsle: 0.1097 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1017 - rmsle: 0.0655 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1291 - val_msle: 8.5225 - val_rmsle: 0.1255 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.0851 - rmsle: 0.0653 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0972 - val_msle: 6.3796 - val_rmsle: 0.0937 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0063 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 5.8606 - val_rmsle: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0672 - msle: 3.9835 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.9019 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9365 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.5347 - val_rmsle: 0.0732 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9208 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.4081 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8812 - rmsle: 0.0634 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.8243 - val_rmsle: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8685 - rmsle: 0.0634 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9017 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8405 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9659 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8339 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.0673 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8047 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8173 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8045 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9057 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7977 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8022 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7878 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0371 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7908 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9266 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7833 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7392 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7692 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7223 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7610 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7644 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7562 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7034 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7599 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7804 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7548 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7062 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7456 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7411 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7485 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7673 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.062461874196870285\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 2.3680 - msle: 79.8253 - rmsle: 1.6128 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.2038 - val_msle: 8.9853 - val_rmsle: 0.1817 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0922 - msle: 5.2849 - rmsle: 0.0741 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0926 - val_msle: 5.3971 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0801 - msle: 4.6273 - rmsle: 0.0699 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 5.0595 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0764 - msle: 4.4267 - rmsle: 0.0686 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 5.4479 - val_rmsle: 0.0770 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0734 - msle: 4.2784 - rmsle: 0.0672 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0909 - val_msle: 7.4160 - val_rmsle: 0.0856 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.2358 - rmsle: 0.0669 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 4.9360 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.1774 - rmsle: 0.0665 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 5.1136 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.1025 - rmsle: 0.0655 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0988 - val_msle: 7.1477 - val_rmsle: 0.0952 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.0665 - rmsle: 0.0651 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 6.2590 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9586 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.2431 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9244 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9985 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8971 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.1446 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8854 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.2160 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8665 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.2351 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8074 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7359 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8042 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7841 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7954 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7707 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7846 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7322 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7698 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7625 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7724 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7482 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7723 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7370 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7775 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7124 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7647 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7040 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7567 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6935 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7554 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7044 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7581 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6801 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7231 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6533 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7090 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6617 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7192 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6357 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7147 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6388 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7119 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6341 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060627919740913125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 16:36:46,777] Trial 1 finished with value: 0.0615441242843887 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'relu', 'reg': 0.003924717694834827, 'do_rate': 0.2589743619243372, 'hidden_layers': 2}. Best is trial 1 with value: 0.0615441242843887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_1_loss: 0.0000e+00 - loss: 2.4082 - msle: 97.9503 - rmsle: 2.3913 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2980 - val_msle: 27.6988 - val_rmsle: 0.2858 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1650 - msle: 14.4208 - rmsle: 0.1546 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0981 - val_msle: 5.9954 - val_rmsle: 0.0911 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0830 - msle: 5.6861 - rmsle: 0.0767 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1008 - val_msle: 6.5959 - val_rmsle: 0.0960 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0756 - msle: 5.3049 - rmsle: 0.0712 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1002 - val_msle: 6.9461 - val_rmsle: 0.0966 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0724 - msle: 5.0546 - rmsle: 0.0690 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1053 - val_msle: 7.5298 - val_rmsle: 0.1024 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.8710 - rmsle: 0.0675 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 5.7150 - val_rmsle: 0.0775 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.7659 - rmsle: 0.0669 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 5.9132 - val_rmsle: 0.0823 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.6875 - rmsle: 0.0666 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0904 - val_msle: 6.4469 - val_rmsle: 0.0882 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.6225 - rmsle: 0.0662 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0923 - val_msle: 6.4255 - val_rmsle: 0.0903 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.5477 - rmsle: 0.0657 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.8750 - val_rmsle: 0.0705 - learning_rate: 1.2500e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.5191 - rmsle: 0.0655 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 5.0554 - val_rmsle: 0.0719 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.4832 - rmsle: 0.0652 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.9684 - val_rmsle: 0.0710 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.4525 - rmsle: 0.0652 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 5.0881 - val_rmsle: 0.0729 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.4203 - rmsle: 0.0649 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.3776 - val_rmsle: 0.0651 - learning_rate: 6.2500e-05\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.4147 - rmsle: 0.0648 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.3449 - val_rmsle: 0.0651 - learning_rate: 6.2500e-05\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.3952 - rmsle: 0.0647 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.4023 - val_rmsle: 0.0654 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.3833 - rmsle: 0.0646 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.3232 - val_rmsle: 0.0646 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.3717 - rmsle: 0.0645 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.3324 - val_rmsle: 0.0649 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.3553 - rmsle: 0.0645 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.3451 - val_rmsle: 0.0648 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.3464 - rmsle: 0.0644 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.4109 - val_rmsle: 0.0659 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.3354 - rmsle: 0.0643 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.1211 - val_rmsle: 0.0627 - learning_rate: 3.1250e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3233 - rmsle: 0.0642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.1363 - val_rmsle: 0.0629 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3266 - rmsle: 0.0642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.1037 - val_rmsle: 0.0627 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.3187 - rmsle: 0.0642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.1166 - val_rmsle: 0.0628 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.3050 - rmsle: 0.0641 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 4.0554 - val_rmsle: 0.0621 - learning_rate: 1.5625e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.3033 - rmsle: 0.0641 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 4.0567 - val_rmsle: 0.0622 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.2934 - rmsle: 0.0640 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 4.0529 - val_rmsle: 0.0621 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2981 - rmsle: 0.0640 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 4.0554 - val_rmsle: 0.0622 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2987 - rmsle: 0.0639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 4.0445 - val_rmsle: 0.0620 - learning_rate: 7.8125e-06\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2932 - rmsle: 0.0639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 4.0430 - val_rmsle: 0.0620 - learning_rate: 7.8125e-06\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2950 - rmsle: 0.0640 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 4.0422 - val_rmsle: 0.0620 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06289169749690271\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 8s 8ms/step - dense_3_loss: 0.0000e+00 - loss: 2.4090 - msle: 97.9219 - rmsle: 2.3921 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2925 - val_msle: 27.4640 - val_rmsle: 0.2803 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1654 - msle: 14.4490 - rmsle: 0.1550 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1207 - val_msle: 7.1536 - val_rmsle: 0.1138 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0828 - msle: 5.7269 - rmsle: 0.0766 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1297 - val_msle: 8.1635 - val_rmsle: 0.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0754 - msle: 5.3358 - rmsle: 0.0711 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1274 - val_msle: 8.4067 - val_rmsle: 0.1238 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0724 - msle: 5.0932 - rmsle: 0.0690 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1321 - val_msle: 8.7876 - val_rmsle: 0.1292 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.8934 - rmsle: 0.0677 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0944 - val_msle: 6.5826 - val_rmsle: 0.0919 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.7945 - rmsle: 0.0670 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0942 - val_msle: 6.3762 - val_rmsle: 0.0919 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.7114 - rmsle: 0.0665 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1016 - val_msle: 7.0123 - val_rmsle: 0.0994 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.6440 - rmsle: 0.0661 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1002 - val_msle: 6.6647 - val_rmsle: 0.0982 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.5915 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1033 - val_msle: 7.0768 - val_rmsle: 0.1014 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.5302 - rmsle: 0.0653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 5.0641 - val_rmsle: 0.0716 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.4930 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.8727 - val_rmsle: 0.0700 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.4662 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 5.1827 - val_rmsle: 0.0743 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.4331 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.5556 - val_rmsle: 0.0776 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.4081 - rmsle: 0.0647 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 5.3313 - val_rmsle: 0.0769 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.3960 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.4740 - val_rmsle: 0.0662 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.3700 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.4335 - val_rmsle: 0.0657 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.3735 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.5702 - val_rmsle: 0.0674 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.3527 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.6276 - val_rmsle: 0.0673 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3463 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.5384 - val_rmsle: 0.0667 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.3301 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1780 - val_rmsle: 0.0634 - learning_rate: 3.1250e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.3206 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1813 - val_rmsle: 0.0632 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.3176 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1975 - val_rmsle: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.3155 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.1807 - val_rmsle: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.3053 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.1452 - val_rmsle: 0.0629 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.3078 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1610 - val_rmsle: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.3010 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1774 - val_rmsle: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.2997 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.1707 - val_rmsle: 0.0634 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.2862 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 4.0746 - val_rmsle: 0.0620 - learning_rate: 1.5625e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.2858 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 4.0704 - val_rmsle: 0.0620 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.2844 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 4.0713 - val_rmsle: 0.0620 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06258418490342053\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 8s 8ms/step - dense_5_loss: 0.0000e+00 - loss: 2.4102 - msle: 97.8568 - rmsle: 2.3932 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.3058 - val_msle: 28.3907 - val_rmsle: 0.2937 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1629 - msle: 14.2400 - rmsle: 0.1525 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0901 - val_msle: 6.0527 - val_rmsle: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0820 - msle: 5.6859 - rmsle: 0.0757 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 5.2615 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0747 - msle: 5.2922 - rmsle: 0.0703 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.9650 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0716 - msle: 5.0462 - rmsle: 0.0683 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 5.3021 - val_rmsle: 0.0732 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.8707 - rmsle: 0.0672 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 5.8672 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.7389 - rmsle: 0.0665 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 5.8167 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.6261 - rmsle: 0.0655 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.5357 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.5450 - rmsle: 0.0652 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3825 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.4969 - rmsle: 0.0649 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.8176 - val_rmsle: 0.0707 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.4632 - rmsle: 0.0647 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.6813 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.4230 - rmsle: 0.0646 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.7845 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3569 - rmsle: 0.0641 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0720 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.3392 - rmsle: 0.0639 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0402 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.3205 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.3408 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.3101 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1618 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.2856 - rmsle: 0.0636 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1909 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.2629 - rmsle: 0.0634 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9049 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.2586 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9775 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.2526 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.9110 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.2496 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9509 - val_rmsle: 0.0625 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.2236 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8721 - val_rmsle: 0.0617 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.2292 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8854 - val_rmsle: 0.0618 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.2253 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8693 - val_rmsle: 0.0616 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.2162 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8704 - val_rmsle: 0.0617 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.2152 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8501 - val_rmsle: 0.0613 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.2115 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8478 - val_rmsle: 0.0614 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.2069 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8512 - val_rmsle: 0.0614 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0638 - msle: 4.2097 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8474 - val_rmsle: 0.0613 - learning_rate: 1.5625e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0638 - msle: 4.1966 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8397 - val_rmsle: 0.0613 - learning_rate: 7.8125e-06\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0638 - msle: 4.2016 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8402 - val_rmsle: 0.0613 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.062000756944736515\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 8s 7ms/step - dense_7_loss: 0.0000e+00 - loss: 2.4107 - msle: 97.9760 - rmsle: 2.3937 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.3112 - val_msle: 29.1519 - val_rmsle: 0.2988 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1650 - msle: 14.5610 - rmsle: 0.1544 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0999 - val_msle: 5.8777 - val_rmsle: 0.0929 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0827 - msle: 5.6924 - rmsle: 0.0764 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1121 - val_msle: 6.7827 - val_rmsle: 0.1073 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0756 - msle: 5.3019 - rmsle: 0.0712 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1290 - val_msle: 7.8687 - val_rmsle: 0.1255 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0726 - msle: 5.0596 - rmsle: 0.0693 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1445 - val_msle: 9.3489 - val_rmsle: 0.1417 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.8755 - rmsle: 0.0679 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 5.6811 - val_rmsle: 0.0891 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.7757 - rmsle: 0.0672 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0988 - val_msle: 6.2184 - val_rmsle: 0.0965 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.6887 - rmsle: 0.0668 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0983 - val_msle: 5.8829 - val_rmsle: 0.0962 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.6284 - rmsle: 0.0664 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1104 - val_msle: 6.6888 - val_rmsle: 0.1085 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.5585 - rmsle: 0.0659 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.6340 - val_rmsle: 0.0728 - learning_rate: 1.2500e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.5353 - rmsle: 0.0657 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 4.6687 - val_rmsle: 0.0750 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.5062 - rmsle: 0.0656 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.7862 - val_rmsle: 0.0748 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.4782 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.8228 - val_rmsle: 0.0755 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.4418 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2413 - val_rmsle: 0.0667 - learning_rate: 6.2500e-05\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.4248 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.2113 - val_rmsle: 0.0664 - learning_rate: 6.2500e-05\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.4146 - rmsle: 0.0649 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1787 - val_rmsle: 0.0662 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.3945 - rmsle: 0.0648 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1908 - val_rmsle: 0.0665 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.3804 - rmsle: 0.0647 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1977 - val_rmsle: 0.0665 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.3761 - rmsle: 0.0648 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.2331 - val_rmsle: 0.0669 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.3619 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0409 - val_rmsle: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.3467 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0439 - val_rmsle: 0.0634 - learning_rate: 3.1250e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.3449 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0537 - val_rmsle: 0.0638 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.3393 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0322 - val_rmsle: 0.0634 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.3313 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9998 - val_rmsle: 0.0625 - learning_rate: 1.5625e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.3304 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9967 - val_rmsle: 0.0625 - learning_rate: 1.5625e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.3305 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9967 - val_rmsle: 0.0625 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.3259 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9906 - val_rmsle: 0.0624 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3190 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9801 - val_rmsle: 0.0622 - learning_rate: 7.8125e-06\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3217 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9806 - val_rmsle: 0.0622 - learning_rate: 7.8125e-06\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.3205 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9805 - val_rmsle: 0.0622 - learning_rate: 7.8125e-06\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3144 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9807 - val_rmsle: 0.0622 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06307927545352039\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_9_loss: 0.0000e+00 - loss: 2.4116 - msle: 98.1202 - rmsle: 2.3947 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.3024 - val_msle: 28.5920 - val_rmsle: 0.2902 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.1645 - msle: 14.4538 - rmsle: 0.1541 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1017 - val_msle: 5.8878 - val_rmsle: 0.0947 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0821 - msle: 5.6620 - rmsle: 0.0758 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0929 - val_msle: 5.7695 - val_rmsle: 0.0881 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0749 - msle: 5.2751 - rmsle: 0.0705 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0973 - val_msle: 5.9022 - val_rmsle: 0.0937 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0719 - msle: 5.0271 - rmsle: 0.0686 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1044 - val_msle: 5.9765 - val_rmsle: 0.1015 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.8492 - rmsle: 0.0676 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1104 - val_msle: 6.3450 - val_rmsle: 0.1080 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.7031 - rmsle: 0.0666 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.5396 - val_rmsle: 0.0672 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.6293 - rmsle: 0.0662 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.5402 - val_rmsle: 0.0697 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.5625 - rmsle: 0.0658 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.5627 - val_rmsle: 0.0686 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.5132 - rmsle: 0.0656 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.7591 - val_rmsle: 0.0729 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.4338 - rmsle: 0.0650 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1594 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.4223 - rmsle: 0.0649 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.1818 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.3874 - rmsle: 0.0647 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.1482 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.3575 - rmsle: 0.0645 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.1032 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.3394 - rmsle: 0.0645 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0953 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.3162 - rmsle: 0.0644 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1021 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.3023 - rmsle: 0.0642 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 4.0324 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.2823 - rmsle: 0.0642 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0935 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.2581 - rmsle: 0.0641 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0410 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2445 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0628 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.2245 - rmsle: 0.0638 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9525 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.2079 - rmsle: 0.0636 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9478 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.2005 - rmsle: 0.0635 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9395 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.1938 - rmsle: 0.0635 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9318 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.1953 - rmsle: 0.0636 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.9270 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.1860 - rmsle: 0.0634 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.9151 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.1825 - rmsle: 0.0634 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.9089 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.1698 - rmsle: 0.0633 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.9079 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1659 - rmsle: 0.0633 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.9069 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1703 - rmsle: 0.0633 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.9022 - val_rmsle: 0.0609 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1568 - rmsle: 0.0633 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.9001 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06158103382989392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 16:42:38,438] Trial 2 finished with value: 0.06242738972569482 and parameters: {'units': 256, 'num_cross_layers': 1, 'activation': 'relu', 'reg': 0.0006889890893119075, 'do_rate': 0.25374588352655936, 'hidden_layers': 1}. Best is trial 1 with value: 0.0615441242843887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.4976 - msle: 97.2728 - rmsle: 2.3175 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.3489 - val_msle: 29.4766 - val_rmsle: 1.2868 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1652 - msle: 8.7006 - rmsle: 0.1154 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1432 - val_msle: 6.1557 - val_rmsle: 0.1172 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1076 - msle: 5.4128 - rmsle: 0.0854 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1238 - val_msle: 6.0860 - val_rmsle: 0.1091 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0937 - msle: 5.1433 - rmsle: 0.0805 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1064 - val_msle: 5.3738 - val_rmsle: 0.0961 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0883 - msle: 5.0104 - rmsle: 0.0787 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0906 - val_msle: 4.6828 - val_rmsle: 0.0823 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0848 - msle: 4.8896 - rmsle: 0.0767 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 5.1516 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0821 - msle: 4.8261 - rmsle: 0.0751 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0930 - val_msle: 5.3627 - val_rmsle: 0.0864 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0797 - msle: 4.7307 - rmsle: 0.0735 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.4178 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0789 - msle: 4.7106 - rmsle: 0.0731 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.1275 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0768 - msle: 4.6054 - rmsle: 0.0714 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.5011 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0752 - msle: 4.5465 - rmsle: 0.0704 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0876 - val_msle: 5.4741 - val_rmsle: 0.0829 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4621 - rmsle: 0.0694 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.2634 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.3703 - rmsle: 0.0675 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.3835 - val_rmsle: 0.0740 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.3471 - rmsle: 0.0674 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.4583 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.3030 - rmsle: 0.0669 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.9071 - val_rmsle: 0.0703 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.2860 - rmsle: 0.0666 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9176 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.2463 - rmsle: 0.0664 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.4159 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.2055 - rmsle: 0.0660 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0241 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1830 - rmsle: 0.0657 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.9854 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1248 - rmsle: 0.0649 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8986 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1093 - rmsle: 0.0647 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8678 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0785 - rmsle: 0.0647 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1233 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0580 - rmsle: 0.0642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8650 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.0513 - rmsle: 0.0639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7076 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0339 - rmsle: 0.0639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7515 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0326 - rmsle: 0.0638 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7649 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0116 - rmsle: 0.0638 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6831 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0127 - rmsle: 0.0637 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8184 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.0155 - rmsle: 0.0637 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8367 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0002 - rmsle: 0.0635 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7092 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9849 - rmsle: 0.0635 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6896 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0615872577422449\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_3_loss: 0.0000e+00 - loss: 2.4992 - msle: 97.4876 - rmsle: 2.3198 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8216 - val_msle: 24.8511 - val_rmsle: 0.7621 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1689 - msle: 9.5757 - rmsle: 0.1204 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1379 - val_msle: 6.0310 - val_rmsle: 0.1123 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1083 - msle: 5.4712 - rmsle: 0.0862 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1261 - val_msle: 5.5916 - val_rmsle: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0935 - msle: 5.1642 - rmsle: 0.0803 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0991 - val_msle: 4.8700 - val_rmsle: 0.0887 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0871 - msle: 4.9980 - rmsle: 0.0775 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1172 - val_msle: 9.5197 - val_rmsle: 0.1089 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0832 - msle: 4.8872 - rmsle: 0.0754 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1018 - val_msle: 5.9362 - val_rmsle: 0.0947 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0817 - msle: 4.8512 - rmsle: 0.0749 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1204 - val_msle: 7.0753 - val_rmsle: 0.1141 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0775 - msle: 4.6956 - rmsle: 0.0716 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.3776 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0763 - msle: 4.6373 - rmsle: 0.0711 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0834 - val_msle: 4.9537 - val_rmsle: 0.0785 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0752 - msle: 4.5951 - rmsle: 0.0704 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.8809 - val_rmsle: 0.0729 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0744 - msle: 4.5513 - rmsle: 0.0699 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 5.1002 - val_rmsle: 0.0731 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.4845 - rmsle: 0.0687 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8101 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.4621 - rmsle: 0.0685 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9489 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.4404 - rmsle: 0.0682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2888 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.4168 - rmsle: 0.0679 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0328 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.3996 - rmsle: 0.0676 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.0359 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.3822 - rmsle: 0.0674 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0491 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.3586 - rmsle: 0.0671 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.4507 - val_rmsle: 0.0667 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.3199 - rmsle: 0.0665 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8354 - val_rmsle: 0.0634 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.3147 - rmsle: 0.0663 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9044 - val_rmsle: 0.0628 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.3080 - rmsle: 0.0661 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8238 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.2873 - rmsle: 0.0662 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8503 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.2790 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8207 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.2778 - rmsle: 0.0661 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8135 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.2651 - rmsle: 0.0658 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8202 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.2621 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7739 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.2431 - rmsle: 0.0657 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8492 - val_rmsle: 0.0625 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2471 - rmsle: 0.0656 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8381 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.2393 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8353 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.2194 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7131 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.1984 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7366 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06092725181925175\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_5_loss: 0.0000e+00 - loss: 2.4933 - msle: 96.9954 - rmsle: 2.3133 - val_dense_5_loss: 0.0000e+00 - val_loss: 1.0946 - val_msle: 25.5509 - val_rmsle: 1.0340 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1643 - msle: 8.4001 - rmsle: 0.1146 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1240 - val_msle: 6.5009 - val_rmsle: 0.0976 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1086 - msle: 5.4200 - rmsle: 0.0858 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1015 - val_msle: 4.3243 - val_rmsle: 0.0863 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0934 - msle: 5.1245 - rmsle: 0.0797 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 4.7910 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0889 - msle: 5.0153 - rmsle: 0.0786 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0871 - val_msle: 5.4512 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0845 - msle: 4.8904 - rmsle: 0.0761 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 5.6568 - val_rmsle: 0.0732 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.7913 - rmsle: 0.0742 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 3.7774 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0796 - msle: 4.7508 - rmsle: 0.0730 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.0242 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0776 - msle: 4.6741 - rmsle: 0.0717 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.8109 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.6108 - rmsle: 0.0705 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.8331 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.5696 - rmsle: 0.0696 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.7674 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.5079 - rmsle: 0.0689 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.0062 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0722 - msle: 4.4441 - rmsle: 0.0679 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.3551 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.3911 - rmsle: 0.0674 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.4281 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.3243 - rmsle: 0.0668 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.0504 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.2947 - rmsle: 0.0663 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.8690 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.1859 - rmsle: 0.0648 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7583 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1555 - rmsle: 0.0645 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.6261 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.1159 - rmsle: 0.0642 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1210 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0984 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.6859 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0869 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7740 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0521 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7039 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0660 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9301 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0543 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8521 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0129 - rmsle: 0.0635 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6454 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0011 - rmsle: 0.0634 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9849 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0003 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.7441 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9783 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6859 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.062254981201548945\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 2.4972 - msle: 97.2671 - rmsle: 2.3166 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.8928 - val_msle: 31.1028 - val_rmsle: 0.8322 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1960 - msle: 9.1786 - rmsle: 0.1468 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1365 - val_msle: 6.5225 - val_rmsle: 0.1103 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1101 - msle: 5.4705 - rmsle: 0.0874 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1429 - val_msle: 5.8479 - val_rmsle: 0.1276 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0947 - msle: 5.1748 - rmsle: 0.0808 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1244 - val_msle: 5.9529 - val_rmsle: 0.1138 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0878 - msle: 5.0073 - rmsle: 0.0779 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1127 - val_msle: 5.1717 - val_rmsle: 0.1042 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0843 - msle: 4.9213 - rmsle: 0.0762 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1205 - val_msle: 5.7954 - val_rmsle: 0.1131 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0819 - msle: 4.8257 - rmsle: 0.0748 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1182 - val_msle: 6.2370 - val_rmsle: 0.1118 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0793 - msle: 4.7459 - rmsle: 0.0730 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1377 - val_msle: 8.4231 - val_rmsle: 0.1317 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0768 - msle: 4.6479 - rmsle: 0.0711 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0896 - val_msle: 4.6164 - val_rmsle: 0.0846 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.6024 - rmsle: 0.0707 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 4.3036 - val_rmsle: 0.0773 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.5697 - rmsle: 0.0701 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 4.5404 - val_rmsle: 0.0782 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.5377 - rmsle: 0.0699 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.5001 - val_rmsle: 0.0791 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.5140 - rmsle: 0.0693 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.6386 - val_rmsle: 0.0791 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.4225 - rmsle: 0.0679 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.0319 - val_rmsle: 0.0699 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.4075 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.2073 - val_rmsle: 0.0689 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.3956 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.0078 - val_rmsle: 0.0698 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.3614 - rmsle: 0.0673 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 3.9609 - val_rmsle: 0.0679 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.3500 - rmsle: 0.0672 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.7306 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.3320 - rmsle: 0.0668 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.1930 - val_rmsle: 0.0686 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.3147 - rmsle: 0.0665 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.2409 - val_rmsle: 0.0720 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.3028 - rmsle: 0.0665 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.7503 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.2912 - rmsle: 0.0665 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.9180 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.2697 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.4712 - val_rmsle: 0.0708 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.2410 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.1866 - val_rmsle: 0.0703 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2089 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.6581 - val_rmsle: 0.0627 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.2051 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.6899 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1816 - rmsle: 0.0653 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7067 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1930 - rmsle: 0.0653 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.6488 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1693 - rmsle: 0.0650 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.5919 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1561 - rmsle: 0.0648 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.5917 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.1383 - rmsle: 0.0647 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6261 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06181427652378489\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_9_loss: 0.0000e+00 - loss: 2.4911 - msle: 97.2072 - rmsle: 2.3108 - val_dense_9_loss: 0.0000e+00 - val_loss: 1.1602 - val_msle: 26.5247 - val_rmsle: 1.0977 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.1613 - msle: 8.2809 - rmsle: 0.1113 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1240 - val_msle: 6.7574 - val_rmsle: 0.0978 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.1071 - msle: 5.3500 - rmsle: 0.0847 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1138 - val_msle: 5.1095 - val_rmsle: 0.0984 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0939 - msle: 5.0732 - rmsle: 0.0801 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1304 - val_msle: 6.0035 - val_rmsle: 0.1198 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0877 - msle: 4.9557 - rmsle: 0.0777 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1446 - val_msle: 6.3792 - val_rmsle: 0.1362 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0842 - msle: 4.8722 - rmsle: 0.0761 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1332 - val_msle: 6.8565 - val_rmsle: 0.1259 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0797 - msle: 4.7472 - rmsle: 0.0729 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.4512 - val_rmsle: 0.0755 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0786 - msle: 4.6983 - rmsle: 0.0726 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.5772 - val_rmsle: 0.0778 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0772 - msle: 4.6461 - rmsle: 0.0717 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 4.2295 - val_rmsle: 0.0731 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0762 - msle: 4.5949 - rmsle: 0.0711 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.1067 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.5626 - rmsle: 0.0707 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.0412 - val_rmsle: 0.0677 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.5315 - rmsle: 0.0701 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.8204 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.5110 - rmsle: 0.0695 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.8231 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.4612 - rmsle: 0.0690 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.0555 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0728 - msle: 4.4532 - rmsle: 0.0687 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 4.2109 - val_rmsle: 0.0725 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.3969 - rmsle: 0.0676 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8873 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.3679 - rmsle: 0.0674 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7421 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.3448 - rmsle: 0.0670 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.7908 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.3152 - rmsle: 0.0668 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7137 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.3049 - rmsle: 0.0668 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.6711 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.3084 - rmsle: 0.0667 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6576 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.2702 - rmsle: 0.0662 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6660 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.2641 - rmsle: 0.0662 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7253 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.2467 - rmsle: 0.0660 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7068 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.2322 - rmsle: 0.0658 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6689 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.1935 - rmsle: 0.0655 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7525 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1723 - rmsle: 0.0652 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6121 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1715 - rmsle: 0.0650 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6812 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.1610 - rmsle: 0.0650 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8168 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1510 - rmsle: 0.0649 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6506 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.1397 - rmsle: 0.0649 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8402 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06058491476105539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 16:49:32,731] Trial 3 finished with value: 0.06143373640957718 and parameters: {'units': 256, 'num_cross_layers': 1, 'activation': 'silu', 'reg': 0.00043288587998977147, 'do_rate': 0.2986190118339311, 'hidden_layers': 3}. Best is trial 3 with value: 0.06143373640957718.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_2_loss: 0.0000e+00 - loss: 3.4517 - msle: 77.8684 - rmsle: 1.3363 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2697 - val_msle: 23.6248 - val_rmsle: 0.2251 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1402 - msle: 6.1932 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2182 - val_msle: 14.7644 - val_rmsle: 0.1853 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1197 - msle: 5.7250 - rmsle: 0.0872 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1869 - val_msle: 11.1771 - val_rmsle: 0.1607 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1068 - msle: 5.3720 - rmsle: 0.0813 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1598 - val_msle: 8.6489 - val_rmsle: 0.1389 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0991 - msle: 5.0859 - rmsle: 0.0771 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1366 - val_msle: 9.1782 - val_rmsle: 0.1188 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0924 - msle: 4.8492 - rmsle: 0.0738 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1110 - val_msle: 7.3767 - val_rmsle: 0.0945 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0866 - msle: 4.6084 - rmsle: 0.0710 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 6.7524 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0823 - msle: 4.4544 - rmsle: 0.0693 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0908 - val_msle: 6.8690 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0793 - msle: 4.3739 - rmsle: 0.0681 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0824 - val_msle: 6.2192 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0784 - msle: 4.3775 - rmsle: 0.0674 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1055 - val_msle: 8.1988 - val_rmsle: 0.0912 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.4202 - rmsle: 0.0675 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 5.7378 - val_rmsle: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0800 - msle: 4.3979 - rmsle: 0.0671 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 5.9836 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.3253 - rmsle: 0.0663 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.7586 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0750 - msle: 4.2814 - rmsle: 0.0660 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.7743 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0757 - msle: 4.3389 - rmsle: 0.0660 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.7766 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.3062 - rmsle: 0.0654 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.3871 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.1818 - rmsle: 0.0651 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.5231 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.1718 - rmsle: 0.0651 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.3105 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.0594 - rmsle: 0.0643 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.8053 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0108 - rmsle: 0.0638 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 5.0253 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9639 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9678 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9460 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2989 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9629 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1554 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9589 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0716 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8822 - rmsle: 0.0628 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8950 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8456 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1575 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8521 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8531 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8345 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.0350 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8231 - rmsle: 0.0624 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8835 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8206 - rmsle: 0.0624 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8528 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8056 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8586 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06314134438401055\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 13ms/step - dense_5_loss: 0.0000e+00 - loss: 3.4575 - msle: 77.9651 - rmsle: 1.3370 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.2713 - val_msle: 15.2795 - val_rmsle: 0.2251 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1374 - msle: 6.0811 - rmsle: 0.0954 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.2892 - val_msle: 12.3116 - val_rmsle: 0.2569 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1193 - msle: 5.7946 - rmsle: 0.0877 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1873 - val_msle: 7.5964 - val_rmsle: 0.1599 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1078 - msle: 5.4632 - rmsle: 0.0818 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1923 - val_msle: 5.9578 - val_rmsle: 0.1663 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1008 - msle: 5.1674 - rmsle: 0.0778 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1283 - val_msle: 6.0411 - val_rmsle: 0.1067 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0931 - msle: 4.8889 - rmsle: 0.0740 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1103 - val_msle: 6.6676 - val_rmsle: 0.0916 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0880 - msle: 4.6818 - rmsle: 0.0716 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0997 - val_msle: 7.2597 - val_rmsle: 0.0830 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0832 - msle: 4.4754 - rmsle: 0.0695 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0899 - val_msle: 5.7537 - val_rmsle: 0.0787 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0806 - msle: 4.4473 - rmsle: 0.0686 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 5.9462 - val_rmsle: 0.0809 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0779 - msle: 4.4160 - rmsle: 0.0677 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 6.4072 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0766 - msle: 4.3824 - rmsle: 0.0672 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.2711 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.3779 - rmsle: 0.0668 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.3524 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.3592 - rmsle: 0.0663 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 6.2187 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0742 - msle: 4.3357 - rmsle: 0.0661 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 6.0223 - val_rmsle: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.1604 - rmsle: 0.0646 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.2800 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1477 - rmsle: 0.0646 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.8821 - val_rmsle: 0.0699 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.1449 - rmsle: 0.0644 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.4184 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1312 - rmsle: 0.0643 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.6595 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0349 - rmsle: 0.0635 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0709 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9869 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0751 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9888 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0492 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9697 - rmsle: 0.0631 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0298 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9549 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9931 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9438 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0317 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9521 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1891 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9497 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9649 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9049 - rmsle: 0.0625 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8815 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8905 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9040 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8831 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8964 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8735 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8926 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8708 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8912 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06187486881988996\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_8_loss: 0.0000e+00 - loss: 3.4224 - msle: 77.5187 - rmsle: 1.3311 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.2695 - val_msle: 23.7659 - val_rmsle: 0.2260 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1355 - msle: 6.1146 - rmsle: 0.0951 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1734 - val_msle: 12.1884 - val_rmsle: 0.1408 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1183 - msle: 5.7023 - rmsle: 0.0869 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1561 - val_msle: 11.5706 - val_rmsle: 0.1264 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1105 - msle: 5.4556 - rmsle: 0.0819 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1526 - val_msle: 11.3163 - val_rmsle: 0.1283 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0999 - msle: 5.1416 - rmsle: 0.0768 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1200 - val_msle: 9.5542 - val_rmsle: 0.0995 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0934 - msle: 4.8337 - rmsle: 0.0732 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0971 - val_msle: 6.8905 - val_rmsle: 0.0788 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0862 - msle: 4.5936 - rmsle: 0.0703 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1002 - val_msle: 8.4242 - val_rmsle: 0.0844 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0819 - msle: 4.4690 - rmsle: 0.0685 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0968 - val_msle: 7.8853 - val_rmsle: 0.0850 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0781 - msle: 4.3783 - rmsle: 0.0674 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 6.0510 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0753 - msle: 4.3547 - rmsle: 0.0666 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 7.0238 - val_rmsle: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.3376 - rmsle: 0.0662 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 7.5661 - val_rmsle: 0.0817 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.3009 - rmsle: 0.0656 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 6.3854 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2627 - rmsle: 0.0652 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1105 - val_msle: 9.0978 - val_rmsle: 0.1020 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.2462 - rmsle: 0.0649 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 6.2107 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2596 - rmsle: 0.0650 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0923 - val_msle: 7.6028 - val_rmsle: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1459 - rmsle: 0.0640 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9308 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.0696 - rmsle: 0.0634 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.5546 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0731 - rmsle: 0.0634 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.5644 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0470 - rmsle: 0.0632 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.4017 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9620 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7658 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9517 - rmsle: 0.0624 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8353 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9433 - rmsle: 0.0623 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.3265 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9262 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.2063 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9161 - rmsle: 0.0621 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8868 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8738 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7050 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8678 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6953 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8692 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7717 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8659 - rmsle: 0.0616 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7450 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8258 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6548 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8297 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6666 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8198 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6854 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06169798110800364\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_11_loss: 0.0000e+00 - loss: 3.4511 - msle: 77.7608 - rmsle: 1.3369 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.3012 - val_msle: 15.2230 - val_rmsle: 0.2535 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1370 - msle: 6.1150 - rmsle: 0.0950 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.2062 - val_msle: 6.6926 - val_rmsle: 0.1717 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1184 - msle: 5.7527 - rmsle: 0.0867 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.2010 - val_msle: 6.8952 - val_rmsle: 0.1749 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1066 - msle: 5.3855 - rmsle: 0.0811 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.2388 - val_msle: 8.8336 - val_rmsle: 0.2157 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0985 - msle: 5.0967 - rmsle: 0.0764 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1713 - val_msle: 8.7969 - val_rmsle: 0.1505 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0916 - msle: 4.8154 - rmsle: 0.0732 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1685 - val_msle: 7.7391 - val_rmsle: 0.1516 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0860 - msle: 4.5911 - rmsle: 0.0707 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1293 - val_msle: 6.2404 - val_rmsle: 0.1131 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0826 - msle: 4.4436 - rmsle: 0.0689 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.2523 - val_msle: 17.2780 - val_rmsle: 0.2384 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0789 - msle: 4.3444 - rmsle: 0.0678 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1135 - val_msle: 6.5027 - val_rmsle: 0.1007 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0779 - msle: 4.3521 - rmsle: 0.0671 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.2398 - val_msle: 17.8229 - val_rmsle: 0.2277 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0766 - msle: 4.3313 - rmsle: 0.0667 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1760 - val_msle: 17.2257 - val_rmsle: 0.1634 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0759 - msle: 4.3309 - rmsle: 0.0666 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.5636 - val_msle: 38.1469 - val_rmsle: 0.5492 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0725 - msle: 4.2043 - rmsle: 0.0653 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1549 - val_msle: 17.2316 - val_rmsle: 0.1492 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1520 - rmsle: 0.0649 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 8.5397 - val_rmsle: 0.0789 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1438 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 6.4215 - val_rmsle: 0.0717 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1392 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 9.6227 - val_rmsle: 0.0857 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.1345 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.4798 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.1238 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0984 - val_msle: 9.4004 - val_rmsle: 0.0935 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.0988 - rmsle: 0.0646 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 6.9120 - val_rmsle: 0.0788 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.0747 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 5.4170 - val_rmsle: 0.0723 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9957 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.4774 - val_rmsle: 0.0743 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9531 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.1429 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9260 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.9502 - val_rmsle: 0.0670 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9586 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.0294 - val_rmsle: 0.0680 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9177 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.0573 - val_rmsle: 0.0682 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9086 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9283 - val_rmsle: 0.0667 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8979 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.1835 - val_rmsle: 0.0684 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8915 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9223 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8849 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 3.9992 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8707 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.3712 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8723 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.0176 - val_rmsle: 0.0677 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06714202901418218\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 14ms/step - dense_14_loss: 0.0000e+00 - loss: 3.4295 - msle: 77.7578 - rmsle: 1.3287 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.2616 - val_msle: 17.1022 - val_rmsle: 0.2138 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1363 - msle: 6.1416 - rmsle: 0.0951 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.2172 - val_msle: 7.4267 - val_rmsle: 0.1812 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1203 - msle: 5.7670 - rmsle: 0.0876 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1903 - val_msle: 10.1206 - val_rmsle: 0.1632 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1066 - msle: 5.3981 - rmsle: 0.0813 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1753 - val_msle: 9.9437 - val_rmsle: 0.1529 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0992 - msle: 5.1238 - rmsle: 0.0776 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1477 - val_msle: 8.3565 - val_rmsle: 0.1283 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0925 - msle: 4.8324 - rmsle: 0.0736 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1591 - val_msle: 6.9541 - val_rmsle: 0.1444 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0868 - msle: 4.5609 - rmsle: 0.0709 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1329 - val_msle: 6.1883 - val_rmsle: 0.1206 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0837 - msle: 4.4569 - rmsle: 0.0692 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.3434 - val_msle: 26.7311 - val_rmsle: 0.3285 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0836 - msle: 4.4400 - rmsle: 0.0683 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0931 - val_msle: 6.6041 - val_rmsle: 0.0818 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0778 - msle: 4.3299 - rmsle: 0.0672 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0990 - val_msle: 6.2379 - val_rmsle: 0.0897 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0824 - msle: 4.3814 - rmsle: 0.0673 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 4.5790 - val_rmsle: 0.0817 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0771 - msle: 4.2994 - rmsle: 0.0666 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.3616 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0764 - msle: 4.3148 - rmsle: 0.0665 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.4087 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.2699 - rmsle: 0.0659 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.4330 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0766 - msle: 4.2588 - rmsle: 0.0659 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 5.1183 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.2110 - rmsle: 0.0653 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0944 - val_msle: 5.1630 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.1659 - rmsle: 0.0651 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 5.0354 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.0646 - rmsle: 0.0642 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.2518 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0048 - rmsle: 0.0637 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.7037 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.0197 - rmsle: 0.0639 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.6502 - val_rmsle: 0.0667 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0682 - msle: 3.9709 - rmsle: 0.0636 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 5.1771 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9128 - rmsle: 0.0629 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.0728 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8827 - rmsle: 0.0627 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9655 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8676 - rmsle: 0.0626 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8436 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8558 - rmsle: 0.0626 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.3720 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8435 - rmsle: 0.0625 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.1418 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8410 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.4171 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8042 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7474 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7794 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8196 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7846 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8517 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7768 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7695 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.061927917385284664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 16:58:22,669] Trial 4 finished with value: 0.06315682814227419 and parameters: {'units': 1024, 'num_cross_layers': 2, 'activation': 'prelu', 'reg': 0.004042905517735184, 'do_rate': 0.3599852673542245, 'hidden_layers': 3}. Best is trial 3 with value: 0.06143373640957718.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 16ms/step - dense_3_loss: 0.0000e+00 - loss: 1.9846 - msle: 81.8794 - rmsle: 1.8075 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1572 - val_msle: 7.8487 - val_rmsle: 0.1257 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0981 - msle: 5.7130 - rmsle: 0.0758 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.2676 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0767 - msle: 4.6294 - rmsle: 0.0687 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 5.3904 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.3387 - rmsle: 0.0667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.6262 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.2050 - rmsle: 0.0657 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.5005 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1346 - rmsle: 0.0651 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.8367 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0855 - rmsle: 0.0647 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 5.4479 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0465 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1564 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0023 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9845 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9757 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.2682 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9517 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.3287 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9200 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0871 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8455 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.3586 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8397 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.1209 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8087 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0902 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8009 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.2630 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7943 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 4.0216 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7853 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0839 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7883 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 4.0153 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7713 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.2231 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7554 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 4.0556 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7420 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8988 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7378 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9400 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7276 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8617 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7276 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.9450 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7224 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7520 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7109 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.9683 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7270 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9605 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7176 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.9758 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6731 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7374 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6820 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7443 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061766224618081136\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 1.9892 - msle: 82.0090 - rmsle: 1.8126 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1779 - val_msle: 7.9541 - val_rmsle: 0.1471 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0980 - msle: 5.7362 - rmsle: 0.0762 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 5.7089 - val_rmsle: 0.0777 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0766 - msle: 4.6764 - rmsle: 0.0687 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.5910 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0720 - msle: 4.4045 - rmsle: 0.0668 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.9318 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.2715 - rmsle: 0.0657 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 5.7055 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1887 - rmsle: 0.0652 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.9215 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1184 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.4235 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0722 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 5.0311 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0534 - rmsle: 0.0639 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 5.2424 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.0137 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 5.3640 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9264 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.5649 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9031 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0847 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8937 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 4.0550 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8638 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.2606 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8566 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.1006 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8518 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 4.1361 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8084 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8001 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7912 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.8659 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7928 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7770 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7713 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7845 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7807 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8052 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7730 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7937 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7685 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7811 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7470 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7863 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7453 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7836 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7377 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7944 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7329 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7423 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7273 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7392 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7209 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7548 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7303 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7492 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7155 - rmsle: 0.0605 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.7260 - val_rmsle: 0.0599 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06049050001937164\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 1.9925 - msle: 82.0144 - rmsle: 1.8165 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1612 - val_msle: 7.3894 - val_rmsle: 0.1315 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0969 - msle: 5.8231 - rmsle: 0.0758 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.5504 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.7370 - rmsle: 0.0683 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.3589 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.4414 - rmsle: 0.0664 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0906 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.2916 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8843 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2209 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8972 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1401 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0009 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0937 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8424 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0473 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8664 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0102 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7235 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0079 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8894 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9510 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9344 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9468 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.4432 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8736 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6960 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8356 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6516 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8225 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6328 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8202 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7446 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8031 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6314 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7823 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6324 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7572 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5819 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7405 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6067 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7533 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6127 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7376 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5990 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7267 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5673 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7198 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5715 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7142 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5692 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7053 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5754 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6912 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5613 - val_rmsle: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6954 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5615 - val_rmsle: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6987 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5564 - val_rmsle: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6837 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5591 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.060642001577997796\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 1.9828 - msle: 81.8521 - rmsle: 1.8053 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1679 - val_msle: 8.0022 - val_rmsle: 0.1365 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0982 - msle: 5.7279 - rmsle: 0.0760 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0855 - val_msle: 5.7083 - val_rmsle: 0.0763 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0767 - msle: 4.6430 - rmsle: 0.0687 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 4.9723 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.3666 - rmsle: 0.0667 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 5.3516 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.2476 - rmsle: 0.0659 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0887 - val_msle: 5.9156 - val_rmsle: 0.0852 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1647 - rmsle: 0.0653 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.8284 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.1110 - rmsle: 0.0648 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 5.1259 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0584 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.8074 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.0425 - rmsle: 0.0641 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 5.4384 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9909 - rmsle: 0.0638 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.7311 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9651 - rmsle: 0.0636 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.6695 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8968 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.1954 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8658 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.3354 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8633 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.2292 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8470 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.5202 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8382 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9409 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8269 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1340 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8201 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8356 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8009 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8845 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7991 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7441 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7813 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8168 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7748 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7560 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7751 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9377 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7419 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6216 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7340 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6291 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7389 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6237 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7350 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6212 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7228 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6232 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7209 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6115 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7190 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6074 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7101 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6116 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06159162184473568\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 1.9955 - msle: 82.2670 - rmsle: 1.8199 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1756 - val_msle: 7.7166 - val_rmsle: 0.1456 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0965 - msle: 5.6751 - rmsle: 0.0753 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 4.6199 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0764 - msle: 4.6309 - rmsle: 0.0685 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.5353 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.3619 - rmsle: 0.0666 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.2855 - val_rmsle: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.2581 - rmsle: 0.0660 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.3054 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.1443 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.7896 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1038 - rmsle: 0.0646 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1054 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0691 - rmsle: 0.0644 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.4158 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0079 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.3048 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9553 - rmsle: 0.0635 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.0252 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8806 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7351 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8572 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8101 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8585 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7200 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8384 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7239 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8216 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7245 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8169 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7017 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8078 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7060 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7991 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7095 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7884 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6743 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7449 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6424 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7396 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6430 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7330 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6467 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7269 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6327 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7318 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6365 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6974 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6212 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6978 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6223 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6866 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6130 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6822 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6312 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6777 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6138 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6960 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6118 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6743 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6004 - val_rmsle: 0.0594 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060178380484452544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:05:29,533] Trial 5 finished with value: 0.060933745708927754 and parameters: {'units': 256, 'num_cross_layers': 3, 'activation': 'relu', 'reg': 0.0009256030868110645, 'do_rate': 0.3406910123899549, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 18s 18ms/step - dense_3_loss: 0.0000e+00 - loss: 1.8228 - msle: 75.8151 - rmsle: 1.3388 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1324 - val_msle: 9.1155 - val_rmsle: 0.1092 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0987 - msle: 5.7718 - rmsle: 0.0794 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 4.9538 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0871 - msle: 5.1017 - rmsle: 0.0744 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 5.2636 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0826 - msle: 4.8479 - rmsle: 0.0720 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0845 - val_msle: 4.9315 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0789 - msle: 4.6288 - rmsle: 0.0698 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.6779 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0763 - msle: 4.4792 - rmsle: 0.0682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.7226 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0734 - msle: 4.3312 - rmsle: 0.0669 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.5144 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.2377 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.4290 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.1647 - rmsle: 0.0654 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1454 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1082 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.3499 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.0539 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2802 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0441 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.0744 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0010 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1702 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9726 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1293 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9449 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0762 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9183 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9225 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8788 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9054 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8817 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8760 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8523 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9818 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7835 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1232 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7635 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8366 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7570 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9291 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7449 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7905 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7338 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.9051 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7363 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8567 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7292 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8077 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6967 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7442 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6901 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8153 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6875 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7932 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6832 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7617 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6821 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7305 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061685788990164456\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.8259 - msle: 75.7637 - rmsle: 1.3404 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1564 - val_msle: 7.8340 - val_rmsle: 0.1331 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0986 - msle: 5.8188 - rmsle: 0.0791 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1287 - val_msle: 8.0388 - val_rmsle: 0.1148 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0867 - msle: 5.2018 - rmsle: 0.0743 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1325 - val_msle: 8.3186 - val_rmsle: 0.1213 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0818 - msle: 4.9287 - rmsle: 0.0719 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1273 - val_msle: 8.9345 - val_rmsle: 0.1184 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0779 - msle: 4.7453 - rmsle: 0.0699 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1336 - val_msle: 11.5212 - val_rmsle: 0.1255 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0757 - msle: 4.5631 - rmsle: 0.0684 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1189 - val_msle: 10.3802 - val_rmsle: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.4232 - rmsle: 0.0669 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1427 - val_msle: 14.0803 - val_rmsle: 0.1358 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.2986 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 5.2031 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.2325 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 7.3739 - val_rmsle: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1687 - rmsle: 0.0650 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 5.2828 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1365 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 5.6357 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0974 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 6.0704 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0647 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 5.7083 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0094 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 5.6808 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9901 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 5.1191 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9553 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.7396 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9406 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.9605 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9100 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 5.4716 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8933 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.4515 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8732 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.6335 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8567 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.4637 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8347 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.2995 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8233 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0238 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8024 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.2349 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8100 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9932 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7832 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0395 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7781 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8620 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7777 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8508 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7587 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 4.0009 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7431 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.9088 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7418 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8911 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 8ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06202335146632656\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.8142 - msle: 75.5181 - rmsle: 1.3333 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1385 - val_msle: 10.0114 - val_rmsle: 0.1155 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0973 - msle: 5.7287 - rmsle: 0.0781 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1079 - val_msle: 8.8773 - val_rmsle: 0.0943 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0860 - msle: 5.0796 - rmsle: 0.0734 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1023 - val_msle: 7.6681 - val_rmsle: 0.0910 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.8494 - rmsle: 0.0710 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0834 - val_msle: 5.1956 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0780 - msle: 4.6886 - rmsle: 0.0691 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.6769 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.5413 - rmsle: 0.0677 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.8645 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.4289 - rmsle: 0.0664 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.3690 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.2883 - rmsle: 0.0655 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.1884 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.2046 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.0746 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1435 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3952 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0917 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.9949 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0754 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2339 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0344 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.6001 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9996 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8473 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9816 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7872 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9425 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9050 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9069 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7425 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8265 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7015 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8166 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7720 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7895 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6275 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7909 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9786 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7420 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.5885 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7437 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.5886 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7456 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5802 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7345 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5806 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7302 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6163 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7325 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6136 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7097 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5548 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7005 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5635 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7101 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5597 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6985 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5637 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06106355518126054\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 1.8063 - msle: 75.5240 - rmsle: 1.3286 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1341 - val_msle: 7.3899 - val_rmsle: 0.1122 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0974 - msle: 5.7525 - rmsle: 0.0785 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0938 - val_msle: 7.8577 - val_rmsle: 0.0807 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0868 - msle: 5.1508 - rmsle: 0.0741 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1237 - val_msle: 9.7196 - val_rmsle: 0.1134 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.9163 - rmsle: 0.0717 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1093 - val_msle: 9.2800 - val_rmsle: 0.1005 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0784 - msle: 4.6823 - rmsle: 0.0696 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1202 - val_msle: 11.0882 - val_rmsle: 0.1128 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.4168 - rmsle: 0.0669 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0975 - val_msle: 7.8861 - val_rmsle: 0.0925 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.3491 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 7.6583 - val_rmsle: 0.0880 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.3014 - rmsle: 0.0658 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0865 - val_msle: 7.7093 - val_rmsle: 0.0822 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.2285 - rmsle: 0.0653 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 6.0481 - val_rmsle: 0.0719 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1811 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0833 - val_msle: 7.0373 - val_rmsle: 0.0797 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.1478 - rmsle: 0.0646 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 5.8805 - val_rmsle: 0.0769 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.1208 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 6.7033 - val_rmsle: 0.0760 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0077 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 5.4850 - val_rmsle: 0.0683 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9830 - rmsle: 0.0634 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 5.1991 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9721 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 5.7871 - val_rmsle: 0.0689 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9742 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.7749 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9610 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 5.2308 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9505 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 5.2219 - val_rmsle: 0.0672 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9465 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.9567 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8955 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8489 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8779 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8615 - val_rmsle: 0.0625 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8751 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9870 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8670 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7933 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8650 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9826 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8505 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8549 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8511 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8822 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8215 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7142 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8168 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7556 - val_rmsle: 0.0613 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8186 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7373 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8110 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7985 - val_rmsle: 0.0616 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7972 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6405 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06146562455754523\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.8184 - msle: 75.7408 - rmsle: 1.3392 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1265 - val_msle: 8.0978 - val_rmsle: 0.1025 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0976 - msle: 5.7776 - rmsle: 0.0781 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0885 - val_msle: 5.6770 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0862 - msle: 5.0820 - rmsle: 0.0736 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 4.3515 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0819 - msle: 4.8648 - rmsle: 0.0714 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.1006 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0781 - msle: 4.6629 - rmsle: 0.0693 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 4.4762 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0757 - msle: 4.5544 - rmsle: 0.0681 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.9237 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.4002 - rmsle: 0.0668 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.0904 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0723 - msle: 4.2895 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 3.9724 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.1918 - rmsle: 0.0653 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.6534 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1190 - rmsle: 0.0647 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1516 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.0757 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.6805 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0380 - rmsle: 0.0642 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0385 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0048 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2522 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9749 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9569 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9448 - rmsle: 0.0635 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2932 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9152 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8802 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8813 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0539 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8635 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9164 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8551 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8229 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8284 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8990 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8026 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7187 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7885 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7815 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7780 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6856 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7712 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8109 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7586 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7534 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7448 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6794 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7459 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7485 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7343 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6743 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7261 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6900 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7180 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6746 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7192 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6844 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06134803328679227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:13:03,732] Trial 6 finished with value: 0.06151727069641781 and parameters: {'units': 1024, 'num_cross_layers': 3, 'activation': 'relu', 'reg': 0.0011668738294210545, 'do_rate': 0.3459636420587856, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_2_loss: 0.0000e+00 - loss: 1.8439 - msle: 78.3726 - rmsle: 1.3382 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1570 - val_msle: 13.7747 - val_rmsle: 0.1251 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1092 - msle: 5.4451 - rmsle: 0.0849 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0988 - val_msle: 7.4178 - val_rmsle: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0911 - msle: 5.2549 - rmsle: 0.0777 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0984 - val_msle: 6.2324 - val_rmsle: 0.0870 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0836 - msle: 5.0026 - rmsle: 0.0733 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0962 - val_msle: 6.8362 - val_rmsle: 0.0864 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0804 - msle: 4.8021 - rmsle: 0.0713 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0879 - val_msle: 7.3570 - val_rmsle: 0.0795 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0774 - msle: 4.6388 - rmsle: 0.0696 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 7.6975 - val_rmsle: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0753 - msle: 4.4916 - rmsle: 0.0683 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 7.8394 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0735 - msle: 4.3545 - rmsle: 0.0673 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 5.7748 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.2684 - rmsle: 0.0667 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 5.4817 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.2014 - rmsle: 0.0662 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.7509 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.1258 - rmsle: 0.0655 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.6786 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.0725 - rmsle: 0.0651 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 5.4930 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.0610 - rmsle: 0.0648 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.9255 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.0531 - rmsle: 0.0646 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.2752 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.0444 - rmsle: 0.0644 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.1776 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.0369 - rmsle: 0.0643 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.2782 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0173 - rmsle: 0.0640 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1196 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0138 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.3595 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9871 - rmsle: 0.0637 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0857 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9661 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.2590 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9784 - rmsle: 0.0636 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.2411 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9313 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4059 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9235 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0930 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9294 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.0571 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8269 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1963 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8232 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9710 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8352 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0421 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8112 - rmsle: 0.0622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.2382 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8235 - rmsle: 0.0622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1095 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7737 - rmsle: 0.0618 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7919 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7605 - rmsle: 0.0617 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7768 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.062466043360256955\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_5_loss: 0.0000e+00 - loss: 1.8475 - msle: 78.2772 - rmsle: 1.3430 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1502 - val_msle: 8.9084 - val_rmsle: 0.1199 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1063 - msle: 5.3993 - rmsle: 0.0831 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0902 - val_msle: 4.6251 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0897 - msle: 5.1752 - rmsle: 0.0764 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.3761 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0828 - msle: 5.0007 - rmsle: 0.0727 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0936 - val_msle: 5.9893 - val_rmsle: 0.0848 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0791 - msle: 4.8045 - rmsle: 0.0707 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0834 - val_msle: 5.2100 - val_rmsle: 0.0754 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0769 - msle: 4.6468 - rmsle: 0.0693 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.9388 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.5221 - rmsle: 0.0680 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 4.6675 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0731 - msle: 4.3855 - rmsle: 0.0672 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.5635 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.2650 - rmsle: 0.0665 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 4.8305 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.1781 - rmsle: 0.0659 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 6.0823 - val_rmsle: 0.0821 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.1420 - rmsle: 0.0656 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.2238 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.0741 - rmsle: 0.0650 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.2335 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.0248 - rmsle: 0.0646 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.7392 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.0263 - rmsle: 0.0644 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.7262 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.0388 - rmsle: 0.0642 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2096 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.0257 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.7280 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0226 - rmsle: 0.0638 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.1011 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0136 - rmsle: 0.0636 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1601 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9497 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.6496 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9062 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.8637 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9092 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.4609 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9025 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 5.0425 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8909 - rmsle: 0.0625 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.6351 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8768 - rmsle: 0.0625 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.5222 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8710 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.4552 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8741 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.4327 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8654 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2821 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8300 - rmsle: 0.0619 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7885 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8016 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.9016 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8013 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 4.0020 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7984 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.9034 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06142692346474181\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 14ms/step - dense_8_loss: 0.0000e+00 - loss: 1.8343 - msle: 78.0385 - rmsle: 1.3377 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1839 - val_msle: 10.5697 - val_rmsle: 0.1542 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1063 - msle: 5.3547 - rmsle: 0.0828 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1616 - val_msle: 7.0173 - val_rmsle: 0.1471 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0892 - msle: 5.1126 - rmsle: 0.0758 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1089 - val_msle: 6.4212 - val_rmsle: 0.0978 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0821 - msle: 4.9100 - rmsle: 0.0719 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1087 - val_msle: 8.6334 - val_rmsle: 0.0997 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0779 - msle: 4.7089 - rmsle: 0.0696 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0907 - val_msle: 7.9426 - val_rmsle: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0762 - msle: 4.5693 - rmsle: 0.0683 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0967 - val_msle: 8.9565 - val_rmsle: 0.0894 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.4476 - rmsle: 0.0672 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0895 - val_msle: 5.2994 - val_rmsle: 0.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.3265 - rmsle: 0.0661 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 7.2288 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2580 - rmsle: 0.0655 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 5.6992 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.1703 - rmsle: 0.0651 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 5.8477 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.0903 - rmsle: 0.0643 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.5487 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.0773 - rmsle: 0.0641 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.4470 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0460 - rmsle: 0.0638 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 5.0230 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0248 - rmsle: 0.0634 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3722 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0221 - rmsle: 0.0633 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 5.3232 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0103 - rmsle: 0.0631 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.4398 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9959 - rmsle: 0.0629 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.5723 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9181 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7199 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9072 - rmsle: 0.0621 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0151 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9021 - rmsle: 0.0621 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.8465 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8811 - rmsle: 0.0619 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7596 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8718 - rmsle: 0.0618 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8797 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8749 - rmsle: 0.0618 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9212 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8660 - rmsle: 0.0618 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7234 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8139 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7200 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8010 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7586 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7993 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 4.0046 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7949 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6104 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7927 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7934 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7906 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8258 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7866 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8228 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06204716300969969\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_11_loss: 0.0000e+00 - loss: 1.8485 - msle: 78.3896 - rmsle: 1.3456 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1512 - val_msle: 8.0804 - val_rmsle: 0.1217 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1078 - msle: 5.5539 - rmsle: 0.0847 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1103 - val_msle: 5.9074 - val_rmsle: 0.0955 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0924 - msle: 5.3583 - rmsle: 0.0784 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1170 - val_msle: 11.9456 - val_rmsle: 0.1055 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0869 - msle: 5.1384 - rmsle: 0.0744 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0984 - val_msle: 10.5368 - val_rmsle: 0.0890 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0802 - msle: 4.9068 - rmsle: 0.0713 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1337 - val_msle: 19.2151 - val_rmsle: 0.1252 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0777 - msle: 4.7153 - rmsle: 0.0696 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1026 - val_msle: 6.9964 - val_rmsle: 0.0946 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.5532 - rmsle: 0.0683 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1009 - val_msle: 7.7876 - val_rmsle: 0.0931 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0725 - msle: 4.3112 - rmsle: 0.0663 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 6.4453 - val_rmsle: 0.0827 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.2666 - rmsle: 0.0658 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0865 - val_msle: 7.3995 - val_rmsle: 0.0822 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.2054 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0879 - val_msle: 7.5736 - val_rmsle: 0.0840 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1682 - rmsle: 0.0650 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0951 - val_msle: 7.8805 - val_rmsle: 0.0912 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1366 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0915 - val_msle: 8.2276 - val_rmsle: 0.0878 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0038 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.7350 - val_rmsle: 0.0691 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9811 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 5.0801 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9734 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 5.3822 - val_rmsle: 0.0678 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9528 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 5.0637 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9373 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 5.0519 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9269 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 5.1339 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9223 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.6851 - val_rmsle: 0.0657 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9057 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.4908 - val_rmsle: 0.0674 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8972 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.9222 - val_rmsle: 0.0672 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8461 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7875 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8324 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9010 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8248 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9989 - val_rmsle: 0.0639 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8153 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8031 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8149 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7358 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8094 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8237 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8091 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9350 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7715 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6826 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7646 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7127 - val_rmsle: 0.0613 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7596 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7280 - val_rmsle: 0.0617 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06183374091406456\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 14ms/step - dense_14_loss: 0.0000e+00 - loss: 1.8308 - msle: 78.1158 - rmsle: 1.3314 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1515 - val_msle: 10.7984 - val_rmsle: 0.1205 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1073 - msle: 5.3922 - rmsle: 0.0835 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0973 - val_msle: 9.3729 - val_rmsle: 0.0818 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0899 - msle: 5.1887 - rmsle: 0.0764 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 5.4601 - val_rmsle: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0834 - msle: 4.9497 - rmsle: 0.0725 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1065 - val_msle: 12.7340 - val_rmsle: 0.0972 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0796 - msle: 4.8150 - rmsle: 0.0709 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1013 - val_msle: 9.5107 - val_rmsle: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0772 - msle: 4.6100 - rmsle: 0.0691 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0855 - val_msle: 6.1950 - val_rmsle: 0.0772 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0754 - msle: 4.4877 - rmsle: 0.0679 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0881 - val_msle: 6.0368 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3583 - rmsle: 0.0670 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.8547 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.2578 - rmsle: 0.0664 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 3.9584 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.1544 - rmsle: 0.0655 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.0921 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.1195 - rmsle: 0.0650 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1006 - val_msle: 6.4857 - val_rmsle: 0.0953 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.0814 - rmsle: 0.0649 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 4.0305 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.0447 - rmsle: 0.0644 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.1239 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.0500 - rmsle: 0.0642 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0933 - val_msle: 7.9412 - val_rmsle: 0.0888 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.0386 - rmsle: 0.0644 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0942 - val_msle: 8.7906 - val_rmsle: 0.0899 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.0612 - rmsle: 0.0643 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 5.0613 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9314 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.3799 - val_rmsle: 0.0739 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9205 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0906 - val_msle: 4.4464 - val_rmsle: 0.0881 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9101 - rmsle: 0.0629 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0899 - val_msle: 5.3102 - val_rmsle: 0.0874 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8517 - rmsle: 0.0623 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7294 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8314 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.7805 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8384 - rmsle: 0.0622 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7403 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8145 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7125 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8153 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6643 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7994 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7416 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7955 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7198 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7973 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6524 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8084 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6982 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8007 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6866 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7909 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6609 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7588 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6298 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06092809188019459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:21:39,360] Trial 7 finished with value: 0.06174039252579152 and parameters: {'units': 1024, 'num_cross_layers': 2, 'activation': 'relu', 'reg': 0.0004710126068985212, 'do_rate': 0.2840309622313059, 'hidden_layers': 3}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 16ms/step - dense_1_loss: 0.0000e+00 - loss: 2.7667 - msle: 97.4774 - rmsle: 2.4832 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3555 - val_msle: 26.0243 - val_rmsle: 0.3098 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1959 - msle: 15.8100 - rmsle: 0.1609 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1627 - val_msle: 7.3946 - val_rmsle: 0.1439 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1111 - msle: 6.5006 - rmsle: 0.0943 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1484 - val_msle: 6.7464 - val_rmsle: 0.1358 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0944 - msle: 5.5981 - rmsle: 0.0827 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1177 - val_msle: 5.9358 - val_rmsle: 0.1082 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0874 - msle: 5.4048 - rmsle: 0.0783 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1087 - val_msle: 5.8202 - val_rmsle: 0.1007 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0813 - msle: 5.1798 - rmsle: 0.0738 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1056 - val_msle: 6.1099 - val_rmsle: 0.0991 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0768 - msle: 4.9294 - rmsle: 0.0709 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0957 - val_msle: 6.5630 - val_rmsle: 0.0907 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.7494 - rmsle: 0.0692 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0907 - val_msle: 6.0448 - val_rmsle: 0.0863 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0722 - msle: 4.5972 - rmsle: 0.0680 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0949 - val_msle: 6.0229 - val_rmsle: 0.0909 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.5328 - rmsle: 0.0679 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1073 - val_msle: 6.9536 - val_rmsle: 0.1038 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.4692 - rmsle: 0.0674 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0947 - val_msle: 6.3758 - val_rmsle: 0.0916 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.3350 - rmsle: 0.0663 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.2376 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.2921 - rmsle: 0.0660 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.2655 - val_rmsle: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.2599 - rmsle: 0.0657 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.4443 - val_rmsle: 0.0717 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.2464 - rmsle: 0.0658 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1032 - val_msle: 8.3622 - val_rmsle: 0.1010 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.1898 - rmsle: 0.0651 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9777 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.1556 - rmsle: 0.0647 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.4216 - val_rmsle: 0.0686 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.1116 - rmsle: 0.0647 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2316 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.1164 - rmsle: 0.0645 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.3490 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0889 - rmsle: 0.0642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7773 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0671 - rmsle: 0.0639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9641 - val_rmsle: 0.0650 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0515 - rmsle: 0.0639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8588 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0400 - rmsle: 0.0638 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.1041 - val_rmsle: 0.0670 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0367 - rmsle: 0.0635 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7346 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.0145 - rmsle: 0.0634 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7761 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9993 - rmsle: 0.0633 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7460 - val_rmsle: 0.0613 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0011 - rmsle: 0.0633 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7845 - val_rmsle: 0.0625 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9970 - rmsle: 0.0632 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7428 - val_rmsle: 0.0609 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9812 - rmsle: 0.0630 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7378 - val_rmsle: 0.0607 - learning_rate: 1.5625e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9781 - rmsle: 0.0630 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7328 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9846 - rmsle: 0.0630 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7303 - val_rmsle: 0.0607 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061649454503258934\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.7612 - msle: 97.3593 - rmsle: 2.4775 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3573 - val_msle: 26.2415 - val_rmsle: 0.3104 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1988 - msle: 16.1159 - rmsle: 0.1627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1503 - val_msle: 7.2187 - val_rmsle: 0.1310 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1131 - msle: 6.5919 - rmsle: 0.0960 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1186 - val_msle: 5.1837 - val_rmsle: 0.1058 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0951 - msle: 5.6406 - rmsle: 0.0832 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1065 - val_msle: 5.0360 - val_rmsle: 0.0969 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0869 - msle: 5.3966 - rmsle: 0.0779 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1021 - val_msle: 6.6785 - val_rmsle: 0.0943 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0817 - msle: 5.2158 - rmsle: 0.0744 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 4.7797 - val_rmsle: 0.0820 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0771 - msle: 4.9554 - rmsle: 0.0711 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0885 - val_msle: 5.2907 - val_rmsle: 0.0834 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0742 - msle: 4.7920 - rmsle: 0.0694 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.0923 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0723 - msle: 4.6392 - rmsle: 0.0681 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0919 - val_msle: 6.8053 - val_rmsle: 0.0880 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.5421 - rmsle: 0.0675 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 5.5848 - val_rmsle: 0.0793 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.4894 - rmsle: 0.0673 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0964 - val_msle: 8.5876 - val_rmsle: 0.0932 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.3954 - rmsle: 0.0664 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.7647 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.3215 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.5438 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2903 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 5.8885 - val_rmsle: 0.0708 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.2574 - rmsle: 0.0657 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.3554 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.2252 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.5955 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.2165 - rmsle: 0.0654 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.9640 - val_rmsle: 0.0688 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.1952 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.4480 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.1362 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.5173 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0932 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.2767 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.1050 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.6511 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0994 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.2571 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0822 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.0654 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.0785 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.1154 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0654 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.2965 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0635 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.3139 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0597 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.5632 - val_rmsle: 0.0703 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0273 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.9609 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9964 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9634 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0021 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9132 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9934 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.8590 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.061585555478345266\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_5_loss: 0.0000e+00 - loss: 2.7605 - msle: 97.2082 - rmsle: 2.4775 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.3614 - val_msle: 25.7586 - val_rmsle: 0.3158 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1949 - msle: 15.5691 - rmsle: 0.1597 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1364 - val_msle: 8.4531 - val_rmsle: 0.1173 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1100 - msle: 6.5443 - rmsle: 0.0930 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0925 - val_msle: 5.7206 - val_rmsle: 0.0800 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0933 - msle: 5.5832 - rmsle: 0.0818 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0912 - val_msle: 4.7019 - val_rmsle: 0.0819 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0852 - msle: 5.3321 - rmsle: 0.0765 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 4.2863 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0800 - msle: 5.1358 - rmsle: 0.0730 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.8215 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.9129 - rmsle: 0.0701 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.2906 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.7563 - rmsle: 0.0682 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 5.2076 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.6219 - rmsle: 0.0676 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.4149 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.5205 - rmsle: 0.0671 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.9625 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.4636 - rmsle: 0.0667 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.5247 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.4197 - rmsle: 0.0664 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.4818 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.3451 - rmsle: 0.0662 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.6793 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2479 - rmsle: 0.0652 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7779 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.2092 - rmsle: 0.0649 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9186 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.1934 - rmsle: 0.0649 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.3568 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.1525 - rmsle: 0.0645 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0479 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.1054 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6970 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0899 - rmsle: 0.0638 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7666 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0812 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7055 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0823 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8865 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.0433 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7192 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0202 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6791 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0331 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7093 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.0118 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6891 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0151 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9245 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9940 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6019 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9979 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6262 - val_rmsle: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9829 - rmsle: 0.0625 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6146 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.9833 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6933 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.9802 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5915 - val_rmsle: 0.0603 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0764760971069336\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06105027011535487\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 2.7648 - msle: 97.4512 - rmsle: 2.4818 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.3501 - val_msle: 25.5688 - val_rmsle: 0.3038 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1961 - msle: 15.8667 - rmsle: 0.1607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1584 - val_msle: 7.3559 - val_rmsle: 0.1389 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1115 - msle: 6.5563 - rmsle: 0.0942 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1472 - val_msle: 6.9863 - val_rmsle: 0.1344 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0941 - msle: 5.5655 - rmsle: 0.0823 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1307 - val_msle: 7.7235 - val_rmsle: 0.1211 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0865 - msle: 5.3809 - rmsle: 0.0774 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1483 - val_msle: 8.0817 - val_rmsle: 0.1406 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0818 - msle: 5.2161 - rmsle: 0.0743 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 5.5818 - val_rmsle: 0.0850 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0771 - msle: 4.9566 - rmsle: 0.0711 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0892 - val_msle: 5.5705 - val_rmsle: 0.0840 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0744 - msle: 4.7833 - rmsle: 0.0694 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0977 - val_msle: 7.9840 - val_rmsle: 0.0933 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0727 - msle: 4.6515 - rmsle: 0.0685 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 5.9063 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.5650 - rmsle: 0.0681 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0920 - val_msle: 7.4845 - val_rmsle: 0.0885 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.5053 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0930 - val_msle: 5.8980 - val_rmsle: 0.0898 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.4527 - rmsle: 0.0675 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1154 - val_msle: 8.5616 - val_rmsle: 0.1124 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.3434 - rmsle: 0.0664 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 5.2724 - val_rmsle: 0.0766 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.2858 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.6022 - val_rmsle: 0.0736 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2707 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.5262 - val_rmsle: 0.0741 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2196 - rmsle: 0.0656 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.5807 - val_rmsle: 0.0686 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2147 - rmsle: 0.0657 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.5164 - val_rmsle: 0.0724 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.1833 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.6885 - val_rmsle: 0.0739 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1636 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.6290 - val_rmsle: 0.0730 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.1106 - rmsle: 0.0647 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1548 - val_rmsle: 0.0667 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.0798 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1219 - val_rmsle: 0.0663 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0668 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1111 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0770 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.2542 - val_rmsle: 0.0692 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0594 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.6327 - val_rmsle: 0.0726 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0487 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.2639 - val_rmsle: 0.0691 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0206 - rmsle: 0.0639 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8447 - val_rmsle: 0.0640 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0082 - rmsle: 0.0635 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6889 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0054 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7872 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0117 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7993 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9891 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7448 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9789 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6607 - val_rmsle: 0.0616 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.0625209794505502\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_9_loss: 0.0000e+00 - loss: 2.7623 - msle: 97.4477 - rmsle: 2.4787 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.3635 - val_msle: 25.6579 - val_rmsle: 0.3165 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.1978 - msle: 15.8356 - rmsle: 0.1614 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1589 - val_msle: 7.8982 - val_rmsle: 0.1395 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.1112 - msle: 6.5966 - rmsle: 0.0940 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1147 - val_msle: 5.4642 - val_rmsle: 0.1020 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0943 - msle: 5.6056 - rmsle: 0.0826 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1036 - val_msle: 4.9423 - val_rmsle: 0.0941 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0866 - msle: 5.3459 - rmsle: 0.0777 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 4.9823 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0818 - msle: 5.1981 - rmsle: 0.0745 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 4.4713 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0771 - msle: 4.9406 - rmsle: 0.0711 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.2411 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.7163 - rmsle: 0.0689 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.1982 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.6230 - rmsle: 0.0681 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.0410 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.5093 - rmsle: 0.0675 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 5.5284 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.4457 - rmsle: 0.0674 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.0107 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.4083 - rmsle: 0.0670 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 5.4280 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.3047 - rmsle: 0.0661 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9639 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.2475 - rmsle: 0.0657 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.4591 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2494 - rmsle: 0.0659 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7472 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.2096 - rmsle: 0.0654 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9985 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1827 - rmsle: 0.0653 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9266 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.1568 - rmsle: 0.0650 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7750 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.0808 - rmsle: 0.0644 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8282 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0770 - rmsle: 0.0643 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8850 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0688 - rmsle: 0.0642 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8248 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0674 - rmsle: 0.0642 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 4.0058 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0474 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7627 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0564 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6958 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0381 - rmsle: 0.0639 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7110 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0202 - rmsle: 0.0638 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9316 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0269 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6912 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9872 - rmsle: 0.0634 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8243 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9655 - rmsle: 0.0632 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6680 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9619 - rmsle: 0.0632 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7341 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9759 - rmsle: 0.0630 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7779 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0491533279418945\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06097818575766216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:28:53,413] Trial 8 finished with value: 0.06155688906103428 and parameters: {'units': 128, 'num_cross_layers': 1, 'activation': 'relu', 'reg': 0.001482252841266971, 'do_rate': 0.3274955070002784, 'hidden_layers': 3}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 1.9791 - msle: 81.7544 - rmsle: 1.8663 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1080 - val_msle: 6.7002 - val_rmsle: 0.0894 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0905 - msle: 5.6757 - rmsle: 0.0767 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 5.1313 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.8081 - rmsle: 0.0691 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 5.2307 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.4963 - rmsle: 0.0671 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 5.1255 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.3085 - rmsle: 0.0661 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 5.3385 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.1841 - rmsle: 0.0654 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.9681 - val_rmsle: 0.0754 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.1008 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.8307 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0317 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.8528 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9871 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.7397 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9505 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.7262 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9224 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.6691 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8968 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.3076 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8796 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.4448 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8659 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.2135 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8530 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.2929 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8441 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.3354 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8325 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.2054 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8221 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.1564 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8139 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0724 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8018 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.3023 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7874 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.1876 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7854 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0634 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7766 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2930 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7843 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.1393 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7707 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.3813 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7538 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.1420 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7583 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.1587 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7365 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9112 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7226 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9470 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7189 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8816 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7152 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8953 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06279372359819252\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 8ms/step - dense_7_loss: 0.0000e+00 - loss: 1.9783 - msle: 81.7305 - rmsle: 1.8655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1071 - val_msle: 6.4953 - val_rmsle: 0.0885 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0905 - msle: 5.6689 - rmsle: 0.0768 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0983 - val_msle: 5.8767 - val_rmsle: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.8231 - rmsle: 0.0692 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1014 - val_msle: 6.3734 - val_rmsle: 0.0987 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.5178 - rmsle: 0.0670 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0981 - val_msle: 6.2638 - val_rmsle: 0.0962 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.3298 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1001 - val_msle: 6.5380 - val_rmsle: 0.0987 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.2101 - rmsle: 0.0652 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0882 - val_msle: 5.8814 - val_rmsle: 0.0869 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.1151 - rmsle: 0.0647 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0911 - val_msle: 6.0786 - val_rmsle: 0.0900 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0533 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 5.7088 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.0139 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0881 - val_msle: 5.8747 - val_rmsle: 0.0871 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9784 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 6.2097 - val_rmsle: 0.0874 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9541 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 5.8323 - val_rmsle: 0.0845 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9188 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.7094 - val_rmsle: 0.0706 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8955 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.5815 - val_rmsle: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8852 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.8467 - val_rmsle: 0.0729 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8728 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.7299 - val_rmsle: 0.0716 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8673 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.5201 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8552 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.8111 - val_rmsle: 0.0719 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8477 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.8050 - val_rmsle: 0.0712 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8419 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.6084 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8302 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.6923 - val_rmsle: 0.0717 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8281 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.7900 - val_rmsle: 0.0707 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8204 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.7188 - val_rmsle: 0.0710 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8023 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1360 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7914 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.1931 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7897 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.1747 - val_rmsle: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7849 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0935 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7841 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0910 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7807 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1431 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7757 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.1111 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7683 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.9002 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7604 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.9063 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06227439703209321\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_11_loss: 0.0000e+00 - loss: 1.9766 - msle: 81.6450 - rmsle: 1.8638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1097 - val_msle: 6.6952 - val_rmsle: 0.0912 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0901 - msle: 5.6905 - rmsle: 0.0764 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.9543 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.8260 - rmsle: 0.0686 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.5102 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.5132 - rmsle: 0.0667 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3393 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.3200 - rmsle: 0.0655 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1356 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.1943 - rmsle: 0.0649 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0459 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.1077 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9826 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0464 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9244 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9958 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9222 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9639 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8642 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9362 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8311 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9122 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8267 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8985 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7922 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8787 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8264 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8647 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7603 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8490 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7540 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8379 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7312 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8286 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7589 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8235 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7179 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7931 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7171 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7786 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6975 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7766 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6953 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7706 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6911 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7552 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6615 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7455 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6596 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7438 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6641 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7442 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6574 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7422 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6681 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7399 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6545 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7383 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6655 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7278 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6429 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.022842526435852\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061352838767185\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 8ms/step - dense_15_loss: 0.0000e+00 - loss: 1.9771 - msle: 81.7502 - rmsle: 1.8642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1062 - val_msle: 6.5939 - val_rmsle: 0.0875 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0913 - msle: 5.7845 - rmsle: 0.0775 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1032 - val_msle: 6.2544 - val_rmsle: 0.0973 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0744 - msle: 4.8957 - rmsle: 0.0697 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1071 - val_msle: 6.5738 - val_rmsle: 0.1042 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.5592 - rmsle: 0.0675 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1083 - val_msle: 6.7643 - val_rmsle: 0.1063 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.3617 - rmsle: 0.0663 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0977 - val_msle: 6.2295 - val_rmsle: 0.0961 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.2319 - rmsle: 0.0658 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1046 - val_msle: 6.7777 - val_rmsle: 0.1033 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.1329 - rmsle: 0.0652 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1006 - val_msle: 6.3738 - val_rmsle: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0632 - rmsle: 0.0647 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0944 - val_msle: 6.0674 - val_rmsle: 0.0933 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0130 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1041 - val_msle: 6.8105 - val_rmsle: 0.1031 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9745 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0972 - val_msle: 6.1450 - val_rmsle: 0.0963 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9428 - rmsle: 0.0640 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 5.8115 - val_rmsle: 0.0880 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9226 - rmsle: 0.0638 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 5.8234 - val_rmsle: 0.0880 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8997 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 5.8880 - val_rmsle: 0.0854 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8817 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0848 - val_msle: 5.6716 - val_rmsle: 0.0840 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8672 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 5.2693 - val_rmsle: 0.0800 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8583 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 5.6726 - val_rmsle: 0.0892 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8493 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 5.4170 - val_rmsle: 0.0818 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8407 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 5.3728 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8301 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.0676 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8241 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.1621 - val_rmsle: 0.0836 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8150 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.8394 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8095 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 5.0561 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7866 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0024 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7733 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1482 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7672 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1260 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7650 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1881 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7561 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7805 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7437 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7894 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7420 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8093 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7430 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7518 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7374 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8329 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06268572955340208\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_19_loss: 0.0000e+00 - loss: 1.9822 - msle: 81.9073 - rmsle: 1.8693 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1061 - val_msle: 6.4883 - val_rmsle: 0.0875 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0907 - msle: 5.6371 - rmsle: 0.0769 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0852 - val_msle: 5.2625 - val_rmsle: 0.0794 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.7894 - rmsle: 0.0691 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 5.4664 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.4877 - rmsle: 0.0670 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 5.4795 - val_rmsle: 0.0824 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.3024 - rmsle: 0.0659 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 5.3475 - val_rmsle: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.1728 - rmsle: 0.0651 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 5.4475 - val_rmsle: 0.0830 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0806 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 5.2982 - val_rmsle: 0.0805 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0173 - rmsle: 0.0642 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 5.2704 - val_rmsle: 0.0795 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9728 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 5.1587 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9314 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 5.0764 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9074 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 5.1436 - val_rmsle: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8832 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.9957 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8650 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.8349 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8491 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.5926 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8376 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.5220 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8207 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.4637 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8126 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.4710 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8062 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.4230 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7938 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.1594 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7855 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2786 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7771 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.5932 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7695 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1737 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7701 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.2606 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7553 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1019 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7513 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.1401 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7372 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8078 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7159 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7064 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7110 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7263 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7094 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7365 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7136 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7464 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6995 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6812 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06100537160317142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:35:27,481] Trial 9 finished with value: 0.06202241211080885 and parameters: {'units': 256, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.006396443765039699, 'do_rate': 0.2941213265429994, 'hidden_layers': 1}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 2.0325 - msle: 90.2882 - rmsle: 1.9781 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1674 - val_msle: 7.6947 - val_rmsle: 0.1322 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1209 - msle: 5.5207 - rmsle: 0.0906 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0861 - val_msle: 4.6147 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0942 - msle: 4.8505 - rmsle: 0.0778 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.3786 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0827 - msle: 4.5736 - rmsle: 0.0730 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.3017 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0769 - msle: 4.3927 - rmsle: 0.0703 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.5347 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.2920 - rmsle: 0.0685 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.4056 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.1871 - rmsle: 0.0671 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.3057 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.1329 - rmsle: 0.0663 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.3846 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.0930 - rmsle: 0.0656 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2754 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0387 - rmsle: 0.0648 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.1683 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0209 - rmsle: 0.0647 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1490 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9839 - rmsle: 0.0642 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1143 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9571 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0115 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9554 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2321 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9207 - rmsle: 0.0638 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1756 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9114 - rmsle: 0.0634 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0112 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9009 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9842 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8849 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0365 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8683 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.1940 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8623 - rmsle: 0.0630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9797 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8437 - rmsle: 0.0628 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2536 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8468 - rmsle: 0.0629 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0397 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8327 - rmsle: 0.0628 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1493 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7959 - rmsle: 0.0622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9459 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7880 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8872 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7860 - rmsle: 0.0621 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9599 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7714 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.9584 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7730 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8871 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7592 - rmsle: 0.0617 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7718 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7482 - rmsle: 0.0616 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8111 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7417 - rmsle: 0.0615 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7765 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061765456658125995\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_5_loss: 0.0000e+00 - loss: 2.0370 - msle: 90.8017 - rmsle: 1.9827 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1530 - val_msle: 6.6975 - val_rmsle: 0.1178 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1217 - msle: 5.6540 - rmsle: 0.0914 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 4.6880 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0945 - msle: 4.9217 - rmsle: 0.0779 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.4058 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0826 - msle: 4.6151 - rmsle: 0.0729 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.2810 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0768 - msle: 4.4323 - rmsle: 0.0703 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1659 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0731 - msle: 4.3219 - rmsle: 0.0682 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1221 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.2132 - rmsle: 0.0669 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0394 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1481 - rmsle: 0.0659 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.1002 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1059 - rmsle: 0.0652 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0581 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0691 - rmsle: 0.0646 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1434 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0400 - rmsle: 0.0643 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2273 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0145 - rmsle: 0.0639 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1591 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9647 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9507 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9367 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9348 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9247 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0139 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9119 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1247 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9025 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9417 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9114 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8889 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8602 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8992 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8556 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8823 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8476 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8772 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8457 - rmsle: 0.0621 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8522 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8323 - rmsle: 0.0621 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8657 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8294 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8620 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8233 - rmsle: 0.0618 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8202 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8163 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8190 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8132 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8096 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8109 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8349 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8057 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8046 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8083 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7989 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7984 - rmsle: 0.0615 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7743 - val_rmsle: 0.0601 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06077876662882339\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_8_loss: 0.0000e+00 - loss: 2.0309 - msle: 90.2441 - rmsle: 1.9765 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1442 - val_msle: 7.2491 - val_rmsle: 0.1087 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1204 - msle: 5.5762 - rmsle: 0.0897 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0912 - val_msle: 4.7539 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0932 - msle: 4.9315 - rmsle: 0.0766 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0834 - val_msle: 4.4257 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0818 - msle: 4.6196 - rmsle: 0.0721 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.0138 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.4160 - rmsle: 0.0695 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.0734 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.2818 - rmsle: 0.0675 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9162 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.1834 - rmsle: 0.0662 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8591 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1256 - rmsle: 0.0654 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8517 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0771 - rmsle: 0.0647 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8432 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0440 - rmsle: 0.0641 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9483 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0022 - rmsle: 0.0637 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9405 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9460 - rmsle: 0.0628 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7740 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9433 - rmsle: 0.0627 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7619 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9312 - rmsle: 0.0627 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7653 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9181 - rmsle: 0.0626 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7539 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8942 - rmsle: 0.0624 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7352 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8806 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7338 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8794 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7889 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8721 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7034 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8620 - rmsle: 0.0621 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7457 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8553 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6860 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8494 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7026 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8277 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6494 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8151 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6280 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8104 - rmsle: 0.0614 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6449 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8107 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6282 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8012 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6493 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8022 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6229 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7847 - rmsle: 0.0609 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6183 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7830 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6037 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7873 - rmsle: 0.0609 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6159 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06095287371696889\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.0386 - msle: 90.4244 - rmsle: 1.9843 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1475 - val_msle: 6.3505 - val_rmsle: 0.1127 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1217 - msle: 5.5513 - rmsle: 0.0916 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 4.5470 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0945 - msle: 4.8841 - rmsle: 0.0779 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.5178 - val_rmsle: 0.0732 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0827 - msle: 4.6127 - rmsle: 0.0729 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.3269 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0772 - msle: 4.4308 - rmsle: 0.0705 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.1859 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.3213 - rmsle: 0.0686 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.1979 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.2189 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.0302 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.1457 - rmsle: 0.0661 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.0690 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.0936 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 3.9844 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0688 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.0820 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0258 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.0345 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0018 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.1166 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9844 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9843 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9612 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8429 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9408 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.5385 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9328 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.0854 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9197 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8698 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8733 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8255 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8565 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8008 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8548 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8336 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8478 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8339 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8422 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7698 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8381 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7472 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8412 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7784 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8285 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8519 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8188 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7378 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8225 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7434 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7950 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6913 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7887 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6963 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7849 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6750 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7805 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6654 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.062181344442069963\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_14_loss: 0.0000e+00 - loss: 2.0479 - msle: 90.7121 - rmsle: 1.9935 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1496 - val_msle: 7.1473 - val_rmsle: 0.1146 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1210 - msle: 5.5407 - rmsle: 0.0908 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 4.7136 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0938 - msle: 4.8706 - rmsle: 0.0775 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.2398 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0825 - msle: 4.6026 - rmsle: 0.0730 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.1550 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0765 - msle: 4.4123 - rmsle: 0.0701 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9920 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.2895 - rmsle: 0.0685 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.0854 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.1858 - rmsle: 0.0668 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9464 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1165 - rmsle: 0.0659 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0787 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0656 - rmsle: 0.0651 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9239 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0307 - rmsle: 0.0646 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9023 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0063 - rmsle: 0.0642 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9169 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9848 - rmsle: 0.0640 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8470 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9417 - rmsle: 0.0638 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8190 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9332 - rmsle: 0.0634 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8445 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9061 - rmsle: 0.0633 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8529 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8484 - rmsle: 0.0627 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7461 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8464 - rmsle: 0.0626 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7512 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8441 - rmsle: 0.0626 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7292 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8297 - rmsle: 0.0625 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7511 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8196 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7511 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8149 - rmsle: 0.0623 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7207 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7914 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6960 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7848 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6774 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7810 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6807 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7690 - rmsle: 0.0617 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6762 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7771 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6742 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7536 - rmsle: 0.0615 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6518 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7475 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6456 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7380 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6418 - val_rmsle: 0.0595 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7561 - rmsle: 0.0615 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6363 - val_rmsle: 0.0595 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7464 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6391 - val_rmsle: 0.0595 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06026140884225566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:42:22,784] Trial 10 finished with value: 0.061187970057648776 and parameters: {'units': 512, 'num_cross_layers': 2, 'activation': 'silu', 'reg': 0.00011293871230093617, 'do_rate': 0.3952360034707797, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 2.0364 - msle: 90.2381 - rmsle: 1.9740 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1525 - val_msle: 6.8581 - val_rmsle: 0.1145 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1227 - msle: 5.5061 - rmsle: 0.0904 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0855 - val_msle: 4.6452 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0945 - msle: 4.8708 - rmsle: 0.0780 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.5008 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0826 - msle: 4.5928 - rmsle: 0.0731 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.4042 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0769 - msle: 4.4163 - rmsle: 0.0704 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.5017 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.2972 - rmsle: 0.0686 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.4973 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.1961 - rmsle: 0.0672 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.5948 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.1366 - rmsle: 0.0664 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.4274 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.0981 - rmsle: 0.0657 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.3668 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0353 - rmsle: 0.0648 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.1396 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0223 - rmsle: 0.0646 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.3422 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9892 - rmsle: 0.0643 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0604 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9645 - rmsle: 0.0640 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1024 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9894 - rmsle: 0.0641 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2171 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9298 - rmsle: 0.0637 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0981 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9155 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.2424 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8931 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0643 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8862 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.1834 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8434 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9995 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8328 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8932 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8145 - rmsle: 0.0624 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0301 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8217 - rmsle: 0.0624 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.9158 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8071 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9474 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8004 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.9653 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8160 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8938 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7878 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8108 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7655 - rmsle: 0.0618 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8016 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7682 - rmsle: 0.0617 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8066 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7662 - rmsle: 0.0617 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7840 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7630 - rmsle: 0.0618 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8303 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7570 - rmsle: 0.0617 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7981 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061888208989053256\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_5_loss: 0.0000e+00 - loss: 2.0432 - msle: 90.6208 - rmsle: 1.9809 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1482 - val_msle: 6.8966 - val_rmsle: 0.1109 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1239 - msle: 5.6488 - rmsle: 0.0921 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 4.6455 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0943 - msle: 4.8804 - rmsle: 0.0778 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.4450 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0829 - msle: 4.6124 - rmsle: 0.0733 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.4223 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0769 - msle: 4.4261 - rmsle: 0.0703 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.1562 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.3153 - rmsle: 0.0683 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0747 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.2028 - rmsle: 0.0670 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.0627 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1344 - rmsle: 0.0658 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.1014 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.1035 - rmsle: 0.0652 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.0416 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0739 - rmsle: 0.0647 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1608 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0418 - rmsle: 0.0643 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3314 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0084 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.1399 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9784 - rmsle: 0.0635 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9678 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9276 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9613 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9183 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0342 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9114 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0883 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9007 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9293 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9037 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9540 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8797 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.1556 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8780 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0171 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8713 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0926 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8505 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8617 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8260 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8570 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8185 - rmsle: 0.0619 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8677 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8210 - rmsle: 0.0619 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8826 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8113 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8292 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8056 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7984 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7968 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8314 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7943 - rmsle: 0.0615 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8012 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7931 - rmsle: 0.0615 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7948 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7902 - rmsle: 0.0615 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8078 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06092930830486023\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_8_loss: 0.0000e+00 - loss: 2.0385 - msle: 90.2105 - rmsle: 1.9760 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1385 - val_msle: 6.8722 - val_rmsle: 0.1006 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1206 - msle: 5.5057 - rmsle: 0.0885 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0946 - val_msle: 4.7751 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0928 - msle: 4.8726 - rmsle: 0.0764 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 4.3573 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.5691 - rmsle: 0.0719 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.0519 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.3914 - rmsle: 0.0694 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.0311 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0723 - msle: 4.2631 - rmsle: 0.0674 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.0405 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.1820 - rmsle: 0.0662 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.9190 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1172 - rmsle: 0.0653 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8460 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0857 - rmsle: 0.0646 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9189 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0454 - rmsle: 0.0641 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8956 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0036 - rmsle: 0.0637 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0334 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9569 - rmsle: 0.0628 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7565 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9444 - rmsle: 0.0627 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7521 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9310 - rmsle: 0.0628 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7444 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9065 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7405 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8964 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7660 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8809 - rmsle: 0.0623 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7529 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8832 - rmsle: 0.0623 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7932 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8515 - rmsle: 0.0618 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6590 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8446 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6594 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8334 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6486 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8319 - rmsle: 0.0616 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6492 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8251 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6374 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8225 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6365 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8157 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6375 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8240 - rmsle: 0.0614 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6348 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8013 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6211 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7990 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6061 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7895 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6180 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7909 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6100 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7965 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6168 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061028003646622433\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.0450 - msle: 90.3005 - rmsle: 1.9824 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1258 - val_msle: 6.2779 - val_rmsle: 0.0870 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1263 - msle: 5.5089 - rmsle: 0.0930 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1006 - val_msle: 4.5965 - val_rmsle: 0.0800 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0953 - msle: 4.8388 - rmsle: 0.0775 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0892 - val_msle: 4.6662 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0831 - msle: 4.5747 - rmsle: 0.0727 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.4427 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0773 - msle: 4.3843 - rmsle: 0.0702 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.3248 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.3091 - rmsle: 0.0686 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.1976 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.2121 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.1478 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.1569 - rmsle: 0.0662 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.3090 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1134 - rmsle: 0.0655 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.0172 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0970 - rmsle: 0.0650 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.2715 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0588 - rmsle: 0.0646 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0331 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0380 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.1149 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0168 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0157 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9909 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.9475 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9713 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1983 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9605 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0193 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9111 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8145 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9045 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8459 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8936 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7788 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8876 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9434 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8613 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7351 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8470 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7218 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8486 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7045 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8529 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6979 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8423 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7256 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8324 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6945 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8342 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6966 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8216 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6691 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8151 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6763 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8065 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6708 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8054 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6649 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06185918047932204\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_14_loss: 0.0000e+00 - loss: 2.0475 - msle: 90.6017 - rmsle: 1.9850 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1427 - val_msle: 6.7932 - val_rmsle: 0.1054 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1202 - msle: 5.4804 - rmsle: 0.0886 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 4.6265 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0929 - msle: 4.8342 - rmsle: 0.0768 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.2751 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0819 - msle: 4.5667 - rmsle: 0.0726 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.1529 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.3861 - rmsle: 0.0697 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.0789 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.2797 - rmsle: 0.0682 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9967 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.1690 - rmsle: 0.0666 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9862 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1008 - rmsle: 0.0657 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9516 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0511 - rmsle: 0.0651 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9372 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0245 - rmsle: 0.0645 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9220 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0096 - rmsle: 0.0642 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9975 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9809 - rmsle: 0.0639 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8619 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9475 - rmsle: 0.0638 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8424 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9369 - rmsle: 0.0635 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8783 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9072 - rmsle: 0.0633 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9154 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8813 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8091 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8831 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8120 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8762 - rmsle: 0.0631 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7486 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8546 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7560 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8453 - rmsle: 0.0629 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8763 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8455 - rmsle: 0.0628 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7841 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8100 - rmsle: 0.0622 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7209 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7992 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6898 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7939 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7123 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7792 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7666 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7885 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6864 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7724 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8747 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7733 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6852 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7633 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6892 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7786 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7689 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7681 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6987 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06105005663566497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:49:15,546] Trial 11 finished with value: 0.061350951611104584 and parameters: {'units': 512, 'num_cross_layers': 2, 'activation': 'silu', 'reg': 0.00013235220616681148, 'do_rate': 0.39855780785346334, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 2.0210 - msle: 90.1038 - rmsle: 1.9711 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1572 - val_msle: 7.4345 - val_rmsle: 0.1238 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1184 - msle: 5.4588 - rmsle: 0.0894 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 4.5856 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0936 - msle: 4.8398 - rmsle: 0.0775 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.4757 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0823 - msle: 4.5587 - rmsle: 0.0728 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.3987 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0766 - msle: 4.3832 - rmsle: 0.0702 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2467 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0731 - msle: 4.2690 - rmsle: 0.0683 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2605 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.1758 - rmsle: 0.0671 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2933 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1153 - rmsle: 0.0661 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.2108 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.0762 - rmsle: 0.0654 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.3314 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0251 - rmsle: 0.0646 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.1693 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0056 - rmsle: 0.0645 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.1335 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9715 - rmsle: 0.0641 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.1136 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9462 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9816 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9584 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.1786 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9133 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.1826 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9005 - rmsle: 0.0634 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1150 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8783 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0338 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8713 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0691 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8575 - rmsle: 0.0631 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1030 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8476 - rmsle: 0.0630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9912 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8365 - rmsle: 0.0628 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.2084 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8405 - rmsle: 0.0629 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0647 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8220 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.1922 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7843 - rmsle: 0.0621 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9190 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7781 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8946 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7727 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9267 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7648 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8760 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7639 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8864 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7651 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9107 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7616 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9525 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7402 - rmsle: 0.0615 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7852 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.062001099511154324\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_5_loss: 0.0000e+00 - loss: 2.0343 - msle: 91.0052 - rmsle: 1.9844 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1607 - val_msle: 6.8412 - val_rmsle: 0.1270 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1212 - msle: 5.7094 - rmsle: 0.0917 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 4.7085 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0946 - msle: 4.9536 - rmsle: 0.0779 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.3510 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0831 - msle: 4.6339 - rmsle: 0.0730 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.4192 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0771 - msle: 4.4527 - rmsle: 0.0704 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.1818 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0734 - msle: 4.3296 - rmsle: 0.0684 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.0535 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.2281 - rmsle: 0.0671 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0652 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1614 - rmsle: 0.0660 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0838 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1075 - rmsle: 0.0653 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0570 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0741 - rmsle: 0.0648 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0900 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0453 - rmsle: 0.0642 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.2535 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0159 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.1070 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.0113 - rmsle: 0.0636 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9562 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9384 - rmsle: 0.0631 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0115 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9257 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0331 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9175 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.1373 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8861 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8793 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8686 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8673 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8586 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8968 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8592 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8915 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8549 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8663 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8531 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8484 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8428 - rmsle: 0.0621 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8669 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8296 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8377 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8328 - rmsle: 0.0619 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8156 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8185 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8290 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8158 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8094 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8110 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.8350 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8102 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8006 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8113 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7990 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8017 - rmsle: 0.0615 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7704 - val_rmsle: 0.0601 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.060778745184591546\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_8_loss: 0.0000e+00 - loss: 2.0261 - msle: 90.1925 - rmsle: 1.9761 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1422 - val_msle: 7.2529 - val_rmsle: 0.1084 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1179 - msle: 5.4996 - rmsle: 0.0884 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 4.6850 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0921 - msle: 4.8888 - rmsle: 0.0759 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 4.3350 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0811 - msle: 4.5870 - rmsle: 0.0717 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 3.9937 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0755 - msle: 4.4022 - rmsle: 0.0692 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.9546 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.2753 - rmsle: 0.0674 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9953 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.1804 - rmsle: 0.0661 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9017 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1272 - rmsle: 0.0653 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8500 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0779 - rmsle: 0.0646 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8310 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0325 - rmsle: 0.0639 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8457 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9826 - rmsle: 0.0635 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9146 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9712 - rmsle: 0.0632 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8734 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9608 - rmsle: 0.0631 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7725 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9138 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7337 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8822 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7323 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8740 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7071 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8634 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7196 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8631 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7452 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8535 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6918 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8261 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6622 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8183 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6429 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8099 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6340 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8115 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6308 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8043 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6219 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8021 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6257 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8030 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6190 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7840 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6116 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7834 - rmsle: 0.0609 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5985 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7738 - rmsle: 0.0608 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6163 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7795 - rmsle: 0.0609 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6025 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7786 - rmsle: 0.0608 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6053 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.060934458890531513\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.0337 - msle: 90.3887 - rmsle: 1.9838 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1364 - val_msle: 6.3907 - val_rmsle: 0.1028 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1202 - msle: 5.4484 - rmsle: 0.0911 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0929 - val_msle: 4.4413 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0935 - msle: 4.8041 - rmsle: 0.0772 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0848 - val_msle: 4.3465 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0818 - msle: 4.5520 - rmsle: 0.0720 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.1294 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0763 - msle: 4.3692 - rmsle: 0.0698 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.1395 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.2932 - rmsle: 0.0683 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.0636 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.2051 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.0823 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1444 - rmsle: 0.0661 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.1623 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.0984 - rmsle: 0.0653 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9920 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0833 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.2302 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0404 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.0095 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0163 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.0132 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0114 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.9269 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9837 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9007 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9679 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.6117 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9558 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.1449 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9102 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8316 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9028 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8452 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8888 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7660 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8815 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8345 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8554 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7340 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8449 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7474 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8451 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7032 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8439 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6921 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8338 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7254 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8312 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6957 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8330 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7155 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8156 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6650 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8045 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6699 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7997 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6610 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8022 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6576 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06175583401617952\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_14_loss: 0.0000e+00 - loss: 2.0287 - msle: 90.3493 - rmsle: 1.9788 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1392 - val_msle: 7.0012 - val_rmsle: 0.1057 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1184 - msle: 5.4716 - rmsle: 0.0892 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 4.8760 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0930 - msle: 4.8259 - rmsle: 0.0768 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.1861 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0822 - msle: 4.5703 - rmsle: 0.0726 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.1021 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0762 - msle: 4.3777 - rmsle: 0.0698 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.9512 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.2600 - rmsle: 0.0681 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9876 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.1675 - rmsle: 0.0666 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9459 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.0948 - rmsle: 0.0658 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9620 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0445 - rmsle: 0.0651 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9080 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0107 - rmsle: 0.0645 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9013 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9991 - rmsle: 0.0642 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8943 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9762 - rmsle: 0.0640 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9153 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9025 - rmsle: 0.0631 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7797 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8926 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7710 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8671 - rmsle: 0.0627 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7866 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8654 - rmsle: 0.0628 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7398 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8675 - rmsle: 0.0629 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7443 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8619 - rmsle: 0.0627 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7349 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8360 - rmsle: 0.0626 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7556 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8307 - rmsle: 0.0625 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7792 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8236 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7238 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8252 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7390 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8034 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6992 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7867 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6844 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7768 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6802 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7939 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6845 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7741 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7096 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7780 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6749 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7618 - rmsle: 0.0616 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6607 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7795 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6694 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7692 - rmsle: 0.0617 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6629 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060426897314975386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 17:56:07,650] Trial 12 finished with value: 0.06117940698348645 and parameters: {'units': 512, 'num_cross_layers': 2, 'activation': 'silu', 'reg': 0.00010246843783720811, 'do_rate': 0.38751104574803347, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_2_loss: 0.0000e+00 - loss: 2.0940 - msle: 87.7397 - rmsle: 2.0880 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0968 - val_msle: 6.9548 - val_rmsle: 0.0908 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0929 - msle: 6.4396 - rmsle: 0.0875 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0833 - val_msle: 5.8818 - val_rmsle: 0.0791 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0804 - msle: 5.5450 - rmsle: 0.0765 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 5.2605 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0759 - msle: 5.1132 - rmsle: 0.0729 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.1248 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.8298 - rmsle: 0.0709 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.7835 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.6124 - rmsle: 0.0693 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.5953 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.4608 - rmsle: 0.0681 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.6091 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.3629 - rmsle: 0.0673 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.5841 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.2762 - rmsle: 0.0666 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.4456 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.1978 - rmsle: 0.0659 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.4788 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.1465 - rmsle: 0.0653 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2987 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0962 - rmsle: 0.0649 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.2094 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.0573 - rmsle: 0.0646 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2885 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0296 - rmsle: 0.0642 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1158 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9934 - rmsle: 0.0640 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1746 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9727 - rmsle: 0.0638 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0805 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9440 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0505 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9271 - rmsle: 0.0634 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1645 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9108 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0257 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8955 - rmsle: 0.0632 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0262 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8855 - rmsle: 0.0630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0503 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8748 - rmsle: 0.0630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0066 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8604 - rmsle: 0.0629 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9389 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8488 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9180 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8389 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9836 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8292 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9495 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8191 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9223 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8012 - rmsle: 0.0622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8851 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7943 - rmsle: 0.0621 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.8920 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7963 - rmsle: 0.0621 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.8867 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7860 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.8709 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0625204073338801\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 9ms/step - dense_5_loss: 0.0000e+00 - loss: 2.0898 - msle: 87.6422 - rmsle: 2.0838 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0988 - val_msle: 7.0512 - val_rmsle: 0.0927 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0924 - msle: 6.4455 - rmsle: 0.0869 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0876 - val_msle: 6.1934 - val_rmsle: 0.0833 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0806 - msle: 5.5838 - rmsle: 0.0767 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 5.8030 - val_rmsle: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0763 - msle: 5.1651 - rmsle: 0.0733 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 5.4789 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0735 - msle: 4.8980 - rmsle: 0.0710 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 5.2900 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.7023 - rmsle: 0.0696 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.1109 - val_rmsle: 0.0735 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.5490 - rmsle: 0.0685 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 5.1573 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.4330 - rmsle: 0.0676 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.8319 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.3443 - rmsle: 0.0666 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.6837 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.2619 - rmsle: 0.0660 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.7868 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.2033 - rmsle: 0.0655 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.5894 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.1436 - rmsle: 0.0649 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3587 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.1013 - rmsle: 0.0646 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.4917 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0635 - rmsle: 0.0642 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.4978 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0352 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.3821 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0040 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.3824 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9845 - rmsle: 0.0636 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.2129 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9684 - rmsle: 0.0635 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.2784 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9432 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.2079 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9315 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.1597 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9127 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.1495 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8950 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.1723 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8874 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.1840 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8696 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 4.0050 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8610 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9919 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8527 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.9635 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8451 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9658 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8388 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 4.0112 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8447 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9616 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8284 - rmsle: 0.0621 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9682 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8319 - rmsle: 0.0621 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9764 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0956761837005615\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06247889306379735\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_8_loss: 0.0000e+00 - loss: 2.0892 - msle: 87.5724 - rmsle: 2.0832 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1011 - val_msle: 7.2455 - val_rmsle: 0.0950 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0929 - msle: 6.5458 - rmsle: 0.0874 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 5.6468 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0804 - msle: 5.6477 - rmsle: 0.0765 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 5.0878 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0756 - msle: 5.1814 - rmsle: 0.0726 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.7991 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0730 - msle: 4.9024 - rmsle: 0.0705 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.6025 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.6863 - rmsle: 0.0691 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.4987 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.5376 - rmsle: 0.0678 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.3192 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.4196 - rmsle: 0.0671 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2574 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.3234 - rmsle: 0.0663 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.2152 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.2516 - rmsle: 0.0655 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.1349 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.1846 - rmsle: 0.0650 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0856 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.1322 - rmsle: 0.0644 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1142 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.0978 - rmsle: 0.0640 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0026 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.0573 - rmsle: 0.0637 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9632 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0260 - rmsle: 0.0634 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9741 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.0007 - rmsle: 0.0633 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9352 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9768 - rmsle: 0.0631 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8930 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9583 - rmsle: 0.0629 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8639 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.9389 - rmsle: 0.0628 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8524 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.9214 - rmsle: 0.0626 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8770 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.9095 - rmsle: 0.0626 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8192 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.9006 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8103 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8811 - rmsle: 0.0623 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7976 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8692 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7807 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8631 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7766 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8551 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7745 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8389 - rmsle: 0.0619 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7446 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8402 - rmsle: 0.0619 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7569 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.8104 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7093 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.8057 - rmsle: 0.0614 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7113 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.8042 - rmsle: 0.0614 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7073 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0739386081695557\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.062088171051768594\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_11_loss: 0.0000e+00 - loss: 2.0939 - msle: 87.7353 - rmsle: 2.0879 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0969 - val_msle: 7.0501 - val_rmsle: 0.0908 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0923 - msle: 6.4421 - rmsle: 0.0868 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 5.9366 - val_rmsle: 0.0833 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0803 - msle: 5.5816 - rmsle: 0.0764 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 5.6377 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0759 - msle: 5.1461 - rmsle: 0.0729 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 5.2537 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.8674 - rmsle: 0.0709 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 5.1165 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.6694 - rmsle: 0.0693 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.9291 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.5189 - rmsle: 0.0682 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.8712 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.4079 - rmsle: 0.0674 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.6561 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.3140 - rmsle: 0.0665 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.8306 - val_rmsle: 0.0735 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.2424 - rmsle: 0.0659 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.8417 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1811 - rmsle: 0.0654 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.8878 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.1339 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.2222 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.1089 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2542 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0854 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2480 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0631 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2263 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.0459 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0025 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.0309 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9870 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0196 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9920 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0192 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9866 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0063 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9788 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0006 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9903 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9938 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9459 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9813 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9194 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9808 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9166 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9777 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9120 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9775 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9093 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9683 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9032 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9662 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9015 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9616 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8996 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9574 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8839 - val_rmsle: 0.0621 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9571 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8819 - val_rmsle: 0.0621 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06302670759351442\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_14_loss: 0.0000e+00 - loss: 2.0900 - msle: 87.7192 - rmsle: 2.0840 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0998 - val_msle: 7.2178 - val_rmsle: 0.0937 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0922 - msle: 6.5104 - rmsle: 0.0867 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.6742 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0804 - msle: 5.6010 - rmsle: 0.0765 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 5.2431 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0759 - msle: 5.1434 - rmsle: 0.0729 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.8384 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.8499 - rmsle: 0.0708 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.6133 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.6362 - rmsle: 0.0692 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.4142 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.4749 - rmsle: 0.0681 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.2942 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.3500 - rmsle: 0.0670 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2353 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2503 - rmsle: 0.0663 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1822 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.1860 - rmsle: 0.0656 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1374 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.1286 - rmsle: 0.0650 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 4.0696 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.0753 - rmsle: 0.0645 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 4.0080 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0412 - rmsle: 0.0643 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9890 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.0058 - rmsle: 0.0640 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9537 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9799 - rmsle: 0.0638 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9693 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9565 - rmsle: 0.0635 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9239 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9336 - rmsle: 0.0633 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8968 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9135 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9307 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8962 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8917 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8782 - rmsle: 0.0629 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8776 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8674 - rmsle: 0.0628 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8410 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8571 - rmsle: 0.0627 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8495 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8495 - rmsle: 0.0627 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8133 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8323 - rmsle: 0.0625 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.9263 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8274 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8186 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8199 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7933 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8079 - rmsle: 0.0623 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8802 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8041 - rmsle: 0.0622 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7698 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7938 - rmsle: 0.0622 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.8022 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7834 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7778 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7807 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8095 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.061625987132844534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:02:24,838] Trial 13 finished with value: 0.062348033235161006 and parameters: {'units': 256, 'num_cross_layers': 2, 'activation': 'silu', 'reg': 0.00021753794725750859, 'do_rate': 0.44569436108875915, 'hidden_layers': 1}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2797 - msle: 81.9622 - rmsle: 1.7770 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1707 - val_msle: 10.3173 - val_rmsle: 0.1324 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1187 - msle: 6.0471 - rmsle: 0.0873 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1235 - val_msle: 7.3434 - val_rmsle: 0.1040 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0946 - msle: 5.0579 - rmsle: 0.0767 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1095 - val_msle: 7.2636 - val_rmsle: 0.0953 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0873 - msle: 4.7885 - rmsle: 0.0740 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0934 - val_msle: 6.3817 - val_rmsle: 0.0819 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0823 - msle: 4.5601 - rmsle: 0.0717 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1057 - val_msle: 6.2203 - val_rmsle: 0.0965 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0786 - msle: 4.3996 - rmsle: 0.0700 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 6.1686 - val_rmsle: 0.0849 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.2579 - rmsle: 0.0686 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 5.5390 - val_rmsle: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.1741 - rmsle: 0.0674 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0901 - val_msle: 5.8615 - val_rmsle: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.1180 - rmsle: 0.0666 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 4.8792 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.0904 - rmsle: 0.0664 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.2927 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.0631 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.3165 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.0513 - rmsle: 0.0657 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2252 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0686 - msle: 3.9895 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1147 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0685 - msle: 3.9809 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1031 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0682 - msle: 3.9567 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1319 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9372 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9515 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9095 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0279 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.8881 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9908 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.8800 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9445 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.8697 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9396 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8436 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9074 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8380 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8934 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8177 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8741 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8343 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8974 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8208 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8559 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7952 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8580 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7551 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8047 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7477 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8006 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7453 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8028 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7376 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7834 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7422 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7779 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06220014668895197\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 2.2697 - msle: 81.7413 - rmsle: 1.7665 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1904 - val_msle: 10.6532 - val_rmsle: 0.1546 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1129 - msle: 5.8966 - rmsle: 0.0838 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1220 - val_msle: 7.1714 - val_rmsle: 0.1026 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0924 - msle: 5.0381 - rmsle: 0.0754 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1405 - val_msle: 8.5500 - val_rmsle: 0.1271 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0844 - msle: 4.7005 - rmsle: 0.0723 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1254 - val_msle: 7.7020 - val_rmsle: 0.1145 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0802 - msle: 4.5169 - rmsle: 0.0704 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1333 - val_msle: 8.8918 - val_rmsle: 0.1243 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0754 - msle: 4.3156 - rmsle: 0.0680 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 5.8775 - val_rmsle: 0.0810 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0730 - msle: 4.2348 - rmsle: 0.0672 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.8011 - val_rmsle: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.1649 - rmsle: 0.0668 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 4.9435 - val_rmsle: 0.0754 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.1307 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0925 - val_msle: 5.8702 - val_rmsle: 0.0879 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.1033 - rmsle: 0.0657 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 5.2861 - val_rmsle: 0.0789 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.0395 - rmsle: 0.0648 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.4329 - val_rmsle: 0.0688 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0213 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.2800 - val_rmsle: 0.0680 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0033 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.3984 - val_rmsle: 0.0689 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0672 - msle: 3.9983 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.2106 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0671 - msle: 3.9854 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.3256 - val_rmsle: 0.0691 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9708 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.2563 - val_rmsle: 0.0686 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9676 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2117 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9629 - rmsle: 0.0639 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.3621 - val_rmsle: 0.0688 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9521 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.2353 - val_rmsle: 0.0674 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9386 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.2912 - val_rmsle: 0.0687 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9160 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9996 - val_rmsle: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9074 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0726 - val_rmsle: 0.0647 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9098 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9887 - val_rmsle: 0.0637 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9088 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9977 - val_rmsle: 0.0640 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9060 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0066 - val_rmsle: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8999 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9696 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8888 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0124 - val_rmsle: 0.0646 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8823 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9797 - val_rmsle: 0.0637 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8872 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9586 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8793 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8849 - val_rmsle: 0.0620 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8682 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8883 - val_rmsle: 0.0617 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06232464983092555\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.2558 - msle: 81.5910 - rmsle: 1.7470 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1825 - val_msle: 10.6784 - val_rmsle: 0.1445 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1129 - msle: 5.9849 - rmsle: 0.0830 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1333 - val_msle: 7.1089 - val_rmsle: 0.1156 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0914 - msle: 5.0010 - rmsle: 0.0749 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1028 - val_msle: 5.4189 - val_rmsle: 0.0903 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0833 - msle: 4.6572 - rmsle: 0.0714 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.5295 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0793 - msle: 4.4959 - rmsle: 0.0699 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 4.3172 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0763 - msle: 4.3460 - rmsle: 0.0684 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1666 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.2346 - rmsle: 0.0672 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.0217 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.1632 - rmsle: 0.0662 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.0908 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.1214 - rmsle: 0.0658 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0648 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.0646 - rmsle: 0.0651 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9421 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.0425 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9249 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0044 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.1125 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0675 - msle: 3.9708 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8323 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9438 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8053 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9111 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8621 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.8995 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7940 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8859 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7776 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8621 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7373 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8520 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7687 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8468 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7526 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8268 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7439 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8228 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7480 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8248 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7798 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8263 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.6944 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7760 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6754 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7695 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6625 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7761 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6624 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7657 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6547 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7562 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6576 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7518 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6523 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7563 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6473 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.0624847074966322\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 2.2723 - msle: 81.6145 - rmsle: 1.7613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.2045 - val_msle: 10.8871 - val_rmsle: 0.1683 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1136 - msle: 5.9266 - rmsle: 0.0841 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1459 - val_msle: 8.2217 - val_rmsle: 0.1277 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0920 - msle: 5.0304 - rmsle: 0.0754 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1233 - val_msle: 6.5443 - val_rmsle: 0.1104 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0854 - msle: 4.7509 - rmsle: 0.0730 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1122 - val_msle: 5.8433 - val_rmsle: 0.1019 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0809 - msle: 4.5447 - rmsle: 0.0711 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1112 - val_msle: 5.8897 - val_rmsle: 0.1021 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0783 - msle: 4.4087 - rmsle: 0.0697 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1118 - val_msle: 6.1172 - val_rmsle: 0.1043 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.2898 - rmsle: 0.0685 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 5.3297 - val_rmsle: 0.0870 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.1916 - rmsle: 0.0673 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0918 - val_msle: 5.0129 - val_rmsle: 0.0862 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.1797 - rmsle: 0.0673 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 4.8348 - val_rmsle: 0.0802 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.1123 - rmsle: 0.0661 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 4.8372 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.0830 - rmsle: 0.0659 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0934 - val_msle: 5.3853 - val_rmsle: 0.0892 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.0414 - rmsle: 0.0654 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0892 - val_msle: 4.7704 - val_rmsle: 0.0847 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.0242 - rmsle: 0.0653 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.2082 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0687 - msle: 3.9967 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 4.5313 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0676 - msle: 3.9578 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.2335 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 3.9308 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.0698 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8807 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8887 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8657 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9262 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8608 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8475 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8494 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9557 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8255 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7635 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8221 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7597 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8159 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8188 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8181 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7671 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8012 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7143 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7997 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7206 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7950 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7073 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7954 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7038 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7941 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7161 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7938 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6982 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7824 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7113 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.062463141585446226\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 10ms/step - dense_19_loss: 0.0000e+00 - loss: 2.2707 - msle: 81.9168 - rmsle: 1.7607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1851 - val_msle: 11.0978 - val_rmsle: 0.1486 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1121 - msle: 5.8767 - rmsle: 0.0827 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1035 - val_msle: 6.2270 - val_rmsle: 0.0848 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0912 - msle: 4.9599 - rmsle: 0.0745 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0967 - val_msle: 6.2149 - val_rmsle: 0.0838 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0838 - msle: 4.6211 - rmsle: 0.0716 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0860 - val_msle: 4.8557 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0797 - msle: 4.4597 - rmsle: 0.0700 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0945 - val_msle: 5.9039 - val_rmsle: 0.0865 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0770 - msle: 4.3163 - rmsle: 0.0689 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.5203 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.2216 - rmsle: 0.0676 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 4.8700 - val_rmsle: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.1517 - rmsle: 0.0669 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.5744 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.0948 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 3.9841 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.0689 - rmsle: 0.0656 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.1355 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.0249 - rmsle: 0.0651 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.1693 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0685 - msle: 3.9874 - rmsle: 0.0647 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9956 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0680 - msle: 3.9573 - rmsle: 0.0644 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.9822 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0672 - msle: 3.9201 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8390 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.8960 - rmsle: 0.0638 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8381 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.8827 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8502 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.8519 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8955 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8468 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8171 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8254 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8865 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8344 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8177 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8222 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7389 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8025 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7676 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8045 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7370 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7801 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7386 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7746 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7204 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7763 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7432 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7710 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7340 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7471 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7113 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7277 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6894 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7300 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7246 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7264 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6787 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06114691306641269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:09:31,137] Trial 14 finished with value: 0.06212391173367373 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'silu', 'reg': 0.002180686404328363, 'do_rate': 0.3707678635051536, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_2_loss: 0.0000e+00 - loss: 1.8416 - msle: 86.0314 - rmsle: 1.8351 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0922 - val_msle: 6.7783 - val_rmsle: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0852 - msle: 6.1684 - rmsle: 0.0802 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 5.7086 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0748 - msle: 5.3466 - rmsle: 0.0715 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 5.4912 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.9856 - rmsle: 0.0689 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 5.4760 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.7608 - rmsle: 0.0675 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 5.6938 - val_rmsle: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.5800 - rmsle: 0.0665 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 5.6521 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.4514 - rmsle: 0.0659 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 5.8361 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.3528 - rmsle: 0.0651 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.7110 - val_rmsle: 0.0701 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.3027 - rmsle: 0.0648 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.7225 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.2576 - rmsle: 0.0646 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.7911 - val_rmsle: 0.0705 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.2203 - rmsle: 0.0644 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.7070 - val_rmsle: 0.0714 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.1759 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.2137 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.1509 - rmsle: 0.0638 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1943 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.1443 - rmsle: 0.0636 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1465 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.1212 - rmsle: 0.0636 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.2468 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1106 - rmsle: 0.0635 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1730 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.0854 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.2133 - val_rmsle: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0669 - rmsle: 0.0630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 4.0402 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0574 - rmsle: 0.0631 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 4.0397 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0637 - msle: 4.0509 - rmsle: 0.0630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 4.0396 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0637 - msle: 4.0459 - rmsle: 0.0629 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 4.0317 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0636 - msle: 4.0377 - rmsle: 0.0629 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.9959 - val_rmsle: 0.0619 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0635 - msle: 4.0275 - rmsle: 0.0628 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9894 - val_rmsle: 0.0618 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0635 - msle: 4.0269 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.9827 - val_rmsle: 0.0618 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0635 - msle: 4.0187 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9868 - val_rmsle: 0.0618 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 4.0187 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.9723 - val_rmsle: 0.0617 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 4.0099 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.9733 - val_rmsle: 0.0617 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0634 - msle: 4.0123 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9563 - val_rmsle: 0.0616 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 4.0002 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9543 - val_rmsle: 0.0615 - learning_rate: 1.5625e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 4.0024 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.9518 - val_rmsle: 0.0615 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 4.0028 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.9489 - val_rmsle: 0.0615 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06243441059459265\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_5_loss: 0.0000e+00 - loss: 1.8410 - msle: 86.0035 - rmsle: 1.8344 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0979 - val_msle: 6.6923 - val_rmsle: 0.0921 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0845 - msle: 5.9662 - rmsle: 0.0794 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1029 - val_msle: 6.6789 - val_rmsle: 0.0992 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0744 - msle: 5.1718 - rmsle: 0.0711 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0968 - val_msle: 6.1855 - val_rmsle: 0.0941 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.8326 - rmsle: 0.0684 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0965 - val_msle: 6.1594 - val_rmsle: 0.0944 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.6264 - rmsle: 0.0669 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 5.8838 - val_rmsle: 0.0900 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.4773 - rmsle: 0.0660 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0908 - val_msle: 5.7528 - val_rmsle: 0.0893 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.3652 - rmsle: 0.0654 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0956 - val_msle: 6.0718 - val_rmsle: 0.0943 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.2827 - rmsle: 0.0650 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 5.7416 - val_rmsle: 0.0871 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.2092 - rmsle: 0.0645 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0894 - val_msle: 5.7499 - val_rmsle: 0.0882 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.1476 - rmsle: 0.0641 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0935 - val_msle: 6.1752 - val_rmsle: 0.0924 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.1103 - rmsle: 0.0639 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0871 - val_msle: 5.7357 - val_rmsle: 0.0861 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.0632 - rmsle: 0.0637 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0899 - val_msle: 5.7933 - val_rmsle: 0.0890 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0399 - rmsle: 0.0635 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0864 - val_msle: 5.6174 - val_rmsle: 0.0855 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0641 - msle: 4.0005 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0893 - val_msle: 5.8703 - val_rmsle: 0.0884 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9869 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0891 - val_msle: 5.8472 - val_rmsle: 0.0883 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9550 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 5.2869 - val_rmsle: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9360 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0920 - val_msle: 6.1341 - val_rmsle: 0.0912 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.9253 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 5.3214 - val_rmsle: 0.0817 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.9062 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 5.4972 - val_rmsle: 0.0828 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8836 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.4560 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8598 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.5997 - val_rmsle: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8558 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.3893 - val_rmsle: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8535 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.3721 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8460 - rmsle: 0.0619 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.5133 - val_rmsle: 0.0694 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8373 - rmsle: 0.0618 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2543 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8319 - rmsle: 0.0618 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2927 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8289 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.2509 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8151 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.2402 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8114 - rmsle: 0.0617 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2917 - val_rmsle: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8000 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.4658 - val_rmsle: 0.0696 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.8011 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2332 - val_rmsle: 0.0668 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.048526406288147\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06733932247548782\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_8_loss: 0.0000e+00 - loss: 1.8430 - msle: 85.9583 - rmsle: 1.8364 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0959 - val_msle: 6.6063 - val_rmsle: 0.0902 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0837 - msle: 5.9818 - rmsle: 0.0787 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 5.3519 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0733 - msle: 5.1407 - rmsle: 0.0701 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.7660 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.8017 - rmsle: 0.0676 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.4918 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.5883 - rmsle: 0.0662 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3571 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.4526 - rmsle: 0.0655 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.2402 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.3478 - rmsle: 0.0649 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1141 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.2638 - rmsle: 0.0644 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0604 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2013 - rmsle: 0.0640 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0649 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.1418 - rmsle: 0.0637 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9725 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.0938 - rmsle: 0.0634 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0173 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0554 - rmsle: 0.0631 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0500 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0366 - rmsle: 0.0630 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9996 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 4.0032 - rmsle: 0.0628 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0175 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.9734 - rmsle: 0.0626 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2121 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.9546 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8241 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.9334 - rmsle: 0.0624 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8808 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.9151 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0573 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8999 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8687 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8673 - rmsle: 0.0616 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7380 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8504 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7256 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8455 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8714 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.8361 - rmsle: 0.0614 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7435 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.8213 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6821 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.8162 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6731 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.8211 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6669 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.8092 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6952 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.8130 - rmsle: 0.0610 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6991 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.8026 - rmsle: 0.0608 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6507 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.8017 - rmsle: 0.0608 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6544 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7987 - rmsle: 0.0608 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6513 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061245288217769034\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_11_loss: 0.0000e+00 - loss: 1.8431 - msle: 86.1115 - rmsle: 1.8366 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0924 - val_msle: 6.8941 - val_rmsle: 0.0868 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0850 - msle: 6.2194 - rmsle: 0.0800 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 5.8343 - val_rmsle: 0.0799 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0750 - msle: 5.3826 - rmsle: 0.0717 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 5.9818 - val_rmsle: 0.0841 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0715 - msle: 5.0068 - rmsle: 0.0691 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0891 - val_msle: 6.2880 - val_rmsle: 0.0870 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.7717 - rmsle: 0.0676 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 6.0477 - val_rmsle: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.6164 - rmsle: 0.0664 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.7682 - val_rmsle: 0.0707 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.5306 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.7769 - val_rmsle: 0.0717 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.4622 - rmsle: 0.0657 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.8724 - val_rmsle: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.4000 - rmsle: 0.0653 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.8825 - val_rmsle: 0.0726 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.3494 - rmsle: 0.0649 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.3119 - val_rmsle: 0.0658 - learning_rate: 1.2500e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.3059 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.3707 - val_rmsle: 0.0663 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.2837 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.3705 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.2613 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3080 - val_rmsle: 0.0661 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2329 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.1056 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.2191 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.1100 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.2110 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.1007 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.1909 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0852 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.1797 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0778 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.1783 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0669 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.1638 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0444 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.1523 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0442 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.1437 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0368 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.1322 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0154 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1245 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0424 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1155 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0163 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.1052 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9831 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0938 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9721 - val_rmsle: 0.0627 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0882 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9855 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0790 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9819 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0695 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9705 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 4.0597 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8979 - val_rmsle: 0.0620 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06293583281500392\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_14_loss: 0.0000e+00 - loss: 1.8435 - msle: 86.1688 - rmsle: 1.8369 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0973 - val_msle: 6.8874 - val_rmsle: 0.0915 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0854 - msle: 6.1007 - rmsle: 0.0802 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 5.9030 - val_rmsle: 0.0820 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0748 - msle: 5.2352 - rmsle: 0.0714 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0852 - val_msle: 5.5640 - val_rmsle: 0.0824 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.8848 - rmsle: 0.0687 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 5.3486 - val_rmsle: 0.0820 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.6762 - rmsle: 0.0674 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 5.0305 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.5279 - rmsle: 0.0664 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 5.0543 - val_rmsle: 0.0763 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.4133 - rmsle: 0.0658 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.8728 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.3271 - rmsle: 0.0653 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.8111 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.2502 - rmsle: 0.0649 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.6919 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.1935 - rmsle: 0.0645 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.6724 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.1450 - rmsle: 0.0643 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.5024 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.0958 - rmsle: 0.0640 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.5142 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.0650 - rmsle: 0.0638 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.3005 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0316 - rmsle: 0.0636 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2512 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0045 - rmsle: 0.0634 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0946 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9753 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9771 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9534 - rmsle: 0.0631 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.2313 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9280 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9870 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9123 - rmsle: 0.0628 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.0411 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8707 - rmsle: 0.0623 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8048 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8602 - rmsle: 0.0622 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8331 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8508 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7853 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8544 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7780 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8406 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7491 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8251 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7676 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8314 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7446 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8195 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7437 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8149 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7405 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7942 - rmsle: 0.0615 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7097 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7790 - rmsle: 0.0615 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6993 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7905 - rmsle: 0.0615 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.7060 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060906224620009115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:15:49,585] Trial 15 finished with value: 0.06297221574457251 and parameters: {'units': 256, 'num_cross_layers': 2, 'activation': 'relu', 'reg': 0.00025376514391773096, 'do_rate': 0.3297778817175854, 'hidden_layers': 1}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 2.0800 - msle: 89.9863 - rmsle: 1.9691 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1646 - val_msle: 7.7245 - val_rmsle: 0.1197 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1243 - msle: 5.4251 - rmsle: 0.0888 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 4.8187 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0931 - msle: 4.8286 - rmsle: 0.0779 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.4312 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0823 - msle: 4.5524 - rmsle: 0.0732 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 5.0646 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0773 - msle: 4.3865 - rmsle: 0.0704 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.3754 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.2893 - rmsle: 0.0688 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.7513 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.1978 - rmsle: 0.0675 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.6777 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.1458 - rmsle: 0.0666 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.4511 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.0568 - rmsle: 0.0650 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.2582 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0182 - rmsle: 0.0645 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1456 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9992 - rmsle: 0.0643 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.3807 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9771 - rmsle: 0.0640 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0732 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9549 - rmsle: 0.0638 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.1182 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9592 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2843 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9365 - rmsle: 0.0636 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0758 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9247 - rmsle: 0.0634 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.1145 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9116 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9921 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9032 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1074 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8944 - rmsle: 0.0633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1426 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8644 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8587 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8428 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9128 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8456 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8403 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8382 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8879 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8307 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8422 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8328 - rmsle: 0.0624 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8145 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8276 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8763 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8125 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8484 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8187 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8565 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8062 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7816 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7965 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8057 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7947 - rmsle: 0.0619 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7820 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06182260799165621\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_5_loss: 0.0000e+00 - loss: 2.0763 - msle: 90.1255 - rmsle: 1.9656 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1376 - val_msle: 6.4114 - val_rmsle: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1256 - msle: 5.4783 - rmsle: 0.0899 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0873 - val_msle: 4.6416 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0922 - msle: 4.8107 - rmsle: 0.0769 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.4398 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.5624 - rmsle: 0.0729 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.6024 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0769 - msle: 4.4088 - rmsle: 0.0702 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.3522 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.2999 - rmsle: 0.0684 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.1387 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.2096 - rmsle: 0.0672 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2608 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.1541 - rmsle: 0.0661 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1994 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.0991 - rmsle: 0.0654 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.1346 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1160 - rmsle: 0.0652 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.4875 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0661 - rmsle: 0.0647 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.3706 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0292 - rmsle: 0.0639 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1627 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9655 - rmsle: 0.0635 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9942 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9575 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.1779 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9555 - rmsle: 0.0634 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1458 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9323 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.4234 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9331 - rmsle: 0.0632 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2396 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9108 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0796 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06422359509584719\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_8_loss: 0.0000e+00 - loss: 2.0757 - msle: 89.8653 - rmsle: 1.9648 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1475 - val_msle: 7.1592 - val_rmsle: 0.1032 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1225 - msle: 5.4633 - rmsle: 0.0875 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0931 - val_msle: 4.8350 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0910 - msle: 4.8744 - rmsle: 0.0762 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.4359 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.5672 - rmsle: 0.0718 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.4059 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.3909 - rmsle: 0.0691 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.3459 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.2672 - rmsle: 0.0674 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.2851 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.1886 - rmsle: 0.0662 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.0711 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1151 - rmsle: 0.0653 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0251 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0723 - rmsle: 0.0646 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9663 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0514 - rmsle: 0.0642 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.0204 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0123 - rmsle: 0.0638 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.2013 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9620 - rmsle: 0.0629 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7746 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9549 - rmsle: 0.0629 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7416 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9319 - rmsle: 0.0629 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7490 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9228 - rmsle: 0.0627 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7562 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9106 - rmsle: 0.0627 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7555 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8996 - rmsle: 0.0625 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8319 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8949 - rmsle: 0.0624 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8231 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8627 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6892 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8579 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7139 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8450 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6648 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8394 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6650 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8367 - rmsle: 0.0617 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6455 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8330 - rmsle: 0.0616 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6688 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8271 - rmsle: 0.0616 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6698 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8276 - rmsle: 0.0616 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6765 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8088 - rmsle: 0.0614 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6472 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8074 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6228 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7993 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6394 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7987 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6243 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8019 - rmsle: 0.0611 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6423 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06120973077124636\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 2.0808 - msle: 89.7790 - rmsle: 1.9701 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1474 - val_msle: 7.0507 - val_rmsle: 0.1002 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1310 - msle: 5.5069 - rmsle: 0.0930 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1006 - val_msle: 4.6986 - val_rmsle: 0.0808 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0942 - msle: 4.8035 - rmsle: 0.0773 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0936 - val_msle: 4.9817 - val_rmsle: 0.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0826 - msle: 4.5694 - rmsle: 0.0726 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 5.0675 - val_rmsle: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0773 - msle: 4.4003 - rmsle: 0.0701 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0905 - val_msle: 5.2097 - val_rmsle: 0.0844 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.3069 - rmsle: 0.0685 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0849 - val_msle: 5.0386 - val_rmsle: 0.0797 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0720 - msle: 4.2202 - rmsle: 0.0671 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.2701 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.1691 - rmsle: 0.0663 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 4.9668 - val_rmsle: 0.0752 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.1323 - rmsle: 0.0657 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.2834 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1324 - rmsle: 0.0653 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 4.7761 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0512 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9897 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0317 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1346 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0222 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8854 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9972 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.9881 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9955 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8831 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9924 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1960 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9747 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.1737 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9597 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9238 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9233 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7657 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9237 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7870 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9101 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7656 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9101 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7974 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9028 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7231 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9077 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7453 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8943 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7564 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8911 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7386 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8779 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7101 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8667 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7004 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8621 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7041 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8534 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7004 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8583 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6979 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06228456427280785\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_14_loss: 0.0000e+00 - loss: 2.0858 - msle: 90.2451 - rmsle: 1.9748 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1446 - val_msle: 6.5927 - val_rmsle: 0.0997 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1237 - msle: 5.3824 - rmsle: 0.0882 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0882 - val_msle: 4.7200 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0917 - msle: 4.7857 - rmsle: 0.0767 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.3566 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0817 - msle: 4.5668 - rmsle: 0.0727 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.2803 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0767 - msle: 4.3961 - rmsle: 0.0700 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.1194 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.2900 - rmsle: 0.0684 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0021 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.1872 - rmsle: 0.0669 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 3.9773 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.1146 - rmsle: 0.0660 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9941 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.0622 - rmsle: 0.0653 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1419 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9862 - rmsle: 0.0640 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8542 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9783 - rmsle: 0.0639 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8599 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9612 - rmsle: 0.0637 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8020 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9374 - rmsle: 0.0636 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8274 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9279 - rmsle: 0.0633 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8444 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9103 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8124 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8961 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7973 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8613 - rmsle: 0.0628 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7502 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8548 - rmsle: 0.0625 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7309 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8456 - rmsle: 0.0626 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7364 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8425 - rmsle: 0.0625 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7289 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8331 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7212 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8363 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7487 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8369 - rmsle: 0.0624 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7125 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8194 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7007 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8028 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6886 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8093 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6903 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7980 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6857 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7943 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6920 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7765 - rmsle: 0.0616 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6679 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7878 - rmsle: 0.0617 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6769 - val_rmsle: 0.0597 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7766 - rmsle: 0.0616 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6716 - val_rmsle: 0.0597 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06047114012600817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:22:18,546] Trial 16 finished with value: 0.06200232765151316 and parameters: {'units': 512, 'num_cross_layers': 2, 'activation': 'silu', 'reg': 0.00026343065678211187, 'do_rate': 0.3913022457496919, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1764 - msle: 82.6656 - rmsle: 2.1385 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1129 - val_msle: 8.2318 - val_rmsle: 0.0976 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1047 - msle: 7.3465 - rmsle: 0.0921 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 5.8473 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0808 - msle: 5.4926 - rmsle: 0.0746 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.8666 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.7156 - rmsle: 0.0691 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.4945 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.3780 - rmsle: 0.0672 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.2999 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.1920 - rmsle: 0.0661 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1743 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0795 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.1330 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.0107 - rmsle: 0.0651 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0532 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9595 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0386 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9191 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9894 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8941 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9538 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8695 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9470 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8488 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9200 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8293 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9000 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8142 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8661 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8000 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8656 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7835 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8395 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7720 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8462 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7678 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8289 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7585 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8252 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7562 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8169 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7475 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8146 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7429 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8092 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7404 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8047 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7340 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.8036 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7300 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8001 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7310 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7975 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7238 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7955 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7246 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7935 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7185 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7924 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7244 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7916 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06211524963019089\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_7_loss: 0.0000e+00 - loss: 2.1822 - msle: 82.7673 - rmsle: 2.1443 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1108 - val_msle: 7.8853 - val_rmsle: 0.0954 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1022 - msle: 7.0530 - rmsle: 0.0895 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 5.6866 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0792 - msle: 5.3907 - rmsle: 0.0731 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.8880 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0720 - msle: 4.7389 - rmsle: 0.0687 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.6896 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.4443 - rmsle: 0.0671 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.6684 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2788 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.5176 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.1762 - rmsle: 0.0656 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.4464 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.0963 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.3582 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.0419 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.2321 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9962 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1491 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9700 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.1166 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9430 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0763 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9207 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0374 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9031 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0676 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8817 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9795 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8689 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0179 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8558 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9881 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8460 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.9631 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8340 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9256 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8261 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.9269 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8139 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9101 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8036 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9407 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7959 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8905 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7932 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9129 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7827 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8886 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7809 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.9350 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7683 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8368 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7475 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8320 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7520 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8349 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7562 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8263 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7461 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8371 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.061943376537036764\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_11_loss: 0.0000e+00 - loss: 2.1780 - msle: 82.6367 - rmsle: 2.1401 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1120 - val_msle: 7.9684 - val_rmsle: 0.0967 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.1982 - rmsle: 0.0900 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 5.7652 - val_rmsle: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0798 - msle: 5.4681 - rmsle: 0.0737 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.9222 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0723 - msle: 4.7963 - rmsle: 0.0688 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.5210 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.4832 - rmsle: 0.0672 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.2729 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2975 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1728 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.1763 - rmsle: 0.0654 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0336 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0896 - rmsle: 0.0649 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9696 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0314 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9149 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9878 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9088 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9567 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8573 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9256 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8344 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9011 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8138 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8799 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7952 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8626 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7980 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8423 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7584 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8354 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7463 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8257 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7426 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8126 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7349 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8089 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7173 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8030 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7141 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8002 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7129 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7913 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7087 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7905 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7109 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7853 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6990 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7778 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6979 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7857 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6952 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7820 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6924 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7798 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6904 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7757 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6888 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7735 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6879 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0678702592849731\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06166291115966452\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_15_loss: 0.0000e+00 - loss: 2.1777 - msle: 82.8414 - rmsle: 2.1398 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1113 - val_msle: 8.0449 - val_rmsle: 0.0959 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1024 - msle: 7.1108 - rmsle: 0.0897 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 5.5355 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0791 - msle: 5.3014 - rmsle: 0.0730 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.7211 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.6593 - rmsle: 0.0686 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.4294 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.3765 - rmsle: 0.0670 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.4014 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.2104 - rmsle: 0.0660 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.5446 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.1048 - rmsle: 0.0654 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.4932 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0324 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.3908 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9834 - rmsle: 0.0646 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2590 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9422 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1887 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9154 - rmsle: 0.0641 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1198 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8934 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1001 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8706 - rmsle: 0.0636 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1002 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8559 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.1393 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8404 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9503 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8257 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0445 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8148 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8410 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8041 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9154 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7939 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9053 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7850 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9266 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7712 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7594 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7649 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7513 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7589 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7652 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7563 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7606 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7478 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7105 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7479 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7036 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7424 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7069 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7432 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7025 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7370 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7022 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7367 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6939 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7371 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6966 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.0625223110472442\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_19_loss: 0.0000e+00 - loss: 2.1738 - msle: 82.7135 - rmsle: 2.1360 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1147 - val_msle: 7.9765 - val_rmsle: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1029 - msle: 7.1718 - rmsle: 0.0902 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 5.7032 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0796 - msle: 5.4543 - rmsle: 0.0734 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.8631 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0723 - msle: 4.7793 - rmsle: 0.0688 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.5626 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.4643 - rmsle: 0.0671 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.3683 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.2809 - rmsle: 0.0662 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.2690 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1553 - rmsle: 0.0654 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1657 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.0698 - rmsle: 0.0650 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.1441 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0051 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0946 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9580 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9969 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9225 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9319 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8946 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.9001 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8710 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8972 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8538 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8504 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8381 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8708 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8167 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8636 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8054 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8156 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7935 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7698 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7849 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8147 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7680 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7795 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7599 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8015 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7469 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7214 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7396 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7161 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7328 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7110 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7266 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7081 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7220 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7033 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7164 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7076 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7208 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6999 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7154 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6988 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7044 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6927 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7107 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6913 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06111540517091715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:28:53,287] Trial 17 finished with value: 0.06187185070901071 and parameters: {'units': 128, 'num_cross_layers': 3, 'activation': 'silu', 'reg': 0.0018307882110694326, 'do_rate': 0.32152010993315633, 'hidden_layers': 1}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.5091 - msle: 95.5990 - rmsle: 2.1939 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2626 - val_msle: 20.4468 - val_rmsle: 0.2180 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1370 - msle: 8.0869 - rmsle: 0.1037 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1386 - val_msle: 7.2857 - val_rmsle: 0.1225 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0953 - msle: 5.6409 - rmsle: 0.0809 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1134 - val_msle: 5.8560 - val_rmsle: 0.1027 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0853 - msle: 5.3413 - rmsle: 0.0755 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 4.6859 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0804 - msle: 5.1706 - rmsle: 0.0725 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1061 - val_msle: 7.7453 - val_rmsle: 0.0989 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0774 - msle: 5.0476 - rmsle: 0.0707 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1025 - val_msle: 6.3086 - val_rmsle: 0.0964 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0755 - msle: 4.9636 - rmsle: 0.0696 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0896 - val_msle: 6.1292 - val_rmsle: 0.0841 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0728 - msle: 4.7949 - rmsle: 0.0679 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.5496 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.7133 - rmsle: 0.0673 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 5.9849 - val_rmsle: 0.0773 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.6656 - rmsle: 0.0668 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.5299 - val_rmsle: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.6171 - rmsle: 0.0667 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.5365 - val_rmsle: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.4854 - rmsle: 0.0657 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.3446 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.4604 - rmsle: 0.0654 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.5725 - val_rmsle: 0.0700 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.4394 - rmsle: 0.0654 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.7545 - val_rmsle: 0.0691 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.4049 - rmsle: 0.0651 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.8706 - val_rmsle: 0.0731 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.3541 - rmsle: 0.0646 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8770 - val_rmsle: 0.0638 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.3156 - rmsle: 0.0643 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9881 - val_rmsle: 0.0638 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.3007 - rmsle: 0.0642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9923 - val_rmsle: 0.0645 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.3027 - rmsle: 0.0643 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.2339 - val_rmsle: 0.0647 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.2770 - rmsle: 0.0641 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0905 - val_rmsle: 0.0654 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.2357 - rmsle: 0.0638 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7381 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.2085 - rmsle: 0.0637 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7932 - val_rmsle: 0.0619 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2129 - rmsle: 0.0636 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9124 - val_rmsle: 0.0622 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.2016 - rmsle: 0.0635 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7646 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.1721 - rmsle: 0.0633 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6777 - val_rmsle: 0.0606 - learning_rate: 1.5625e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.1574 - rmsle: 0.0631 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6917 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.1485 - rmsle: 0.0631 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7343 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.1580 - rmsle: 0.0632 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7111 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.1596 - rmsle: 0.0631 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6762 - val_rmsle: 0.0604 - learning_rate: 7.8125e-06\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.1264 - rmsle: 0.0629 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6765 - val_rmsle: 0.0604 - learning_rate: 7.8125e-06\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1214 - rmsle: 0.0630 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6730 - val_rmsle: 0.0604 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06133799943527477\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_3_loss: 0.0000e+00 - loss: 2.5017 - msle: 95.4443 - rmsle: 2.1875 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2397 - val_msle: 20.7282 - val_rmsle: 0.1954 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1384 - msle: 8.4434 - rmsle: 0.1054 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1331 - val_msle: 6.4366 - val_rmsle: 0.1170 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0951 - msle: 5.6617 - rmsle: 0.0809 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0860 - val_msle: 4.3530 - val_rmsle: 0.0755 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0852 - msle: 5.3735 - rmsle: 0.0754 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0970 - val_msle: 5.9408 - val_rmsle: 0.0890 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0799 - msle: 5.2050 - rmsle: 0.0723 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0892 - val_msle: 6.2349 - val_rmsle: 0.0825 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0769 - msle: 5.0838 - rmsle: 0.0705 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1052 - val_msle: 8.7908 - val_rmsle: 0.0995 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.8996 - rmsle: 0.0685 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 4.9461 - val_rmsle: 0.0746 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0722 - msle: 4.8359 - rmsle: 0.0679 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.0602 - val_rmsle: 0.0752 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.7723 - rmsle: 0.0676 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.0723 - val_rmsle: 0.0767 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.7052 - rmsle: 0.0671 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.8768 - val_rmsle: 0.0688 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.6549 - rmsle: 0.0668 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.5375 - val_rmsle: 0.0702 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.5982 - rmsle: 0.0665 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 5.0510 - val_rmsle: 0.0735 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.5373 - rmsle: 0.0663 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 6.0954 - val_rmsle: 0.0769 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.4385 - rmsle: 0.0654 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.6837 - val_rmsle: 0.0693 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.3938 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.6144 - val_rmsle: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.3900 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.3976 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.3544 - rmsle: 0.0648 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.3199 - val_rmsle: 0.0732 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.3298 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.0541 - val_rmsle: 0.0733 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.2914 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.4489 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.2549 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9207 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.2222 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.1508 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.2173 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8101 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.1982 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2406 - val_rmsle: 0.0644 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.2015 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9164 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.1913 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7856 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.1642 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9036 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.1673 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 4.0221 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.1755 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.1439 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.1414 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8377 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.1221 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7541 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.1118 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8037 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.060977188318649025\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_5_loss: 0.0000e+00 - loss: 2.5131 - msle: 95.5311 - rmsle: 2.1973 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.2154 - val_msle: 19.2607 - val_rmsle: 0.1707 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1393 - msle: 8.6730 - rmsle: 0.1058 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1131 - val_msle: 8.7043 - val_rmsle: 0.0965 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0948 - msle: 5.6933 - rmsle: 0.0803 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0950 - val_msle: 8.3468 - val_rmsle: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0850 - msle: 5.3639 - rmsle: 0.0749 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 6.7725 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0801 - msle: 5.2011 - rmsle: 0.0722 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 5.5137 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0769 - msle: 5.0928 - rmsle: 0.0704 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 6.9043 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.9630 - rmsle: 0.0690 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 6.2132 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0727 - msle: 4.8512 - rmsle: 0.0679 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 5.9672 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.7503 - rmsle: 0.0672 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 5.4600 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.6496 - rmsle: 0.0668 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 6.9203 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.5936 - rmsle: 0.0665 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 5.7124 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.5063 - rmsle: 0.0662 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 6.0206 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.4585 - rmsle: 0.0659 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 6.1681 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.4045 - rmsle: 0.0657 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.6649 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.3385 - rmsle: 0.0653 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 6.7954 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.3004 - rmsle: 0.0651 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 5.0544 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.2674 - rmsle: 0.0651 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.7332 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.1834 - rmsle: 0.0643 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8193 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.1444 - rmsle: 0.0640 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8842 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.1170 - rmsle: 0.0638 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9668 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.1190 - rmsle: 0.0638 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.1908 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0670 - rmsle: 0.0633 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7211 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.0550 - rmsle: 0.0630 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7227 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0348 - rmsle: 0.0629 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6030 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0283 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6604 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0251 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6961 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0252 - rmsle: 0.0628 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6706 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0067 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7855 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0065 - rmsle: 0.0626 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6628 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9495 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6153 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.9487 - rmsle: 0.0621 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6053 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061329555444431555\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 2.5098 - msle: 95.5803 - rmsle: 2.1940 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.2474 - val_msle: 21.9341 - val_rmsle: 0.2025 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1383 - msle: 8.4774 - rmsle: 0.1048 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1462 - val_msle: 9.1439 - val_rmsle: 0.1299 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0955 - msle: 5.6340 - rmsle: 0.0811 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1172 - val_msle: 5.8338 - val_rmsle: 0.1066 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0861 - msle: 5.3735 - rmsle: 0.0762 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1400 - val_msle: 9.4427 - val_rmsle: 0.1317 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0815 - msle: 5.2530 - rmsle: 0.0735 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1004 - val_msle: 7.2678 - val_rmsle: 0.0934 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0778 - msle: 5.1240 - rmsle: 0.0712 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1063 - val_msle: 7.9119 - val_rmsle: 0.1005 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0756 - msle: 5.0147 - rmsle: 0.0699 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0936 - val_msle: 7.5926 - val_rmsle: 0.0882 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.8940 - rmsle: 0.0688 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1228 - val_msle: 12.1522 - val_rmsle: 0.1183 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0725 - msle: 4.7721 - rmsle: 0.0681 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1077 - val_msle: 9.5905 - val_rmsle: 0.1035 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0720 - msle: 4.6809 - rmsle: 0.0677 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 5.5146 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.6094 - rmsle: 0.0675 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1022 - val_msle: 8.7499 - val_rmsle: 0.0985 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.5347 - rmsle: 0.0669 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1084 - val_msle: 10.4153 - val_rmsle: 0.1049 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.4782 - rmsle: 0.0666 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1175 - val_msle: 11.5587 - val_rmsle: 0.1138 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.3444 - rmsle: 0.0657 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.5073 - val_rmsle: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.3142 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 5.1486 - val_rmsle: 0.0782 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.3028 - rmsle: 0.0653 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.8930 - val_rmsle: 0.0735 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.2552 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 7.0387 - val_rmsle: 0.0818 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1987 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 5.1093 - val_rmsle: 0.0742 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.1705 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.7911 - val_rmsle: 0.0715 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.1450 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.6080 - val_rmsle: 0.0688 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.1336 - rmsle: 0.0642 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 5.2658 - val_rmsle: 0.0743 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.1239 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.6285 - val_rmsle: 0.0692 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.1197 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.9265 - val_rmsle: 0.0733 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.0793 - rmsle: 0.0635 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8650 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0656 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9083 - val_rmsle: 0.0642 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0580 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0708 - val_rmsle: 0.0638 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0306 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9113 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0160 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6653 - val_rmsle: 0.0616 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0098 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6692 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 4.0054 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7025 - val_rmsle: 0.0613 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9957 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6757 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061972810528987975\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_9_loss: 0.0000e+00 - loss: 2.5083 - msle: 95.7278 - rmsle: 2.1933 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.2287 - val_msle: 19.5903 - val_rmsle: 0.1839 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.1377 - msle: 8.5401 - rmsle: 0.1046 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1305 - val_msle: 8.1131 - val_rmsle: 0.1144 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0952 - msle: 5.6748 - rmsle: 0.0809 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.1152 - val_msle: 5.5724 - val_rmsle: 0.1049 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0847 - msle: 5.3549 - rmsle: 0.0750 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 4.3512 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0798 - msle: 5.1820 - rmsle: 0.0721 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0865 - val_msle: 5.4334 - val_rmsle: 0.0797 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0772 - msle: 5.0967 - rmsle: 0.0706 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.4196 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.9629 - rmsle: 0.0694 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 5.1612 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0735 - msle: 4.8684 - rmsle: 0.0685 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.0171 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.7725 - rmsle: 0.0680 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9424 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.6488 - rmsle: 0.0678 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 5.8341 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.5707 - rmsle: 0.0674 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 7.0657 - val_rmsle: 0.0837 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.5137 - rmsle: 0.0671 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9942 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.3847 - rmsle: 0.0658 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7986 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.3275 - rmsle: 0.0654 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8011 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.3040 - rmsle: 0.0654 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0402 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.2653 - rmsle: 0.0650 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8900 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1919 - rmsle: 0.0644 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7656 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.1594 - rmsle: 0.0642 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7582 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.1596 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8819 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.1226 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6366 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.1264 - rmsle: 0.0639 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6809 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.1162 - rmsle: 0.0640 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7171 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0979 - rmsle: 0.0638 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7265 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0593 - rmsle: 0.0633 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6845 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.0534 - rmsle: 0.0630 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6868 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0643 - msle: 4.0309 - rmsle: 0.0630 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8223 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0218 - rmsle: 0.0629 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6309 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0642 - msle: 4.0196 - rmsle: 0.0630 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6854 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0640 - msle: 4.0176 - rmsle: 0.0628 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6553 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0100 - rmsle: 0.0628 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6157 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_9_loss: 0.0000e+00 - loss: 0.0639 - msle: 4.0095 - rmsle: 0.0628 - val_dense_9_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8267 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060606707645029664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:36:09,987] Trial 18 finished with value: 0.061244852274474605 and parameters: {'units': 256, 'num_cross_layers': 1, 'activation': 'relu', 'reg': 0.0008662761706323586, 'do_rate': 0.3715450530192932, 'hidden_layers': 3}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 1.9138 - msle: 85.9446 - rmsle: 1.7372 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1327 - val_msle: 6.8149 - val_rmsle: 0.0958 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1078 - msle: 5.2926 - rmsle: 0.0801 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0911 - val_msle: 4.6118 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0853 - msle: 4.8781 - rmsle: 0.0733 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 4.6126 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0789 - msle: 4.6727 - rmsle: 0.0704 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.2367 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0755 - msle: 4.5132 - rmsle: 0.0688 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.3183 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.3829 - rmsle: 0.0675 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.1550 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2845 - rmsle: 0.0665 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.1622 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.2025 - rmsle: 0.0660 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0295 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1120 - rmsle: 0.0652 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1781 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.0734 - rmsle: 0.0649 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.3696 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0260 - rmsle: 0.0645 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.0628 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0674 - msle: 3.9940 - rmsle: 0.0642 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.1467 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0671 - msle: 3.9795 - rmsle: 0.0640 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.5206 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9761 - rmsle: 0.0639 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.3859 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8946 - rmsle: 0.0629 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1962 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8769 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.1289 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8655 - rmsle: 0.0627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1363 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8508 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.1827 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8412 - rmsle: 0.0626 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9228 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8351 - rmsle: 0.0625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.0448 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8119 - rmsle: 0.0623 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.0042 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8167 - rmsle: 0.0624 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0862 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8000 - rmsle: 0.0622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.1582 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8044 - rmsle: 0.0622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9692 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7913 - rmsle: 0.0621 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9841 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7869 - rmsle: 0.0621 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9552 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7755 - rmsle: 0.0620 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9720 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7596 - rmsle: 0.0617 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8000 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7477 - rmsle: 0.0616 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8432 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7375 - rmsle: 0.0615 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7840 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7348 - rmsle: 0.0615 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8022 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06173491530775414\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_5_loss: 0.0000e+00 - loss: 1.9087 - msle: 85.7513 - rmsle: 1.7313 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.1291 - val_msle: 6.8073 - val_rmsle: 0.0909 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.1084 - msle: 5.3118 - rmsle: 0.0799 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0969 - val_msle: 4.6155 - val_rmsle: 0.0830 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0853 - msle: 4.8880 - rmsle: 0.0731 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0906 - val_msle: 4.6151 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0792 - msle: 4.6791 - rmsle: 0.0706 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.3000 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.5443 - rmsle: 0.0688 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.2880 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0734 - msle: 4.4173 - rmsle: 0.0676 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.4396 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.3107 - rmsle: 0.0667 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.2662 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.2154 - rmsle: 0.0658 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2622 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1474 - rmsle: 0.0652 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.1746 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.1073 - rmsle: 0.0649 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1721 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0665 - rmsle: 0.0644 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.1129 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0388 - rmsle: 0.0642 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0737 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0133 - rmsle: 0.0639 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.4026 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0133 - rmsle: 0.0638 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.1769 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9806 - rmsle: 0.0636 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1221 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9177 - rmsle: 0.0627 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9210 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8716 - rmsle: 0.0625 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9451 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8614 - rmsle: 0.0624 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8672 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8459 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9566 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8397 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8997 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8449 - rmsle: 0.0623 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8617 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8290 - rmsle: 0.0622 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8699 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8276 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8285 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8112 - rmsle: 0.0620 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8574 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7924 - rmsle: 0.0616 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.8124 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7772 - rmsle: 0.0615 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7705 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7725 - rmsle: 0.0614 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7920 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7628 - rmsle: 0.0614 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7811 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7552 - rmsle: 0.0613 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7587 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7537 - rmsle: 0.0613 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7693 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_5_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7602 - rmsle: 0.0614 - val_dense_5_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7757 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.060823493122678464\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_8_loss: 0.0000e+00 - loss: 1.9093 - msle: 85.8023 - rmsle: 1.7330 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.1510 - val_msle: 8.1214 - val_rmsle: 0.1137 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.1070 - msle: 5.3364 - rmsle: 0.0790 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0879 - val_msle: 5.0783 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0843 - msle: 4.8961 - rmsle: 0.0722 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0814 - val_msle: 4.2355 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0783 - msle: 4.6956 - rmsle: 0.0697 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.1178 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.5244 - rmsle: 0.0679 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.1218 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0725 - msle: 4.4003 - rmsle: 0.0668 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9455 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.3026 - rmsle: 0.0659 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9587 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.2147 - rmsle: 0.0653 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8464 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1452 - rmsle: 0.0647 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.0085 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.1079 - rmsle: 0.0644 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9966 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0422 - rmsle: 0.0640 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0444 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0154 - rmsle: 0.0636 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2915 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9511 - rmsle: 0.0627 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7390 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9375 - rmsle: 0.0626 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8654 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9244 - rmsle: 0.0624 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8392 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8993 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7707 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8855 - rmsle: 0.0622 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7616 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8862 - rmsle: 0.0621 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8475 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8853 - rmsle: 0.0620 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8000 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8413 - rmsle: 0.0615 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7334 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8242 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7010 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8147 - rmsle: 0.0613 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6719 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8222 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6857 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8072 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6722 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7982 - rmsle: 0.0612 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6859 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7794 - rmsle: 0.0609 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6231 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7705 - rmsle: 0.0607 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6403 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7665 - rmsle: 0.0606 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6135 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7611 - rmsle: 0.0606 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6010 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7600 - rmsle: 0.0607 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6140 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_8_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7664 - rmsle: 0.0606 - val_dense_8_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6095 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.0609208808893304\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 1.9187 - msle: 86.0340 - rmsle: 1.7424 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1249 - val_msle: 6.9342 - val_rmsle: 0.0879 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1074 - msle: 5.3375 - rmsle: 0.0797 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0891 - val_msle: 4.5058 - val_rmsle: 0.0755 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0852 - msle: 4.8922 - rmsle: 0.0731 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.6643 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0790 - msle: 4.6961 - rmsle: 0.0704 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.2373 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0757 - msle: 4.5200 - rmsle: 0.0688 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.3495 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0734 - msle: 4.4108 - rmsle: 0.0676 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.4528 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.3114 - rmsle: 0.0666 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.1182 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.2163 - rmsle: 0.0659 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0008 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1407 - rmsle: 0.0653 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1995 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.0798 - rmsle: 0.0649 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9565 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0458 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.0496 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0198 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9904 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0134 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.3357 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9313 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8678 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9143 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8277 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8999 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8678 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8866 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7633 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8708 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7916 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8642 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9019 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8637 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7753 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8247 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7021 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8054 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7223 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8041 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7199 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8018 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7017 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7945 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7611 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7888 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7001 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7920 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6753 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7816 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6999 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7845 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6970 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7743 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7049 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7617 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6271 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06145399778112521\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_14_loss: 0.0000e+00 - loss: 1.9167 - msle: 86.0333 - rmsle: 1.7404 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.1390 - val_msle: 7.4431 - val_rmsle: 0.1020 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.1069 - msle: 5.2954 - rmsle: 0.0793 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0951 - val_msle: 4.4182 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0850 - msle: 4.8656 - rmsle: 0.0729 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.3897 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0787 - msle: 4.6580 - rmsle: 0.0702 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.1769 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0755 - msle: 4.4917 - rmsle: 0.0686 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.1174 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.3988 - rmsle: 0.0675 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 3.9079 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2857 - rmsle: 0.0665 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.1062 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.2056 - rmsle: 0.0660 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9830 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1287 - rmsle: 0.0653 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1006 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.0755 - rmsle: 0.0648 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.1497 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0299 - rmsle: 0.0643 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9451 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0190 - rmsle: 0.0642 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.1746 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0672 - msle: 3.9951 - rmsle: 0.0641 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9197 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9795 - rmsle: 0.0637 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9016 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9514 - rmsle: 0.0635 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0110 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9123 - rmsle: 0.0633 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1172 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9087 - rmsle: 0.0632 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9353 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8823 - rmsle: 0.0630 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9713 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8269 - rmsle: 0.0623 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7254 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8129 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7469 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7978 - rmsle: 0.0621 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7240 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7876 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9513 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7819 - rmsle: 0.0620 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6781 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7726 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7587 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7680 - rmsle: 0.0618 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7278 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7783 - rmsle: 0.0619 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7137 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7361 - rmsle: 0.0613 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6695 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7326 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6357 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7223 - rmsle: 0.0613 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6571 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7347 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6160 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_14_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7202 - rmsle: 0.0614 - val_dense_14_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6114 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06047718251979246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:43:22,392] Trial 19 finished with value: 0.06108209392413614 and parameters: {'units': 512, 'num_cross_layers': 2, 'activation': 'prelu', 'reg': 0.0004815434124209812, 'do_rate': 0.4170021163912924, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7752 - msle: 80.4499 - rmsle: 1.6272 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1466 - val_msle: 7.5746 - val_rmsle: 0.1111 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1045 - msle: 5.6832 - rmsle: 0.0782 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 5.1729 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.6864 - rmsle: 0.0710 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.3989 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0755 - msle: 4.4203 - rmsle: 0.0685 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.0949 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.2956 - rmsle: 0.0669 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.0451 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.1909 - rmsle: 0.0658 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1008 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1250 - rmsle: 0.0653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.1216 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.0710 - rmsle: 0.0648 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9803 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0263 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9319 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9781 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8934 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9445 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9393 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9073 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2390 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8796 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9492 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8201 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9648 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7977 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8588 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7847 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 4.0026 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7695 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8969 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7598 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9202 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7578 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9523 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7446 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8789 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7153 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7274 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7052 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7341 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6931 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7232 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6859 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7126 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6876 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7204 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6954 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7131 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6816 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7279 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6610 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6773 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6567 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6821 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6610 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6861 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6557 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6816 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061165777256079926\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7684 - msle: 80.2403 - rmsle: 1.6209 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1633 - val_msle: 7.6028 - val_rmsle: 0.1280 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1039 - msle: 5.7084 - rmsle: 0.0777 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0848 - val_msle: 4.6888 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0806 - msle: 4.6859 - rmsle: 0.0703 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.2623 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.4420 - rmsle: 0.0677 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.0992 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.3218 - rmsle: 0.0663 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.9918 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.2343 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1062 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1633 - rmsle: 0.0648 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0088 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.1083 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0265 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0510 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8838 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.0044 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9896 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9576 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9360 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9345 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9782 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8908 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9574 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8822 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8802 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8511 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9744 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8339 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9227 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8305 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9729 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8164 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8824 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7989 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8859 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7651 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7840 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7410 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7558 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7261 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7866 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7322 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7485 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7270 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7684 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7209 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7150 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6964 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7308 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6912 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7187 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6899 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7421 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6852 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7094 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6887 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7242 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6871 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7393 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.0606667175883078\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7767 - msle: 80.4958 - rmsle: 1.6299 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1248 - val_msle: 6.9417 - val_rmsle: 0.0902 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1031 - msle: 5.8091 - rmsle: 0.0774 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.6166 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0804 - msle: 4.7374 - rmsle: 0.0702 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.0837 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.4527 - rmsle: 0.0676 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9938 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.3278 - rmsle: 0.0662 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.8755 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.2475 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9665 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1532 - rmsle: 0.0646 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8312 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0990 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.0993 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0435 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8022 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9876 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8907 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9757 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8390 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9278 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8798 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8533 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6542 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8264 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6627 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8140 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7542 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7943 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6881 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7916 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6673 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7777 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6682 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7724 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6444 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7652 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6826 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7527 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6408 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7295 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5850 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7192 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5831 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7149 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6281 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7095 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5856 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7060 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5714 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7120 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5702 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6964 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5746 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6966 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5905 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6809 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5555 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6944 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5458 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.060913831151377454\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7824 - msle: 80.6071 - rmsle: 1.6340 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1465 - val_msle: 7.8244 - val_rmsle: 0.1106 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1050 - msle: 5.8058 - rmsle: 0.0784 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.5526 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0816 - msle: 4.7268 - rmsle: 0.0710 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.6559 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0755 - msle: 4.4625 - rmsle: 0.0685 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.5213 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0725 - msle: 4.3113 - rmsle: 0.0670 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.4511 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2263 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.1317 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1461 - rmsle: 0.0653 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.5995 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0935 - rmsle: 0.0648 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.0136 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0364 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.5579 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 3.9824 - rmsle: 0.0640 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.5740 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9558 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2942 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9270 - rmsle: 0.0636 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1629 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.8890 - rmsle: 0.0634 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0823 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8770 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0991 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8513 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9563 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8253 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1736 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8069 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7900 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7953 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8129 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7924 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7269 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7777 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7158 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7756 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7372 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7663 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9245 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7614 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6746 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7500 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7731 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7546 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7094 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7446 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.6769 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7150 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6406 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7070 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6587 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6998 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6240 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7126 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6110 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6973 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6055 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061834756084305824\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7685 - msle: 80.3891 - rmsle: 1.6213 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1577 - val_msle: 7.8004 - val_rmsle: 0.1226 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1031 - msle: 5.7465 - rmsle: 0.0772 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.4926 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.6928 - rmsle: 0.0703 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.1144 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0748 - msle: 4.4227 - rmsle: 0.0679 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.0765 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.2958 - rmsle: 0.0663 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 3.9558 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.2112 - rmsle: 0.0656 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.8641 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1306 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8186 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0641 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9443 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0110 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8661 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9701 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.7972 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9313 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8713 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9004 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7850 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8689 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7199 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8498 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8412 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8171 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7430 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7975 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9421 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7758 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7929 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7737 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6945 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7658 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6714 - val_rmsle: 0.0607 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7453 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6672 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7491 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6881 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7320 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6944 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7012 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6281 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6856 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6348 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6798 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6232 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6872 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6425 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6780 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6057 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6802 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6318 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6763 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6290 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6725 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6103 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6544 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5848 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06041239539567378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:50:54,089] Trial 20 finished with value: 0.060998695495148955 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00038465468626069845, 'do_rate': 0.4269572453217638, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.8170 - msle: 80.6245 - rmsle: 1.6317 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1452 - val_msle: 7.4019 - val_rmsle: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1028 - msle: 5.6859 - rmsle: 0.0780 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.8848 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.7178 - rmsle: 0.0708 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.4445 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.4598 - rmsle: 0.0684 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.2777 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0723 - msle: 4.3155 - rmsle: 0.0667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.0522 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.2108 - rmsle: 0.0657 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0169 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1489 - rmsle: 0.0653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0592 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0843 - rmsle: 0.0647 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1480 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0349 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9201 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9790 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0707 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9647 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9612 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9157 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8986 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8851 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9173 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8695 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0379 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8418 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8583 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8278 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9833 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7947 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8579 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7871 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9219 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7743 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8338 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7759 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8022 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7556 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7930 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7471 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8969 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7277 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7857 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7256 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8097 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7360 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7702 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7322 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7741 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7154 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.7519 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7078 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7530 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7037 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7665 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6871 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7221 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6755 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7370 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06201570837349979\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.8071 - msle: 80.2315 - rmsle: 1.6218 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1584 - val_msle: 7.7744 - val_rmsle: 0.1247 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1027 - msle: 5.7159 - rmsle: 0.0780 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.5982 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.7441 - rmsle: 0.0708 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.5307 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0751 - msle: 4.4910 - rmsle: 0.0680 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.2310 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0722 - msle: 4.3601 - rmsle: 0.0666 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.0266 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.2576 - rmsle: 0.0657 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0820 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1883 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.3293 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1203 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0373 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0704 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0397 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0229 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9601 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9664 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.1063 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9445 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9691 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8951 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0528 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8877 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9494 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8606 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9254 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8317 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.0038 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8261 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0537 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7923 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8317 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7588 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8005 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7557 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7878 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7504 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8220 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7343 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7851 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7344 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7870 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7234 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7199 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7087 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7224 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7016 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7334 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6982 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7358 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6948 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7455 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6891 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.7039 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6788 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7090 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6683 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.7041 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06059948923352933\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.8117 - msle: 80.3711 - rmsle: 1.6277 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1447 - val_msle: 7.3971 - val_rmsle: 0.1120 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1024 - msle: 5.8488 - rmsle: 0.0782 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 4.6498 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.7835 - rmsle: 0.0704 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.1183 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.4908 - rmsle: 0.0677 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.0734 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.3667 - rmsle: 0.0662 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9329 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.2640 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9632 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1783 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0914 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1059 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.2511 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0565 - rmsle: 0.0637 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8405 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0100 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7520 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9830 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7578 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9422 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7584 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9167 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8053 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8885 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7618 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8603 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.2150 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7915 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6934 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7686 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6690 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7592 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6420 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7574 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6692 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7453 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6775 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7324 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6197 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7293 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6627 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7376 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6161 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7323 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6601 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6959 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5733 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6922 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5614 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6969 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5879 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6848 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5797 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6785 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5631 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6824 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5745 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6903 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5503 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06112304001581758\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.8270 - msle: 80.7014 - rmsle: 1.6400 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1501 - val_msle: 7.8319 - val_rmsle: 0.1162 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1041 - msle: 5.7818 - rmsle: 0.0792 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 5.0320 - val_rmsle: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0821 - msle: 4.7509 - rmsle: 0.0715 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.6729 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.4817 - rmsle: 0.0686 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.2906 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0730 - msle: 4.3383 - rmsle: 0.0671 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.7949 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.2480 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.6988 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.1741 - rmsle: 0.0655 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.9073 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.1141 - rmsle: 0.0649 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.5701 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0649 - rmsle: 0.0647 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.4095 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9953 - rmsle: 0.0641 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.4645 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9756 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.2533 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9418 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.2861 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9013 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1414 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8790 - rmsle: 0.0632 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1711 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8592 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8911 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8334 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9557 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8079 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8101 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8098 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7998 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8029 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7835 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7849 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7299 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7807 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7539 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7790 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8196 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7405 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6475 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7327 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6510 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7247 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6218 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7150 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6265 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7149 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6272 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7142 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6384 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6958 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6114 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6980 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6187 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6778 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6119 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061754965713058455\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.8133 - msle: 80.6036 - rmsle: 1.6284 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1661 - val_msle: 7.9604 - val_rmsle: 0.1329 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1017 - msle: 5.7244 - rmsle: 0.0773 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 4.4453 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0811 - msle: 4.7128 - rmsle: 0.0706 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.1598 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0752 - msle: 4.4704 - rmsle: 0.0680 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 3.9748 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.3364 - rmsle: 0.0667 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9393 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.2337 - rmsle: 0.0658 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9634 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1671 - rmsle: 0.0652 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.1327 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.0854 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8792 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0176 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8636 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9857 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0004 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9476 - rmsle: 0.0635 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8526 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9089 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8173 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8786 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8017 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8506 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7947 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8245 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8098 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8130 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7827 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7907 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9189 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7400 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6884 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7308 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6842 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7224 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6736 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7170 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6520 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7029 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6726 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7103 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6667 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.6983 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6408 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6979 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6776 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6967 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6245 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6976 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6367 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6856 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6394 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6824 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6797 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6612 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5901 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6583 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6144 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06054822335180013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 18:58:27,235] Trial 21 finished with value: 0.06120828533754106 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.0005198929291621279, 'do_rate': 0.44900820303593847, 'hidden_layers': 2}. Best is trial 5 with value: 0.060933745708927754.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7584 - msle: 80.5434 - rmsle: 1.6278 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1472 - val_msle: 7.3746 - val_rmsle: 0.1105 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1052 - msle: 5.7287 - rmsle: 0.0778 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 4.7031 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.6900 - rmsle: 0.0709 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.4894 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0750 - msle: 4.4153 - rmsle: 0.0683 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.2111 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.2803 - rmsle: 0.0667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0653 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.1778 - rmsle: 0.0656 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9719 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1235 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1569 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0621 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0406 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0120 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0555 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9616 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9249 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9390 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0989 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.8979 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9962 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8707 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9961 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8646 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.0099 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8341 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9030 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8074 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8944 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.7940 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8130 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7787 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9656 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7661 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8979 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7245 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8182 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7053 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7641 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7039 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8733 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.6977 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8114 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6850 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7588 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6683 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7013 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6618 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6923 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6570 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6950 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6533 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7056 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6546 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6931 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6492 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6696 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6345 - rmsle: 0.0606 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6741 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061103510722401305\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7480 - msle: 80.1681 - rmsle: 1.6185 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1497 - val_msle: 7.3809 - val_rmsle: 0.1142 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1044 - msle: 5.6657 - rmsle: 0.0778 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0824 - val_msle: 4.5474 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.6761 - rmsle: 0.0703 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 4.4338 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.4326 - rmsle: 0.0677 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1736 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.3034 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.0156 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.2184 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1871 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1480 - rmsle: 0.0647 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.1023 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0949 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0911 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0389 - rmsle: 0.0639 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0590 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9941 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9777 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9533 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9767 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9277 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9983 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8941 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0445 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8729 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0012 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8506 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9481 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8286 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9044 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8263 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9798 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8053 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9301 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8015 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9356 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7619 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7712 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7356 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7579 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7270 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8054 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7283 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7484 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7218 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7801 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7133 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7113 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6924 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7152 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6826 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7215 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6841 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7205 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6835 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6992 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6820 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7070 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6748 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7159 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06066698068995525\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7592 - msle: 80.4952 - rmsle: 1.6297 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1219 - val_msle: 6.7202 - val_rmsle: 0.0863 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1038 - msle: 5.7531 - rmsle: 0.0772 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.5493 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0805 - msle: 4.7185 - rmsle: 0.0700 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.1221 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.4375 - rmsle: 0.0675 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.9738 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.3030 - rmsle: 0.0661 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.8320 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.2372 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8090 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1485 - rmsle: 0.0646 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9531 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0745 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.2949 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0344 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9728 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9905 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8118 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9639 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8390 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9348 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7735 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8975 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7755 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8776 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8230 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8453 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8889 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7843 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6201 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7654 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6451 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7570 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6162 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7510 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6913 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7445 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6538 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7378 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6552 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7160 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5859 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7085 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5997 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6995 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5878 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7039 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5906 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7008 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5711 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7008 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5561 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6850 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5655 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6763 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5497 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6637 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5456 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6803 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5516 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06078439365681302\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7624 - msle: 80.7139 - rmsle: 1.6327 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1369 - val_msle: 7.2324 - val_rmsle: 0.1011 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1047 - msle: 5.7951 - rmsle: 0.0778 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 4.6185 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0809 - msle: 4.6939 - rmsle: 0.0704 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.3976 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.4337 - rmsle: 0.0679 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.2263 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.2929 - rmsle: 0.0665 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.1491 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.2155 - rmsle: 0.0657 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9320 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1308 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1285 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0779 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0141 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0225 - rmsle: 0.0641 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.4509 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9725 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1662 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9571 - rmsle: 0.0636 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.5009 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8831 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9292 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8517 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8884 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8465 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1073 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8248 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8315 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8181 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7786 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7937 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8503 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7920 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7387 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7911 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7632 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7824 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6667 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7797 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7163 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7709 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7613 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7662 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6727 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7364 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6221 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7231 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6112 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7145 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6122 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7109 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6020 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7195 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6042 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7012 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6163 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7201 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6143 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7034 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5954 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06152147029485209\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7524 - msle: 80.4931 - rmsle: 1.6230 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1512 - val_msle: 7.3749 - val_rmsle: 0.1160 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1029 - msle: 5.6978 - rmsle: 0.0768 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 4.4254 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.6783 - rmsle: 0.0703 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.0830 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.4195 - rmsle: 0.0678 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9789 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.2862 - rmsle: 0.0664 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9757 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.2056 - rmsle: 0.0656 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.8846 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1291 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8129 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0620 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8149 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0064 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8325 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9663 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7619 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9289 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8101 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8998 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7674 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8729 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7645 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8414 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7710 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8228 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7192 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8055 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8763 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7755 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9978 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7743 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6849 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7631 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7563 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7633 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6907 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7572 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6965 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7365 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8303 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7319 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7265 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.6926 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6170 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6741 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6263 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6862 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6314 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6696 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6141 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6766 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6294 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6521 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5864 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6477 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.5922 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6426 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5804 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06031996775235883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:06:04,778] Trial 22 finished with value: 0.0608792646232761 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00032633282400151235, 'do_rate': 0.4211676501468306, 'hidden_layers': 2}. Best is trial 22 with value: 0.0608792646232761.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7582 - msle: 80.7371 - rmsle: 1.6330 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1525 - val_msle: 7.4429 - val_rmsle: 0.1161 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1054 - msle: 5.7766 - rmsle: 0.0782 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 4.8934 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.6956 - rmsle: 0.0709 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.2927 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0752 - msle: 4.4113 - rmsle: 0.0684 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.1769 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0719 - msle: 4.2892 - rmsle: 0.0667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2746 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.1949 - rmsle: 0.0656 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0301 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1348 - rmsle: 0.0653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2864 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0677 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9464 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0090 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9694 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9726 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9212 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9419 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1345 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.8994 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0178 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8334 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8532 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8239 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8466 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8078 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9330 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7900 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9741 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7765 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8779 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7678 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8498 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7656 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9151 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7586 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9382 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7274 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7411 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7140 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7752 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7066 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7141 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6908 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7218 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6971 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7552 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7005 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7025 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6864 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7262 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6689 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6852 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6660 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6879 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6743 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6859 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6615 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6885 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061121458715008986\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7490 - msle: 80.3112 - rmsle: 1.6240 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1479 - val_msle: 7.2523 - val_rmsle: 0.1115 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1046 - msle: 5.7015 - rmsle: 0.0774 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.5584 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.6957 - rmsle: 0.0703 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.3477 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.4314 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.1646 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.3113 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.0191 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.2232 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1102 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1573 - rmsle: 0.0648 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.2666 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.1026 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9170 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0397 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9833 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9912 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0073 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9529 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0890 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9239 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9425 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8831 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9769 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8731 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9349 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8535 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9321 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8302 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9196 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8265 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 4.0477 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8125 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 4.0571 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7702 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7838 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7446 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7721 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7387 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7774 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7258 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7810 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7255 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7505 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7109 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7118 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7072 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7153 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6954 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7141 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6917 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7102 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6884 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7224 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6921 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7014 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6897 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7177 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6896 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7286 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06068255124082454\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7548 - msle: 80.5157 - rmsle: 1.6303 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1279 - val_msle: 6.7845 - val_rmsle: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1037 - msle: 5.7989 - rmsle: 0.0772 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 4.5949 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0803 - msle: 4.7291 - rmsle: 0.0700 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.1069 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4358 - rmsle: 0.0674 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.9276 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.2982 - rmsle: 0.0659 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9421 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.2246 - rmsle: 0.0650 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8439 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.1460 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8689 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0754 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9633 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0190 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0440 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9779 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7535 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9543 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9925 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9270 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7963 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9002 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8443 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8266 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6329 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7918 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7494 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7857 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6339 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7714 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6322 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7676 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6122 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7572 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7201 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7557 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6823 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7125 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5878 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7150 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5829 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7157 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5797 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7130 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6068 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6973 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5544 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6888 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5485 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6893 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5454 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6822 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5447 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6791 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5431 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6752 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5471 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6819 - rmsle: 0.0599 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5445 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06055841758736592\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7630 - msle: 80.6633 - rmsle: 1.6373 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1407 - val_msle: 7.5080 - val_rmsle: 0.1040 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1062 - msle: 5.8190 - rmsle: 0.0786 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 4.5177 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.7289 - rmsle: 0.0709 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.4013 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0751 - msle: 4.4519 - rmsle: 0.0683 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.3243 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0721 - msle: 4.2958 - rmsle: 0.0668 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.3614 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.2132 - rmsle: 0.0660 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.1965 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1393 - rmsle: 0.0652 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.9043 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0843 - rmsle: 0.0646 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9134 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0312 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.7084 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9751 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.1508 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9519 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.3876 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8772 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9847 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8486 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.0390 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8433 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.4094 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8228 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.0913 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7888 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7058 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7685 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7111 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7687 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6590 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7726 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6445 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7658 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6238 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7654 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6368 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7576 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6840 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7473 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6092 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7460 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6406 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7459 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6076 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7382 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6200 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7241 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5959 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7164 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6073 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7045 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6016 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7193 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6043 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7052 - rmsle: 0.0609 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5898 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06128471555052064\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7466 - msle: 80.4525 - rmsle: 1.6220 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1520 - val_msle: 7.5408 - val_rmsle: 0.1163 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1037 - msle: 5.7405 - rmsle: 0.0769 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 4.4443 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0810 - msle: 4.6861 - rmsle: 0.0704 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.0606 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.4318 - rmsle: 0.0678 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0663 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.2914 - rmsle: 0.0664 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 3.9614 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.2060 - rmsle: 0.0657 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8573 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1302 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8030 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0629 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8079 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0047 - rmsle: 0.0638 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8030 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9569 - rmsle: 0.0635 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7399 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9339 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7870 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8915 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7723 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8620 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7477 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8484 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7990 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8120 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7295 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.7999 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8143 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7749 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8997 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7714 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7444 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7646 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6791 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7504 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6607 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7517 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6604 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7300 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7245 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7323 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6699 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.6902 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6285 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6801 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6134 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6825 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6293 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6782 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6138 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6736 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6180 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6480 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5815 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6435 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.5883 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6464 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5975 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06036097630750333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:13:38,211] Trial 23 finished with value: 0.06080162388024468 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00031027452415022987, 'do_rate': 0.4258388710735644, 'hidden_layers': 2}. Best is trial 23 with value: 0.06080162388024468.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7140 - msle: 80.7654 - rmsle: 1.6343 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1333 - val_msle: 6.9548 - val_rmsle: 0.0980 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1058 - msle: 5.7742 - rmsle: 0.0778 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 4.5234 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0824 - msle: 4.6717 - rmsle: 0.0707 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.1846 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.3872 - rmsle: 0.0682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.1178 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.2549 - rmsle: 0.0667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0313 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1599 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0109 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.1075 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9678 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0458 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9533 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9977 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8982 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9482 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8711 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9213 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9204 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8845 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9409 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8502 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8724 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8425 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8706 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8248 - rmsle: 0.0627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8472 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8053 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8617 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7855 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9702 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7667 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9366 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7269 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8393 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7140 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8417 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7068 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7508 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7087 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7628 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.6960 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7388 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.6891 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7413 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6857 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7710 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6885 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7512 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6658 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7008 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6542 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6846 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6570 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6836 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6650 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6823 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6539 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7128 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06128857474937749\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7071 - msle: 80.4983 - rmsle: 1.6275 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1276 - val_msle: 6.6684 - val_rmsle: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1048 - msle: 5.6777 - rmsle: 0.0772 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 4.6036 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0816 - msle: 4.6611 - rmsle: 0.0702 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.1440 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.3972 - rmsle: 0.0675 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0709 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2779 - rmsle: 0.0661 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9494 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1976 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9866 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1313 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9574 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0684 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8552 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0163 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8464 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9719 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8599 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9320 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8525 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9153 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8907 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8700 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8801 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8608 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8850 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8426 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8777 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8231 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8685 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8136 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8696 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7957 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8467 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7953 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8640 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7870 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8303 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7691 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8774 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7616 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8421 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7580 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8680 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7477 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8180 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7394 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7499 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7133 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7693 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6986 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7616 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7017 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7363 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6918 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7454 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6961 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7542 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6944 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7411 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06108268104347417\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7096 - msle: 80.5516 - rmsle: 1.6303 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1127 - val_msle: 6.5038 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1041 - msle: 5.8000 - rmsle: 0.0770 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 4.5783 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0814 - msle: 4.7165 - rmsle: 0.0700 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.0156 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.4179 - rmsle: 0.0675 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9400 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2843 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8317 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.2009 - rmsle: 0.0651 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8048 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.1242 - rmsle: 0.0644 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7666 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0547 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9613 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0075 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7525 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9570 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6976 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9389 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7622 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9008 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7901 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8764 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7817 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8083 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6210 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7912 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6778 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7802 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6188 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7708 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6276 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7619 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6237 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7606 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6285 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7303 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5771 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7115 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5954 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7175 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5588 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7190 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5705 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7140 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5828 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7097 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5700 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7001 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5472 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7055 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5482 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6886 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5482 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6844 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5438 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6749 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5500 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6988 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5448 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.0606078372502736\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7101 - msle: 80.6874 - rmsle: 1.6307 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1226 - val_msle: 6.8112 - val_rmsle: 0.0881 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1054 - msle: 5.8614 - rmsle: 0.0782 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 4.5024 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.7127 - rmsle: 0.0707 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.2493 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0748 - msle: 4.4211 - rmsle: 0.0682 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.2183 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2630 - rmsle: 0.0666 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.0017 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.1895 - rmsle: 0.0658 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8802 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1171 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0350 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0641 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9206 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0078 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.4558 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9278 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9427 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9071 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 4.1147 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8878 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8926 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8645 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8262 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8559 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.2196 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8317 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8571 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8261 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8963 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8116 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9444 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8070 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8110 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7818 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6502 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7690 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6159 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7638 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6191 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7627 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6570 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7522 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6082 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7465 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6154 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7507 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6305 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7456 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6125 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7254 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5969 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7194 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6025 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7057 - rmsle: 0.0609 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5882 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7244 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5954 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7132 - rmsle: 0.0609 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6017 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06124536720886965\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7042 - msle: 80.6123 - rmsle: 1.6248 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1353 - val_msle: 6.7792 - val_rmsle: 0.1009 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1038 - msle: 5.7182 - rmsle: 0.0767 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 4.3389 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0811 - msle: 4.6472 - rmsle: 0.0699 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.0132 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.3752 - rmsle: 0.0675 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.9168 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2477 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8929 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1622 - rmsle: 0.0652 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8654 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0954 - rmsle: 0.0646 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8365 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0327 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8798 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9760 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7762 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9346 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7066 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9089 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7395 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8748 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7255 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8416 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7122 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8236 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7744 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8047 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7516 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7517 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6295 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7341 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6607 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7368 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6419 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7250 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6403 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7063 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6079 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6967 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5994 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6895 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6109 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6931 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5980 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6836 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6069 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6809 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6066 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6676 - rmsle: 0.0606 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5849 - val_rmsle: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6602 - rmsle: 0.0606 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5759 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6575 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5850 - val_rmsle: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6525 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5811 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6497 - rmsle: 0.0604 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5734 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6581 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5815 - val_rmsle: 0.0593 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.05996483974444578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:21:10,296] Trial 24 finished with value: 0.06083785999928813 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00017745000725989457, 'do_rate': 0.410382676976832, 'hidden_layers': 2}. Best is trial 23 with value: 0.06080162388024468.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 13ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7119 - msle: 80.6764 - rmsle: 1.6323 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1332 - val_msle: 7.0241 - val_rmsle: 0.0979 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1061 - msle: 5.7969 - rmsle: 0.0781 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 4.5855 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0824 - msle: 4.6829 - rmsle: 0.0708 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2145 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.3916 - rmsle: 0.0682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.1084 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.2695 - rmsle: 0.0668 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0682 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1616 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0142 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1027 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0658 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0411 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9734 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 3.9976 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9779 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9544 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8783 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9261 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0594 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8863 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9097 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8536 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8993 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8066 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8763 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7894 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8631 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7697 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9801 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7676 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8738 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7530 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8195 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7411 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8193 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7435 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8523 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7352 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8238 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7341 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8434 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7272 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7660 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7149 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.8483 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7077 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.8100 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7104 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8321 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7071 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7984 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6807 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6890 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6704 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7014 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6767 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6923 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6674 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7100 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06125871823266828\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7082 - msle: 80.5865 - rmsle: 1.6287 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1330 - val_msle: 6.7706 - val_rmsle: 0.0981 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1052 - msle: 5.7290 - rmsle: 0.0776 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 4.6485 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0816 - msle: 4.6690 - rmsle: 0.0702 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.1821 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3931 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.1431 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2764 - rmsle: 0.0661 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9845 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1994 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9442 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1333 - rmsle: 0.0647 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9918 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0691 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9471 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0186 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8760 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9748 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8741 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9369 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8610 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9107 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9207 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8720 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8508 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8585 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8477 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8359 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8327 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8214 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8739 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8122 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8942 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7725 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7836 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7516 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7660 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7441 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7689 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7328 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7509 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7300 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7671 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7259 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7515 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7269 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7336 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7295 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7481 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7220 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7302 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7042 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7393 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7007 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7037 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6836 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7008 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6862 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7038 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6813 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7113 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06061924396528569\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 14ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7076 - msle: 80.4613 - rmsle: 1.6284 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1146 - val_msle: 6.4357 - val_rmsle: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1037 - msle: 5.7659 - rmsle: 0.0768 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 4.5424 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0811 - msle: 4.6957 - rmsle: 0.0699 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.0194 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.4150 - rmsle: 0.0674 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0094 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2899 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8572 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1984 - rmsle: 0.0649 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8699 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.1243 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7694 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0444 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8595 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0089 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8019 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9601 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7593 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9357 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7803 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9043 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8468 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8695 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7219 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8498 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7055 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8278 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8701 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06282006994207857\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7102 - msle: 80.6693 - rmsle: 1.6309 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1222 - val_msle: 6.7788 - val_rmsle: 0.0877 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1053 - msle: 5.8430 - rmsle: 0.0781 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.4883 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.7018 - rmsle: 0.0706 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.1447 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.4232 - rmsle: 0.0683 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.1166 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2634 - rmsle: 0.0665 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.1056 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0697 - msle: 4.1905 - rmsle: 0.0658 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 3.9551 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1159 - rmsle: 0.0650 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9923 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0615 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0181 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0070 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.3471 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9557 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9713 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9313 - rmsle: 0.0636 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2267 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9005 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9956 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8710 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9342 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8557 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3478 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8265 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8504 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8091 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8365 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7898 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7247 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7844 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7787 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7774 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8032 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7704 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6828 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7617 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6876 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7632 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7485 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7515 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6741 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7458 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7355 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7491 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6649 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7323 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6880 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7320 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6933 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7272 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6464 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7154 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7243 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7200 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6485 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7205 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6464 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.062278403535020864\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7027 - msle: 80.6128 - rmsle: 1.6235 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1330 - val_msle: 6.8328 - val_rmsle: 0.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1039 - msle: 5.7127 - rmsle: 0.0767 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 4.4186 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.6482 - rmsle: 0.0699 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 3.9960 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.3681 - rmsle: 0.0674 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9292 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2475 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8738 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1571 - rmsle: 0.0651 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7973 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0896 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8008 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0310 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7906 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9744 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7630 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9351 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6952 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9093 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8466 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8716 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7120 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8410 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7297 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8211 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8069 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8038 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8908 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7638 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6395 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7328 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7266 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7359 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6506 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7298 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6545 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7239 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6323 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7226 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6449 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6877 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6088 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6906 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6044 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6842 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6013 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6757 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6195 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6723 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5797 - val_rmsle: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6554 - rmsle: 0.0606 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5745 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6521 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5861 - val_rmsle: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6517 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5781 - val_rmsle: 0.0591 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6501 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5772 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6542 - rmsle: 0.0604 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5856 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.05994029749689039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:28:12,215] Trial 25 finished with value: 0.061383346634388755 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00017691705851701286, 'do_rate': 0.4112137149783216, 'hidden_layers': 2}. Best is trial 23 with value: 0.06080162388024468.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7002 - msle: 83.0344 - rmsle: 1.6950 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 7.0536 - val_rmsle: 0.0829 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0849 - msle: 6.1922 - rmsle: 0.0802 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.8479 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.8197 - rmsle: 0.0703 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.3973 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.4725 - rmsle: 0.0675 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.2001 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.3082 - rmsle: 0.0662 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.1494 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.1939 - rmsle: 0.0653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0563 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.1068 - rmsle: 0.0646 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0625 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 4.0390 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.2451 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9826 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.2722 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9341 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9693 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9075 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9731 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8863 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0353 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8663 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9745 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8413 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0203 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8275 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8434 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8118 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8771 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7977 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8790 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7907 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8341 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7842 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8670 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7771 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8418 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7708 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8520 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7647 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7870 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7561 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7845 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7494 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7920 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7509 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7815 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7477 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7699 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7485 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7673 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7418 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7662 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7460 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7664 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7399 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7588 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7411 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7585 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06147471899288878\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_7_loss: 0.0000e+00 - loss: 1.6949 - msle: 82.8957 - rmsle: 1.6898 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 7.1672 - val_rmsle: 0.0844 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0849 - msle: 6.2352 - rmsle: 0.0800 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.1235 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0733 - msle: 4.8496 - rmsle: 0.0701 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.6098 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.5053 - rmsle: 0.0674 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4857 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.3227 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.4521 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.2071 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.5133 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.1204 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.5995 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0529 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.8510 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9970 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1890 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9554 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1502 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9276 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.2026 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.9104 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.1748 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8841 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.1478 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8633 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.2394 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8508 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.2263 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8345 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0825 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8175 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.0901 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8096 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.1287 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7970 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.1451 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7797 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8891 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7748 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8799 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7667 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8891 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7673 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8658 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7609 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8756 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7550 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8521 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7513 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8952 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7491 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.8013 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7495 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7931 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7427 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7972 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7418 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.8025 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7422 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.8041 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.0611884579432301\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_11_loss: 0.0000e+00 - loss: 1.6948 - msle: 82.8288 - rmsle: 1.6897 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0951 - val_msle: 7.1790 - val_rmsle: 0.0895 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0846 - msle: 6.2064 - rmsle: 0.0797 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.7920 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0730 - msle: 4.8300 - rmsle: 0.0696 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4395 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.4978 - rmsle: 0.0671 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.2747 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.3101 - rmsle: 0.0656 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1145 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.2099 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0289 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.1145 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9679 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 4.0541 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8692 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9897 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8506 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9516 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8265 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.9104 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8115 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8816 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8119 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8541 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8984 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8374 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7212 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8164 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8463 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8012 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6736 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7894 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7291 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7762 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6912 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7704 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.6499 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7521 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6397 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7355 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6228 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7245 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6263 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7291 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6322 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7241 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6207 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7148 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5995 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7058 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5993 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7079 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6016 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7056 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5930 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6992 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5919 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6951 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5899 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6955 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5891 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06097601962995574\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_15_loss: 0.0000e+00 - loss: 1.6964 - msle: 82.9801 - rmsle: 1.6912 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0895 - val_msle: 7.0516 - val_rmsle: 0.0841 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0852 - msle: 6.2152 - rmsle: 0.0805 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.7952 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0735 - msle: 4.8471 - rmsle: 0.0702 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.3209 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.4879 - rmsle: 0.0675 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2230 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.3223 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2284 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.2117 - rmsle: 0.0654 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.2839 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.1221 - rmsle: 0.0647 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4650 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.0517 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9959 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.0118 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0028 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9783 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.0472 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9446 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1721 - val_rmsle: 0.0668 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9155 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8119 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.9023 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8086 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8839 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8235 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8739 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8407 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8617 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7547 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8510 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7372 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8486 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7454 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8377 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7427 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8377 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7287 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8319 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7171 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8250 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7141 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8209 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7114 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8237 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7113 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8142 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7079 - val_rmsle: 0.0610 - learning_rate: 1.5625e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8165 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7072 - val_rmsle: 0.0610 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8112 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7066 - val_rmsle: 0.0610 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8123 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7062 - val_rmsle: 0.0610 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8110 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7043 - val_rmsle: 0.0609 - learning_rate: 7.8125e-06\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8127 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7042 - val_rmsle: 0.0609 - learning_rate: 7.8125e-06\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8128 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7038 - val_rmsle: 0.0609 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06189050641729585\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_19_loss: 0.0000e+00 - loss: 1.6989 - msle: 83.0752 - rmsle: 1.6937 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0912 - val_msle: 7.1729 - val_rmsle: 0.0857 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0845 - msle: 6.1725 - rmsle: 0.0797 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.7464 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0732 - msle: 4.7969 - rmsle: 0.0700 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.3575 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.4698 - rmsle: 0.0673 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1720 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.2890 - rmsle: 0.0659 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0320 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.1774 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9462 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0857 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9174 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 4.0268 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8662 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9754 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8834 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9238 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7826 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9008 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7856 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8802 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7649 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8593 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7563 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8379 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7441 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8222 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7330 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8167 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7259 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7998 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7178 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7831 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7368 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7762 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7013 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7672 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6991 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7548 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7018 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7508 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6926 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7363 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6807 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7284 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6832 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7260 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6724 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7230 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6670 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7213 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6727 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7135 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6676 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7100 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6641 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7057 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6592 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7061 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6537 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060567737005677504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:35:12,304] Trial 26 finished with value: 0.061219487997809595 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00016584131065920419, 'do_rate': 0.43510140536449987, 'hidden_layers': 1}. Best is trial 23 with value: 0.06080162388024468.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 18s 15ms/step - dense_3_loss: 0.0000e+00 - loss: 1.8348 - msle: 81.3125 - rmsle: 1.5925 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1711 - val_msle: 8.4260 - val_rmsle: 0.1129 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1248 - msle: 6.1372 - rmsle: 0.0826 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0909 - val_msle: 5.0369 - val_rmsle: 0.0734 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0874 - msle: 5.0077 - rmsle: 0.0727 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0873 - val_msle: 5.0204 - val_rmsle: 0.0778 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0779 - msle: 4.6587 - rmsle: 0.0692 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 5.0011 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.5036 - rmsle: 0.0676 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.3086 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.3774 - rmsle: 0.0664 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.1808 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.2761 - rmsle: 0.0656 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.4058 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1931 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.8615 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.1132 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2390 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0263 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.1865 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0671 - msle: 3.9978 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0574 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0672 - msle: 3.9524 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.0332 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.8955 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.1671 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.8956 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9820 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.8607 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 3.8769 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.7802 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7705 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7716 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7675 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7688 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7886 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7610 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7959 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7672 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7942 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7415 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8345 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7421 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7879 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7255 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7590 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7173 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7493 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7197 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7572 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7322 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7371 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7059 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 4.1258 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.6961 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7048 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6689 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7006 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6690 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6918 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6662 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7214 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06190610668396229\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 14ms/step - dense_7_loss: 0.0000e+00 - loss: 1.8334 - msle: 81.2603 - rmsle: 1.5907 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.2054 - val_msle: 8.5176 - val_rmsle: 0.1475 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1236 - msle: 5.9739 - rmsle: 0.0819 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0988 - val_msle: 5.1030 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0864 - msle: 4.9647 - rmsle: 0.0720 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 5.2893 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0774 - msle: 4.6624 - rmsle: 0.0689 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 6.0573 - val_rmsle: 0.0770 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.5173 - rmsle: 0.0672 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.5028 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.4081 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.6513 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.2777 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 5.6601 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1895 - rmsle: 0.0649 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 5.1794 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1260 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0085 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0532 - rmsle: 0.0639 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.5351 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0136 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.8969 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9842 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8844 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9264 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0115 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9164 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9329 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8802 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0288 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8943 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0022 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8720 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9736 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8521 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9205 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8366 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9407 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8253 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9371 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8380 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0020 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8040 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0583 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8070 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9823 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8077 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8762 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7909 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0484 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7772 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9429 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7617 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8863 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7716 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8474 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7633 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8758 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7525 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8830 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7457 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8715 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06216864849933518\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 14ms/step - dense_11_loss: 0.0000e+00 - loss: 1.8285 - msle: 80.9674 - rmsle: 1.5869 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1781 - val_msle: 8.0524 - val_rmsle: 0.1207 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1224 - msle: 6.0711 - rmsle: 0.0810 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0873 - val_msle: 4.5870 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0857 - msle: 4.9896 - rmsle: 0.0713 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.2099 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0768 - msle: 4.6445 - rmsle: 0.0681 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.8059 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.5088 - rmsle: 0.0669 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.1334 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.3666 - rmsle: 0.0655 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.7990 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.2792 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1837 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.1551 - rmsle: 0.0642 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8113 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1129 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1882 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0474 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.7509 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9801 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8339 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9449 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0019 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9207 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7344 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8929 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7965 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8664 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.1546 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8425 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.6529 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8149 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7772 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8200 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.6986 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8112 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6794 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7439 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6330 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7326 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6125 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7358 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.5949 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7273 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6651 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7210 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6504 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7227 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.5900 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6944 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5824 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6903 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6015 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6780 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5903 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6770 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5756 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6790 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5707 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6790 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6055 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06128560433983177\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 14ms/step - dense_15_loss: 0.0000e+00 - loss: 1.8356 - msle: 81.2263 - rmsle: 1.5925 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1889 - val_msle: 8.3509 - val_rmsle: 0.1304 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1245 - msle: 6.0418 - rmsle: 0.0820 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0997 - val_msle: 5.0605 - val_rmsle: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0865 - msle: 4.9409 - rmsle: 0.0717 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 4.6837 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0777 - msle: 4.6483 - rmsle: 0.0688 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.5408 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.4857 - rmsle: 0.0672 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.2253 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.3877 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.3934 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.2932 - rmsle: 0.0655 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.7960 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0687 - msle: 4.1880 - rmsle: 0.0647 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.0854 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.1099 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0840 - val_msle: 4.5141 - val_rmsle: 0.0805 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0530 - rmsle: 0.0640 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.1645 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0127 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.1939 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9020 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7155 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8717 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7691 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8594 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7378 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8469 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7760 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8037 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6594 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7831 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6444 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7764 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6904 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7728 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6452 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7742 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7014 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7540 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7287 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7610 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6413 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7529 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6337 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7485 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8449 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7455 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6289 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7175 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5826 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7076 - rmsle: 0.0612 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5774 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7030 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5888 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6976 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5783 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7063 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5787 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6930 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5786 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061383013048307955\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 14ms/step - dense_19_loss: 0.0000e+00 - loss: 1.8363 - msle: 81.4688 - rmsle: 1.5948 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1970 - val_msle: 8.3989 - val_rmsle: 0.1404 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1225 - msle: 6.1151 - rmsle: 0.0815 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0928 - val_msle: 4.8897 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0857 - msle: 4.9410 - rmsle: 0.0717 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.4075 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0775 - msle: 4.6708 - rmsle: 0.0691 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.0438 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.5132 - rmsle: 0.0674 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.3921 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.3820 - rmsle: 0.0663 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.1738 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.3371 - rmsle: 0.0657 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9407 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1837 - rmsle: 0.0649 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.1017 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.1178 - rmsle: 0.0644 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.2164 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0448 - rmsle: 0.0641 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9319 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0087 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9084 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9286 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0841 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.8972 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7724 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.8824 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.1362 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8516 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8818 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8316 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8007 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.7989 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8993 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.7963 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.0644 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.7860 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8847 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7290 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7003 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7348 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6756 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7094 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6570 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7196 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7828 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7126 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6732 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6846 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5932 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6762 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5897 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6811 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6120 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6724 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5964 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6694 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6210 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6596 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5854 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6656 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5940 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06043564666389971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:43:31,449] Trial 27 finished with value: 0.061435803847067386 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00031794241921916805, 'do_rate': 0.40977727737878555, 'hidden_layers': 3}. Best is trial 23 with value: 0.06080162388024468.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7132 - msle: 80.7373 - rmsle: 1.6345 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1364 - val_msle: 6.8946 - val_rmsle: 0.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1059 - msle: 5.8271 - rmsle: 0.0783 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 4.8517 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0824 - msle: 4.7043 - rmsle: 0.0709 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.2718 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0748 - msle: 4.4114 - rmsle: 0.0682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.1178 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.2835 - rmsle: 0.0668 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.9925 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1826 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9827 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.1165 - rmsle: 0.0651 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9386 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0564 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9465 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0084 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9619 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9679 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9169 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9315 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9145 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8886 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0170 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8606 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9089 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8542 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9844 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8220 - rmsle: 0.0627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8981 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7994 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8666 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7901 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8922 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7715 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8827 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7716 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9352 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7568 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7918 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7391 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8005 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7132 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7921 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6925 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7311 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6767 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7896 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6807 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7639 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6840 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7217 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6685 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6938 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6493 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6791 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6528 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6885 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6563 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6692 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6448 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6848 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06120005817807444\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7044 - msle: 80.3778 - rmsle: 1.6256 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1293 - val_msle: 6.6295 - val_rmsle: 0.0948 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1047 - msle: 5.7211 - rmsle: 0.0775 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 4.5856 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0816 - msle: 4.6846 - rmsle: 0.0704 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.1791 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4216 - rmsle: 0.0676 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0918 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.3012 - rmsle: 0.0661 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9724 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.2139 - rmsle: 0.0655 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0154 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.1344 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9851 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0751 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9185 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0214 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8528 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9814 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8562 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9407 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8494 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9114 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8577 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8676 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8837 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8589 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8805 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8379 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8869 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8159 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8677 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8074 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.9074 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7938 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8526 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7843 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8511 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7802 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8082 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7671 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8267 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7581 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8565 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7648 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8377 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7363 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7596 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7221 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7435 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7096 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7564 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6944 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7541 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6924 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7008 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6750 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6911 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6768 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7057 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6766 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6943 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.060636238914134\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7134 - msle: 80.6462 - rmsle: 1.6351 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1145 - val_msle: 6.4813 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1047 - msle: 5.8644 - rmsle: 0.0777 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 4.4656 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.7437 - rmsle: 0.0701 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.0438 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4374 - rmsle: 0.0675 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9852 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.3008 - rmsle: 0.0658 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7968 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.2146 - rmsle: 0.0650 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7786 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1324 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7736 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0660 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9779 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0184 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7016 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9765 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7098 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9440 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8020 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9080 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7293 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8841 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7764 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8178 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6218 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8027 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6398 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7814 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6091 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7774 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6353 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7756 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6245 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7572 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6222 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7532 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6272 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7484 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6415 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7232 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5671 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7223 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5763 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7153 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5848 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7117 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5711 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7144 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5598 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7101 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5564 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6998 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5711 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6984 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5549 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6978 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5606 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7060 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5580 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06086401191314117\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7194 - msle: 80.8104 - rmsle: 1.6404 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1241 - val_msle: 6.8437 - val_rmsle: 0.0892 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1063 - msle: 5.8922 - rmsle: 0.0788 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 4.5626 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0825 - msle: 4.7426 - rmsle: 0.0710 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2420 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0750 - msle: 4.4458 - rmsle: 0.0684 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.1418 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.2908 - rmsle: 0.0667 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.0110 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.2051 - rmsle: 0.0660 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8457 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1279 - rmsle: 0.0651 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0217 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0685 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9570 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0226 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2143 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9281 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1590 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.9101 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.0103 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8856 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0546 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8684 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9262 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8577 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.1874 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8366 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0001 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8200 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.0115 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7849 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6655 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7802 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6419 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7814 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6594 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7733 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6110 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7743 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6320 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7674 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6324 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7620 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6242 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7446 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6037 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7450 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6017 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7302 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5959 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7294 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6022 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7320 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6083 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7195 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5953 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7359 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6058 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7178 - rmsle: 0.0608 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5773 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06099380657382869\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7041 - msle: 80.6126 - rmsle: 1.6258 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1365 - val_msle: 6.7651 - val_rmsle: 0.1026 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1037 - msle: 5.7452 - rmsle: 0.0770 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 4.3879 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0812 - msle: 4.6686 - rmsle: 0.0701 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.0147 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4047 - rmsle: 0.0676 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9061 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2815 - rmsle: 0.0662 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8905 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1833 - rmsle: 0.0653 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8195 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1143 - rmsle: 0.0646 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7699 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0504 - rmsle: 0.0641 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7860 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9882 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7275 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9365 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6977 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9127 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7216 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8783 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7273 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8464 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7221 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8297 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7156 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8067 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6927 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7900 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8435 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7736 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7635 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7680 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6615 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7484 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6507 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7390 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6407 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7443 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6438 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.6958 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6231 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6961 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6062 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6814 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6152 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6809 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6163 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6808 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6244 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6602 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.5843 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6495 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.5829 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6474 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5864 - val_rmsle: 0.0594 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6422 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5840 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6442 - rmsle: 0.0606 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6033 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.0602396851496214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:51:11,552] Trial 28 finished with value: 0.06078676014575994 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00017487476578950428, 'do_rate': 0.4311074948149878, 'hidden_layers': 2}. Best is trial 28 with value: 0.06078676014575994.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.9289 - msle: 81.1753 - rmsle: 1.9053 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1026 - val_msle: 7.0129 - val_rmsle: 0.0860 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0977 - msle: 6.4887 - rmsle: 0.0831 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 5.1412 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0811 - msle: 5.1978 - rmsle: 0.0725 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.5589 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.7020 - rmsle: 0.0688 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.2986 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.4496 - rmsle: 0.0672 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1672 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.2757 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0431 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.1817 - rmsle: 0.0651 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9999 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0808 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.0293 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0299 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.0938 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9721 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.3021 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9512 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8703 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9049 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8914 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8993 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8105 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8608 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8361 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8395 - rmsle: 0.0627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7916 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8240 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8889 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7961 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7576 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7835 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8373 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7872 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8989 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7586 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7320 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7517 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7616 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7466 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7772 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7427 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7857 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7171 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7833 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7186 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7157 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6931 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7829 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6805 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6859 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6650 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7017 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6711 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7352 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6666 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7060 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6514 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6663 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061219719335158615\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_7_loss: 0.0000e+00 - loss: 1.9286 - msle: 81.2472 - rmsle: 1.9050 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1059 - val_msle: 7.0435 - val_rmsle: 0.0895 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0980 - msle: 6.5108 - rmsle: 0.0835 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.2264 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0814 - msle: 5.2386 - rmsle: 0.0729 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.6502 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.7640 - rmsle: 0.0693 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.4113 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.5140 - rmsle: 0.0674 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2248 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.3380 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0906 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.2242 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0365 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.1463 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0048 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0888 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9367 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.0260 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9388 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 4.0039 - rmsle: 0.0635 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9482 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9592 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9258 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9215 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.0170 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9015 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8977 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8362 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8216 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8361 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8882 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8341 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7645 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8140 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7578 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8112 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7869 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7986 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7654 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7892 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7649 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7865 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7417 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7783 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7589 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7447 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7211 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7524 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7229 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7455 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.7102 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7464 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.7123 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7431 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7306 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7364 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.7129 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7346 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.7034 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7189 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.7027 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.060420626592180234\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 1.9305 - msle: 81.2259 - rmsle: 1.9069 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1021 - val_msle: 6.9384 - val_rmsle: 0.0856 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0974 - msle: 6.5423 - rmsle: 0.0828 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 5.0570 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0811 - msle: 5.2620 - rmsle: 0.0725 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.4675 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.7677 - rmsle: 0.0688 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.2368 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.5055 - rmsle: 0.0669 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0600 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.3273 - rmsle: 0.0654 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9857 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.2262 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8869 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0656 - msle: 4.1431 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8767 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0650 - msle: 4.0759 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7430 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 4.0161 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7378 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9854 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7491 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9476 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7015 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9207 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8574 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8858 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6670 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8669 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6541 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8618 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6600 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8293 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6576 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8044 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6416 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7888 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7287 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7471 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6054 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7328 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5938 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7494 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6116 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7371 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.5955 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7357 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.5826 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7104 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5771 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7139 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5645 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6964 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5668 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7013 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5656 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6995 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5659 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7088 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5616 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6887 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5605 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.0609664275386515\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 1.9279 - msle: 81.2334 - rmsle: 1.9043 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1043 - val_msle: 7.0808 - val_rmsle: 0.0879 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0982 - msle: 6.5421 - rmsle: 0.0838 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 5.1549 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0813 - msle: 5.2415 - rmsle: 0.0728 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.5217 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0744 - msle: 4.7501 - rmsle: 0.0694 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.2493 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.4867 - rmsle: 0.0673 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0865 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.3313 - rmsle: 0.0663 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9868 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.2276 - rmsle: 0.0655 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9832 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.1341 - rmsle: 0.0647 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.2215 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0948 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1157 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0164 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8261 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9802 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7509 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9577 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7482 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.9443 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7672 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9159 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6826 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9034 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7200 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8820 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6915 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8870 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7058 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8363 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6511 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8358 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6558 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8313 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6465 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8252 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6570 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8145 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6294 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8071 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6267 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8071 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6316 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7985 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6298 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8085 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6282 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8204 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6285 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8006 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6264 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7935 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6198 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7815 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6187 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7935 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6163 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06137372587355811\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 1.9283 - msle: 81.3162 - rmsle: 1.9048 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1052 - val_msle: 7.1126 - val_rmsle: 0.0888 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0977 - msle: 6.5420 - rmsle: 0.0833 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 5.1523 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0810 - msle: 5.2218 - rmsle: 0.0725 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.5061 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.7293 - rmsle: 0.0690 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2622 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.4870 - rmsle: 0.0671 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1375 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.3115 - rmsle: 0.0659 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0347 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.2191 - rmsle: 0.0652 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8865 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 4.1257 - rmsle: 0.0644 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8176 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0654 - msle: 4.0541 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8073 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0008 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7783 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9679 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8165 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.9310 - rmsle: 0.0632 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7519 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9135 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7032 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8808 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6989 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8441 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7560 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8206 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6684 - val_rmsle: 0.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8109 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6599 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7875 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6667 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7819 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6464 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7405 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6621 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7380 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6486 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7256 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6263 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7214 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6189 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7176 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6225 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7076 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6227 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7051 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6043 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7117 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6206 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6817 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5881 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6746 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6006 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6725 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6116 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6784 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5913 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06032644753245935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 19:58:37,265] Trial 29 finished with value: 0.06086138937440157 and parameters: {'units': 128, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.0001663922171838162, 'do_rate': 0.4344282056717862, 'hidden_layers': 2}. Best is trial 28 with value: 0.06078676014575994.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7209 - msle: 80.7000 - rmsle: 1.6301 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1336 - val_msle: 6.6476 - val_rmsle: 0.0977 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1048 - msle: 5.6152 - rmsle: 0.0768 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0814 - val_msle: 4.4370 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.6297 - rmsle: 0.0703 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.2066 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0744 - msle: 4.3726 - rmsle: 0.0679 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.1888 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0712 - msle: 4.2500 - rmsle: 0.0664 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.0982 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1455 - rmsle: 0.0653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0003 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0683 - msle: 4.0952 - rmsle: 0.0648 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0371 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0242 - rmsle: 0.0642 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0019 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9854 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0580 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9396 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8752 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9166 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9430 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8776 - rmsle: 0.0631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0287 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8511 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8720 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8054 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8357 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7866 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8192 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7696 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.9680 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7613 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8228 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7464 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8019 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7458 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8846 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7373 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7916 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7103 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7087 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7022 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7267 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6945 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7022 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6810 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7128 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6880 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7346 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6889 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6929 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6798 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7153 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6758 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6946 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6805 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7472 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6742 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6743 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6554 - rmsle: 0.0606 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6798 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06100054271178551\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7141 - msle: 80.4258 - rmsle: 1.6231 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1360 - val_msle: 6.7106 - val_rmsle: 0.1003 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1046 - msle: 5.6536 - rmsle: 0.0769 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.4908 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0811 - msle: 4.6589 - rmsle: 0.0701 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.2022 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.3937 - rmsle: 0.0674 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.1892 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2797 - rmsle: 0.0662 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9882 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1894 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0695 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1179 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0499 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0706 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9565 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.0188 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8524 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9757 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8679 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9377 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9204 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9083 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9693 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8779 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8737 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8582 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9223 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8424 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8837 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8286 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9746 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8156 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9115 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7780 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8057 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7576 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7816 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7460 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7810 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7450 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7823 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7314 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7568 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7301 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7605 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7258 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7630 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7324 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7477 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7260 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7402 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7151 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7420 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7106 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7413 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7102 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7433 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7077 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7403 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6883 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7041 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06060221318923696\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7187 - msle: 80.5455 - rmsle: 1.6280 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1175 - val_msle: 6.4808 - val_rmsle: 0.0825 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1038 - msle: 5.7249 - rmsle: 0.0766 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 4.5951 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.6904 - rmsle: 0.0698 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.0232 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.3986 - rmsle: 0.0673 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9489 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2779 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8265 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.2071 - rmsle: 0.0651 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8390 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1204 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7888 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0609 - rmsle: 0.0639 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1619 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.0071 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7388 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9628 - rmsle: 0.0631 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7091 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9337 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7405 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8993 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7647 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8789 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7351 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8547 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7327 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8296 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0317 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7753 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6516 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7627 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6553 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7518 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6107 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7424 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6487 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7395 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6333 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7285 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6499 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7376 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6065 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7406 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6466 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7301 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6689 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7213 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6148 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7154 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6002 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7250 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6133 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7049 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6385 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6855 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5783 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6751 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5627 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6920 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5758 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06098848383542262\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7215 - msle: 80.6096 - rmsle: 1.6303 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1280 - val_msle: 6.7771 - val_rmsle: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1055 - msle: 5.7571 - rmsle: 0.0780 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0828 - val_msle: 4.7304 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.6971 - rmsle: 0.0708 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.2820 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0751 - msle: 4.4278 - rmsle: 0.0684 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.1928 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0718 - msle: 4.2750 - rmsle: 0.0669 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0629 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.1938 - rmsle: 0.0660 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.8811 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1200 - rmsle: 0.0652 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1395 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0612 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0470 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0156 - rmsle: 0.0644 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.3413 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9646 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.0858 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9351 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.3867 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8754 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9244 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8510 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9198 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8407 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2748 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8174 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0261 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8133 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9121 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7782 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6807 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7661 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6441 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7666 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6728 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7649 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6117 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7553 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6199 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7530 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6355 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7428 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6228 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7459 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6253 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7434 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6263 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7242 - rmsle: 0.0612 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5921 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7153 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5999 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7181 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6108 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7074 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5981 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7160 - rmsle: 0.0609 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5770 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6983 - rmsle: 0.0607 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5752 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.060980048073873666\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7135 - msle: 80.5473 - rmsle: 1.6227 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1327 - val_msle: 6.9091 - val_rmsle: 0.0972 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1041 - msle: 5.7080 - rmsle: 0.0766 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 4.3501 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0812 - msle: 4.6387 - rmsle: 0.0700 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.0547 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3753 - rmsle: 0.0675 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.9772 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2505 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8384 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1651 - rmsle: 0.0652 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8519 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0964 - rmsle: 0.0646 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8500 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0287 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8034 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9748 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7717 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9341 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7216 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9010 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8781 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8724 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7417 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8456 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7276 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8218 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7808 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8063 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7447 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7850 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7672 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7703 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8276 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7577 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7059 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7478 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7166 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7429 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6561 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7453 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6664 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7266 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6863 - val_rmsle: 0.0607 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7208 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6328 - val_rmsle: 0.0604 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7079 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6252 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7034 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6340 - val_rmsle: 0.0603 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7083 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6703 - val_rmsle: 0.0604 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7011 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6173 - val_rmsle: 0.0604 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7008 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6429 - val_rmsle: 0.0604 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6743 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6088 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6655 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6139 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6725 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6288 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06072945613984406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:06:05,001] Trial 30 finished with value: 0.06086014879003256 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00020877782796120163, 'do_rate': 0.40441493903637415, 'hidden_layers': 2}. Best is trial 28 with value: 0.06078676014575994.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 13ms/step - dense_3_loss: 0.0000e+00 - loss: 1.7253 - msle: 80.7893 - rmsle: 1.6355 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1372 - val_msle: 7.0095 - val_rmsle: 0.1011 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1060 - msle: 5.7579 - rmsle: 0.0779 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 4.5867 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.6638 - rmsle: 0.0706 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.3221 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0748 - msle: 4.3769 - rmsle: 0.0682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0613 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0715 - msle: 4.2583 - rmsle: 0.0666 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.0512 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0696 - msle: 4.1633 - rmsle: 0.0656 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9944 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1096 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9417 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0432 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0357 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0670 - msle: 3.9943 - rmsle: 0.0641 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0089 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9487 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8936 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9304 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9515 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8877 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9797 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8578 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9032 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8075 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8487 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7865 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8779 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7684 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8939 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7652 - rmsle: 0.0620 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8456 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7537 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7939 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7441 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8853 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7436 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8228 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7316 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8363 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7322 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8484 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7190 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7766 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7073 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7651 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7070 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8204 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7127 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7474 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6801 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7237 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6674 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6991 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6725 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6908 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6760 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6961 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6678 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7249 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061257383037117696\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.7149 - msle: 80.5107 - rmsle: 1.6255 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1304 - val_msle: 6.6803 - val_rmsle: 0.0951 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1046 - msle: 5.6882 - rmsle: 0.0771 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 4.5764 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0811 - msle: 4.6628 - rmsle: 0.0701 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.1837 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4040 - rmsle: 0.0675 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.1624 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.2862 - rmsle: 0.0663 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0120 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1978 - rmsle: 0.0654 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0749 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.1274 - rmsle: 0.0646 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9573 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0670 - rmsle: 0.0641 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9455 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.0224 - rmsle: 0.0637 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8703 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9795 - rmsle: 0.0634 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8727 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9394 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8956 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9144 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8957 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8715 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8913 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8619 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8555 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8457 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8993 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8272 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 4.0026 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8080 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.9059 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7818 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7865 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7583 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7723 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7487 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7749 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7424 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7688 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7338 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7579 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7301 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7532 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7270 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7769 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7192 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7183 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7007 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7040 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6861 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7021 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6892 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7049 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6921 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7174 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6865 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6987 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6830 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7260 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.0605890756516589\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.7197 - msle: 80.5837 - rmsle: 1.6302 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1129 - val_msle: 6.4400 - val_rmsle: 0.0778 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1039 - msle: 5.7454 - rmsle: 0.0766 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.4737 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0807 - msle: 4.6991 - rmsle: 0.0698 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.0268 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.4243 - rmsle: 0.0675 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9510 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2904 - rmsle: 0.0660 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8766 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.2056 - rmsle: 0.0650 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7801 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.1256 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7982 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0585 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1110 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0165 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7063 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9639 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7543 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9395 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7095 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9053 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7359 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8440 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6168 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8085 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6198 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7994 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6821 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7867 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6341 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7801 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6228 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7479 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.5863 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7294 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5788 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7326 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5799 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7214 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6021 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7210 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5711 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7295 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5718 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7188 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6059 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7177 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5744 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6986 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5485 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7100 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5497 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6939 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5518 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6909 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5486 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6842 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5532 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7049 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5373 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06059052410421725\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7216 - msle: 80.6957 - rmsle: 1.6316 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1278 - val_msle: 7.0487 - val_rmsle: 0.0919 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1061 - msle: 5.8542 - rmsle: 0.0782 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 4.4851 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.7006 - rmsle: 0.0707 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.2397 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.4229 - rmsle: 0.0683 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.1878 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.2650 - rmsle: 0.0667 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.2688 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0699 - msle: 4.1923 - rmsle: 0.0659 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.9565 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0686 - msle: 4.1231 - rmsle: 0.0651 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.2707 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0651 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8484 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0097 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.5967 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9585 - rmsle: 0.0638 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9628 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9309 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.2697 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8682 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9450 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8424 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8686 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8382 - rmsle: 0.0625 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.2692 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8158 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9827 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8074 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9010 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7690 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6330 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7607 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6356 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7640 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6557 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7618 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6110 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7529 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6213 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7563 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6563 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7468 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6144 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7325 - rmsle: 0.0612 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6035 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7329 - rmsle: 0.0612 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6024 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7237 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5967 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7176 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5954 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7158 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6083 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7031 - rmsle: 0.0609 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5884 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7183 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6015 - val_rmsle: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7067 - rmsle: 0.0608 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5769 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06096766411736605\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 1.7143 - msle: 80.7095 - rmsle: 1.6250 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1412 - val_msle: 7.0328 - val_rmsle: 0.1060 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1038 - msle: 5.6781 - rmsle: 0.0764 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.3331 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0812 - msle: 4.6436 - rmsle: 0.0700 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.0338 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3657 - rmsle: 0.0675 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.9444 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2433 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8855 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1657 - rmsle: 0.0653 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9198 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0965 - rmsle: 0.0646 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8682 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0341 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7757 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9791 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8654 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9373 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7273 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9087 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7464 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8748 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7051 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8428 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7246 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8243 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7521 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8093 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8894 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7897 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7712 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7655 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9014 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7610 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7819 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7501 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7574 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7448 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6650 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7384 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6619 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7268 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6867 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7193 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6765 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7122 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6437 - val_rmsle: 0.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7106 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7492 - val_rmsle: 0.0607 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7110 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7051 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7038 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6395 - val_rmsle: 0.0607 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6694 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6085 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6554 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6067 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6652 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6321 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6651 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6215 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060617344086182925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:13:35,373] Trial 31 finished with value: 0.060804398199308565 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.0002054031430176781, 'do_rate': 0.4062436498557265, 'hidden_layers': 2}. Best is trial 28 with value: 0.06078676014575994.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.6962 - msle: 80.6496 - rmsle: 1.6269 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1262 - val_msle: 6.7192 - val_rmsle: 0.0923 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1044 - msle: 5.7353 - rmsle: 0.0772 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 4.5330 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0822 - msle: 4.6408 - rmsle: 0.0703 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.1662 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0749 - msle: 4.3639 - rmsle: 0.0681 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.0572 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.2382 - rmsle: 0.0667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0733 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.1430 - rmsle: 0.0656 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.9715 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.0858 - rmsle: 0.0652 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9480 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0260 - rmsle: 0.0645 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9216 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9849 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8922 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9557 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8688 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9202 - rmsle: 0.0635 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9979 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8802 - rmsle: 0.0633 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8831 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8580 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8726 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8450 - rmsle: 0.0630 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0520 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8279 - rmsle: 0.0627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8769 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.7990 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9430 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.7935 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8903 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7774 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8299 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7595 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0217 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7601 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.2003 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7488 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9368 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7099 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8022 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.6966 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7386 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6844 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7749 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6788 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7569 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6860 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7352 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6627 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7104 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6502 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6844 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6481 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6771 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6540 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6767 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6506 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6766 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.061110559503591226\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.6942 - msle: 80.7117 - rmsle: 1.6254 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1195 - val_msle: 6.4263 - val_rmsle: 0.0860 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1033 - msle: 5.6300 - rmsle: 0.0764 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 4.4632 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0817 - msle: 4.6171 - rmsle: 0.0699 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.1517 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0739 - msle: 4.3613 - rmsle: 0.0673 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.0903 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.2525 - rmsle: 0.0660 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9807 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1649 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.2839 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.1010 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0176 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0473 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.9437 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0030 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.9243 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9590 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8677 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9257 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8980 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9015 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8392 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8620 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8383 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8550 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.9039 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8377 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8883 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8244 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8470 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8087 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8961 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7964 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8672 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7892 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8766 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7587 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7629 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7382 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7476 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7247 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7583 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7250 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7423 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7142 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7329 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7106 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7069 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6945 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7003 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6866 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7087 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6845 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6985 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6820 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6936 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6798 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6990 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6766 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6953 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06045294500787437\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 1.6903 - msle: 80.3716 - rmsle: 1.6214 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1094 - val_msle: 6.2312 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1017 - msle: 5.6234 - rmsle: 0.0753 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 4.4637 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0804 - msle: 4.6177 - rmsle: 0.0690 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.0834 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0735 - msle: 4.3686 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8745 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0701 - msle: 4.2446 - rmsle: 0.0655 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8026 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1786 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7565 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0975 - rmsle: 0.0640 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8122 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0662 - msle: 4.0236 - rmsle: 0.0634 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9269 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9978 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7209 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9512 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7063 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9224 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.6799 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8937 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6995 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8712 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7631 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8476 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.6858 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8196 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8419 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7700 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6277 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7545 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6120 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7493 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6107 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7420 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6605 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7362 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6029 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7271 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6440 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7267 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6036 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7261 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6286 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7039 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5801 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6899 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5721 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6893 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5545 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6945 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5546 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6898 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5510 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6775 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5497 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6797 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5520 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7047 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5410 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06081156158522057\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.7001 - msle: 80.7238 - rmsle: 1.6311 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1196 - val_msle: 6.7137 - val_rmsle: 0.0861 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1045 - msle: 5.7578 - rmsle: 0.0775 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.4958 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.6393 - rmsle: 0.0701 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2033 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.3722 - rmsle: 0.0679 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.0991 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0710 - msle: 4.2191 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.2346 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1566 - rmsle: 0.0656 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9513 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0822 - rmsle: 0.0648 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9965 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0297 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8054 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9910 - rmsle: 0.0641 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2657 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9382 - rmsle: 0.0636 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0008 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9149 - rmsle: 0.0634 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.3451 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8589 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9011 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8393 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8250 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8299 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0822 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8087 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8698 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8007 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8934 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7943 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8294 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7821 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8013 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7881 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9369 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7751 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7089 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7601 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7499 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7623 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7471 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7556 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6705 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7478 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6992 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7469 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6439 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7429 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6517 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7346 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6472 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7302 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6433 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7216 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6760 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7266 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6825 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7049 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.5939 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061695556455677605\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 1.6891 - msle: 80.4324 - rmsle: 1.6201 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1265 - val_msle: 6.5229 - val_rmsle: 0.0934 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1023 - msle: 5.6509 - rmsle: 0.0758 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 4.5199 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0812 - msle: 4.6022 - rmsle: 0.0696 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.0229 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3466 - rmsle: 0.0674 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9347 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2191 - rmsle: 0.0661 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8668 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1393 - rmsle: 0.0652 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8425 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0836 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8223 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0150 - rmsle: 0.0640 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7898 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9601 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8650 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9322 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7247 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8982 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8080 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8686 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7120 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8388 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7205 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8191 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.7153 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8048 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.7576 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7631 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6461 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7404 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6836 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7416 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6345 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7258 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6336 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7285 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6291 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7248 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6296 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6942 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5976 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6916 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.5989 - val_rmsle: 0.0594 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6870 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6096 - val_rmsle: 0.0594 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6753 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6004 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6889 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6080 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6657 - rmsle: 0.0606 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5726 - val_rmsle: 0.0591 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6615 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5862 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6586 - rmsle: 0.0605 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5751 - val_rmsle: 0.0591 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6501 - rmsle: 0.0604 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.5728 - val_rmsle: 0.0590 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6569 - rmsle: 0.0604 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.5699 - val_rmsle: 0.0590 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.05981306877215869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:21:05,566] Trial 32 finished with value: 0.0607767382649045 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00015008021220464898, 'do_rate': 0.37725649695563407, 'hidden_layers': 2}. Best is trial 32 with value: 0.0607767382649045.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.6915 - msle: 80.7426 - rmsle: 1.6288 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1258 - val_msle: 6.6501 - val_rmsle: 0.0934 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1036 - msle: 5.7036 - rmsle: 0.0772 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 4.5193 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.6216 - rmsle: 0.0702 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.1856 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0747 - msle: 4.3449 - rmsle: 0.0680 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.0377 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.2234 - rmsle: 0.0664 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9852 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1316 - rmsle: 0.0654 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0514 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.0686 - rmsle: 0.0650 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9542 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0196 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9418 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9753 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9479 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9403 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8482 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9143 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8584 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8750 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8922 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8415 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9554 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8285 - rmsle: 0.0628 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8454 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7864 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8592 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7612 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9414 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7544 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8082 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7396 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7893 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7355 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8120 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7364 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8161 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7250 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7818 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7266 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7818 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7146 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7541 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7033 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7545 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7036 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.8201 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7092 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7320 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6756 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7056 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6671 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6833 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6674 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6809 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6734 - rmsle: 0.0609 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6920 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6670 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6918 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06116158807289375\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.6853 - msle: 80.5183 - rmsle: 1.6228 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1146 - val_msle: 6.3393 - val_rmsle: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1028 - msle: 5.6252 - rmsle: 0.0764 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.4747 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0820 - msle: 4.6257 - rmsle: 0.0700 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.1461 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3659 - rmsle: 0.0673 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.1293 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.2386 - rmsle: 0.0659 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.0088 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1643 - rmsle: 0.0652 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9426 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0925 - rmsle: 0.0645 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9350 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0449 - rmsle: 0.0640 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9110 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9990 - rmsle: 0.0636 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8443 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9526 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8756 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9200 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9243 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8977 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8548 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8561 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8431 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8543 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8247 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8369 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8319 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8194 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8887 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8077 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8490 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7911 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8714 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7816 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8291 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7765 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8833 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7765 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 4.0445 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7384 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7535 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7154 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7449 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7126 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7510 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7167 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7415 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7080 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7299 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6951 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7322 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6962 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7430 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6872 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6869 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6732 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6915 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6691 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.7107 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06046393850937407\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.6820 - msle: 80.3202 - rmsle: 1.6197 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1091 - val_msle: 6.2685 - val_rmsle: 0.0772 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1018 - msle: 5.6571 - rmsle: 0.0758 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 4.7218 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0810 - msle: 4.6440 - rmsle: 0.0692 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.0820 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.3779 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9478 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.2516 - rmsle: 0.0657 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8346 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1825 - rmsle: 0.0648 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8299 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1063 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8957 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 4.0373 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1320 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0071 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7536 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.9598 - rmsle: 0.0629 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7399 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9259 - rmsle: 0.0626 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7756 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9038 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6974 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8815 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7765 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8549 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7219 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8362 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8160 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7767 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6335 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7679 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6259 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7626 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6096 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7519 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6404 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7471 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6189 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7367 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6506 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7409 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.5790 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7347 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6408 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7151 - rmsle: 0.0605 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5849 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6997 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5664 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7031 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5634 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7078 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5472 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6978 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5667 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6901 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5508 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6847 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5745 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6897 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5408 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06054035843180735\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.6919 - msle: 80.7109 - rmsle: 1.6293 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1167 - val_msle: 6.5392 - val_rmsle: 0.0844 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1037 - msle: 5.7713 - rmsle: 0.0774 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 4.4276 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0821 - msle: 4.6489 - rmsle: 0.0701 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.2462 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.3683 - rmsle: 0.0678 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.0903 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2176 - rmsle: 0.0662 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9507 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1595 - rmsle: 0.0656 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9153 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0831 - rmsle: 0.0647 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8679 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0322 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8233 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9892 - rmsle: 0.0640 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.2036 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9362 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8884 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9142 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1721 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8605 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8419 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8347 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.8489 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8328 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9856 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8013 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8705 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8004 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8059 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7919 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8001 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7833 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8001 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7812 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8103 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7740 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.7292 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7594 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6927 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7589 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7215 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7507 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6384 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7454 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6768 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7465 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6709 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7408 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6274 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7306 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6382 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7313 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6107 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7225 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6258 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7124 - rmsle: 0.0612 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5905 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7010 - rmsle: 0.0610 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5976 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06138831634026338\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 1.6873 - msle: 80.6367 - rmsle: 1.6247 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1241 - val_msle: 6.5762 - val_rmsle: 0.0919 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1026 - msle: 5.7273 - rmsle: 0.0765 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.5299 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0818 - msle: 4.6301 - rmsle: 0.0699 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.1398 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.3576 - rmsle: 0.0677 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9429 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0711 - msle: 4.2301 - rmsle: 0.0663 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8264 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1499 - rmsle: 0.0655 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8298 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0959 - rmsle: 0.0648 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8123 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0328 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7793 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9791 - rmsle: 0.0638 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7479 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9478 - rmsle: 0.0635 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7626 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9029 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7058 - val_rmsle: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8764 - rmsle: 0.0629 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7084 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8514 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7214 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8253 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6768 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8151 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7071 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7965 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6786 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7791 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7743 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7452 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6510 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7196 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6340 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7279 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6326 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7216 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6482 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7088 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6170 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7121 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6106 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7094 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6221 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6994 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6388 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7077 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6142 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6959 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6049 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6875 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6188 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6860 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6054 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6820 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6011 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6646 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5757 - val_rmsle: 0.0593 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060117824427632686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:28:33,424] Trial 33 finished with value: 0.06073440515639424 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00013373807147214304, 'do_rate': 0.37820080628960817, 'hidden_layers': 2}. Best is trial 33 with value: 0.06073440515639424.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 1.6895 - msle: 80.5368 - rmsle: 1.6258 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1222 - val_msle: 6.7339 - val_rmsle: 0.0892 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1041 - msle: 5.7138 - rmsle: 0.0772 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.6266 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0824 - msle: 4.6247 - rmsle: 0.0703 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.2224 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0748 - msle: 4.3387 - rmsle: 0.0680 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.0765 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0714 - msle: 4.2259 - rmsle: 0.0666 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9849 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1349 - rmsle: 0.0655 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0020 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.0820 - rmsle: 0.0651 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9700 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0124 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9632 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0668 - msle: 3.9766 - rmsle: 0.0640 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8914 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9381 - rmsle: 0.0637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8694 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9074 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.0195 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8767 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9409 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8063 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8239 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7984 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.8462 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7914 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8096 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7700 - rmsle: 0.0621 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.9888 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7682 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8107 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7550 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7749 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7498 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7964 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7485 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.9220 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7422 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.8374 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7376 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8033 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7094 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7018 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6920 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6984 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6890 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7154 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6915 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6878 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6781 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6766 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6645 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6767 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6683 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6761 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6705 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6718 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6649 - rmsle: 0.0606 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6733 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06087120676775308\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.6885 - msle: 80.6774 - rmsle: 1.6252 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1128 - val_msle: 6.3001 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1027 - msle: 5.6241 - rmsle: 0.0762 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 4.4744 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0817 - msle: 4.6044 - rmsle: 0.0697 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1355 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0740 - msle: 4.3562 - rmsle: 0.0672 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.0904 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.2402 - rmsle: 0.0659 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9665 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1572 - rmsle: 0.0651 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0200 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0975 - rmsle: 0.0644 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9529 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0392 - rmsle: 0.0639 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8714 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9948 - rmsle: 0.0635 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9244 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9498 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.8598 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9225 - rmsle: 0.0630 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8769 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9003 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.8578 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8625 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8230 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8515 - rmsle: 0.0624 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8161 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8311 - rmsle: 0.0623 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8205 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8129 - rmsle: 0.0622 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.8922 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8053 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8392 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7957 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8567 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7663 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7670 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7417 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7616 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7399 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7671 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7359 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7440 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7252 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7609 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7226 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7435 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7277 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7389 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7222 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7484 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7075 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7353 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7106 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7296 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6961 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6966 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6839 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7031 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6791 - rmsle: 0.0606 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6940 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.060354935791721936\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_11_loss: 0.0000e+00 - loss: 1.6856 - msle: 80.4166 - rmsle: 1.6224 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1098 - val_msle: 6.2539 - val_rmsle: 0.0780 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1014 - msle: 5.6296 - rmsle: 0.0756 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.4932 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0808 - msle: 4.6354 - rmsle: 0.0692 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.1604 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0736 - msle: 4.3700 - rmsle: 0.0670 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.8597 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.2500 - rmsle: 0.0656 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8009 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1788 - rmsle: 0.0647 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7911 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.1026 - rmsle: 0.0641 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8986 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.0273 - rmsle: 0.0635 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9328 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9969 - rmsle: 0.0632 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7073 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9521 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7128 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9224 - rmsle: 0.0625 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6736 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8948 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6817 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8706 - rmsle: 0.0622 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7606 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8508 - rmsle: 0.0621 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7412 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8246 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7717 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7782 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.6266 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7623 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6238 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7551 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6108 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7437 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6268 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7343 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6148 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7098 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5711 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7091 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5592 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7116 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5656 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7107 - rmsle: 0.0604 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5790 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7002 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5590 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6957 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5707 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7033 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5468 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7003 - rmsle: 0.0603 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5599 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6766 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5450 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6688 - rmsle: 0.0599 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5391 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6900 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5387 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.098909616470337\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06051782160192692\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_15_loss: 0.0000e+00 - loss: 1.6921 - msle: 80.6693 - rmsle: 1.6286 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1180 - val_msle: 6.7040 - val_rmsle: 0.0855 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1037 - msle: 5.7488 - rmsle: 0.0773 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 4.6016 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0822 - msle: 4.6408 - rmsle: 0.0702 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.5058 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.3558 - rmsle: 0.0678 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.0508 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.2094 - rmsle: 0.0661 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9241 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0693 - msle: 4.1460 - rmsle: 0.0655 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8855 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0775 - rmsle: 0.0648 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9215 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0321 - rmsle: 0.0642 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8208 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9856 - rmsle: 0.0640 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2293 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.9397 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8353 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9161 - rmsle: 0.0634 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1574 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8936 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0285 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8684 - rmsle: 0.0630 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9557 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8189 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9539 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7966 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7786 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7857 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8353 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7865 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7649 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7732 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7666 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7723 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8362 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7638 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6864 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7484 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6875 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7515 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7451 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7481 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6393 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7373 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6449 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7391 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6248 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7327 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6334 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7258 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6871 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7213 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6736 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6968 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5871 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7051 - rmsle: 0.0611 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5873 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6953 - rmsle: 0.0609 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5878 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061413367832760274\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_19_loss: 0.0000e+00 - loss: 1.6856 - msle: 80.6006 - rmsle: 1.6221 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1213 - val_msle: 6.4847 - val_rmsle: 0.0889 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1023 - msle: 5.6699 - rmsle: 0.0760 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0815 - val_msle: 4.5090 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.6058 - rmsle: 0.0696 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.1467 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.3488 - rmsle: 0.0675 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.8964 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0708 - msle: 4.2186 - rmsle: 0.0660 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8439 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1421 - rmsle: 0.0652 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8348 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0840 - rmsle: 0.0645 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7912 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0128 - rmsle: 0.0639 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8311 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9615 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7608 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.9265 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7146 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8968 - rmsle: 0.0630 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7153 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8660 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7191 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8382 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7034 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8142 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7231 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8030 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7221 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7645 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6298 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7374 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6817 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7398 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6264 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7222 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6364 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7304 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6266 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7248 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6359 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7161 - rmsle: 0.0614 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6273 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7138 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6267 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7086 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6410 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7019 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6788 - val_rmsle: 0.0599 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6910 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5925 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6794 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5879 - val_rmsle: 0.0594 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6744 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5869 - val_rmsle: 0.0594 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6639 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5797 - val_rmsle: 0.0593 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6636 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5842 - val_rmsle: 0.0593 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6710 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.5844 - val_rmsle: 0.0593 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060060452412472584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:35:58,734] Trial 34 finished with value: 0.06064355688132696 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.0001360583533261253, 'do_rate': 0.3763917280440354, 'hidden_layers': 2}. Best is trial 34 with value: 0.06064355688132696.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 13ms/step - dense_3_loss: 0.0000e+00 - loss: 1.4457 - msle: 76.0765 - rmsle: 1.3383 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1217 - val_msle: 6.5798 - val_rmsle: 0.0834 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1121 - msle: 5.8508 - rmsle: 0.0820 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0851 - val_msle: 4.6019 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0891 - msle: 5.0038 - rmsle: 0.0755 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.3036 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0810 - msle: 4.6901 - rmsle: 0.0720 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.1700 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0762 - msle: 4.4806 - rmsle: 0.0693 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.0691 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0731 - msle: 4.3292 - rmsle: 0.0674 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 3.9985 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0709 - msle: 4.1883 - rmsle: 0.0660 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0508 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.0823 - rmsle: 0.0649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0094 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0138 - rmsle: 0.0643 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.0430 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9526 - rmsle: 0.0638 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0298 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9039 - rmsle: 0.0634 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9718 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0661 - msle: 3.8741 - rmsle: 0.0632 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0401 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8420 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8790 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.8254 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9619 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.7997 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.9711 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.7930 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8325 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.7644 - rmsle: 0.0623 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8701 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.7548 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7881 - val_rmsle: 0.0623 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.7428 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8168 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7013 - rmsle: 0.0616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7527 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.6911 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7405 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.6858 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7644 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.6792 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8518 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.6761 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7423 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.6558 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6842 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6550 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6973 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6399 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6915 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6499 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6782 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6444 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6723 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6430 - rmsle: 0.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6790 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6371 - rmsle: 0.0607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6811 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06120138965412495\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_7_loss: 0.0000e+00 - loss: 1.4460 - msle: 75.7313 - rmsle: 1.3392 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.1458 - val_msle: 7.1745 - val_rmsle: 0.1090 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.1113 - msle: 5.9537 - rmsle: 0.0824 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0939 - val_msle: 5.1691 - val_rmsle: 0.0789 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0884 - msle: 5.0834 - rmsle: 0.0754 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 4.4693 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0804 - msle: 4.7651 - rmsle: 0.0717 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.3181 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0760 - msle: 4.5770 - rmsle: 0.0693 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.2080 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.4093 - rmsle: 0.0673 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.2283 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.2735 - rmsle: 0.0659 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0715 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1441 - rmsle: 0.0649 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9847 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0682 - msle: 4.0812 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0117 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.0142 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0216 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9697 - rmsle: 0.0633 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.0894 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9428 - rmsle: 0.0632 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.9326 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9073 - rmsle: 0.0629 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0864 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8927 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9567 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8643 - rmsle: 0.0626 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8915 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8064 - rmsle: 0.0620 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8243 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7815 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.8232 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7729 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8507 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7673 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8138 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7633 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7987 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7567 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7844 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7464 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7856 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7375 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.8216 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7300 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7946 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7340 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7853 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7121 - rmsle: 0.0610 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7105 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7010 - rmsle: 0.0609 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7273 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6980 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7114 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6998 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7165 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6926 - rmsle: 0.0608 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7130 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6873 - rmsle: 0.0607 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7180 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06060286602372541\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_11_loss: 0.0000e+00 - loss: 1.4413 - msle: 75.8096 - rmsle: 1.3351 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.1421 - val_msle: 7.0783 - val_rmsle: 0.1052 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.1109 - msle: 6.0439 - rmsle: 0.0820 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0897 - val_msle: 4.8812 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0880 - msle: 5.1186 - rmsle: 0.0748 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 5.0509 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0801 - msle: 4.7779 - rmsle: 0.0713 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 5.0725 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0758 - msle: 4.5665 - rmsle: 0.0689 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.2370 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.3876 - rmsle: 0.0667 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.4240 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0700 - msle: 4.2465 - rmsle: 0.0652 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2522 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.1298 - rmsle: 0.0643 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0183 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.0516 - rmsle: 0.0636 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.1200 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9815 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1942 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9462 - rmsle: 0.0628 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9253 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.8618 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8774 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.8378 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7403 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8219 - rmsle: 0.0617 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7306 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.8166 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7187 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7962 - rmsle: 0.0615 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7843 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7584 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.5907 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7495 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.5837 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7494 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.5721 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7426 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.5858 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7359 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5750 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7328 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.5824 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7233 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5795 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7279 - rmsle: 0.0606 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5747 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7069 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5337 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6993 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5382 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7015 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5411 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6976 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5393 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6893 - rmsle: 0.0601 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5322 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6999 - rmsle: 0.0602 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5308 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6861 - rmsle: 0.0600 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5377 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0021032094955444\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06048232017421416\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_15_loss: 0.0000e+00 - loss: 1.4364 - msle: 75.6689 - rmsle: 1.3298 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.1314 - val_msle: 6.7060 - val_rmsle: 0.0945 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.1105 - msle: 5.8971 - rmsle: 0.0815 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0851 - val_msle: 4.8042 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0881 - msle: 5.0724 - rmsle: 0.0750 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.4221 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0801 - msle: 4.7450 - rmsle: 0.0715 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.1311 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.5346 - rmsle: 0.0688 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.3906 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0728 - msle: 4.3825 - rmsle: 0.0673 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.5932 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0706 - msle: 4.2408 - rmsle: 0.0658 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.5636 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1327 - rmsle: 0.0649 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.5204 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0680 - msle: 4.0460 - rmsle: 0.0643 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.3688 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0673 - msle: 3.9845 - rmsle: 0.0639 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2946 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9428 - rmsle: 0.0635 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.2214 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0664 - msle: 3.9169 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1718 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.8866 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1693 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8603 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8708 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8376 - rmsle: 0.0628 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1625 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8198 - rmsle: 0.0627 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0199 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8062 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7229 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.7843 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7901 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.7728 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7462 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.7608 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6877 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.7574 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6954 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7467 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6901 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7479 - rmsle: 0.0621 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6859 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7362 - rmsle: 0.0620 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7490 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7290 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.6530 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7287 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6683 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7224 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6708 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7175 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6815 - val_rmsle: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.6994 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6390 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6879 - rmsle: 0.0613 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6235 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6873 - rmsle: 0.0612 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.5990 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.061726633191836765\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_19_loss: 0.0000e+00 - loss: 1.4407 - msle: 75.8425 - rmsle: 1.3339 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.1370 - val_msle: 7.3081 - val_rmsle: 0.0999 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.1102 - msle: 5.8936 - rmsle: 0.0811 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0881 - val_msle: 5.0721 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0878 - msle: 5.0255 - rmsle: 0.0747 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.9542 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0799 - msle: 4.7231 - rmsle: 0.0712 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.4782 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0756 - msle: 4.5080 - rmsle: 0.0688 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.1620 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0728 - msle: 4.3563 - rmsle: 0.0671 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.1808 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.2188 - rmsle: 0.0658 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.9841 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.1120 - rmsle: 0.0647 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8821 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.0379 - rmsle: 0.0643 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.9575 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0672 - msle: 3.9716 - rmsle: 0.0637 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8354 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9345 - rmsle: 0.0634 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8395 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.8972 - rmsle: 0.0631 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8846 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0658 - msle: 3.8702 - rmsle: 0.0628 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7601 - val_rmsle: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8405 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7795 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8215 - rmsle: 0.0626 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8160 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8020 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7864 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.7884 - rmsle: 0.0624 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7300 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.7554 - rmsle: 0.0621 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7438 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.7608 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.0795 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7347 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7760 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7241 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6800 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7193 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6997 - val_rmsle: 0.0607 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7097 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7621 - val_rmsle: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7086 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.6818 - val_rmsle: 0.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7029 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6721 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.6929 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6636 - val_rmsle: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7016 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6904 - val_rmsle: 0.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.6865 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6332 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.6886 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6274 - val_rmsle: 0.0603 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.6760 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6403 - val_rmsle: 0.0604 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.6753 - rmsle: 0.0613 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6307 - val_rmsle: 0.0602 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.060906610032923775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:43:54,592] Trial 35 finished with value: 0.060983963815365014 and parameters: {'units': 1024, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.00013149808582653364, 'do_rate': 0.3786379943853548, 'hidden_layers': 2}. Best is trial 34 with value: 0.06064355688132696.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 1.6840 - msle: 82.5178 - rmsle: 1.6797 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0886 - val_msle: 7.0953 - val_rmsle: 0.0839 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0838 - msle: 6.1638 - rmsle: 0.0796 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.8804 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0729 - msle: 4.7858 - rmsle: 0.0699 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.4033 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0695 - msle: 4.4213 - rmsle: 0.0672 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.1959 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.2519 - rmsle: 0.0659 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1264 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.1409 - rmsle: 0.0651 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.0533 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0658 - msle: 4.0596 - rmsle: 0.0644 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0831 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9949 - rmsle: 0.0639 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2722 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9424 - rmsle: 0.0636 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1292 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8988 - rmsle: 0.0629 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.0365 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8741 - rmsle: 0.0626 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.9786 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8562 - rmsle: 0.0625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 4.0292 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8360 - rmsle: 0.0624 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.0128 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8142 - rmsle: 0.0622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 4.0419 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8025 - rmsle: 0.0619 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.8245 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7867 - rmsle: 0.0618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8659 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7774 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.8549 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7705 - rmsle: 0.0617 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.8225 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7572 - rmsle: 0.0615 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7903 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7535 - rmsle: 0.0614 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7909 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7533 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7873 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7495 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7805 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7468 - rmsle: 0.0613 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7837 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7388 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7888 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7395 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7788 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7384 - rmsle: 0.0612 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7577 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7370 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7581 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7296 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7569 - val_rmsle: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7360 - rmsle: 0.0611 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7548 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7292 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7470 - val_rmsle: 0.0604 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7273 - rmsle: 0.0610 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7470 - val_rmsle: 0.0604 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06140652223086323\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_7_loss: 0.0000e+00 - loss: 1.6843 - msle: 82.5154 - rmsle: 1.6800 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0891 - val_msle: 7.0992 - val_rmsle: 0.0843 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0836 - msle: 6.1677 - rmsle: 0.0793 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 5.1292 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0726 - msle: 4.8185 - rmsle: 0.0697 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.6530 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.4643 - rmsle: 0.0671 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.5429 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.2792 - rmsle: 0.0658 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.5816 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0665 - msle: 4.1669 - rmsle: 0.0649 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.6930 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0657 - msle: 4.0868 - rmsle: 0.0643 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.6899 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0649 - msle: 4.0227 - rmsle: 0.0638 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.7898 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9677 - rmsle: 0.0631 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.2171 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.9314 - rmsle: 0.0628 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2039 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.9084 - rmsle: 0.0627 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2219 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8924 - rmsle: 0.0625 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1975 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.8659 - rmsle: 0.0621 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.9591 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8473 - rmsle: 0.0619 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.9889 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8423 - rmsle: 0.0618 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.9849 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8315 - rmsle: 0.0617 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.9557 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.8185 - rmsle: 0.0616 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8548 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8180 - rmsle: 0.0615 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8562 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.8055 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8739 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.8019 - rmsle: 0.0614 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.8627 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.8007 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.8157 - val_rmsle: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7934 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.8179 - val_rmsle: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7973 - rmsle: 0.0613 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.8147 - val_rmsle: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7942 - rmsle: 0.0612 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.8163 - val_rmsle: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7910 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7971 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7870 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7962 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7896 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7967 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7909 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.7948 - val_rmsle: 0.0605 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7859 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7914 - val_rmsle: 0.0603 - learning_rate: 7.8125e-06\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7848 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7913 - val_rmsle: 0.0603 - learning_rate: 7.8125e-06\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_7_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7855 - rmsle: 0.0611 - val_dense_7_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.7909 - val_rmsle: 0.0603 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06097510745087363\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_11_loss: 0.0000e+00 - loss: 1.6823 - msle: 82.4265 - rmsle: 1.6780 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0941 - val_msle: 6.9874 - val_rmsle: 0.0894 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0822 - msle: 6.0304 - rmsle: 0.0781 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.7917 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0722 - msle: 4.7686 - rmsle: 0.0693 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.3878 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.4484 - rmsle: 0.0667 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.2863 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0672 - msle: 4.2717 - rmsle: 0.0653 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1113 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0661 - msle: 4.1675 - rmsle: 0.0645 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0972 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0652 - msle: 4.0801 - rmsle: 0.0638 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9234 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0645 - msle: 4.0220 - rmsle: 0.0633 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8904 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.9642 - rmsle: 0.0630 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8610 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.9246 - rmsle: 0.0627 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7840 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8888 - rmsle: 0.0624 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7852 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8631 - rmsle: 0.0623 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7898 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8380 - rmsle: 0.0620 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8961 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8180 - rmsle: 0.0619 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7271 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8036 - rmsle: 0.0618 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7866 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7858 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7516 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7768 - rmsle: 0.0616 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.6921 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7611 - rmsle: 0.0614 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6531 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7533 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6625 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7504 - rmsle: 0.0613 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.6406 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7434 - rmsle: 0.0612 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.6687 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7325 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.6242 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7279 - rmsle: 0.0611 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6284 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7253 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.6227 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7215 - rmsle: 0.0610 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6306 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7190 - rmsle: 0.0609 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6249 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7125 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6421 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7120 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.6191 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7060 - rmsle: 0.0608 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6023 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7004 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6112 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_11_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7036 - rmsle: 0.0607 - val_dense_11_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5976 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.062105901145316646\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 9ms/step - dense_15_loss: 0.0000e+00 - loss: 1.6828 - msle: 82.5507 - rmsle: 1.6785 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 7.1637 - val_rmsle: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0835 - msle: 6.1543 - rmsle: 0.0794 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.8114 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0727 - msle: 4.7714 - rmsle: 0.0698 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.3368 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.4255 - rmsle: 0.0671 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2489 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.2612 - rmsle: 0.0659 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2086 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.1569 - rmsle: 0.0651 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.3445 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0750 - rmsle: 0.0645 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.4649 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0648 - msle: 4.0117 - rmsle: 0.0637 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9737 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9751 - rmsle: 0.0633 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0089 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.9478 - rmsle: 0.0631 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.0850 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.9147 - rmsle: 0.0629 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1095 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8926 - rmsle: 0.0626 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7987 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8761 - rmsle: 0.0624 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8319 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.8640 - rmsle: 0.0623 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7984 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8517 - rmsle: 0.0622 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8301 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8399 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0626 - val_msle: 3.7460 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.8323 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7308 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.8293 - rmsle: 0.0619 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7274 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8193 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7267 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8220 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7193 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.8172 - rmsle: 0.0618 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7155 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8091 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7224 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.8050 - rmsle: 0.0617 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7106 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.8020 - rmsle: 0.0616 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6943 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7920 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6913 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7932 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6896 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7907 - rmsle: 0.0615 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6889 - val_rmsle: 0.0609 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7870 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6865 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7887 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6858 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7885 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6860 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_15_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7879 - rmsle: 0.0614 - val_dense_15_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6851 - val_rmsle: 0.0608 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06176740705515593\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_19_loss: 0.0000e+00 - loss: 1.6870 - msle: 82.6785 - rmsle: 1.6827 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0908 - val_msle: 7.1173 - val_rmsle: 0.0861 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0827 - msle: 6.0670 - rmsle: 0.0785 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.7328 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0722 - msle: 4.7293 - rmsle: 0.0693 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3083 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.3994 - rmsle: 0.0669 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1313 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.2291 - rmsle: 0.0656 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9895 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0663 - msle: 4.1273 - rmsle: 0.0647 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9240 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0655 - msle: 4.0425 - rmsle: 0.0642 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9032 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.9837 - rmsle: 0.0636 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8625 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.9395 - rmsle: 0.0633 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.8841 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8882 - rmsle: 0.0627 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7720 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8703 - rmsle: 0.0625 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7706 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.8482 - rmsle: 0.0623 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7476 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8335 - rmsle: 0.0622 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7363 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.8125 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7265 - val_rmsle: 0.0607 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7990 - rmsle: 0.0619 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7331 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7953 - rmsle: 0.0620 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7109 - val_rmsle: 0.0606 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7777 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6990 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7658 - rmsle: 0.0618 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7102 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7578 - rmsle: 0.0617 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6891 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7476 - rmsle: 0.0616 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6810 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7384 - rmsle: 0.0615 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6754 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7236 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6758 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7211 - rmsle: 0.0612 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6756 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7180 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6801 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7145 - rmsle: 0.0611 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6619 - val_rmsle: 0.0600 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7095 - rmsle: 0.0610 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6554 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7093 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6562 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7016 - rmsle: 0.0609 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6562 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6971 - rmsle: 0.0608 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6545 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6981 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6495 - val_rmsle: 0.0596 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_19_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6949 - rmsle: 0.0607 - val_dense_19_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6490 - val_rmsle: 0.0595 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06034366687663624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 20:50:40,594] Trial 36 finished with value: 0.06131972095176913 and parameters: {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.0001348950441926795, 'do_rate': 0.360817709633252, 'hidden_layers': 1}. Best is trial 34 with value: 0.06064355688132696.\n"
          ]
        }
      ],
      "source": [
        "nn3_study = tune_hyperparameters(X_fin, y_fin, model_class=wide_deep_cross, n_trials=37, n_splits_ = 5 ,n_repeats_=3, use_gpu=True)\n",
        "\n",
        "cat_params = nn3_study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_params"
      ],
      "metadata": {
        "id": "NWxvWm1esZhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3951f4d8-3d1f-4257-f105-7dccaacce4c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 512,\n",
              " 'num_cross_layers': 3,\n",
              " 'activation': 'prelu',\n",
              " 'reg': 0.0001360583533261253,\n",
              " 'do_rate': 0.3763917280440354,\n",
              " 'hidden_layers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 Train Model:"
      ],
      "metadata": {
        "id": "eBV-209nohAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'units': 512, 'num_cross_layers': 3, 'activation': 'prelu', 'reg': 0.0001360583533261253, 'do_rate': 0.3763917280440354,  'hidden_layers': 2}"
      ],
      "metadata": {
        "id": "UvJEkaPhohAA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM = TrainModels(X=data.X, y=data.y, X_test=data.X_test, test_finc_target=y_test_fic, X_original=None, y_original=None, model_=wide_deep_cross, parameters=param)"
      ],
      "metadata": {
        "id": "IhVSLADSohAA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM.fit_model(name=\"NN_widedeepcross_00\")"
      ],
      "metadata": {
        "id": "0gHPUXs5ohAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "742923d6-471c-488f-ac5f-22dd020c31fd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 15s 10ms/step - dense_27_loss: 0.0000e+00 - loss: 1.5761 - msle: 78.1115 - rmsle: 1.5129 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.1042 - val_msle: 6.1364 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.1065 - msle: 5.8161 - rmsle: 0.0795 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.2408 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0827 - msle: 4.6333 - rmsle: 0.0704 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.0788 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0741 - msle: 4.3606 - rmsle: 0.0672 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.6275 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.2044 - rmsle: 0.0657 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.2049 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1513 - rmsle: 0.0654 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0056 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0233 - rmsle: 0.0639 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7751 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0011 - rmsle: 0.0642 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9089 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.9004 - rmsle: 0.0630 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.3483 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8766 - rmsle: 0.0633 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1591 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0648 - msle: 3.8561 - rmsle: 0.0627 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.1173 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8012 - rmsle: 0.0625 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.1045 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8075 - rmsle: 0.0618 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7391 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7701 - rmsle: 0.0615 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7698 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7781 - rmsle: 0.0619 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.9232 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7436 - rmsle: 0.0614 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7190 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7439 - rmsle: 0.0612 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6873 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7973 - rmsle: 0.0613 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7202 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7042 - rmsle: 0.0611 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6761 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7398 - rmsle: 0.0609 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7164 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7178 - rmsle: 0.0612 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6506 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7444 - rmsle: 0.0613 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.7170 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7156 - rmsle: 0.0609 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6491 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6852 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6541 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6905 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6590 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7238 - rmsle: 0.0611 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6522 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6444 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6423 - val_rmsle: 0.0596 - learning_rate: 3.1250e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6534 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6306 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6860 - rmsle: 0.0605 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6391 - val_rmsle: 0.0595 - learning_rate: 3.1250e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6863 - rmsle: 0.0606 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6433 - val_rmsle: 0.0596 - learning_rate: 3.1250e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6804 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6366 - val_rmsle: 0.0594 - learning_rate: 1.5625e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6637 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6365 - val_rmsle: 0.0594 - learning_rate: 1.5625e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6728 - rmsle: 0.0606 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6390 - val_rmsle: 0.0595 - learning_rate: 1.5625e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.7003 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6314 - val_rmsle: 0.0594 - learning_rate: 1.5625e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6439 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6338 - val_rmsle: 0.0594 - learning_rate: 7.8125e-06\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6841 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6325 - val_rmsle: 0.0594 - learning_rate: 7.8125e-06\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6775 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6298 - val_rmsle: 0.0594 - learning_rate: 7.8125e-06\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6598 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6309 - val_rmsle: 0.0594 - learning_rate: 7.8125e-06\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6702 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6313 - val_rmsle: 0.0593 - learning_rate: 7.8125e-06\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6572 - rmsle: 0.0594 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6311 - val_rmsle: 0.0593 - learning_rate: 7.8125e-06\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6395 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6323 - val_rmsle: 0.0593 - learning_rate: 3.9063e-06\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6250 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6290 - val_rmsle: 0.0593 - learning_rate: 3.9063e-06\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6466 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6327 - val_rmsle: 0.0593 - learning_rate: 3.9063e-06\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6640 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6310 - val_rmsle: 0.0593 - learning_rate: 1.9531e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6883 - rmsle: 0.0604 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6305 - val_rmsle: 0.0593 - learning_rate: 1.9531e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6262 - rmsle: 0.0595 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6316 - val_rmsle: 0.0593 - learning_rate: 1.9531e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7045 - rmsle: 0.0605 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6314 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6545 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6312 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6605 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6315 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6686 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6324 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6722 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6309 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6556 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6310 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6382 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6317 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5829 - rmsle: 0.0589 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6301 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6405 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6316 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6538 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6307 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6409 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6308 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6401 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6300 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6589 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6308 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6943 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6292 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6679 - rmsle: 0.0604 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6293 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6332 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6302 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6707 - rmsle: 0.0604 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6306 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6650 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6296 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6107 - rmsle: 0.0594 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6297 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6254 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6291 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6305 - rmsle: 0.0594 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6305 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6505 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6305 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6212 - rmsle: 0.0595 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6294 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6479 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6292 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6454 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6298 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6532 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6301 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6362 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6303 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6416 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6310 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6421 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6301 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6796 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6301 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6237 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6310 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6510 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6304 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6634 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6301 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6383 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6304 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6358 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6305 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6396 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6318 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7099 - rmsle: 0.0603 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6294 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6514 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6302 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6257 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6299 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6413 - rmsle: 0.0603 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6299 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6522 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6295 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6555 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6300 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6776 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6299 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6419 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6296 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6742 - rmsle: 0.0603 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6296 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6292 - rmsle: 0.0595 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6287 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6390 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6300 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6396 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6292 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6188 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6295 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6277 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6281 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6131 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6281 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6334 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6280 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6757 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6294 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6318 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6273 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6776 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6292 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6460 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6281 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6558 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6282 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6992 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6287 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6258 - rmsle: 0.0592 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6285 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6543 - rmsle: 0.0603 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6286 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6434 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6284 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6479 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6282 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6492 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6299 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6887 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6298 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6582 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6298 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6496 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6290 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6802 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6283 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6756 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6283 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6798 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6280 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6797 - rmsle: 0.0607 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6282 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6433 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6288 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6650 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6291 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6357 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6295 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6546 - rmsle: 0.0595 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6285 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6248 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6286 - val_rmsle: 0.0593 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6786 - rmsle: 0.0594 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6289 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6475 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6283 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.5903 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6284 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6629 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6288 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6337 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6276 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6252 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6271 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6810 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6275 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6747 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6280 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6513 - rmsle: 0.0598 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6273 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6252 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6266 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6319 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6286 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6560 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6291 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6497 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6294 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6809 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6268 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6641 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6281 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6272 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6283 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6344 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6277 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6396 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6275 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6594 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6269 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6875 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6287 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6306 - rmsle: 0.0591 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6277 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6308 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6273 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6267 - rmsle: 0.0595 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6266 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6337 - rmsle: 0.0599 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6277 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6442 - rmsle: 0.0596 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6275 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6435 - rmsle: 0.0602 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6271 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6402 - rmsle: 0.0595 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6257 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6550 - rmsle: 0.0600 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6255 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6461 - rmsle: 0.0601 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6269 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_27_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6728 - rmsle: 0.0597 - val_dense_27_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6277 - val_rmsle: 0.0592 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 1 → Training set Score: 1.36158 | Validation set Score: 0.06023\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 16s 10ms/step - dense_31_loss: 0.0000e+00 - loss: 1.6108 - msle: 79.7073 - rmsle: 1.5485 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.1106 - val_msle: 6.3205 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.1032 - msle: 5.8021 - rmsle: 0.0786 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.8137 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0825 - msle: 4.6973 - rmsle: 0.0711 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.4917 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0753 - msle: 4.4117 - rmsle: 0.0686 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.0241 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.2452 - rmsle: 0.0667 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.1179 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0705 - msle: 4.1920 - rmsle: 0.0663 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.0034 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1317 - rmsle: 0.0649 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.2075 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.0688 - rmsle: 0.0644 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0311 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0675 - msle: 3.9864 - rmsle: 0.0644 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9340 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9656 - rmsle: 0.0637 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9563 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0666 - msle: 3.9743 - rmsle: 0.0639 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0694 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9240 - rmsle: 0.0634 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9479 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8691 - rmsle: 0.0630 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9707 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0643 - msle: 3.8276 - rmsle: 0.0622 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.2507 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8037 - rmsle: 0.0620 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8230 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8002 - rmsle: 0.0623 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8964 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7716 - rmsle: 0.0618 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8972 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.7872 - rmsle: 0.0625 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8974 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7177 - rmsle: 0.0607 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8039 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7843 - rmsle: 0.0617 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9037 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7440 - rmsle: 0.0611 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7656 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7327 - rmsle: 0.0616 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8543 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7226 - rmsle: 0.0609 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8162 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7075 - rmsle: 0.0608 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0633 - val_msle: 3.8039 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6994 - rmsle: 0.0611 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7543 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7099 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7617 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6752 - rmsle: 0.0606 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7739 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6781 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7527 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6769 - rmsle: 0.0603 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7400 - val_rmsle: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6961 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7418 - val_rmsle: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6872 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7520 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6816 - rmsle: 0.0606 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7363 - val_rmsle: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6672 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7329 - val_rmsle: 0.0606 - learning_rate: 1.5625e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6431 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7359 - val_rmsle: 0.0606 - learning_rate: 1.5625e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6399 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7313 - val_rmsle: 0.0606 - learning_rate: 1.5625e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6725 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7341 - val_rmsle: 0.0606 - learning_rate: 1.5625e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6436 - rmsle: 0.0593 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7315 - val_rmsle: 0.0605 - learning_rate: 7.8125e-06\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6577 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7288 - val_rmsle: 0.0605 - learning_rate: 7.8125e-06\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6930 - rmsle: 0.0603 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7313 - val_rmsle: 0.0605 - learning_rate: 7.8125e-06\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6670 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7276 - val_rmsle: 0.0605 - learning_rate: 7.8125e-06\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6992 - rmsle: 0.0605 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 3.9063e-06\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6713 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7289 - val_rmsle: 0.0605 - learning_rate: 3.9063e-06\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6480 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7276 - val_rmsle: 0.0605 - learning_rate: 3.9063e-06\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6809 - rmsle: 0.0605 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7285 - val_rmsle: 0.0605 - learning_rate: 1.9531e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6841 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7279 - val_rmsle: 0.0605 - learning_rate: 1.9531e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6762 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7277 - val_rmsle: 0.0605 - learning_rate: 1.9531e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6430 - rmsle: 0.0593 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7288 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6611 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7294 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6878 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7288 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6806 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7292 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6318 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6652 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7283 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6744 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7285 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6674 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7293 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6683 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7286 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6863 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6288 - rmsle: 0.0593 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7284 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6689 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7263 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6570 - rmsle: 0.0603 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7273 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6565 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7277 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6644 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7261 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6603 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7274 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6659 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7288 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6772 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7278 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6580 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7292 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6580 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7295 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6439 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7287 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6696 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7293 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6701 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6998 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6730 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7188 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6662 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7274 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6611 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7275 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6671 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7286 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6491 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7285 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6728 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7282 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6747 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7284 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6781 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7278 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6832 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7283 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6570 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7296 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6841 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7282 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6568 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7279 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6697 - rmsle: 0.0603 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7275 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6445 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7279 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6443 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6768 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7271 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7128 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7284 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6580 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7272 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6691 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7284 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6443 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7262 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6380 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6318 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7280 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6532 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7275 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6499 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7279 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6682 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7267 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6417 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7274 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6475 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7264 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6612 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7282 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6346 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7278 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6260 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7275 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6835 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7285 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6627 - rmsle: 0.0602 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7269 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6871 - rmsle: 0.0603 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7272 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6833 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7280 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6755 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7279 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6253 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7287 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6302 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7271 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6571 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7275 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6409 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7296 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6752 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7278 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6812 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7276 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6664 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7268 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6600 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6828 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7269 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6303 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7270 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6234 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7276 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6879 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7258 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6598 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7262 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6580 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7270 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6493 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7262 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6606 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7262 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6735 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7277 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6662 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7272 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6843 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7260 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6817 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7272 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6568 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7273 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6406 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7287 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6396 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7270 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6256 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7274 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6915 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7262 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6503 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7270 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6578 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7292 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6825 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7265 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6602 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7256 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6880 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7263 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6478 - rmsle: 0.0598 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7265 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6465 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7275 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6484 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7281 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6585 - rmsle: 0.0594 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7266 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6421 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7262 - val_rmsle: 0.0605 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6700 - rmsle: 0.0601 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7262 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6453 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7257 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.7010 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7254 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6602 - rmsle: 0.0596 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7270 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6488 - rmsle: 0.0597 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7264 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6755 - rmsle: 0.0600 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7272 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6342 - rmsle: 0.0595 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7266 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6466 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7268 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6655 - rmsle: 0.0599 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7268 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_31_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6627 - rmsle: 0.0604 - val_dense_31_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7272 - val_rmsle: 0.0604 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step\n",
            "Fold 2 → Training set Score: 1.35999 | Validation set Score: 0.06130\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 15s 10ms/step - dense_35_loss: 0.0000e+00 - loss: 1.6143 - msle: 78.4317 - rmsle: 1.5515 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.1352 - val_msle: 6.4973 - val_rmsle: 0.1063 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.1001 - msle: 5.8400 - rmsle: 0.0771 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 4.5159 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0797 - msle: 4.7208 - rmsle: 0.0698 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0555 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0737 - msle: 4.4623 - rmsle: 0.0679 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.0941 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0704 - msle: 4.2973 - rmsle: 0.0662 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9573 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0685 - msle: 4.1417 - rmsle: 0.0651 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8401 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0677 - msle: 4.0664 - rmsle: 0.0647 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8030 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0473 - rmsle: 0.0642 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0461 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9313 - rmsle: 0.0638 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0030 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.9137 - rmsle: 0.0628 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6575 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8926 - rmsle: 0.0627 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6767 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8278 - rmsle: 0.0618 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7845 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8005 - rmsle: 0.0618 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7275 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8176 - rmsle: 0.0617 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7829 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.8066 - rmsle: 0.0619 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6493 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7544 - rmsle: 0.0615 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6386 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7695 - rmsle: 0.0617 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6309 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7395 - rmsle: 0.0613 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6146 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7197 - rmsle: 0.0609 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.7349 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7777 - rmsle: 0.0613 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5899 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7447 - rmsle: 0.0612 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.6894 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7467 - rmsle: 0.0611 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5646 - val_rmsle: 0.0590 - learning_rate: 6.2500e-05\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6989 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5794 - val_rmsle: 0.0590 - learning_rate: 6.2500e-05\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7502 - rmsle: 0.0609 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5879 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7444 - rmsle: 0.0609 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.5714 - val_rmsle: 0.0589 - learning_rate: 6.2500e-05\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7310 - rmsle: 0.0611 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.5715 - val_rmsle: 0.0590 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7030 - rmsle: 0.0609 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.5570 - val_rmsle: 0.0589 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7027 - rmsle: 0.0611 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.5873 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7076 - rmsle: 0.0606 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0597 - val_msle: 3.5641 - val_rmsle: 0.0588 - learning_rate: 3.1250e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6894 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0597 - val_msle: 3.5539 - val_rmsle: 0.0588 - learning_rate: 3.1250e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6920 - rmsle: 0.0606 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5707 - val_rmsle: 0.0592 - learning_rate: 3.1250e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6773 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.5608 - val_rmsle: 0.0588 - learning_rate: 3.1250e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7208 - rmsle: 0.0606 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.5470 - val_rmsle: 0.0586 - learning_rate: 1.5625e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6987 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.5512 - val_rmsle: 0.0587 - learning_rate: 1.5625e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6622 - rmsle: 0.0598 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.5492 - val_rmsle: 0.0587 - learning_rate: 1.5625e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7158 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5482 - val_rmsle: 0.0586 - learning_rate: 1.5625e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7140 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5518 - val_rmsle: 0.0586 - learning_rate: 7.8125e-06\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6978 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5457 - val_rmsle: 0.0586 - learning_rate: 7.8125e-06\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6847 - rmsle: 0.0606 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5468 - val_rmsle: 0.0586 - learning_rate: 7.8125e-06\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6718 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5478 - val_rmsle: 0.0586 - learning_rate: 3.9063e-06\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7051 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5493 - val_rmsle: 0.0586 - learning_rate: 3.9063e-06\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7229 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5490 - val_rmsle: 0.0586 - learning_rate: 3.9063e-06\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7306 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5458 - val_rmsle: 0.0586 - learning_rate: 1.9531e-06\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6832 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5449 - val_rmsle: 0.0585 - learning_rate: 1.9531e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6877 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5454 - val_rmsle: 0.0585 - learning_rate: 1.9531e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6800 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5456 - val_rmsle: 0.0586 - learning_rate: 1.9531e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6666 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5461 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6961 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5445 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6720 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5460 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6795 - rmsle: 0.0599 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5443 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7192 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5457 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6912 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5449 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6935 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5468 - val_rmsle: 0.0586 - learning_rate: 1.0000e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6654 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5462 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6780 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5463 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6869 - rmsle: 0.0599 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5461 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6895 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5441 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6596 - rmsle: 0.0599 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5458 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6878 - rmsle: 0.0599 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5455 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6782 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5460 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6852 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5458 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6289 - rmsle: 0.0593 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5459 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6701 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5457 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6357 - rmsle: 0.0596 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5462 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6560 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5440 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6979 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5456 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6425 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5452 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6779 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5462 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6358 - rmsle: 0.0597 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5448 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6891 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5459 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6219 - rmsle: 0.0598 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5447 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6660 - rmsle: 0.0596 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5451 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6892 - rmsle: 0.0606 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5452 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6806 - rmsle: 0.0607 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5442 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6658 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5450 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6652 - rmsle: 0.0597 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5457 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7199 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5449 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6520 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5452 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6587 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5447 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6514 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5447 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6999 - rmsle: 0.0607 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5464 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6893 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5440 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6488 - rmsle: 0.0595 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5448 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7211 - rmsle: 0.0605 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5466 - val_rmsle: 0.0586 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6966 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5457 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7363 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5444 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7248 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5461 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7110 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5466 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7300 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5441 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6720 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5445 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6775 - rmsle: 0.0598 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5460 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7028 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5442 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6816 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5439 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7164 - rmsle: 0.0606 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5446 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6784 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5444 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6713 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5439 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6608 - rmsle: 0.0598 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5448 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6588 - rmsle: 0.0599 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5455 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6913 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5440 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6613 - rmsle: 0.0603 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5451 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6745 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5442 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6737 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5457 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6553 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5437 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7030 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5450 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7057 - rmsle: 0.0608 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5443 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6464 - rmsle: 0.0594 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5451 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6879 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5446 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6901 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5439 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6700 - rmsle: 0.0598 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5446 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6933 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5447 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6921 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5438 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7386 - rmsle: 0.0604 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5433 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6765 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5449 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6942 - rmsle: 0.0607 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5440 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6861 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5442 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6619 - rmsle: 0.0600 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5443 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6743 - rmsle: 0.0599 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5447 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6729 - rmsle: 0.0598 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5455 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6776 - rmsle: 0.0601 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5443 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_35_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6577 - rmsle: 0.0602 - val_dense_35_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5438 - val_rmsle: 0.0585 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step\n",
            "Fold 3 → Training set Score: 1.36107 | Validation set Score: 0.05917\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 15s 9ms/step - dense_39_loss: 0.0000e+00 - loss: 1.5211 - msle: 77.4732 - rmsle: 1.4604 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.1211 - val_msle: 6.8137 - val_rmsle: 0.0933 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0990 - msle: 5.8426 - rmsle: 0.0765 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0864 - val_msle: 4.8228 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0796 - msle: 4.6408 - rmsle: 0.0694 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.3168 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0730 - msle: 4.3385 - rmsle: 0.0671 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.4391 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0694 - msle: 4.1810 - rmsle: 0.0652 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.8137 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0951 - rmsle: 0.0645 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.9247 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0667 - msle: 4.0162 - rmsle: 0.0638 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.0726 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0656 - msle: 3.9450 - rmsle: 0.0631 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1189 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0665 - msle: 3.9721 - rmsle: 0.0642 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8759 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8864 - rmsle: 0.0633 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8545 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8458 - rmsle: 0.0628 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.9485 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8235 - rmsle: 0.0623 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.9107 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7896 - rmsle: 0.0622 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8770 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7648 - rmsle: 0.0620 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.9375 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7582 - rmsle: 0.0620 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7818 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7265 - rmsle: 0.0616 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.7677 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6967 - rmsle: 0.0612 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8202 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7429 - rmsle: 0.0616 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.1480 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6847 - rmsle: 0.0606 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7786 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6934 - rmsle: 0.0607 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0623 - val_msle: 3.7353 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7249 - rmsle: 0.0618 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7271 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6970 - rmsle: 0.0615 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0625 - val_msle: 3.7820 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6828 - rmsle: 0.0603 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7161 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6606 - rmsle: 0.0602 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6721 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6991 - rmsle: 0.0602 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6829 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7024 - rmsle: 0.0605 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6880 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6688 - rmsle: 0.0607 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6625 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6756 - rmsle: 0.0604 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6732 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6796 - rmsle: 0.0601 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.6574 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6357 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6559 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6321 - rmsle: 0.0601 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6676 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6367 - rmsle: 0.0600 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6593 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6249 - rmsle: 0.0593 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6603 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6550 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6515 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.6250 - rmsle: 0.0590 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6685 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6812 - rmsle: 0.0603 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6469 - val_rmsle: 0.0603 - learning_rate: 1.5625e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6427 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6503 - val_rmsle: 0.0603 - learning_rate: 1.5625e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6675 - rmsle: 0.0593 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6457 - val_rmsle: 0.0602 - learning_rate: 1.5625e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6104 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6570 - val_rmsle: 0.0602 - learning_rate: 1.5625e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6177 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6479 - val_rmsle: 0.0602 - learning_rate: 7.8125e-06\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6834 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6492 - val_rmsle: 0.0602 - learning_rate: 7.8125e-06\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6369 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6467 - val_rmsle: 0.0602 - learning_rate: 7.8125e-06\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6322 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6471 - val_rmsle: 0.0602 - learning_rate: 7.8125e-06\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6781 - rmsle: 0.0602 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6452 - val_rmsle: 0.0602 - learning_rate: 3.9063e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6569 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6462 - val_rmsle: 0.0602 - learning_rate: 3.9063e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6542 - rmsle: 0.0605 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6442 - val_rmsle: 0.0602 - learning_rate: 3.9063e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6903 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6430 - val_rmsle: 0.0602 - learning_rate: 1.9531e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6450 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6430 - val_rmsle: 0.0602 - learning_rate: 1.9531e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6160 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6447 - val_rmsle: 0.0601 - learning_rate: 1.9531e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6440 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6418 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6180 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6432 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6434 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6432 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6068 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6425 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6528 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6427 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6517 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6520 - rmsle: 0.0598 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6607 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6434 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6490 - rmsle: 0.0604 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6424 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6535 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6437 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.6171 - rmsle: 0.0590 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6429 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6620 - rmsle: 0.0601 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6423 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6595 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6419 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6532 - rmsle: 0.0600 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6427 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6487 - rmsle: 0.0601 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6433 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6276 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6428 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6180 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6437 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6560 - rmsle: 0.0598 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6453 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6426 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6403 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6424 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.5956 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6447 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6128 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6494 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6417 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6220 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6422 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6191 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6429 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6291 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6419 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5943 - rmsle: 0.0589 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6430 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6481 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6408 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6493 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6415 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6372 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6500 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6430 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6418 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6417 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6408 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6425 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6148 - rmsle: 0.0598 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6428 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6074 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6436 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6449 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6427 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6302 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6406 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6544 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6415 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.6222 - rmsle: 0.0590 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6192 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6409 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6300 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6432 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6184 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6418 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6542 - rmsle: 0.0602 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6424 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6316 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6412 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6543 - rmsle: 0.0600 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6422 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6420 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6426 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6092 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6431 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6166 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6413 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6252 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6583 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6413 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6634 - rmsle: 0.0601 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6428 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6546 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6422 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6232 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.6051 - rmsle: 0.0590 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6412 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6328 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6410 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6297 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6413 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6987 - rmsle: 0.0605 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6418 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6158 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6120 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6413 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6047 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6412 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6226 - rmsle: 0.0593 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6415 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6541 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6418 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6063 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6427 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6401 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6435 - rmsle: 0.0604 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6481 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6409 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6266 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6420 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6398 - rmsle: 0.0593 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6364 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6408 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6075 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6420 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6254 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6428 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6009 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5844 - rmsle: 0.0593 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6427 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6224 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6408 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6241 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6426 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6975 - rmsle: 0.0603 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6410 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6555 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6413 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6083 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6414 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6622 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6410 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6341 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6414 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6624 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6411 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5960 - rmsle: 0.0592 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6415 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6267 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6416 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6394 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6401 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6467 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6403 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6116 - rmsle: 0.0593 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6427 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6303 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6425 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5961 - rmsle: 0.0589 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6306 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6409 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6191 - rmsle: 0.0596 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6411 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6554 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6414 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6409 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6415 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.6144 - rmsle: 0.0591 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6417 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6398 - rmsle: 0.0597 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6444 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5951 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6421 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6363 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6409 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6098 - rmsle: 0.0591 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6424 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6322 - rmsle: 0.0599 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6412 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6120 - rmsle: 0.0595 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6419 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6254 - rmsle: 0.0594 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6419 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6620 - rmsle: 0.0591 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6419 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_39_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6374 - rmsle: 0.0600 - val_dense_39_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6418 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 4 → Training set Score: 1.36299 | Validation set Score: 0.06095\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 16s 10ms/step - dense_43_loss: 0.0000e+00 - loss: 1.5651 - msle: 78.1765 - rmsle: 1.5033 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.1158 - val_msle: 5.6602 - val_rmsle: 0.0868 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0999 - msle: 5.5033 - rmsle: 0.0765 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 4.2338 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0809 - msle: 4.6036 - rmsle: 0.0703 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 3.8677 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.3748 - rmsle: 0.0681 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.7906 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0717 - msle: 4.1975 - rmsle: 0.0670 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8860 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0691 - msle: 4.1242 - rmsle: 0.0653 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.6465 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0678 - msle: 4.0465 - rmsle: 0.0645 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.3071 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0203 - rmsle: 0.0643 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0578 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9528 - rmsle: 0.0640 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8329 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8900 - rmsle: 0.0630 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6134 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8612 - rmsle: 0.0633 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.6121 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.8936 - rmsle: 0.0625 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.9815 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7936 - rmsle: 0.0619 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7125 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8150 - rmsle: 0.0618 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.5716 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7956 - rmsle: 0.0617 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.5381 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0633 - msle: 3.7965 - rmsle: 0.0619 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.4868 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7585 - rmsle: 0.0616 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.5495 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7755 - rmsle: 0.0613 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.5704 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7674 - rmsle: 0.0616 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.4824 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0631 - msle: 3.7749 - rmsle: 0.0618 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.5527 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7631 - rmsle: 0.0608 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.5189 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7581 - rmsle: 0.0615 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.5637 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7186 - rmsle: 0.0609 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5039 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7274 - rmsle: 0.0615 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5054 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7103 - rmsle: 0.0607 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.5138 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7221 - rmsle: 0.0606 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.4714 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7653 - rmsle: 0.0613 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.4682 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7408 - rmsle: 0.0610 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.5188 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7160 - rmsle: 0.0606 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.4563 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6959 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.4536 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7212 - rmsle: 0.0605 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.4423 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7155 - rmsle: 0.0606 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.4448 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7277 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.4353 - val_rmsle: 0.0602 - learning_rate: 3.1250e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7259 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.4323 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6869 - rmsle: 0.0605 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.4441 - val_rmsle: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7086 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.4435 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7594 - rmsle: 0.0609 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.4551 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7001 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.4435 - val_rmsle: 0.0599 - learning_rate: 1.5625e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7150 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.4373 - val_rmsle: 0.0598 - learning_rate: 1.5625e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7093 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.4350 - val_rmsle: 0.0598 - learning_rate: 1.5625e-05\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6587 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.4308 - val_rmsle: 0.0598 - learning_rate: 1.5625e-05\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7780 - rmsle: 0.0607 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.4301 - val_rmsle: 0.0597 - learning_rate: 1.5625e-05\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6667 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.4348 - val_rmsle: 0.0598 - learning_rate: 1.5625e-05\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6914 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.4278 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6700 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.4312 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6943 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.4268 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6783 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.4321 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6894 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4279 - val_rmsle: 0.0597 - learning_rate: 3.9063e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6432 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4273 - val_rmsle: 0.0597 - learning_rate: 3.9063e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7256 - rmsle: 0.0607 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4304 - val_rmsle: 0.0597 - learning_rate: 3.9063e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7400 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4298 - val_rmsle: 0.0597 - learning_rate: 1.9531e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6537 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4287 - val_rmsle: 0.0597 - learning_rate: 1.9531e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7245 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4289 - val_rmsle: 0.0597 - learning_rate: 1.9531e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6969 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4290 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6906 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4285 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6715 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4300 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6733 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4297 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6708 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4288 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7120 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4277 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7049 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4279 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6858 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4290 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7202 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4299 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6937 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4294 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7203 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4299 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6718 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4295 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6623 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4280 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6707 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4291 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6275 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4297 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6217 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4278 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6680 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4296 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6956 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4282 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6416 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4284 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7189 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4284 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6587 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4274 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7079 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4279 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6816 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4297 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6711 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4274 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6993 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4279 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.7114 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4271 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7207 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4289 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6565 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4285 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6747 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4274 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6663 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4282 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6739 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4295 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7018 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4285 - val_rmsle: 0.0597 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6933 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4285 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6688 - rmsle: 0.0592 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4275 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6643 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6647 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4273 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.7219 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4291 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6932 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4275 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7036 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4286 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6926 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4300 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6978 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4294 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6698 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.4270 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6938 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6951 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4269 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6664 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4275 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6756 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4278 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7265 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4298 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6907 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4282 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6978 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4266 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7139 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4287 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6971 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4277 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6884 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4262 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6734 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6999 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4268 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7007 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4274 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6954 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4269 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6746 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6899 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4275 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7118 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.7091 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4282 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6401 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4277 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6853 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4278 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7139 - rmsle: 0.0603 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4277 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6654 - rmsle: 0.0595 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4279 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.7003 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4265 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6838 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4281 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6811 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4283 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6905 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4283 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6848 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4271 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6950 - rmsle: 0.0605 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4274 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6614 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4277 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6813 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4265 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6897 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4271 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6733 - rmsle: 0.0595 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6585 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4287 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7138 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4276 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6893 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4263 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6836 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4268 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6847 - rmsle: 0.0605 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4270 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6707 - rmsle: 0.0601 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4257 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7026 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4262 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6723 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4270 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6771 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4262 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6644 - rmsle: 0.0594 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4259 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7151 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4272 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7180 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4266 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6692 - rmsle: 0.0598 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4267 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6945 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4268 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6966 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4256 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6557 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4267 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7213 - rmsle: 0.0604 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4260 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7049 - rmsle: 0.0600 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4260 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6626 - rmsle: 0.0602 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4246 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6887 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4257 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6622 - rmsle: 0.0596 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4269 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6785 - rmsle: 0.0597 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4262 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6461 - rmsle: 0.0592 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4260 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_43_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6789 - rmsle: 0.0599 - val_dense_43_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.4263 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step\n",
            "Fold 5 → Training set Score: 1.36077 | Validation set Score: 0.06048\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 15s 10ms/step - dense_47_loss: 0.0000e+00 - loss: 1.5366 - msle: 78.6568 - rmsle: 1.4759 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.1193 - val_msle: 7.0778 - val_rmsle: 0.0917 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0983 - msle: 5.7573 - rmsle: 0.0761 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.4364 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0789 - msle: 4.6632 - rmsle: 0.0690 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.1017 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0724 - msle: 4.3683 - rmsle: 0.0668 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.5598 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.2212 - rmsle: 0.0649 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.6737 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0675 - msle: 4.1188 - rmsle: 0.0644 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0334 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0666 - msle: 4.0538 - rmsle: 0.0640 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1404 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9996 - rmsle: 0.0637 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1323 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.9095 - rmsle: 0.0631 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8379 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.8969 - rmsle: 0.0629 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.2376 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8998 - rmsle: 0.0630 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.2241 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8156 - rmsle: 0.0621 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.8441 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0637 - msle: 3.7394 - rmsle: 0.0621 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1612 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0640 - msle: 3.7986 - rmsle: 0.0624 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.8505 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.7657 - rmsle: 0.0627 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8178 - val_rmsle: 0.0619 - learning_rate: 5.0000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7207 - rmsle: 0.0612 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8233 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.6969 - rmsle: 0.0613 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.9420 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6489 - rmsle: 0.0607 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.9759 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6655 - rmsle: 0.0611 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.7378 - val_rmsle: 0.0609 - learning_rate: 2.5000e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6847 - rmsle: 0.0609 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7044 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6940 - rmsle: 0.0611 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7469 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.6745 - rmsle: 0.0610 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8046 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6863 - rmsle: 0.0608 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7690 - val_rmsle: 0.0623 - learning_rate: 2.5000e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6986 - rmsle: 0.0604 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6927 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.6720 - rmsle: 0.0608 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.6729 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6644 - rmsle: 0.0604 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6988 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6833 - rmsle: 0.0605 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6922 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6569 - rmsle: 0.0606 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6696 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6248 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.6962 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6222 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6777 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6438 - rmsle: 0.0600 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6742 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6138 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6575 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6375 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6603 - val_rmsle: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6244 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6515 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6064 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6718 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6559 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6596 - val_rmsle: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6032 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6578 - val_rmsle: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6632 - rmsle: 0.0604 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6523 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6354 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6538 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6590 - rmsle: 0.0603 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6477 - val_rmsle: 0.0597 - learning_rate: 1.5625e-05\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6553 - rmsle: 0.0602 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6524 - val_rmsle: 0.0597 - learning_rate: 1.5625e-05\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6216 - rmsle: 0.0600 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6512 - val_rmsle: 0.0598 - learning_rate: 1.5625e-05\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6180 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6499 - val_rmsle: 0.0598 - learning_rate: 1.5625e-05\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6187 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6479 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6420 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6464 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5811 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6464 - val_rmsle: 0.0597 - learning_rate: 7.8125e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5826 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6483 - val_rmsle: 0.0596 - learning_rate: 3.9063e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5911 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6475 - val_rmsle: 0.0596 - learning_rate: 3.9063e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6092 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6470 - val_rmsle: 0.0596 - learning_rate: 3.9063e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6011 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6468 - val_rmsle: 0.0596 - learning_rate: 3.9063e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6148 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6471 - val_rmsle: 0.0596 - learning_rate: 3.9063e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6156 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6469 - val_rmsle: 0.0596 - learning_rate: 1.9531e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6041 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6459 - val_rmsle: 0.0596 - learning_rate: 1.9531e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6118 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6475 - val_rmsle: 0.0596 - learning_rate: 1.9531e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6131 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6463 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5912 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6465 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6840 - rmsle: 0.0602 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6455 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6643 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6467 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6041 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6462 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6190 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6461 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6047 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6462 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6465 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6452 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.5834 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6459 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6591 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6454 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5697 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6459 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6021 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6458 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5911 - rmsle: 0.0590 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6461 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5991 - rmsle: 0.0590 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6036 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6455 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5873 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6458 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6046 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6462 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6878 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6132 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6460 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6485 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6455 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6075 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6450 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5860 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6450 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5719 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6457 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0593 - msle: 3.5851 - rmsle: 0.0588 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6455 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6027 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6451 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6310 - rmsle: 0.0602 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6454 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6379 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6446 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6481 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6382 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6446 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5914 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6401 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6449 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5939 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6458 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6425 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6445 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5775 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6456 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5873 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6448 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6146 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6456 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6289 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6412 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6448 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6092 - rmsle: 0.0601 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6447 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6226 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6461 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5899 - rmsle: 0.0591 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5863 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6458 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.6148 - rmsle: 0.0591 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6451 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6262 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6461 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5953 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6447 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0594 - msle: 3.5723 - rmsle: 0.0590 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6448 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6469 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6451 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6388 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6065 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6449 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.6198 - rmsle: 0.0590 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6112 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6452 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6130 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6442 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6207 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6147 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5681 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6446 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6698 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6446 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5870 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6446 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6393 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6448 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6229 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6454 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0593 - msle: 3.5905 - rmsle: 0.0589 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6445 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0591 - msle: 3.5863 - rmsle: 0.0586 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6446 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5986 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6681 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6451 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6053 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6444 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5842 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6447 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6157 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6447 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6244 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6443 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5939 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6555 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5881 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6444 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0592 - msle: 3.5836 - rmsle: 0.0587 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6447 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0593 - msle: 3.6150 - rmsle: 0.0588 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6445 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6203 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6450 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6010 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6449 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6078 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6438 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5969 - rmsle: 0.0591 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6444 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5921 - rmsle: 0.0591 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5727 - rmsle: 0.0590 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6447 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6363 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6189 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6449 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6240 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6448 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6448 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6448 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6119 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6450 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5755 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6444 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6386 - rmsle: 0.0599 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6437 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6263 - rmsle: 0.0593 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6440 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6310 - rmsle: 0.0596 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6441 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6054 - rmsle: 0.0594 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6444 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6400 - rmsle: 0.0598 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6437 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5893 - rmsle: 0.0592 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6452 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0594 - msle: 3.5940 - rmsle: 0.0590 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6451 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6072 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6437 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6350 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6437 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.5842 - rmsle: 0.0591 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6441 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0594 - msle: 3.5882 - rmsle: 0.0589 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6444 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6199 - rmsle: 0.0595 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6439 - val_rmsle: 0.0596 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_47_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5906 - rmsle: 0.0597 - val_dense_47_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6440 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 6 → Training set Score: 1.36073 | Validation set Score: 0.06015\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 19s 10ms/step - dense_51_loss: 0.0000e+00 - loss: 1.4973 - msle: 77.1038 - rmsle: 1.4363 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.1346 - val_msle: 5.9315 - val_rmsle: 0.1065 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0995 - msle: 5.5001 - rmsle: 0.0767 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 4.2870 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0813 - msle: 4.6314 - rmsle: 0.0706 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.0507 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0743 - msle: 4.3731 - rmsle: 0.0677 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 3.8429 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0716 - msle: 4.2345 - rmsle: 0.0667 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.5038 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.1851 - rmsle: 0.0662 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8469 - val_rmsle: 0.0612 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0692 - msle: 4.1015 - rmsle: 0.0657 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.4066 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0679 - msle: 4.0554 - rmsle: 0.0648 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0635 - val_msle: 3.7167 - val_rmsle: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0120 - rmsle: 0.0644 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.9848 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0673 - msle: 4.0021 - rmsle: 0.0647 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.1899 - val_rmsle: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0663 - msle: 3.9509 - rmsle: 0.0638 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.8672 - val_rmsle: 0.0615 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0651 - msle: 3.8343 - rmsle: 0.0630 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.5683 - val_rmsle: 0.0586 - learning_rate: 2.5000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8436 - rmsle: 0.0625 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.6053 - val_rmsle: 0.0600 - learning_rate: 2.5000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8594 - rmsle: 0.0625 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.8065 - val_rmsle: 0.0602 - learning_rate: 2.5000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7902 - rmsle: 0.0622 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.6510 - val_rmsle: 0.0594 - learning_rate: 2.5000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8258 - rmsle: 0.0622 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.5699 - val_rmsle: 0.0586 - learning_rate: 1.2500e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.7690 - rmsle: 0.0617 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.4969 - val_rmsle: 0.0581 - learning_rate: 1.2500e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7361 - rmsle: 0.0617 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0597 - val_msle: 3.5661 - val_rmsle: 0.0584 - learning_rate: 1.2500e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7748 - rmsle: 0.0617 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5657 - val_rmsle: 0.0587 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7695 - rmsle: 0.0615 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.4946 - val_rmsle: 0.0580 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7176 - rmsle: 0.0613 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6162 - val_rmsle: 0.0590 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7393 - rmsle: 0.0618 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.5303 - val_rmsle: 0.0582 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7525 - rmsle: 0.0611 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7007 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7815 - rmsle: 0.0610 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0589 - val_msle: 3.5040 - val_rmsle: 0.0578 - learning_rate: 6.2500e-05\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7590 - rmsle: 0.0614 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0590 - val_msle: 3.4821 - val_rmsle: 0.0579 - learning_rate: 6.2500e-05\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7258 - rmsle: 0.0610 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0590 - val_msle: 3.4965 - val_rmsle: 0.0580 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7272 - rmsle: 0.0612 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5325 - val_rmsle: 0.0589 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7019 - rmsle: 0.0608 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0584 - val_msle: 3.4698 - val_rmsle: 0.0574 - learning_rate: 3.1250e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7097 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0584 - val_msle: 3.4819 - val_rmsle: 0.0574 - learning_rate: 3.1250e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7070 - rmsle: 0.0608 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0584 - val_msle: 3.4624 - val_rmsle: 0.0574 - learning_rate: 3.1250e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7465 - rmsle: 0.0611 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0584 - val_msle: 3.4687 - val_rmsle: 0.0574 - learning_rate: 3.1250e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7087 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0583 - val_msle: 3.4608 - val_rmsle: 0.0573 - learning_rate: 1.5625e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6809 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0582 - val_msle: 3.4598 - val_rmsle: 0.0572 - learning_rate: 1.5625e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6414 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0582 - val_msle: 3.4612 - val_rmsle: 0.0572 - learning_rate: 1.5625e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7101 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0581 - val_msle: 3.4581 - val_rmsle: 0.0572 - learning_rate: 1.5625e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7118 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0581 - val_msle: 3.4571 - val_rmsle: 0.0572 - learning_rate: 1.5625e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6993 - rmsle: 0.0607 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0581 - val_msle: 3.4578 - val_rmsle: 0.0572 - learning_rate: 1.5625e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6997 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0582 - val_msle: 3.4633 - val_rmsle: 0.0573 - learning_rate: 1.5625e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6670 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0581 - val_msle: 3.4660 - val_rmsle: 0.0572 - learning_rate: 7.8125e-06\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7333 - rmsle: 0.0608 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0581 - val_msle: 3.4558 - val_rmsle: 0.0572 - learning_rate: 7.8125e-06\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7130 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0581 - val_msle: 3.4601 - val_rmsle: 0.0572 - learning_rate: 7.8125e-06\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7395 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4591 - val_rmsle: 0.0571 - learning_rate: 3.9063e-06\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7009 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4601 - val_rmsle: 0.0572 - learning_rate: 3.9063e-06\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7303 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 3.9063e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6798 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4578 - val_rmsle: 0.0571 - learning_rate: 1.9531e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.7048 - rmsle: 0.0609 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4571 - val_rmsle: 0.0571 - learning_rate: 1.9531e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7185 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4558 - val_rmsle: 0.0571 - learning_rate: 1.9531e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7526 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4557 - val_rmsle: 0.0572 - learning_rate: 1.9531e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6857 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4575 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6861 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4571 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6796 - rmsle: 0.0596 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4563 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6870 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4569 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6908 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4581 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6952 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4574 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6933 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4564 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6926 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4570 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6456 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4571 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7242 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4578 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7229 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4562 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7054 - rmsle: 0.0612 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4569 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7153 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4565 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6802 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4573 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6969 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4569 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6664 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4558 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6998 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4574 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6804 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4561 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7006 - rmsle: 0.0608 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4558 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6660 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4555 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6820 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4566 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6775 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4563 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6551 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4565 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6526 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4557 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7259 - rmsle: 0.0608 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0580 - val_msle: 3.4555 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6670 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4576 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7539 - rmsle: 0.0607 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4571 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6837 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4554 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6711 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4570 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6724 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4566 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7453 - rmsle: 0.0612 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4554 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7464 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4554 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6709 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4558 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6934 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6753 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4574 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7024 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4548 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6985 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4549 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6672 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4567 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6987 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4565 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7014 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4544 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6887 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4553 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7045 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4557 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6821 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4559 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6778 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4551 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7188 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4546 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7050 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4573 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7212 - rmsle: 0.0610 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4561 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6782 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4553 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6529 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4561 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6946 - rmsle: 0.0607 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6821 - rmsle: 0.0607 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4553 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6824 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4555 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6973 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4550 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7270 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4548 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6854 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4563 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7141 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4561 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6783 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4547 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7306 - rmsle: 0.0608 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4546 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6951 - rmsle: 0.0597 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4566 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6763 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4550 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7082 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4563 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6950 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4562 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7009 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4544 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6488 - rmsle: 0.0597 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4543 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6947 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4564 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6893 - rmsle: 0.0597 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4550 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6899 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4559 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6799 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4544 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6944 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4553 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6614 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4559 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6610 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4552 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6671 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4552 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6998 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4538 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6596 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4545 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6873 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4546 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6591 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6779 - rmsle: 0.0605 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6709 - rmsle: 0.0607 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4548 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6958 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4546 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6842 - rmsle: 0.0599 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4563 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7109 - rmsle: 0.0611 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4562 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6770 - rmsle: 0.0607 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4545 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6989 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4562 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7087 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4565 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6775 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4538 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6983 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4559 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6516 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6636 - rmsle: 0.0595 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4534 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6734 - rmsle: 0.0603 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4549 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7116 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4554 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6860 - rmsle: 0.0594 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4538 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7424 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4542 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7121 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4540 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6872 - rmsle: 0.0600 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4551 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6884 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4545 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7055 - rmsle: 0.0604 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4538 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6479 - rmsle: 0.0601 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4555 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6658 - rmsle: 0.0597 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4546 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7080 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4550 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6790 - rmsle: 0.0602 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4539 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6588 - rmsle: 0.0595 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4540 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6860 - rmsle: 0.0606 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4556 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_51_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6658 - rmsle: 0.0598 - val_dense_51_loss: 0.0000e+00 - val_loss: 0.0579 - val_msle: 3.4538 - val_rmsle: 0.0571 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 7 → Training set Score: 1.36123 | Validation set Score: 0.05757\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 16s 10ms/step - dense_55_loss: 0.0000e+00 - loss: 1.5136 - msle: 77.4480 - rmsle: 1.4517 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.1047 - val_msle: 6.8224 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.1035 - msle: 6.1180 - rmsle: 0.0792 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 4.7319 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.8002 - rmsle: 0.0706 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1325 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0746 - msle: 4.4716 - rmsle: 0.0683 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2050 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0707 - msle: 4.2866 - rmsle: 0.0663 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1389 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0688 - msle: 4.1829 - rmsle: 0.0652 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9493 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0681 - msle: 4.1477 - rmsle: 0.0649 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.3010 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0674 - msle: 4.0897 - rmsle: 0.0646 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 5.8167 - val_rmsle: 0.0855 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0669 - msle: 4.0230 - rmsle: 0.0642 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.3343 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0659 - msle: 3.9921 - rmsle: 0.0633 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 4.0548 - val_rmsle: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0659 - msle: 4.0027 - rmsle: 0.0635 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9033 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9532 - rmsle: 0.0634 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0636 - val_msle: 3.7921 - val_rmsle: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.9104 - rmsle: 0.0632 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.8236 - val_rmsle: 0.0611 - learning_rate: 5.0000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0650 - msle: 3.8954 - rmsle: 0.0628 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.6035 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0652 - msle: 3.8837 - rmsle: 0.0631 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.9760 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.8543 - rmsle: 0.0627 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8654 - val_rmsle: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7880 - rmsle: 0.0616 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7651 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7351 - rmsle: 0.0615 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7343 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.8048 - rmsle: 0.0624 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0628 - val_msle: 3.8299 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7609 - rmsle: 0.0624 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7708 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.7668 - rmsle: 0.0613 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7393 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0630 - msle: 3.7533 - rmsle: 0.0617 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.7090 - val_rmsle: 0.0602 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7113 - rmsle: 0.0612 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.8674 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7439 - rmsle: 0.0611 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.7427 - val_rmsle: 0.0606 - learning_rate: 1.2500e-04\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7180 - rmsle: 0.0611 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6779 - val_rmsle: 0.0597 - learning_rate: 1.2500e-04\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7241 - rmsle: 0.0612 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8058 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7122 - rmsle: 0.0613 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7645 - val_rmsle: 0.0608 - learning_rate: 1.2500e-04\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0617 - msle: 3.6872 - rmsle: 0.0607 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6607 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6839 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6581 - val_rmsle: 0.0594 - learning_rate: 6.2500e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6652 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6455 - val_rmsle: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6950 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6529 - val_rmsle: 0.0597 - learning_rate: 6.2500e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.7019 - rmsle: 0.0607 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6453 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7159 - rmsle: 0.0610 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.6413 - val_rmsle: 0.0591 - learning_rate: 6.2500e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7017 - rmsle: 0.0607 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6649 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6663 - rmsle: 0.0602 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6504 - val_rmsle: 0.0595 - learning_rate: 6.2500e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7041 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6578 - val_rmsle: 0.0590 - learning_rate: 3.1250e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6673 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0599 - val_msle: 3.6382 - val_rmsle: 0.0590 - learning_rate: 3.1250e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6707 - rmsle: 0.0605 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6497 - val_rmsle: 0.0595 - learning_rate: 3.1250e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6560 - rmsle: 0.0605 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0597 - val_msle: 3.6378 - val_rmsle: 0.0589 - learning_rate: 3.1250e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6364 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0598 - val_msle: 3.6440 - val_rmsle: 0.0591 - learning_rate: 3.1250e-05\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6522 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0598 - val_msle: 3.6442 - val_rmsle: 0.0590 - learning_rate: 3.1250e-05\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6684 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0598 - val_msle: 3.6694 - val_rmsle: 0.0591 - learning_rate: 3.1250e-05\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7043 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.6380 - val_rmsle: 0.0588 - learning_rate: 1.5625e-05\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6644 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.6471 - val_rmsle: 0.0589 - learning_rate: 1.5625e-05\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6182 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0597 - val_msle: 3.6526 - val_rmsle: 0.0590 - learning_rate: 1.5625e-05\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6825 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.6346 - val_rmsle: 0.0589 - learning_rate: 1.5625e-05\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6520 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.6354 - val_rmsle: 0.0588 - learning_rate: 7.8125e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6984 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.6382 - val_rmsle: 0.0588 - learning_rate: 7.8125e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6360 - rmsle: 0.0598 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6316 - val_rmsle: 0.0588 - learning_rate: 7.8125e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6557 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.6382 - val_rmsle: 0.0589 - learning_rate: 7.8125e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6082 - rmsle: 0.0594 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6319 - val_rmsle: 0.0588 - learning_rate: 7.8125e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6655 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6366 - val_rmsle: 0.0588 - learning_rate: 7.8125e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6396 - rmsle: 0.0602 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6343 - val_rmsle: 0.0588 - learning_rate: 3.9063e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6438 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6346 - val_rmsle: 0.0588 - learning_rate: 3.9063e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6436 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6344 - val_rmsle: 0.0588 - learning_rate: 3.9063e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6336 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6333 - val_rmsle: 0.0588 - learning_rate: 1.9531e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6356 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6363 - val_rmsle: 0.0588 - learning_rate: 1.9531e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6637 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6341 - val_rmsle: 0.0588 - learning_rate: 1.9531e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6678 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6329 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6567 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6344 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6373 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6330 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6490 - rmsle: 0.0605 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6325 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6449 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6331 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6470 - rmsle: 0.0602 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6338 - val_rmsle: 0.0588 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6566 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6345 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6678 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6328 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6445 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6328 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6441 - rmsle: 0.0598 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6356 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6382 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6332 - val_rmsle: 0.0588 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6642 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6344 - val_rmsle: 0.0588 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6243 - rmsle: 0.0594 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6342 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6527 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.6340 - val_rmsle: 0.0588 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6790 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6339 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6591 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6348 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6186 - rmsle: 0.0605 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6337 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6290 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6332 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6795 - rmsle: 0.0602 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6340 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6421 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6330 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6367 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6327 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6595 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6330 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6396 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6332 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6461 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6331 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6583 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6322 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6601 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6326 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6778 - rmsle: 0.0598 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6341 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6258 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6329 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6492 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6326 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6169 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6326 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6240 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6352 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6401 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6336 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6628 - rmsle: 0.0598 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6313 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6481 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6336 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6560 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6322 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6820 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6332 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6226 - rmsle: 0.0594 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6325 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6590 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6340 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6116 - rmsle: 0.0593 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6349 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6326 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6336 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6667 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6338 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6376 - rmsle: 0.0593 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6317 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6320 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6338 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6620 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6324 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6242 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6329 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6020 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6324 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6228 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6335 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6339 - rmsle: 0.0602 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6323 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6861 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6327 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6511 - rmsle: 0.0598 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6318 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6694 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6329 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6341 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6315 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6358 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6316 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6477 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6318 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6187 - rmsle: 0.0591 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6324 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6115 - rmsle: 0.0592 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6326 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6462 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6322 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6226 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6333 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6540 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6319 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6137 - rmsle: 0.0598 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6318 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5882 - rmsle: 0.0592 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6320 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6691 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6311 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6871 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6339 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6476 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6335 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6590 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6321 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6411 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6325 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6476 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6337 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6244 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6323 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6316 - rmsle: 0.0599 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6326 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6119 - rmsle: 0.0592 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6331 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6836 - rmsle: 0.0604 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6324 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6748 - rmsle: 0.0594 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6323 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6109 - rmsle: 0.0595 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6337 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6315 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6331 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6334 - rmsle: 0.0594 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6335 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6690 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6315 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6873 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6318 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6633 - rmsle: 0.0603 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6324 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6148 - rmsle: 0.0601 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6321 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6450 - rmsle: 0.0600 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6321 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6421 - rmsle: 0.0596 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6336 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6215 - rmsle: 0.0592 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6317 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_55_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6522 - rmsle: 0.0597 - val_dense_55_loss: 0.0000e+00 - val_loss: 0.0594 - val_msle: 3.6322 - val_rmsle: 0.0587 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step\n",
            "Fold 8 → Training set Score: 1.36020 | Validation set Score: 0.05927\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 16s 10ms/step - dense_59_loss: 0.0000e+00 - loss: 1.5450 - msle: 77.7985 - rmsle: 1.4828 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.1326 - val_msle: 6.0788 - val_rmsle: 0.1030 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.1016 - msle: 5.6944 - rmsle: 0.0776 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.3964 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0816 - msle: 4.6160 - rmsle: 0.0707 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 4.2800 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0745 - msle: 4.3916 - rmsle: 0.0682 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.2943 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0702 - msle: 4.1674 - rmsle: 0.0658 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.4079 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0684 - msle: 4.0985 - rmsle: 0.0648 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0220 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0670 - msle: 4.0320 - rmsle: 0.0639 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0025 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0662 - msle: 3.9358 - rmsle: 0.0634 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0649 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9001 - rmsle: 0.0632 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0330 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.8655 - rmsle: 0.0633 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.0302 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0655 - msle: 3.8556 - rmsle: 0.0633 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.0091 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0654 - msle: 3.8521 - rmsle: 0.0633 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8995 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.8069 - rmsle: 0.0617 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.7950 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.7703 - rmsle: 0.0618 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.8365 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.7637 - rmsle: 0.0621 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0630 - val_msle: 3.7913 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7244 - rmsle: 0.0613 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.8026 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6932 - rmsle: 0.0612 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7148 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7167 - rmsle: 0.0609 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7190 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.6754 - rmsle: 0.0607 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0622 - val_msle: 3.7478 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.6904 - rmsle: 0.0609 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7149 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7151 - rmsle: 0.0613 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.7321 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.7098 - rmsle: 0.0608 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.7188 - val_rmsle: 0.0605 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0624 - msle: 3.7104 - rmsle: 0.0613 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.7095 - val_rmsle: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7082 - rmsle: 0.0609 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7312 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.7308 - rmsle: 0.0614 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0613 - val_msle: 3.7084 - val_rmsle: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7244 - rmsle: 0.0610 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.7495 - val_rmsle: 0.0607 - learning_rate: 1.2500e-04\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6664 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6790 - val_rmsle: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6911 - rmsle: 0.0604 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.7097 - val_rmsle: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7196 - rmsle: 0.0611 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6745 - val_rmsle: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6976 - rmsle: 0.0603 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.6869 - val_rmsle: 0.0599 - learning_rate: 6.2500e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6556 - rmsle: 0.0603 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6731 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6801 - rmsle: 0.0602 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6656 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6571 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.6754 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6656 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6744 - val_rmsle: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7003 - rmsle: 0.0604 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6708 - val_rmsle: 0.0597 - learning_rate: 3.1250e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6694 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6718 - val_rmsle: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7054 - rmsle: 0.0604 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6766 - val_rmsle: 0.0597 - learning_rate: 3.1250e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6880 - rmsle: 0.0607 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6825 - val_rmsle: 0.0597 - learning_rate: 3.1250e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6571 - rmsle: 0.0603 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6726 - val_rmsle: 0.0596 - learning_rate: 1.5625e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6573 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6637 - val_rmsle: 0.0596 - learning_rate: 1.5625e-05\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6429 - rmsle: 0.0602 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.6645 - val_rmsle: 0.0597 - learning_rate: 1.5625e-05\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6122 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6577 - val_rmsle: 0.0595 - learning_rate: 1.5625e-05\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6380 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6613 - val_rmsle: 0.0596 - learning_rate: 1.5625e-05\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6749 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6633 - val_rmsle: 0.0596 - learning_rate: 1.5625e-05\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6708 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6619 - val_rmsle: 0.0595 - learning_rate: 1.5625e-05\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6193 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6612 - val_rmsle: 0.0596 - learning_rate: 7.8125e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6701 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0603 - val_msle: 3.6596 - val_rmsle: 0.0595 - learning_rate: 7.8125e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6552 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6648 - val_rmsle: 0.0595 - learning_rate: 7.8125e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6304 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6615 - val_rmsle: 0.0595 - learning_rate: 3.9063e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6735 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6597 - val_rmsle: 0.0595 - learning_rate: 3.9063e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6559 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6590 - val_rmsle: 0.0595 - learning_rate: 3.9063e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6351 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6588 - val_rmsle: 0.0595 - learning_rate: 1.9531e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6655 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6594 - val_rmsle: 0.0595 - learning_rate: 1.9531e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6580 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6579 - val_rmsle: 0.0595 - learning_rate: 1.9531e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6475 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6586 - val_rmsle: 0.0595 - learning_rate: 1.9531e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6158 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6562 - val_rmsle: 0.0595 - learning_rate: 1.9531e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6743 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.9531e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6418 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6580 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6777 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6575 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6460 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6579 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6484 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6590 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6447 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6572 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6531 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6574 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6396 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6506 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6560 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6573 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6561 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6337 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6568 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6585 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6564 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6720 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6581 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6615 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6564 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6312 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6578 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6355 - rmsle: 0.0592 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6573 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7011 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6424 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6572 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6495 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6557 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6622 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6569 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6261 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6560 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6400 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6689 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6565 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6618 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6551 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6440 - rmsle: 0.0592 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6546 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6277 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6558 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6493 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6729 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6542 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6486 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6557 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6454 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6562 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6965 - rmsle: 0.0603 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6327 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6567 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6548 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6579 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6535 - rmsle: 0.0600 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6558 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6723 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6559 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6389 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6564 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6317 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6570 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6753 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6572 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6637 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6565 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6056 - rmsle: 0.0590 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6557 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6708 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6324 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6547 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6820 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6568 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6387 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6573 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6177 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6562 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6799 - rmsle: 0.0604 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6547 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6667 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6564 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6740 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6562 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6731 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6918 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.6567 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6500 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6558 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5911 - rmsle: 0.0591 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6546 - rmsle: 0.0593 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6557 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6525 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6544 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6425 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6558 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6194 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6552 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6219 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6947 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6560 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6651 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6548 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6193 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6546 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6253 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6552 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7034 - rmsle: 0.0601 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6567 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6803 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6546 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6515 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6551 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6784 - rmsle: 0.0603 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6545 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6369 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6569 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6415 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6541 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6214 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6552 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6291 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6562 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6428 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6570 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6842 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6542 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6466 - rmsle: 0.0592 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6553 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6287 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6546 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6625 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6557 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6383 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6564 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6398 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6561 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6671 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6559 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6256 - rmsle: 0.0591 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6559 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6335 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6560 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6488 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6530 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6404 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6544 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6605 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6546 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6149 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6549 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6463 - rmsle: 0.0599 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6552 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6805 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6428 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6563 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6286 - rmsle: 0.0594 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6549 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6305 - rmsle: 0.0596 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6545 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6257 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6558 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6571 - rmsle: 0.0598 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6556 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6731 - rmsle: 0.0592 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6571 - val_rmsle: 0.0595 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6791 - rmsle: 0.0595 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6541 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6414 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6529 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6260 - rmsle: 0.0592 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6550 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_59_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6325 - rmsle: 0.0597 - val_dense_59_loss: 0.0000e+00 - val_loss: 0.0601 - val_msle: 3.6532 - val_rmsle: 0.0594 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 9 → Training set Score: 1.36088 | Validation set Score: 0.06014\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 15s 10ms/step - dense_63_loss: 0.0000e+00 - loss: 1.5549 - msle: 77.0011 - rmsle: 1.4912 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.1066 - val_msle: 5.4231 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.1018 - msle: 5.2520 - rmsle: 0.0753 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.2848 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0815 - msle: 4.5662 - rmsle: 0.0700 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.1415 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0738 - msle: 4.3599 - rmsle: 0.0675 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.8835 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0703 - msle: 4.1905 - rmsle: 0.0659 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.4032 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0690 - msle: 4.1351 - rmsle: 0.0655 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.0730 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0671 - msle: 4.0527 - rmsle: 0.0641 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.4678 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0667 - msle: 3.9841 - rmsle: 0.0640 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8248 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0660 - msle: 3.9166 - rmsle: 0.0635 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 5.3554 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0653 - msle: 3.8749 - rmsle: 0.0629 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8880 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0649 - msle: 3.9050 - rmsle: 0.0628 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7480 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.7896 - rmsle: 0.0626 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7893 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0641 - msle: 3.8093 - rmsle: 0.0622 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0593 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.8115 - rmsle: 0.0625 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.7134 - val_rmsle: 0.0620 - learning_rate: 5.0000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.7550 - rmsle: 0.0620 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.9773 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0636 - msle: 3.7651 - rmsle: 0.0619 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.9305 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0639 - msle: 3.7604 - rmsle: 0.0623 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9238 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0625 - msle: 3.6732 - rmsle: 0.0610 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0634 - val_msle: 3.6878 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.7418 - rmsle: 0.0617 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0632 - val_msle: 3.7208 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.6701 - rmsle: 0.0611 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7950 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0627 - msle: 3.6801 - rmsle: 0.0615 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0631 - val_msle: 3.6769 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6933 - rmsle: 0.0608 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6563 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0619 - msle: 3.6741 - rmsle: 0.0608 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6151 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6705 - rmsle: 0.0604 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0629 - val_msle: 3.6185 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6372 - rmsle: 0.0606 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0624 - val_msle: 3.6621 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6787 - rmsle: 0.0605 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.6351 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.6847 - rmsle: 0.0606 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5925 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0615 - msle: 3.6652 - rmsle: 0.0607 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.5914 - val_rmsle: 0.0606 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6709 - rmsle: 0.0606 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5919 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6651 - rmsle: 0.0603 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0616 - val_msle: 3.5841 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6265 - rmsle: 0.0601 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5855 - val_rmsle: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6397 - rmsle: 0.0603 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.5848 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6392 - rmsle: 0.0606 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.6108 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6577 - rmsle: 0.0601 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0618 - val_msle: 3.6346 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6375 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5787 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6107 - rmsle: 0.0598 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0611 - val_msle: 3.5779 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6180 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0612 - val_msle: 3.5881 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6177 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5804 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6165 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5754 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6477 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5726 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6876 - rmsle: 0.0601 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.5745 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6455 - rmsle: 0.0598 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5744 - val_rmsle: 0.0602 - learning_rate: 1.5625e-05\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6175 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5742 - val_rmsle: 0.0602 - learning_rate: 1.5625e-05\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6476 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5698 - val_rmsle: 0.0602 - learning_rate: 1.5625e-05\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6355 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5757 - val_rmsle: 0.0602 - learning_rate: 1.5625e-05\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6064 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5722 - val_rmsle: 0.0602 - learning_rate: 7.8125e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6239 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5734 - val_rmsle: 0.0602 - learning_rate: 7.8125e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5735 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0608 - val_msle: 3.5722 - val_rmsle: 0.0601 - learning_rate: 7.8125e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5982 - rmsle: 0.0590 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5700 - val_rmsle: 0.0601 - learning_rate: 7.8125e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6432 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5694 - val_rmsle: 0.0601 - learning_rate: 7.8125e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6101 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5706 - val_rmsle: 0.0601 - learning_rate: 3.9063e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6281 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5709 - val_rmsle: 0.0601 - learning_rate: 3.9063e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.6097 - rmsle: 0.0590 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5687 - val_rmsle: 0.0601 - learning_rate: 3.9063e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6102 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5694 - val_rmsle: 0.0601 - learning_rate: 1.9531e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5893 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5699 - val_rmsle: 0.0601 - learning_rate: 1.9531e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6250 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5694 - val_rmsle: 0.0601 - learning_rate: 1.9531e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6527 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5695 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6136 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5701 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6201 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5698 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6537 - rmsle: 0.0602 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5693 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6374 - rmsle: 0.0600 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5697 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6194 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5697 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5915 - rmsle: 0.0591 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5685 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0595 - msle: 3.6039 - rmsle: 0.0589 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5696 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5974 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6038 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6075 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.5881 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6294 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5692 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6201 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6086 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5697 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6066 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6235 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5693 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 74/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6267 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5698 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 75/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6348 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5682 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 76/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6225 - rmsle: 0.0601 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 77/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5813 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5692 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 78/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6193 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5695 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 79/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6020 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 80/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5948 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 81/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6666 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5691 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 82/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.5968 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5693 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 83/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0592 - msle: 3.5824 - rmsle: 0.0586 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 84/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6111 - rmsle: 0.0598 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5701 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 85/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6203 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5694 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 86/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5894 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5687 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 87/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6731 - rmsle: 0.0602 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5697 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 88/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6454 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 89/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6314 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5692 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 90/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6290 - rmsle: 0.0600 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 91/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6183 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 92/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.5946 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5683 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 93/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5980 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5693 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 94/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6398 - rmsle: 0.0600 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5687 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 95/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6024 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5687 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 96/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0591 - msle: 3.5694 - rmsle: 0.0586 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 97/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.5852 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5692 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 98/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0596 - msle: 3.5897 - rmsle: 0.0590 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 99/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6179 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5693 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 100/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5823 - rmsle: 0.0591 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 101/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6382 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5683 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 102/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6227 - rmsle: 0.0601 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5698 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 103/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5679 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5687 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 104/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6316 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5689 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 105/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6143 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5680 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 106/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6161 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5698 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 107/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6595 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5690 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 108/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6367 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 109/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0602 - msle: 3.6351 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 110/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6275 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5689 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 111/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6215 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5691 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 112/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.5948 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5679 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 113/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6179 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5685 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 114/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0594 - msle: 3.6107 - rmsle: 0.0589 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5686 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 115/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6246 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5688 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 116/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6118 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5686 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 117/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6090 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5685 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 118/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6273 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5694 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 119/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6144 - rmsle: 0.0598 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 120/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5747 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5688 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 121/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5864 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5689 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 122/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6252 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5678 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 123/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6136 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5697 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 124/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6004 - rmsle: 0.0598 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5687 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 125/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6155 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5680 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 126/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6570 - rmsle: 0.0600 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5684 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 127/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6421 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5683 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 128/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5908 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5685 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 129/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6067 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5684 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 130/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.5719 - rmsle: 0.0591 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5689 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 131/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6438 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5686 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 132/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6837 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5684 - val_rmsle: 0.0601 - learning_rate: 1.0000e-06\n",
            "Epoch 133/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6077 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5694 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 134/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6200 - rmsle: 0.0596 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5689 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 135/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6531 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5681 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 136/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0599 - msle: 3.6174 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5676 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 137/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6059 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5686 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 138/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6898 - rmsle: 0.0600 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5684 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 139/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0594 - msle: 3.6291 - rmsle: 0.0589 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5682 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 140/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0594 - msle: 3.5821 - rmsle: 0.0589 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5679 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 141/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5822 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5686 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 142/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6416 - rmsle: 0.0597 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5682 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 143/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.5792 - rmsle: 0.0592 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5682 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 144/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6306 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5679 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 145/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0603 - msle: 3.6487 - rmsle: 0.0598 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5686 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 146/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6243 - rmsle: 0.0605 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5680 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 147/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0600 - msle: 3.6301 - rmsle: 0.0594 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5684 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 148/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.6223 - rmsle: 0.0595 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5677 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 149/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6257 - rmsle: 0.0599 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5683 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 150/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0598 - msle: 3.6192 - rmsle: 0.0593 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5687 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n",
            "Epoch 151/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_63_loss: 0.0000e+00 - loss: 0.0597 - msle: 3.6149 - rmsle: 0.0591 - val_dense_63_loss: 0.0000e+00 - val_loss: 0.0606 - val_msle: 3.5680 - val_rmsle: 0.0600 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 10 → Training set Score: 1.36030 | Validation set Score: 0.06082\n",
            "Epoch 1/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 15s 10ms/step - dense_67_loss: 0.0000e+00 - loss: 1.5588 - msle: 78.6503 - rmsle: 1.4967 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.1352 - val_msle: 7.5235 - val_rmsle: 0.1047 - learning_rate: 5.0000e-04\n",
            "Epoch 2/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.1043 - msle: 6.4048 - rmsle: 0.0794 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.1616 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 3/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0833 - msle: 5.0146 - rmsle: 0.0719 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.9453 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 4/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0754 - msle: 4.5479 - rmsle: 0.0688 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0790 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 5/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0713 - msle: 4.3644 - rmsle: 0.0667 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.6231 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 6/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0698 - msle: 4.2693 - rmsle: 0.0660 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.9293 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 7/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0689 - msle: 4.2061 - rmsle: 0.0656 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3425 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 8/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0676 - msle: 4.1486 - rmsle: 0.0647 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 5.4051 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 9/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0668 - msle: 4.0788 - rmsle: 0.0641 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0300 - val_rmsle: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 10/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0657 - msle: 3.9913 - rmsle: 0.0633 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 4.0304 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 11/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0647 - msle: 3.9592 - rmsle: 0.0628 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0627 - val_msle: 3.7802 - val_rmsle: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 12/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0645 - msle: 3.9448 - rmsle: 0.0627 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0962 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 13/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0646 - msle: 3.9561 - rmsle: 0.0629 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0621 - val_msle: 3.7091 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 14/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0644 - msle: 3.9458 - rmsle: 0.0627 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8222 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 15/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8748 - rmsle: 0.0622 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6998 - val_rmsle: 0.0603 - learning_rate: 2.5000e-04\n",
            "Epoch 16/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8983 - rmsle: 0.0622 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8106 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 17/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0638 - msle: 3.8504 - rmsle: 0.0622 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6652 - val_rmsle: 0.0598 - learning_rate: 2.5000e-04\n",
            "Epoch 18/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0634 - msle: 3.8257 - rmsle: 0.0619 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6627 - val_rmsle: 0.0601 - learning_rate: 2.5000e-04\n",
            "Epoch 19/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0642 - msle: 3.8845 - rmsle: 0.0627 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0619 - val_msle: 3.7429 - val_rmsle: 0.0604 - learning_rate: 2.5000e-04\n",
            "Epoch 20/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0635 - msle: 3.8641 - rmsle: 0.0621 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0620 - val_msle: 3.6713 - val_rmsle: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 21/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0626 - msle: 3.7639 - rmsle: 0.0613 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.5986 - val_rmsle: 0.0596 - learning_rate: 1.2500e-04\n",
            "Epoch 22/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0629 - msle: 3.8235 - rmsle: 0.0616 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0607 - val_msle: 3.6395 - val_rmsle: 0.0595 - learning_rate: 1.2500e-04\n",
            "Epoch 23/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0628 - msle: 3.7953 - rmsle: 0.0616 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0610 - val_msle: 3.6132 - val_rmsle: 0.0599 - learning_rate: 1.2500e-04\n",
            "Epoch 24/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0632 - msle: 3.8042 - rmsle: 0.0621 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0615 - val_msle: 3.6879 - val_rmsle: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 25/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0620 - msle: 3.7355 - rmsle: 0.0609 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0609 - val_msle: 3.6213 - val_rmsle: 0.0598 - learning_rate: 1.2500e-04\n",
            "Epoch 26/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0622 - msle: 3.7686 - rmsle: 0.0612 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0602 - val_msle: 3.5787 - val_rmsle: 0.0592 - learning_rate: 6.2500e-05\n",
            "Epoch 27/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0623 - msle: 3.7363 - rmsle: 0.0613 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0617 - val_msle: 3.6119 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 28/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0621 - msle: 3.7237 - rmsle: 0.0611 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0614 - val_msle: 3.6113 - val_rmsle: 0.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 29/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7327 - rmsle: 0.0602 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0605 - val_msle: 3.6162 - val_rmsle: 0.0596 - learning_rate: 6.2500e-05\n",
            "Epoch 30/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0616 - msle: 3.7105 - rmsle: 0.0606 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0598 - val_msle: 3.5511 - val_rmsle: 0.0589 - learning_rate: 3.1250e-05\n",
            "Epoch 31/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6942 - rmsle: 0.0604 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0604 - val_msle: 3.5694 - val_rmsle: 0.0595 - learning_rate: 3.1250e-05\n",
            "Epoch 32/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0618 - msle: 3.7329 - rmsle: 0.0609 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0600 - val_msle: 3.5755 - val_rmsle: 0.0591 - learning_rate: 3.1250e-05\n",
            "Epoch 33/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6673 - rmsle: 0.0602 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.5518 - val_rmsle: 0.0587 - learning_rate: 3.1250e-05\n",
            "Epoch 34/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7216 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0596 - val_msle: 3.5555 - val_rmsle: 0.0587 - learning_rate: 3.1250e-05\n",
            "Epoch 35/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6798 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0598 - val_msle: 3.5619 - val_rmsle: 0.0589 - learning_rate: 3.1250e-05\n",
            "Epoch 36/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6957 - rmsle: 0.0600 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0595 - val_msle: 3.5430 - val_rmsle: 0.0587 - learning_rate: 3.1250e-05\n",
            "Epoch 37/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7007 - rmsle: 0.0602 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5396 - val_rmsle: 0.0585 - learning_rate: 1.5625e-05\n",
            "Epoch 38/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.7047 - rmsle: 0.0603 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5380 - val_rmsle: 0.0584 - learning_rate: 1.5625e-05\n",
            "Epoch 39/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6779 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5402 - val_rmsle: 0.0584 - learning_rate: 1.5625e-05\n",
            "Epoch 40/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.7186 - rmsle: 0.0605 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5397 - val_rmsle: 0.0584 - learning_rate: 1.5625e-05\n",
            "Epoch 41/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7021 - rmsle: 0.0601 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5414 - val_rmsle: 0.0584 - learning_rate: 1.5625e-05\n",
            "Epoch 42/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.7124 - rmsle: 0.0603 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5372 - val_rmsle: 0.0585 - learning_rate: 1.5625e-05\n",
            "Epoch 43/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6904 - rmsle: 0.0600 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5460 - val_rmsle: 0.0584 - learning_rate: 1.5625e-05\n",
            "Epoch 44/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6805 - rmsle: 0.0597 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5435 - val_rmsle: 0.0584 - learning_rate: 7.8125e-06\n",
            "Epoch 45/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0614 - msle: 3.7117 - rmsle: 0.0606 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0593 - val_msle: 3.5422 - val_rmsle: 0.0585 - learning_rate: 7.8125e-06\n",
            "Epoch 46/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6982 - rmsle: 0.0604 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0592 - val_msle: 3.5390 - val_rmsle: 0.0585 - learning_rate: 7.8125e-06\n",
            "Epoch 47/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.7097 - rmsle: 0.0598 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5388 - val_rmsle: 0.0584 - learning_rate: 3.9063e-06\n",
            "Epoch 48/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6687 - rmsle: 0.0601 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5402 - val_rmsle: 0.0584 - learning_rate: 3.9063e-06\n",
            "Epoch 49/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 5ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7259 - rmsle: 0.0600 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5425 - val_rmsle: 0.0583 - learning_rate: 3.9063e-06\n",
            "Epoch 50/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.6663 - rmsle: 0.0606 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5393 - val_rmsle: 0.0584 - learning_rate: 1.9531e-06\n",
            "Epoch 51/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0604 - msle: 3.6435 - rmsle: 0.0597 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5428 - val_rmsle: 0.0584 - learning_rate: 1.9531e-06\n",
            "Epoch 52/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6927 - rmsle: 0.0605 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5396 - val_rmsle: 0.0583 - learning_rate: 1.9531e-06\n",
            "Epoch 53/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.6811 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5402 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 54/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.6850 - rmsle: 0.0601 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5382 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 55/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7055 - rmsle: 0.0601 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5390 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 56/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6666 - rmsle: 0.0597 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5380 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 57/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.7244 - rmsle: 0.0602 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5370 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 58/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7238 - rmsle: 0.0601 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5375 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 59/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0601 - msle: 3.7035 - rmsle: 0.0594 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5391 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 60/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0609 - msle: 3.6962 - rmsle: 0.0602 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5404 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 61/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6708 - rmsle: 0.0597 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5381 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 62/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0611 - msle: 3.6646 - rmsle: 0.0604 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5395 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 63/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0613 - msle: 3.7037 - rmsle: 0.0606 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5395 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 64/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7096 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5397 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 65/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0607 - msle: 3.7086 - rmsle: 0.0600 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5390 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 66/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6604 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5390 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 67/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6788 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5379 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 68/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.7008 - rmsle: 0.0598 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5409 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 69/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0605 - msle: 3.6717 - rmsle: 0.0598 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5395 - val_rmsle: 0.0584 - learning_rate: 1.0000e-06\n",
            "Epoch 70/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0608 - msle: 3.7194 - rmsle: 0.0601 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5383 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 71/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0612 - msle: 3.6965 - rmsle: 0.0605 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5383 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 72/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0606 - msle: 3.6982 - rmsle: 0.0599 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5400 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n",
            "Epoch 73/151\n",
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_67_loss: 0.0000e+00 - loss: 0.0610 - msle: 3.6927 - rmsle: 0.0603 - val_dense_67_loss: 0.0000e+00 - val_loss: 0.0591 - val_msle: 3.5388 - val_rmsle: 0.0583 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680/680 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step\n",
            "68/68 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
            "245/245 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Fold 11 → Training set Score: 1.36106 | Validation set Score: 0.05881\n",
            "Overall → Training set Score: 1.36098±0.0007768 | Validation set Score: 0.05990±0.0010468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 Store Results:"
      ],
      "metadata": {
        "id": "LeslFBCmohAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_experiment = \"NN_widedeepcross_00\"\n",
        "\n",
        "train_pred = TM.OOF_train\n",
        "test_pred = TM.OOF_test\n",
        "train_pred = pd.DataFrame(data = train_pred, columns = [f\"{name_experiment}\"])\n",
        "\n",
        "sub = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "\n",
        "sub[\"Calories\"] =  test_pred.values"
      ],
      "metadata": {
        "id": "h8d9vXAWohAA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.min(), test_pred.max()"
      ],
      "metadata": {
        "id": "D6Y11rQ6ohAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97684f0b-e597-4af3-9fb9-7b30b58e34de"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(NN_widedeepcross_00    1.01192\n",
              " dtype: float64,\n",
              " NN_widedeepcross_00    315.000004\n",
              " dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.head()"
      ],
      "metadata": {
        "id": "uPXhNOISohAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "20e0ef0b-a886-418e-9294-6e7e56425b34"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   NN_widedeepcross_00\n",
              "0            27.319168\n",
              "1           107.833750\n",
              "2            86.240168\n",
              "3           125.123298\n",
              "4            76.275367"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58c80193-3654-40d8-9c32-cd029b8da28d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NN_widedeepcross_00</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.319168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>107.833750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86.240168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>125.123298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76.275367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58c80193-3654-40d8-9c32-cd029b8da28d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58c80193-3654-40d8-9c32-cd029b8da28d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58c80193-3654-40d8-9c32-cd029b8da28d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bc69faf6-d55b-405e-97ff-509c3ba6dde2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc69faf6-d55b-405e-97ff-509c3ba6dde2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bc69faf6-d55b-405e-97ff-509c3ba6dde2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_pred"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub.head()"
      ],
      "metadata": {
        "id": "EQAAybfaohAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "50c9bd67-1f79-4a70-e247-3c0791db0c01"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Calories\n",
              "id                \n",
              "750000   27.319168\n",
              "750001  107.833750\n",
              "750002   86.240168\n",
              "750003  125.123298\n",
              "750004   76.275367"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ca965c6-5527-4581-9b37-c9d28c8b5e5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Calories</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>750000</th>\n",
              "      <td>27.319168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750001</th>\n",
              "      <td>107.833750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750002</th>\n",
              "      <td>86.240168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750003</th>\n",
              "      <td>125.123298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750004</th>\n",
              "      <td>76.275367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ca965c6-5527-4581-9b37-c9d28c8b5e5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ca965c6-5527-4581-9b37-c9d28c8b5e5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ca965c6-5527-4581-9b37-c9d28c8b5e5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b06a221f-ef2f-4b18-a71c-f3de66731876\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b06a221f-ef2f-4b18-a71c-f3de66731876')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b06a221f-ef2f-4b18-a71c-f3de66731876 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sub"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred.head()"
      ],
      "metadata": {
        "id": "n-PrhHyqohAB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1d1d5ecf-f7db-49be-f7d8-04b663579ff0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   NN_widedeepcross_00\n",
              "0           146.682434\n",
              "1            35.850388\n",
              "2            29.253016\n",
              "3           138.080093\n",
              "4           146.500015"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77e424c0-0bc8-40be-beaf-a88414072129\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NN_widedeepcross_00</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146.682434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35.850388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.253016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>138.080093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>146.500015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77e424c0-0bc8-40be-beaf-a88414072129')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77e424c0-0bc8-40be-beaf-a88414072129 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77e424c0-0bc8-40be-beaf-a88414072129');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0fe93a2f-665e-4eec-a15d-6703015b563d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fe93a2f-665e-4eec-a15d-6703015b563d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0fe93a2f-665e-4eec-a15d-6703015b563d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_pred"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "ax[0].hist(train_pred, bins=31)\n",
        "ax[1].hist(sub, bins=31, color=\"salmon\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rauW4cqbohAB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "89fddb3f-0248-4a88-98fa-ca66606f8019"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/submission_{name_experiment}.csv\")\n",
        "train_pred.to_csv(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train_pred_{name_experiment}.csv\")"
      ],
      "metadata": {
        "id": "FQVZtUnOohAB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Y5a2zyDoeka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8l6bRRIoeZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6z2A1j7oIJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}