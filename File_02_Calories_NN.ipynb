{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/Colab_backup/blob/main/File_02_Calories_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTING CALOORIES BURNED\n",
        "\n",
        "## RMSLE Metric and Competition Context\n",
        "\n",
        "This notebook is developed for a data science competition focused on predicting **Calories burned** during exercise. The evaluation metric for this competition is the **Root Mean Squared Logarithmic Error (RMSLE)**, which measures the square root of the mean squared difference between the logarithms of predicted and actual values. RMSLE is ideal for datasets with a wide range of target values, as it emphasizes **relative errors**, ensuring balanced performance across small and large calorie values.\n",
        "\n",
        "The RMSLE formula is:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*AUzyQ1rc6mpQVYfn)\n",
        "\n",
        "### Why RMSLE?\n",
        "- **Handles Wide Ranges**: RMSLE penalizes relative errors proportionally, making it robust for calorie values ranging from small (e.g., 10 calories) to large (e.g., 1000 calories).\n",
        "- **Balanced Evaluation**: Ensures models perform well across the entire spectrum of calorie burn.\n",
        "- **Competition Goal**: A lower RMSLE score indicates a precise and generalizable model, critical for ranking high on the leaderboard.\n",
        "\n",
        "---\n",
        "\n",
        "## Potential Effects of Features on Calorie Burn\n",
        "\n",
        "The dataset includes the following features to predict calorie burn: **Sex**, **Age**, **Height**, **Weight**, **Duration**, **Heart_Rate**, and **Body_Temp**. Below, we explore how each feature might influence calorie burn:\n",
        "\n",
        "### 1. Sex\n",
        "- **Impact**: Differences in metabolic rates and muscle mass between males and females affect calorie burn. Males often have higher muscle mass, leading to greater calorie expenditure for the same exercise.\n",
        "- **Example**: A male running at the same pace and duration as a female may burn more calories due to higher energy demands.\n",
        "\n",
        "### 2. Age\n",
        "- **Impact**: Basal metabolic rate (BMR) decreases with age, reducing calorie burn in older individuals due to lower metabolic rates and muscle mass (sarcopenia).\n",
        "- **Example**: A 20-year-old may burn more calories than a 50-year-old during identical workouts.\n",
        "\n",
        "### 3. Height\n",
        "- **Impact**: Taller individuals have more body mass or muscle, requiring more energy for movement, thus burning more calories. Height’s effect is often linked to weight and exercise intensity.\n",
        "- **Example**: A taller person may expend more energy covering the same distance.\n",
        "\n",
        "### 4. Weight\n",
        "- **Impact**: Heavier individuals burn more calories due to the energy required to move greater body mass. Body composition (fat vs. muscle) also influences calorie burn.\n",
        "- **Example**: A 90 kg individual burns more calories walking the same distance as a 60 kg individual.\n",
        "\n",
        "### 5. Duration\n",
        "- **Impact**: Longer exercise sessions directly increase total calorie expenditure, though intensity and exercise type also matter.\n",
        "- **Example**: Running for 30 minutes burns more calories than running for 15 minutes.\n",
        "\n",
        "### 6. Heart_Rate\n",
        "- **Impact**: Higher heart rates indicate greater exercise intensity and metabolic effort, leading to increased calorie burn. Fitness levels can modulate heart rate responses.\n",
        "- **Example**: High heart rate during a HIIT workout correlates with higher calorie burn.\n",
        "\n",
        "### 7. Body_Temp\n",
        "- **Impact**: Rising body temperature during exercise reflects increased metabolic activity and thermoregulation, potentially increasing calorie burn. Environmental factors (e.g., heat) also play a role.\n",
        "- **Example**: Exercising in a hot environment may increase calorie expenditure due to thermoregulation.\n",
        "\n",
        "---\n",
        "\n",
        "## Transition to Analysis\n",
        "\n",
        "Understanding the relationships between these features and calorie burn is key to building a predictive model. In this notebook, we will:\n",
        "\n",
        "1. **Explore Data**: Analyze the distribution of the target variable (**Calories**) and features using visualizations (e.g., histograms, boxplots).\n",
        "2. **Correlation Analysis**: Identify relationships between features and the target using correlation matrices and polar plots.\n",
        "3. **Outlier Detection**: Address anomalies that could skew model performance.\n",
        "4. **Feature Engineering**: Apply techniques like quantile and equal-width binning to enhance model input.\n",
        "5. **Model Development**: Build and evaluate models to minimize RMSLE, aligning with competition objectives.\n",
        "\n",
        "### Visualization Strategy\n",
        "We will use:\n",
        "- **Histograms** and **boxplots** to examine feature distributions.\n",
        "- **Correlation matrices** to uncover feature relationships.\n",
        "- **Polar plots** for creative visualization of feature impacts.\n",
        "- **Pair plots** to explore pairwise relationships.\n",
        "\n",
        "By systematically analyzing the data, we aim to develop a robust model that accurately predicts calorie burn and excels in the competition.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0plw_SZl679v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.0 Setting"
      ],
      "metadata": {
        "id": "Q4e2HGJH8zTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Import Libraries:"
      ],
      "metadata": {
        "id": "boXswaUo7Uvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall scikit-learn\n",
        "# !pip install scikit-learn==1.4"
      ],
      "metadata": {
        "id": "8fOwAMLAw7Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rYYQgW0Rmxv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!pip install -qq pytorch_tabnet\n",
        "!pip install optuna\n",
        "!pip install --upgrade catboost\n",
        "#!pip install optuna-integration-pytorch-tabnet\n",
        "\n",
        "#from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "!pip install --upgrade category-encoders\n",
        "!pip install optuna-integration\n",
        "!pip install colorama\n",
        "#!pip install pyfiglet\n",
        "#!pip install keras-tuner --upgrade\n",
        "#!pip install keras-nlp\n",
        "#!pip install BorutaShap\n",
        "#!pip install scikit-learn==1.2.2\n",
        "#!pip install scikit-lego\n",
        "!pip install skops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import lightgbm, xgboost, catboost\n",
        "sklearn.__version__, lightgbm.__version__, xgboost.__version__, catboost.__version__"
      ],
      "metadata": {
        "id": "crKlzXJctRD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIS1habP8JGi"
      },
      "outputs": [],
      "source": [
        "# Setup notebook\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "import json\n",
        "import joblib\n",
        "#from joblib import dump, load\n",
        "#import calplot as cal\n",
        "\n",
        "# Graphic Libraries:\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "from termcolor import colored\n",
        "# Set Style\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5});\n",
        "sns.despine(left=True, bottom=True, top=False, right=False);\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "mpl.rc('axes', labelsize=12);\n",
        "plt.rc('xtick',labelsize=10);\n",
        "plt.rc('ytick',labelsize=10);\n",
        "\n",
        "mpl.rcParams['axes.spines.top'] = False;\n",
        "mpl.rcParams['axes.spines.right'] = False;\n",
        "mpl.rcParams['axes.spines.left'] = True;\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "# tool for Excel:\n",
        "from openpyxl import load_workbook, Workbook\n",
        "from openpyxl.drawing.image import Image\n",
        "from openpyxl.styles import Border, Side, PatternFill, Font, GradientFill, Alignment\n",
        "from openpyxl.worksheet.cell_range import CellRange\n",
        "\n",
        "from openpyxl.formatting import Rule\n",
        "from openpyxl.styles import Font, PatternFill, Border\n",
        "from openpyxl.styles.differential import DifferentialStyle\n",
        "\n",
        "# Bloomberg\n",
        "#from xbbg import blp\n",
        "from catboost import CatBoostRegressor, Pool, CatBoostClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "# Time Management\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BMonthEnd, QuarterEnd\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay # BDay is business day, not birthday...\n",
        "import datetime as dt\n",
        "import click\n",
        "import glob\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import string\n",
        "\n",
        "from ipywidgets import AppLayout\n",
        "from ipywidgets import Dropdown, Layout, HTML, AppLayout, VBox, Label, HBox, BoundedFloatText, interact, Output\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "\n",
        "from keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "\n",
        "from keras.utils import FeatureSpace, plot_model\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "#import keras_tuner as kt\n",
        "#from keras_tuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "\n",
        "#from my_func import *\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedKFold, cross_val_score, cross_validate, GroupKFold, GridSearchCV, RepeatedStratifiedKFold, cross_val_predict\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures,\n",
        "                                   FunctionTransformer)\n",
        "\n",
        "# metrics\n",
        "import sklearn\n",
        "#import skops.io as sio\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             root_mean_squared_error,\n",
        "                             root_mean_squared_log_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss,\n",
        "                             make_scorer)\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  HuberRegressor,\n",
        "                                  TweedieRegressor,\n",
        "                                  QuantileRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  TheilSenRegressor,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              AdaBoostClassifier,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              StackingClassifier,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              HistGradientBoostingRegressor,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.base import clone\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from category_encoders import TargetEncoder, CatBoostEncoder, LeaveOneOutEncoder, OrdinalEncoder, CountEncoder\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "from sklearn.multioutput import RegressorChain\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "import scipy.stats as ss\n",
        "\n",
        "#from category_encoders.cat_boost import CatBoostEncoder\n",
        "#from category_encoders.wrapper import PolynomialWrapper\n",
        "#from category_encoders.count import CountEncoder\n",
        "#from category_encoders import TargetEncoder\n",
        "\n",
        "import skops.io as sio\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#import pyfiglet\n",
        "#plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Formatting and Settings:**"
      ],
      "metadata": {
        "id": "yQhbcUmY8EXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkkRPWKZCkYa"
      },
      "outputs": [],
      "source": [
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.5,\n",
        "         'grid.alpha'           :0.5,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : 'black',\n",
        "         'axes.titlesize'       : 12,\n",
        "#         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "# Set Style\n",
        "mpl.rcParams['figure.dpi'] = 120;\n",
        "\n",
        "# import font colors\n",
        "from colorama import Fore, Style, init\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "pd.set_option('display.max_columns', 100);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True\n",
        "\n",
        "init(autoreset=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU7oWpLHRmxy"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from itertools import product\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "import torch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Connect to Colab:#\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Functions:"
      ],
      "metadata": {
        "id": "cVSGNoaQB8fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Plotting Functiss**"
      ],
      "metadata": {
        "id": "3uNczPcrH4iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_scatter(df, x=\"feat1\", y=\"feat2\", color_feature=None, cmap='viridis'):\n",
        "    \"\"\"\n",
        "    Generates a scatter plot with points colored based on a third feature.\n",
        "\n",
        "    Args:\n",
        "        df: Pandas DataFrame containing the data.\n",
        "        x: Name of the column to use for the x-axis.\n",
        "        y: Name of the column to use for the y-axis.\n",
        "        color_feature: Name of the column to use for coloring the points.\n",
        "                       If None, points will be a single color.\n",
        "        cmap: Colormap to use for coloring the points (e.g., 'viridis', 'plasma', 'magma', 'inferno', 'cividis').\n",
        "              See matplotlib documentation for available colormaps.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    if color_feature is not None:\n",
        "        # Ensure the color feature exists\n",
        "        if color_feature not in df.columns:\n",
        "            raise ValueError(f\"Color feature '{color_feature}' not found in DataFrame.\")\n",
        "\n",
        "        # Scatter plot with colors\n",
        "        scatter = plt.scatter(df[x], df[y], c=df[color_feature], cmap=cmap)\n",
        "\n",
        "        # Add a colorbar\n",
        "        cbar = plt.colorbar(scatter)\n",
        "        cbar.set_label(color_feature)  # Label the colorbar\n",
        "\n",
        "    else:\n",
        "        # Simple scatter plot (single color)\n",
        "        plt.scatter(df[x], df[y],color=\"royalblue\",alpha=0.6)\n",
        "\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel(y)\n",
        "    plt.title(\"Scatter Plot\")  # Add a title for better visualization\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RjO42zM1B8FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Dataset Management Functions**:"
      ],
      "metadata": {
        "id": "rVeb3ga2HynB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "\n",
        "    state = 42\n",
        "    n_splits = 10\n",
        "    early_stop = 200\n",
        "\n",
        "    target = 'Calories'\n",
        "    train = pd.read_csv('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/test.csv')\n",
        "    submission = pd.read_csv( \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\")\n",
        "    #train_org = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/original.csv\")\n",
        "\n",
        "    original_data = 'N'\n",
        "    outliers = 'N'\n",
        "    log_trf = 'Y'\n",
        "    scaler_trf = 'Y'\n",
        "    feature_eng = 'N'\n",
        "    missing = 'Y'\n",
        "    sqrt_normalization=\"Y\"\n",
        "    impose_normalization=\"N\"\n",
        "    trg_enc = \"N\"\n",
        "    problem = \"Regression\"\n",
        "    metric_goal=\"LRMSE\"\n",
        "    direction_=\"minimize\"\n",
        "    log_trans_cols = [\"Body_Temp\"]\n",
        "    sqrt_norm_cols = [\"Age\"]\n",
        "    impose_norm_cols = []\n",
        "    trg_enc_feat = []\n",
        "\n",
        "class Preprocessing():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.train = Config.train\n",
        "        self.test = Config.test\n",
        "        self.targets = Config.target\n",
        "\n",
        "        self.prp_data()\n",
        "\n",
        "    def prp_data(self):\n",
        "\n",
        "        if Config.original_data == 'Y':\n",
        "            self.train = pd.concat([self.train, Config.train_org], ignore_index=True).drop_duplicates(ignore_index=True)\n",
        "\n",
        "        self.train = self.train.drop(['id'], axis=1)\n",
        "        self.test = self.test.drop(['id'], axis=1)\n",
        "\n",
        "        self.cat_features = self.train.drop(self.targets, axis=1).select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "        self.num_features = self.train.drop(self.targets, axis=1).select_dtypes(exclude=['object', 'bool']).columns.tolist()\n",
        "\n",
        "        self.train = self.reduce_mem(self.train)\n",
        "        self.test = self.reduce_mem(self.test)\n",
        "        return self\n",
        "\n",
        "    def reduce_mem(self, df):\n",
        "\n",
        "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', \"uint16\", \"uint32\", \"uint64\"]\n",
        "\n",
        "        for col in df.columns:\n",
        "            col_type = df[col].dtypes\n",
        "\n",
        "            if col_type in numerics:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "\n",
        "                if \"int\" in str(col_type):\n",
        "                    if c_min >= np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min >= np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min >= np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min >= np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "                else:\n",
        "                    if c_min >= np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    if c_min >= np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float64)\n",
        "\n",
        "        return df\n",
        "\n",
        "class EDA(Config, Preprocessing):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_info()\n",
        "        self.heatmap()\n",
        "        self.dist_plots()\n",
        "        self.cat_feature_plots()\n",
        "        if Config.problem == 'Classification':\n",
        "          self.target_pie()\n",
        "        else:\n",
        "          self.target_dist()\n",
        "\n",
        "    def data_info(self):\n",
        "\n",
        "        for data, label in zip([self.train, self.test], ['Train', 'Test']):\n",
        "            table_style = [{'selector': 'th:not(.index_name)',\n",
        "                            'props': [('background-color', 'slategrey'),\n",
        "                                      ('color', '#FFFFFF'),\n",
        "                                      ('font-weight', 'bold'),\n",
        "                                      ('border', '1px solid #DCDCDC'),\n",
        "                                      ('text-align', 'center')]\n",
        "                            },\n",
        "                            {'selector': 'tbody td',\n",
        "                             'props': [('border', '1px solid #DCDCDC'),\n",
        "                                       ('font-weight', 'normal')]\n",
        "                            }]\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} head\\n')\n",
        "            display(data.head().style.set_table_styles(table_style))\n",
        "\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} info\\n'+Style.RESET_ALL)\n",
        "            display(data.info())\n",
        "\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} describe\\n')\n",
        "            display(data.describe().drop(index='count', columns=self.targets, errors = 'ignore').T\n",
        "                    .style.set_table_styles(table_style).format('{:.3f}'))\n",
        "\n",
        "            print(Style.BRIGHT+Fore.RED+f'\\n{label} missing values\\n'+Style.RESET_ALL)\n",
        "            display(data.isnull().sum())\n",
        "        return self\n",
        "\n",
        "    def heatmap(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f'\\nCorrelation Heatmap\\n')\n",
        "        plt.figure(figsize=(7,7))\n",
        "        corr = self.train.select_dtypes(exclude='object').corr(method='pearson')\n",
        "        sns.heatmap(corr, fmt = '0.2f', cmap = 'Blues', annot=True, cbar=False)\n",
        "        plt.show()\n",
        "\n",
        "    def dist_plots(self):\n",
        "\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nDistribution analysis - Numerical\\n\")\n",
        "        df = pd.concat([self.train[self.num_features].assign(Source = 'Train'),\n",
        "                        self.test[self.num_features].assign(Source = 'Test'),],\n",
        "                        axis=0, ignore_index = True)\n",
        "\n",
        "        fig, axes = plt.subplots(len(self.num_features), 2 ,figsize = (13, len(self.num_features) * 4),\n",
        "                                 gridspec_kw = {'hspace': 0.3,\n",
        "                                                'wspace': 0.2,\n",
        "                                                'width_ratios': [0.70, 0.30]\n",
        "                                               }\n",
        "                                )\n",
        "        for i,col in enumerate(self.num_features):\n",
        "            try:\n",
        "                ax = axes[i,0]\n",
        "            except:\n",
        "                ax = axes[i]\n",
        "            sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source',\n",
        "                        palette = ['royalblue', 'tomato'], ax = ax, alpha=0.7, linewidth = 2\n",
        "                       )\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.set_title(f\"\\n{col}\")\n",
        "            ax.grid('--',alpha=0.7)\n",
        "\n",
        "            try:\n",
        "                ax = axes[i,1]\n",
        "            except:\n",
        "                ax = axes[1]\n",
        "            sns.boxplot(data = df, y = col, x=df.Source, width = 0.5,\n",
        "                        linewidth = 1, fliersize= 1,\n",
        "                        ax = ax, palette=['royalblue', 'tomato']\n",
        "                       )\n",
        "            ax.set_title(f\"\\n{col}\")\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.tick_params(axis='both', which='major')\n",
        "            ax.set_xticklabels(['Train', 'Test'])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def cat_feature_plots(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nDistribution analysis - Categorical\\n\")\n",
        "        fig, axes = plt.subplots(len(self.cat_features), 2 ,figsize = (18, len(self.cat_features) * 6),\n",
        "                                 gridspec_kw = {'hspace': 0.5,\n",
        "                                                'wspace': 0.2,\n",
        "                                               }\n",
        "                                )\n",
        "\n",
        "        for i, col in enumerate(self.cat_features):\n",
        "            try:\n",
        "                ax = axes[i,0]\n",
        "            except:\n",
        "                ax = axes[i]\n",
        "            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='royalblue', alpha=0.7)\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.set_title(f\"\\n{col} Train\")\n",
        "\n",
        "            try:\n",
        "                ax = axes[i,1]\n",
        "            except:\n",
        "                ax = axes[i+1]\n",
        "            sns.barplot(data=self.test[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='tomato', alpha=0.7)\n",
        "            ax.set(xlabel = '', ylabel = '')\n",
        "            ax.set_title(f\"\\n{col} Test\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def target_pie(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nTarget feature distribution\\n\")\n",
        "        targets = self.train[self.targets]\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(targets.value_counts(), labels=targets.value_counts().index, autopct='%1.2f%%', colors=palette_9)\n",
        "        plt.show()\n",
        "\n",
        "    def target_dist(self):\n",
        "        print(Style.BRIGHT+Fore.RED+f\"\\nTarget feature distribution\\n\")\n",
        "        fig, axes = plt.subplots(1, 1, figsize=(7, 5))\n",
        "        sns.histplot(self.train[self.targets], kde=True, ax=axes)\n",
        "        axes.set_title('Distribution of Price')\n",
        "        axes.set_xlabel(self.targets)\n",
        "        axes.set_ylabel('Frequency')"
      ],
      "metadata": {
        "id": "0595jA_qHZuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 EDA"
      ],
      "metadata": {
        "id": "49q4hFif9abF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Experiment Area:"
      ],
      "metadata": {
        "id": "tTS6MhPt9dWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    SEED    = 333\n",
        "    CV      = KFold(n_splits=15, shuffle=True, random_state=SEED)\n",
        "    VERSION = '1'\n",
        "\n",
        "class Data:\n",
        "    path       = False\n",
        "    or_path    = ''\n",
        "    to_drop    = False\n",
        "    target     = 'Calories'\n",
        "    drop_duplicates = False\n",
        "\n",
        "    def __init__(self):\n",
        "        self.train      = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_train_01.csv\",index_col=0).drop(columns=self.to_drop) if self.to_drop else pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_train_01.csv\",index_col=0)\n",
        "        self.test       = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_test_01.csv\",index_col=0).drop(columns=self.to_drop) if self.to_drop else pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/df_test_01.csv\",index_col=0)\n",
        "        self.submission = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "        self.original   = pd.read_csv(self.or_path) if self.or_path else pd.DataFrame()\n",
        "\n",
        "        self.train.loc[:,\"BMI\"] = np.clip(self.train.BMI, a_min=-5.0, a_max=5.0)\n",
        "        self.test.loc[:,\"BMI\"] = np.clip(self.test.BMI, a_min=-5.0, a_max=5.0)\n",
        "\n",
        "    @property\n",
        "    def X(self):\n",
        "        return self.train.drop(columns=self.target)\n",
        "    @property\n",
        "    def y(self):\n",
        "        return self.train[[self.target]]\n",
        "    @property\n",
        "    def X_test(self):\n",
        "        return self.test\n",
        "    @property\n",
        "    def X_original(self):\n",
        "        if len(self.original) != 0:\n",
        "            return self.original.drop(columns=self.target)\n",
        "        return pd.DataFrame()\n",
        "    @property\n",
        "    def y_original(self):\n",
        "        if len(self.original) != 0:\n",
        "            return self.original[[self.target]]\n",
        "        return pd.DataFrame()\n",
        "    @property\n",
        "    def cat_features(self):\n",
        "        return self.X.select_dtypes(include=['category', 'bool', 'category','int']).columns.to_list()\n",
        "    @property\n",
        "    def num_features(self):\n",
        "        return self.X.select_dtypes(exclude=['category', 'bool', 'category','int']).columns.to_list()\n",
        "\n",
        "    def submit(self, sub: np.ndarray, desc: str):\n",
        "        '''Submit the predictions in the adequate format'''\n",
        "        self.submission[self.target] = sub\n",
        "        self.submission.to_csv(f'SUB_{CFG.VERSION}_{desc}.csv', index=False)\n",
        "        print(colored('Submission has been made.', color='green', attrs=['bold', 'dark']))\n",
        "\n",
        "    @staticmethod\n",
        "    def sep_line():\n",
        "        print(colored(f'{\"_____\"*14}', color='black'))\n",
        "        print('')\n",
        "\n",
        "    @staticmethod\n",
        "    def head(head_text):\n",
        "        print(colored(f'{\"    \"} ➩ {head_text} ', color='green', attrs=['dark']))\n",
        "\n",
        "    def display_data(self):\n",
        "        self.head(f'𝐃𝐚𝐭𝐚𝐬𝐞𝐭 𝐬𝐡𝐚𝐩𝐞𝐬 — 𝐓𝐫𝐚𝐢𝐧 | 𝐓𝐞𝐬𝐭: {self.train.shape} | {self.test.shape}')\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐓𝐫𝐚𝐢𝐧 𝐡𝐞𝐚𝐝')\n",
        "        display(self.train.head(5))\n",
        "        self.head('𝐓𝐞𝐬𝐭 𝐡𝐞𝐚𝐝')\n",
        "        display(self.test.head(5))\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐓𝐫𝐚𝐢𝐧 𝐢𝐧𝐟𝐨')\n",
        "        display(self.train.info())\n",
        "        self.head('𝐓𝐞𝐬𝐭 𝐢𝐧𝐟𝐨')\n",
        "        display(self.test.info())\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐓𝐫𝐚𝐢𝐧 𝐬𝐮𝐦𝐦𝐚𝐫𝐲 𝐬𝐭𝐚𝐭𝐬')\n",
        "        display(self.train.describe().T)\n",
        "        self.head('𝐓𝐞𝐬𝐭 𝐬𝐮𝐦𝐦𝐚𝐫𝐲 𝐬𝐭𝐚𝐭𝐬')\n",
        "        display(self.test.describe().T)\n",
        "        self.sep_line()\n",
        "\n",
        "        def nunique_null(train, test):\n",
        "            nunique_train, nunique_test = {}, {}\n",
        "            nulls_train, nulls_test = {}, {}\n",
        "\n",
        "            for col in test.columns:\n",
        "                nunique_train[col], nunique_test[col] = train[col].nunique(), test[col].nunique()\n",
        "                nulls_train[col], nulls_test[col] = train[col].isna().sum(), test[col].isna().sum()\n",
        "\n",
        "            df = pd.DataFrame([nunique_train, nunique_test,\n",
        "                               nulls_train, nulls_test],\n",
        "                              index=['Train nunique', 'Test nunique',\n",
        "                                     'Train null', 'Test null'])\n",
        "            return df\n",
        "\n",
        "        self.head('𝐍𝐮𝐧𝐢𝐪𝐮𝐞 𝐚𝐧𝐝 𝐧𝐮𝐥𝐥𝐬')\n",
        "        display(nunique_null(self.train, self.test))\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞𝐬')\n",
        "        display(f'Train duplicated: {self.train.duplicated().sum()}')\n",
        "        display(f'Test duplicated: {self.test.duplicated().sum()}')\n",
        "\n",
        "        if self.drop_duplicates==True:\n",
        "          if self.train.duplicated().sum() > 0:\n",
        "              self.train = self.train.drop_duplicates()\n",
        "              print('Train duplicates dropped.')\n",
        "          if self.test.duplicated().sum() > 0:\n",
        "              #self.test = self.test.drop_duplicates()\n",
        "              print('Test duplicates dropped.')\n",
        "        self.sep_line()\n",
        "\n",
        "        self.head('𝐍𝐮𝐧𝐢𝐪𝐮𝐞 𝐢𝐧 𝐭𝐫𝐚𝐢𝐧 𝐧𝐨𝐭 𝐢𝐧 𝐭𝐞𝐬𝐭/𝐢𝐧 𝐭𝐞𝐬𝐭 𝐧𝐨𝐭 𝐢𝐧 𝐭𝐫𝐚𝐢𝐧')\n",
        "        cat_cols = [c for c in self.test.columns if self.train[c].nunique() <= 40 or\n",
        "                    c in self.test.select_dtypes(include=['object', 'category']).columns]\n",
        "\n",
        "        def compare_unique_categories(train, test, cat_cols):\n",
        "            unique_train_dic, unique_test_dic = {}, {}\n",
        "\n",
        "            for c in cat_cols:\n",
        "                unique_train_c = train[c].unique()\n",
        "                unique_test_c = test[c].unique()\n",
        "\n",
        "                count_tr = sum(1 for cat in unique_train_c if cat not in unique_test_c and not pd.isna(cat))\n",
        "                count_te = sum(1 for cat in unique_test_c if (cat not in unique_train_c and not pd.isna(cat)))\n",
        "\n",
        "                unique_train_dic[c] = count_tr\n",
        "                unique_test_dic[c] = count_te\n",
        "\n",
        "            result_df = pd.DataFrame([unique_train_dic, unique_test_dic],\n",
        "                                     index=['in train not in test', 'in test not in train'])\n",
        "\n",
        "            return result_df\n",
        "\n",
        "        display(compare_unique_categories(self.train, self.test, cat_cols))\n",
        "\n",
        "data = Data()\n",
        "data.display_data()"
      ],
      "metadata": {
        "id": "YGfCDVNy67x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.shape, data.y.shape, data.X_test.shape"
      ],
      "metadata": {
        "id": "4-BfljxHg43C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.cat_features)"
      ],
      "metadata": {
        "id": "kEtWXl_ThCwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_scatter(pd.concat([data.X,data.y],axis=1), x=\"BMI\", y=\"Intensity\", color_feature=\"Calories\")"
      ],
      "metadata": {
        "id": "uuFOKAjRPsMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.info(),data.X_test.info()"
      ],
      "metadata": {
        "id": "73sGT_yqY8G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X_test.shape, data.y.shape\n",
        "\n",
        "y_test_fic = data.y[:len(data.X_test)].copy()\n",
        "y_test_fic[\"Calories\"]=np.nan"
      ],
      "metadata": {
        "id": "K8cT8NgpwQin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Neural Networks:\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014189,
          "end_time": "2024-10-26T19:32:03.237017",
          "exception": false,
          "start_time": "2024-10-26T19:32:03.222828",
          "status": "completed"
        },
        "tags": [],
        "id": "7OZ_SPtJ1KTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe, target, categorical_features, numerical_features, shuffle=False, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((dataframe[categorical_features].values,  # First input\n",
        "                                              dataframe[numerical_features].values),\n",
        "                                              target))\n",
        "\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "\n",
        "    return ds\n",
        "\n",
        "def dataframe_to_dataset_test(dataframe, target_finc, categorical_features, numerical_features, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((dataframe[categorical_features].values,  # First input\n",
        "                                              dataframe[numerical_features].values),\n",
        "                                              target_finc))\n",
        "\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "xv1gjhxRLK0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    SEED    = 333\n",
        "    CV      = KFold(n_splits=11, shuffle=True, random_state=SEED)\n",
        "    VERSION = '1'\n",
        "\n",
        "class TrainModels:\n",
        "    def __init__(self, X, y, X_test, test_finc_target, X_original, y_original, model_, parameters):\n",
        "        self.model     = model_\n",
        "        self.parameters = parameters\n",
        "        self.X          = X\n",
        "        self.y          = y\n",
        "        self.test_finc_target = test_finc_target\n",
        "        self.X_test     = X_test\n",
        "        self._OOF_train = pd.DataFrame()\n",
        "        self._OOF_test  = pd.DataFrame()\n",
        "        self.categorical_features = X.select_dtypes(include=['category', 'bool', 'category','int']).columns.to_list()\n",
        "        self.numerical_features = X.select_dtypes(exclude=['category', 'bool', 'category','int']).columns.to_list()\n",
        "\n",
        "    def fit_model(self, name=\"Base_model\"):\n",
        "        oof_train = np.zeros(self.X.shape[0])\n",
        "        oof_test  = np.zeros(self.X_test.shape[0])\n",
        "        scores_train = []\n",
        "        scores_val   = []\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S5E5/layers_3_staked_models')\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(CFG.CV.split(self.X, self.y)):\n",
        "            x_train, y_train = self.X.iloc[train_idx], self.y.iloc[train_idx]\n",
        "            x_val,   y_val   = self.X.iloc[val_idx],   self.y.iloc[val_idx]\n",
        "\n",
        "\n",
        "            train_ds = dataframe_to_dataset(x_train, y_train, self.categorical_features, self.numerical_features, shuffle=True, batch_size=1024)\n",
        "            val_ds = dataframe_to_dataset(x_val, y_val, self.categorical_features, self.numerical_features, shuffle=False, batch_size=1024)\n",
        "            test_ds = dataframe_to_dataset_test(self.X_test, self.test_finc_target, self.categorical_features, self.numerical_features, batch_size=1024)\n",
        "\n",
        "            model = self.model(**self.parameters)\n",
        "\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "            model.compile(optimizer=optimizer,\n",
        "                          loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                          metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "            checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5'\n",
        "            model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "                                                                        filepath=checkpoint_filepath,\n",
        "                                                                        save_weights_only=True,\n",
        "                                                                        monitor='val_rmsle',\n",
        "                                                                        mode='min',\n",
        "                                                                        save_best_only=True\n",
        "                                                                        )\n",
        "\n",
        "            # Fit the model\n",
        "            history = model.fit(train_ds,\n",
        "                                validation_data=val_ds,\n",
        "                                epochs=151,\n",
        "                                batch_size=1024,\n",
        "                                callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                                          keras.callbacks.EarlyStopping(patience=21, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                                          start_from_epoch=3, mode=\"min\"),\n",
        "                                            model_checkpoint_callback])\n",
        "\n",
        "            model.load_weights(checkpoint_filepath)\n",
        "\n",
        "            model.save(f\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S5E5/keras_models/{name}_{fold}.keras\")\n",
        "\n",
        "            model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "            plot_training_session(history)\n",
        "\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred_train = model.predict(train_ds)\n",
        "            y_pred_val   = model.predict(val_ds)\n",
        "            y_pred_test  = model.predict(test_ds)\n",
        "\n",
        "            # Correct Ranges:\n",
        "\n",
        "            y_pred_train = np.maximum(y_pred_train, 1.0)\n",
        "            y_pred_train = np.minimum(y_pred_train, 315.0)\n",
        "\n",
        "            y_pred_val = np.maximum(y_pred_val, 1.0)\n",
        "            y_pred_val = np.minimum(y_pred_val, 315.0)\n",
        "\n",
        "            y_pred_test = np.maximum(y_pred_test, 1.0)\n",
        "            y_pred_test = np.minimum(y_pred_test, 315.0)\n",
        "\n",
        "            # Store Results\n",
        "            oof_train[val_idx] = y_pred_val.reshape(-1)\n",
        "            oof_test   += (y_pred_test/CFG.CV.get_n_splits()).reshape(-1)\n",
        "\n",
        "            train_score = root_mean_squared_log_error(y_train, y_pred_train)\n",
        "            val_score   = root_mean_squared_log_error(y_val, y_pred_val)\n",
        "\n",
        "            print(f'Fold {fold+1} → Training set Score: {train_score:.5f} | Validation set Score: {val_score:.5f}')\n",
        "\n",
        "            scores_train.append(train_score)\n",
        "            scores_val.append(val_score)\n",
        "\n",
        "        self._OOF_train[name] = oof_train\n",
        "        self._OOF_test[name]  = oof_test\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5')\n",
        "\n",
        "        print(colored(f'Overall → Training set Score: {np.mean(scores_train):.5f}±{np.std(scores_train):.7f} | Validation set Score: {np.mean(scores_val):.5f}±{np.std(scores_val):.7f}',\n",
        "              color='green', attrs=['bold', 'dark']))\n",
        "\n",
        "    @property\n",
        "    def OOF_train(self):\n",
        "        return self._OOF_train\n",
        "    @property\n",
        "    def OOF_test(self):\n",
        "        return self._OOF_test\n",
        "\n",
        "    def save_predictions(self):\n",
        "        self._OOF_train.to_csv('OOF_train_many_models.csv', index=False)\n",
        "        self._OOF_test.to_csv('OOF_test_many_models.csv', index=False)"
      ],
      "metadata": {
        "id": "31P8f6EBmOwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_session(history):\n",
        "  # Plot training and validation loss scores\n",
        "  # against the number of epochs.\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(history.history['loss'], label='Train')\n",
        "  plt.plot(history.history['val_loss'], label='Validation')\n",
        "  plt.grid(linestyle='--')\n",
        "  plt.ylabel('val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Train-Validation Scores', pad=13)\n",
        "  plt.legend(loc='upper right');\n",
        "  plt.show()\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Root Mean Squared Logarithmic Error (RMSLE)\n",
        "    \"\"\"\n",
        "    # Ensure y_pred is non-negative and add a small constant to avoid log(0) errors\n",
        "    y_pred = K.maximum(K.cast(y_pred, tf.float32), K.epsilon()) # Corrected: K.maximum\n",
        "\n",
        "    first_log = K.log(K.maximum(K.cast(y_pred, tf.float32), K.epsilon()) + 1.) # Corrected: K.maximum\n",
        "    second_log = K.log(K.maximum(K.cast(y_true, tf.float32), K.epsilon()) + 1.) # Corrected: K.maximum\n",
        "\n",
        "    return K.sqrt(K.mean(K.square(first_log - second_log)))\n",
        "\n",
        "# def rmsle(y_true, y_pred):\n",
        "#     \"\"\"\n",
        "#     Root Mean Squared Logarithm Error\n",
        "#     Args:\n",
        "#         y_true ([np.array]): test samples\n",
        "#         y_pred ([np.array]): predicted samples\n",
        "#     Returns:\n",
        "#         [float]: root mean squared logarithm error\n",
        "#     \"\"\"\n",
        "#     first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
        "#     second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
        "#     return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))"
      ],
      "metadata": {
        "id": "1NQnrDo9ten6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41K1txKVzFhu"
      },
      "source": [
        "### **2.1.0 NeuralNetwork: Dense**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGyFvBNgzFh2"
      },
      "outputs": [],
      "source": [
        "data.X.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.max(axis=0)"
      ],
      "metadata": {
        "id": "grc-F6yEIltY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.min(axis=0)"
      ],
      "metadata": {
        "id": "a5TlsDYEKspq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = data.cat_features\n",
        "num_features = data.num_features\n",
        "\n",
        "cat_features_card = [2,2,8]\n",
        "cat_features_out = [2, 2, 4]\n",
        "\n",
        "print(cat_features,cat_features_card)\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "AbaJACP3minK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ceil(np.sqrt(cat_features_card[1]))"
      ],
      "metadata": {
        "id": "mZqePRWLqJFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(units=512,last_layer = 1, activation=\"relu\", do_rate=0.25, reg=0.001):\n",
        "\n",
        "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
        "    embs = []\n",
        "    for j in range(len(cat_features)):\n",
        "        e = layers.Embedding(cat_features_card[j], cat_features_out[j]) #np.ceil(np.sqrt(cat_features_card[1]))\n",
        "        x = e(x_input_cats[:,j])\n",
        "        x = layers.Flatten()(x)\n",
        "        embs.append(x)\n",
        "\n",
        "    x_input_nums = layers.Input(shape=(len(num_features),))\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
        "    x = layers.Dense(units, activation=activation, kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(do_rate)(x)\n",
        "    x = layers.Dense(units, activation=activation, kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(do_rate)(x)\n",
        "    x = layers.Dense(int(units/last_layer), activation=activation, kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(do_rate)(x)\n",
        "    x_final = layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x_final)\n",
        "    return model"
      ],
      "metadata": {
        "id": "VF6Qd4eziUd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_test = build_model(units=512)\n",
        "mod_test.summary()"
      ],
      "metadata": {
        "id": "HPhVCKp9mOzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ceVtzBwQlNg"
      },
      "source": [
        "#### 2.1.1 Optuna Optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ9CoxtaQlNg"
      },
      "outputs": [],
      "source": [
        "X_fin = data.X\n",
        "X_test_fin = data.X_test\n",
        "\n",
        "X_train_cat = data.X[cat_features]\n",
        "X_train_num = data.X[num_features]\n",
        "\n",
        "X_test_cat = data.X_test[cat_features]\n",
        "X_test_num = data.X_test[num_features]\n",
        "\n",
        "X_train_cat.info()\n",
        "X_train_num.info()\n",
        "\n",
        "y_fin = data.y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fin.isna().sum()"
      ],
      "metadata": {
        "id": "dw84O6QuLEK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMIZATION SECTION**"
      ],
      "metadata": {
        "id": "fqMh80e9vD0H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tObj5kq1QlNg"
      },
      "outputs": [],
      "source": [
        "def objective_nn(trial, X, y, n_splits, n_repeats, model=build_model, use_gpu=True, rs=42, fit_scaling=False, cv_strategy=\"KFold\"):\n",
        "\n",
        "    model_class = model\n",
        "\n",
        "    categorical_features = cat_features.copy()\n",
        "\n",
        "    num_cols = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "    params = {'units': trial.suggest_categorical('units', [128,256,512,1024]),\n",
        "              'last_layer': trial.suggest_int('last_layer', 1,2),\n",
        "              'activation': trial.suggest_categorical('activation', [\"relu\",\"selu\",\"gelu\",\"silu\"]), #, reg=0.001, dropout_rate=0.33)\n",
        "              'reg': trial.suggest_float('reg', 1e-4, 0.1, log=True),\n",
        "              'do_rate': trial.suggest_float('do_rate', 0.30, 0.50)\n",
        "              }\n",
        "\n",
        "    if cv_strategy == 'RepKFold':\n",
        "        kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "    elif cv_strategy == 'KFold':\n",
        "        kf = KFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"StratKFold\":\n",
        "        kf = StratifiedKFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"RepStratKFold\":\n",
        "        kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "    rmsle_scores = []\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    iteration_n=0\n",
        "\n",
        "    for idx_train, idx_valid in kf.split(X, y):\n",
        "        print(f\"Running Fold: {iteration_n}\")\n",
        "        # Split the data into training and validation sets for the current fold\n",
        "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train].to_numpy()#.reshape(-1, 1)\n",
        "        X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid].to_numpy()#.reshape(-1, 1)\n",
        "\n",
        "        X_train_cat = X_train[cat_features]\n",
        "        X_train_num = X_train[num_features]\n",
        "\n",
        "        X_valid_cat = X_valid[cat_features]\n",
        "        X_valid_num = X_valid[num_features]\n",
        "\n",
        "        # Create the model\n",
        "        keras.utils.set_random_seed(rs)\n",
        "        model = model_class(**params)\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "        model.compile(optimizer=optimizer,\n",
        "                      loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                      metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "        checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5'\n",
        "        model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_filepath,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_rmsle',\n",
        "            mode='min',\n",
        "            save_best_only=True)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit([X_train_cat,X_train_num], y_train,\n",
        "                  validation_data=([X_valid_cat, X_valid_num], y_valid),\n",
        "                  epochs=31,\n",
        "                  batch_size=1024,\n",
        "                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                            start_from_epoch=3, mode=\"min\"),\n",
        "                             model_checkpoint_callback])\n",
        "\n",
        "        model.load_weights(checkpoint_filepath)\n",
        "\n",
        "        # Make predictions on the validation set\n",
        "        y_pred = model.predict([X_valid_cat, X_valid_num], batch_size=1024)\n",
        "        y_pred = np.maximum(y_pred, 1.0)\n",
        "        y_pred = np.minimum(y_pred, 315.0)\n",
        "\n",
        "        print(\"Pred Min: {}\".format(y_pred.min()))\n",
        "        print(\"Pred Max: {}\".format(y_pred.max()))\n",
        "\n",
        "        # Calculate the RMSE for the current fold\n",
        "        rmsle_score = root_mean_squared_log_error(y_valid, y_pred)\n",
        "        print(f\"Fold {iteration_n} RMSLE: {rmsle_score}\")\n",
        "\n",
        "        rmsle_scores.append(rmsle_score)\n",
        "        iteration_n+=1\n",
        "\n",
        "    # Calculate the mean RMSLE score across all folds\n",
        "    key_metric = np.mean(rmsle_scores)\n",
        "\n",
        "    return key_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sux1Xc6ZQlNh"
      },
      "outputs": [],
      "source": [
        "# Step 2: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, n_splits_ ,n_repeats_, use_gpu=True):  #use_gpu\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
        "    study.optimize(lambda trial: objective_nn(trial, X, y, n_splits=n_splits_, n_repeats=n_repeats_, model=build_model, use_gpu=use_gpu, cv_strategy=\"KFold\"), n_trials=n_trials)\n",
        "    return study  # Return the study object\n",
        "\n",
        "# Step 3: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")# usage with XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fin.isna().sum(), y_fin.min()"
      ],
      "metadata": {
        "id": "_G7uNJwgKXOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1. Trial 4 finished with value: 0.06326587167991321 and parameters: {'units': 512, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012466698516071345, 'do_rate': 0.32329936440008156}.\n",
        "\n",
        "  2. Trial 12 finished with value: 0.0644081979735794 and parameters: {'units': 256, 'last_layer': 1, 'activation': 'relu', 'reg': 0.0006106006869707281, 'do_rate': 0.3494656732997632}.\n",
        "\n",
        "  3.  Trial 14 finished with value: 0.06490268403547308 and parameters: {'units': 256, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012000706329704339, 'do_rate': 0.3032266090954228}."
      ],
      "metadata": {
        "id": "4gD8te2nDso2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW_aoIIBQlNh"
      },
      "outputs": [],
      "source": [
        "nn0_study = tune_hyperparameters(X_fin, y_fin, model_class=build_model, n_trials=31, n_splits_ = 5 ,n_repeats_=3, use_gpu=True)\n",
        "\n",
        "cat_params = nn0_study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 Train Model:"
      ],
      "metadata": {
        "id": "lIkzAb-rGNGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'units': 512, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012466698516071345, 'do_rate': 0.32329936440008156}\n",
        "TM = TrainModels(X=data.X, y=data.y, X_test=data.X_test, test_finc_target=y_test_fic, X_original=None, y_original=None, model_=build_model, parameters=param)"
      ],
      "metadata": {
        "id": "xGuhYBvImOti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM.fit_model(name=\"NN_exp_00\")"
      ],
      "metadata": {
        "id": "NafO4kd5mOqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 Store Results:"
      ],
      "metadata": {
        "id": "4n5hBAAw8gPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = TM.OOF_train\n",
        "test_pred = TM.OOF_test\n",
        "train_pred = pd.DataFrame(data = train_pred, columns = [\"NN_exp_00\"])\n",
        "\n",
        "\n",
        "sub = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "\n",
        "sub[\"Calories\"] =  test_pred.values\n",
        "\n",
        "sub.to_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/submission_NN_exp_00.csv\")\n",
        "train_pred.to_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train_pred_NN_exp_00.csv\")"
      ],
      "metadata": {
        "id": "crsVb2JXmOns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.min(), test_pred.max()"
      ],
      "metadata": {
        "id": "FkWb5A0jmOkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred"
      ],
      "metadata": {
        "id": "MnoThd5GRKfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvKi8GKnOMjO"
      },
      "source": [
        "### **2.2.0 NeuralNetwork: Wide and Deep Model v0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciGJJnKjOMjP"
      },
      "outputs": [],
      "source": [
        "data.X.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.X.max(axis=0)"
      ],
      "metadata": {
        "id": "nOTFfHx9OMjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "ax[0].hist(data.X.BMI, bins=31)\n",
        "ax[1].hist(data.X_test.BMI, bins=31, color=\"salmon\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s7OEZdd9PQNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = data.cat_features\n",
        "num_features = data.num_features\n",
        "\n",
        "cat_features_card = [2,2,8]\n",
        "cat_features_out = [2, 2, 4]\n",
        "\n",
        "\n",
        "print(cat_features,cat_features_card)\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "9j6EMW2yOMjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wide_deep(units=512, activation=\"relu\", do_rate=0.25, reg=0.001, hidden_layers=3):\n",
        "    '''\n",
        "    In this model embedding is performed for the data feeding into both the Deep and and wide layers:\n",
        "    '''\n",
        "\n",
        "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
        "    embs = []\n",
        "    for j in range(len(cat_features)):\n",
        "        e = layers.Embedding(cat_features_card[j], cat_features_out[j]) #np.ceil(np.sqrt(cat_features_card[1]))\n",
        "        x = e(x_input_cats[:,j])\n",
        "        x = layers.Flatten()(x)\n",
        "        embs.append(x)\n",
        "\n",
        "    x_input_nums = layers.Input(shape=(len(num_features),))\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
        "\n",
        "    wide = layers.BatchNormalization()(x)\n",
        "    deep = x\n",
        "\n",
        "    for lay in range(hidden_layers):\n",
        "        deep = layers.Dense(units,kernel_regularizer=keras.regularizers.l2(reg), name=f\"dense_deep_{lay}\")(deep)\n",
        "        deep = layers.BatchNormalization(name=f\"bn_deep_{lay}\")(deep)\n",
        "        if activation == \"relu\":\n",
        "            deep = layers.ReLU(name=f\"relu_deep_{lay}\")(deep)\n",
        "        elif activation == \"prelu\":\n",
        "            deep = layers.PReLU(name=f\"prelu_deep_{lay}\")(deep)\n",
        "        elif activation == \"gelu \":\n",
        "            deep = activations.gelu(deep)\n",
        "        elif activation == \"silu\":\n",
        "            deep = activations.silu(deep)\n",
        "        elif activation == \"mish\":\n",
        "            deep = layers.Lambda(lambda x: keras.activations.mish(x), name=f\"mish_deep_{lay}\")(deep)\n",
        "        elif activation == \"celu\":\n",
        "            deep = activations.celu(deep)\n",
        "\n",
        "        deep = layers.Dropout(do_rate, name=f\"do_deep_{lay}\")(deep)\n",
        "\n",
        "    merged = layers.concatenate([wide, deep])\n",
        "\n",
        "    x_final = layers.Dense(1, activation='linear')(merged)\n",
        "\n",
        "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x_final)\n",
        "    return model"
      ],
      "metadata": {
        "id": "2XhwdLzZOMjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_test = wide_deep(units=512, activation=\"celu\")\n",
        "mod_test.summary()"
      ],
      "metadata": {
        "id": "0proQYO0OMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keras.utils.plot_model(mod_test, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "G8RnyWJH4oRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYIuPRrOMjQ"
      },
      "source": [
        "#### 2.1.1 Optuna Optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8kcen4hOMjQ"
      },
      "outputs": [],
      "source": [
        "X_fin = data.X\n",
        "X_test_fin = data.X_test\n",
        "\n",
        "X_train_cat = data.X[cat_features]\n",
        "X_train_num = data.X[num_features]\n",
        "\n",
        "X_test_cat = data.X_test[cat_features]\n",
        "X_test_num = data.X_test[num_features]\n",
        "\n",
        "X_train_cat.info()\n",
        "X_train_num.info()\n",
        "\n",
        "y_fin = data.y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fin.isna().sum()"
      ],
      "metadata": {
        "id": "jCYAFlZfOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMIZATION SECTION**"
      ],
      "metadata": {
        "id": "BtRpVIqfOMjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGA_0vWHOMjQ"
      },
      "outputs": [],
      "source": [
        "def objective_nn(trial, X, y, n_splits, n_repeats, model=wide_deep, use_gpu=True, rs=42, fit_scaling=False, cv_strategy=\"KFold\"):\n",
        "\n",
        "    model_class = model\n",
        "\n",
        "    categorical_features = cat_features.copy()\n",
        "\n",
        "    num_cols = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "    params = {\n",
        "              'units': trial.suggest_categorical('units', [128,256,512,1024]),\n",
        "              'last_layer': trial.suggest_int('last_layer', 1,2),\n",
        "              'activation': trial.suggest_categorical('activation', [\"relu\",\"prelu\",\"gelu\",\"silu\",\"mish\",\"celu\"]), #, reg=0.001, dropout_rate=0.33)\n",
        "              'reg': trial.suggest_float('reg', 1e-4, 0.1, log=True),\n",
        "              'do_rate': trial.suggest_float('do_rate', 0.30, 0.50),\n",
        "              'hidden_layers': trial.suggest_int('hidden_layers', 1,4)\n",
        "              }\n",
        "\n",
        "    if cv_strategy == 'RepKFold':\n",
        "        kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "    elif cv_strategy == 'KFold':\n",
        "        kf = KFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"StratKFold\":\n",
        "        kf = StratifiedKFold(n_splits=n_splits, random_state=rs, shuffle=True)\n",
        "    elif cv_strategy == \"RepStratKFold\":\n",
        "        kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "    rmsle_scores = []\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    iteration_n=0\n",
        "\n",
        "    for idx_train, idx_valid in kf.split(X, y):\n",
        "        print(f\"Running Fold: {iteration_n}\")\n",
        "        # Split the data into training and validation sets for the current fold\n",
        "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train].to_numpy()#.reshape(-1, 1)\n",
        "        X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid].to_numpy()#.reshape(-1, 1)\n",
        "\n",
        "        X_train_cat = X_train[cat_features]\n",
        "        X_train_num = X_train[num_features]\n",
        "\n",
        "        X_valid_cat = X_valid[cat_features]\n",
        "        X_valid_num = X_valid[num_features]\n",
        "\n",
        "        # Create the model\n",
        "        keras.utils.set_random_seed(rs)\n",
        "        model = model_class(**params)\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
        "        model.compile(optimizer=optimizer,\n",
        "                      loss=[rmsle, keras.losses.MeanSquaredLogarithmicError(name=\"msle\")],\n",
        "                      metrics=[rmsle, keras.metrics.RootMeanSquaredError(name=\"msle\")])\n",
        "\n",
        "        checkpoint_filepath = '/tmp/ckpt/checkpoint_dw.weights.h5'\n",
        "        model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_filepath,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_rmsle',\n",
        "            mode='min',\n",
        "            save_best_only=True)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit([X_train_cat,X_train_num], y_train,\n",
        "                  validation_data=([X_valid_cat, X_valid_num], y_valid),\n",
        "                  epochs=31,\n",
        "                  batch_size=1024,\n",
        "                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3, factor = 0.5, min_lr=1e-6),\n",
        "                            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_rmsle\",\n",
        "                                                            start_from_epoch=3, mode=\"min\"),\n",
        "                             model_checkpoint_callback])\n",
        "\n",
        "        model.load_weights(checkpoint_filepath)\n",
        "\n",
        "        # Make predictions on the validation set\n",
        "        y_pred = model.predict([X_valid_cat, X_valid_num], batch_size=1024)\n",
        "        y_pred = np.maximum(y_pred, 1.0)\n",
        "        y_pred = np.minimum(y_pred, 315.0)\n",
        "\n",
        "        print(\"Pred Min: {}\".format(y_pred.min()))\n",
        "        print(\"Pred Max: {}\".format(y_pred.max()))\n",
        "\n",
        "        # Calculate the RMSE for the current fold\n",
        "        rmsle_score = root_mean_squared_log_error(y_valid, y_pred)\n",
        "        print(f\"Fold {iteration_n} RMSLE: {rmsle_score}\")\n",
        "\n",
        "        rmsle_scores.append(rmsle_score)\n",
        "        iteration_n+=1\n",
        "\n",
        "    # Calculate the mean RMSLE score across all folds\n",
        "    key_metric = np.mean(rmsle_scores)\n",
        "\n",
        "    return key_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvbmcziROMjQ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Tuning Hyperparameters with Optuna\n",
        "def tune_hyperparameters(X, y, model_class, n_trials, n_splits_ ,n_repeats_, use_gpu=True):  #use_gpu\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
        "    study.optimize(lambda trial: objective_nn(trial, X, y, n_splits=n_splits_, n_repeats=n_repeats_, model=model_class, use_gpu=use_gpu, cv_strategy=\"KFold\"), n_trials=n_trials)\n",
        "    return study  # Return the study object\n",
        "\n",
        "# Step 3: Saving Best Results and Models\n",
        "def save_results(study, model_class, model_name):\n",
        "    best_params_file = f\"{model_name}_best_params.joblib\"\n",
        "    joblib.dump(study.best_params, best_params_file)\n",
        "    print(f\"Best parameters for {model_name} saved to {best_params_file}\")\n",
        "\n",
        "    verbose_file = f\"{model_name}_optuna_verbose.log\"\n",
        "    with open(verbose_file, \"w\") as f:\n",
        "        f.write(str(study.trials))\n",
        "    print(f\"Optuna verbose for {model_name} saved to {verbose_file}\")# usage with XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fin.isna().sum(), y_fin.min()"
      ],
      "metadata": {
        "id": "EGOg0uogOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1. Trial 32 finished with value: 0.06224817614285113 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.000103427172893175, 'do_rate': 0.40056000512858025, 'hidden_layers': 2}\n",
        "\n",
        "  2. Trial 18 finished with value: 0.06211038027842043 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0001004170129215336, 'do_rate': 0.41356627172269655, 'hidden_layers': 3} Best\n",
        "\n",
        "  3.  Trial 23 finished with value: 0.06239891244956206 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00010001356287977584, 'do_rate': 0.4642367345915417, 'hidden_layers': 2}."
      ],
      "metadata": {
        "id": "4T2eke9wOMjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XxPZBhabOMjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb3f881-1fab-420b-b9c6-45f686ba5081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.6188 - rmsle: 0.0918 - val_dense_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9854 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.5606 - rmsle: 0.0913 - val_dense_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8090 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.5293 - rmsle: 0.0910 - val_dense_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 3.9257 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0943 - msle: 7.4720 - rmsle: 0.0897 - val_dense_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.7703 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.4512 - rmsle: 0.0892 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8767 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06288171784347979\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2632 - msle: 99.2146 - rmsle: 2.0973 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8174 - val_msle: 74.8182 - val_rmsle: 0.7579 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6269 - msle: 78.9812 - rmsle: 0.5796 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2584 - val_msle: 52.5188 - val_rmsle: 0.2215 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2728 - msle: 63.3607 - rmsle: 0.2400 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2295 - val_msle: 43.5679 - val_rmsle: 0.2062 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2479 - msle: 51.3771 - rmsle: 0.2267 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2153 - val_msle: 37.3474 - val_rmsle: 0.1993 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2371 - msle: 35.2017 - rmsle: 0.2224 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2201 - val_msle: 16.9964 - val_rmsle: 0.2080 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1577 - msle: 11.7731 - rmsle: 0.1432 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.6778 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1280 - msle: 9.2117 - rmsle: 0.1145 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0814 - val_msle: 4.4639 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1229 - msle: 9.0560 - rmsle: 0.1109 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.1173 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1192 - msle: 8.8974 - rmsle: 0.1084 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 5.1250 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1176 - msle: 8.8594 - rmsle: 0.1074 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.0178 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1151 - msle: 8.7103 - rmsle: 0.1054 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 5.0602 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1131 - msle: 8.5767 - rmsle: 0.1039 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.0197 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1116 - msle: 8.4934 - rmsle: 0.1028 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.3106 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1098 - msle: 8.3371 - rmsle: 0.1015 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.2112 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1091 - msle: 8.3730 - rmsle: 0.1010 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.3596 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1077 - msle: 8.2550 - rmsle: 0.1000 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.3567 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1063 - msle: 8.1467 - rmsle: 0.0990 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.3427 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1057 - msle: 8.1238 - rmsle: 0.0986 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.8241 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1050 - msle: 8.0142 - rmsle: 0.0979 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.5242 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1038 - msle: 7.9628 - rmsle: 0.0969 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.3618 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.7408 - rmsle: 0.0935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 6.1296 - val_rmsle: 0.0779 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.8324 - rmsle: 0.0936 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.0388 - val_rmsle: 0.0699 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.7450 - rmsle: 0.0931 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.7355 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.5559 - rmsle: 0.0911 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 5.0599 - val_rmsle: 0.0690 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0957 - msle: 7.5555 - rmsle: 0.0911 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 5.1886 - val_rmsle: 0.0726 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 299.1005859375\n",
            "Fold 1 RMSLE: 0.06408705626304444\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2705 - msle: 99.1614 - rmsle: 2.1044 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7591 - val_msle: 68.5950 - val_rmsle: 0.6987 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5771 - msle: 74.9115 - rmsle: 0.5237 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2668 - val_msle: 39.7655 - val_rmsle: 0.2268 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2714 - msle: 58.3725 - rmsle: 0.2362 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2262 - val_msle: 48.1861 - val_rmsle: 0.2021 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2459 - msle: 47.8702 - rmsle: 0.2241 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2251 - val_msle: 31.7784 - val_rmsle: 0.2092 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2268 - msle: 31.5725 - rmsle: 0.2119 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0925 - val_msle: 4.6848 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1343 - msle: 9.3316 - rmsle: 0.1185 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 4.5062 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1255 - msle: 9.1872 - rmsle: 0.1123 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 4.3024 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1201 - msle: 8.9516 - rmsle: 0.1084 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 3.9074 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1170 - msle: 8.8512 - rmsle: 0.1063 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 3.7551 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1152 - msle: 8.7604 - rmsle: 0.1051 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 3.7695 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.6132 - rmsle: 0.1031 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 3.9756 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1118 - msle: 8.5283 - rmsle: 0.1027 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 3.7248 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1090 - msle: 8.3631 - rmsle: 0.1004 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 3.8098 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1085 - msle: 8.3604 - rmsle: 0.1002 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 4.3258 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1076 - msle: 8.2817 - rmsle: 0.0996 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 5.2721 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1032 - msle: 8.0277 - rmsle: 0.0960 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 5.3394 - val_rmsle: 0.0812 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1027 - msle: 8.0304 - rmsle: 0.0963 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 4.9268 - val_rmsle: 0.0805 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1020 - msle: 7.9698 - rmsle: 0.0958 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 3.9984 - val_rmsle: 0.0737 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.8407 - rmsle: 0.0933 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.0827 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0053709745407104\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06655746686365756\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2623 - msle: 99.2317 - rmsle: 2.0967 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8140 - val_msle: 74.2005 - val_rmsle: 0.7551 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5829 - msle: 75.9084 - rmsle: 0.5315 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2482 - val_msle: 61.5310 - val_rmsle: 0.2110 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2713 - msle: 60.0308 - rmsle: 0.2383 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2236 - val_msle: 47.1453 - val_rmsle: 0.2003 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2461 - msle: 49.0066 - rmsle: 0.2253 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2137 - val_msle: 27.2347 - val_rmsle: 0.1979 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2364 - msle: 26.1303 - rmsle: 0.2217 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2103 - val_msle: 10.6428 - val_rmsle: 0.1987 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2097 - msle: 14.2094 - rmsle: 0.1978 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0845 - val_msle: 4.8214 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1279 - msle: 9.2495 - rmsle: 0.1147 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 4.9152 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1215 - msle: 9.0692 - rmsle: 0.1100 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.1770 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1183 - msle: 8.9153 - rmsle: 0.1077 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.1693 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1162 - msle: 8.7996 - rmsle: 0.1062 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 3.9692 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1149 - msle: 8.7446 - rmsle: 0.1053 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.4751 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.5955 - rmsle: 0.1036 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 3.9253 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1117 - msle: 8.5207 - rmsle: 0.1030 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.3551 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1075 - msle: 8.2465 - rmsle: 0.0996 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.0205 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1057 - msle: 8.1908 - rmsle: 0.0986 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 3.9490 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1047 - msle: 8.1174 - rmsle: 0.0980 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.3957 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1043 - msle: 8.1522 - rmsle: 0.0978 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.8460 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1031 - msle: 8.0651 - rmsle: 0.0969 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 3.9279 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1024 - msle: 8.0185 - rmsle: 0.0963 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.8282 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1021 - msle: 7.9815 - rmsle: 0.0962 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 3.8496 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1021 - msle: 7.9884 - rmsle: 0.0962 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 3.9501 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.9365 - rmsle: 0.0955 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 3.7909 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.7784 - rmsle: 0.0933 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 5.5604 - val_rmsle: 0.0693 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.7752 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.2163 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.7783 - rmsle: 0.0926 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9158 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.7296 - rmsle: 0.0923 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8335 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.7322 - rmsle: 0.0922 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9098 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.6963 - rmsle: 0.0920 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9753 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.6863 - rmsle: 0.0919 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7522 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.6623 - rmsle: 0.0913 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.8276 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0959 - msle: 7.6586 - rmsle: 0.0916 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8461 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 303.2009582519531\n",
            "Fold 3 RMSLE: 0.06296474406634826\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2695 - msle: 99.3715 - rmsle: 2.1039 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8058 - val_msle: 73.8778 - val_rmsle: 0.7468 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5835 - msle: 76.7990 - rmsle: 0.5329 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2564 - val_msle: 60.6541 - val_rmsle: 0.2201 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2670 - msle: 62.6844 - rmsle: 0.2354 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2391 - val_msle: 48.6887 - val_rmsle: 0.2169 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2459 - msle: 50.8705 - rmsle: 0.2256 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2200 - val_msle: 32.9541 - val_rmsle: 0.2051 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2360 - msle: 34.2522 - rmsle: 0.2219 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2134 - val_msle: 15.4703 - val_rmsle: 0.2020 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2297 - msle: 21.0455 - rmsle: 0.2190 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2079 - val_msle: 10.5753 - val_rmsle: 0.1989 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1891 - msle: 11.7995 - rmsle: 0.1785 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 5.3721 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1255 - msle: 9.1658 - rmsle: 0.1131 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0929 - val_msle: 5.6943 - val_rmsle: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1203 - msle: 8.9739 - rmsle: 0.1091 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 4.7204 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1169 - msle: 8.8282 - rmsle: 0.1066 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.3878 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1148 - msle: 8.6977 - rmsle: 0.1051 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 5.0931 - val_rmsle: 0.0777 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1132 - msle: 8.5924 - rmsle: 0.1039 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 4.5383 - val_rmsle: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1111 - msle: 8.5032 - rmsle: 0.1023 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0928 - val_msle: 4.3073 - val_rmsle: 0.0843 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.1623 - rmsle: 0.0985 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0947 - val_msle: 7.4223 - val_rmsle: 0.0877 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1046 - msle: 8.1020 - rmsle: 0.0978 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 5.7617 - val_rmsle: 0.0722 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.0710 - rmsle: 0.0974 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 6.0361 - val_rmsle: 0.0760 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1034 - msle: 8.0662 - rmsle: 0.0972 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 6.3908 - val_rmsle: 0.0801 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1023 - msle: 7.9699 - rmsle: 0.0963 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 6.2237 - val_rmsle: 0.0782 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.8217 - rmsle: 0.0940 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.3465 - val_rmsle: 0.0690 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.7946 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.3356 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.7957 - rmsle: 0.0935 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 3.9068 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0978 - msle: 7.7663 - rmsle: 0.0931 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.1549 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.7395 - rmsle: 0.0927 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.2727 - val_rmsle: 0.0654 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.7449 - rmsle: 0.0924 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.1790 - val_rmsle: 0.0682 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.7106 - rmsle: 0.0923 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.8090 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.6415 - rmsle: 0.0912 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7589 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.5922 - rmsle: 0.0906 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.7631 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.5773 - rmsle: 0.0907 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9878 - val_rmsle: 0.0639 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0944 - msle: 7.5750 - rmsle: 0.0904 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8403 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.4987 - rmsle: 0.0895 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6393 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0931 - msle: 7.4886 - rmsle: 0.0893 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6642 - val_rmsle: 0.0605 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06120088935179741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:16:32,297] Trial 22 finished with value: 0.06353837487766549 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00019973277177462976, 'do_rate': 0.4031569153546122, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1601 - msle: 97.5285 - rmsle: 2.1122 - val_dense_loss: 0.0000e+00 - val_loss: 0.7870 - val_msle: 65.9286 - val_rmsle: 0.7567 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6356 - msle: 58.3225 - rmsle: 0.6090 - val_dense_loss: 0.0000e+00 - val_loss: 0.2292 - val_msle: 13.0947 - val_rmsle: 0.2109 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2381 - msle: 13.1779 - rmsle: 0.2217 - val_dense_loss: 0.0000e+00 - val_loss: 0.0993 - val_msle: 4.9205 - val_rmsle: 0.0859 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1489 - msle: 9.4803 - rmsle: 0.1362 - val_dense_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 5.9429 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1373 - msle: 9.1983 - rmsle: 0.1268 - val_dense_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.6068 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1311 - msle: 8.9923 - rmsle: 0.1219 - val_dense_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.6044 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1246 - msle: 8.7954 - rmsle: 0.1164 - val_dense_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.7483 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1194 - msle: 8.6568 - rmsle: 0.1120 - val_dense_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 4.5917 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1159 - msle: 8.5374 - rmsle: 0.1090 - val_dense_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.6278 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1138 - msle: 8.4819 - rmsle: 0.1073 - val_dense_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.4308 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1109 - msle: 8.3130 - rmsle: 0.1048 - val_dense_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.2086 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1090 - msle: 8.2558 - rmsle: 0.1033 - val_dense_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 3.9939 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1077 - msle: 8.2086 - rmsle: 0.1022 - val_dense_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.8408 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1056 - msle: 8.1239 - rmsle: 0.1004 - val_dense_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.2110 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1042 - msle: 8.0550 - rmsle: 0.0991 - val_dense_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.2588 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1031 - msle: 7.9967 - rmsle: 0.0982 - val_dense_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.4216 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1006 - msle: 7.8905 - rmsle: 0.0960 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7664 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1002 - msle: 7.8621 - rmsle: 0.0960 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7639 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0994 - msle: 7.8326 - rmsle: 0.0954 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8580 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.8347 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8385 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.8102 - rmsle: 0.0943 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7946 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.8026 - rmsle: 0.0940 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8821 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.7451 - rmsle: 0.0936 - val_dense_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7474 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.7136 - rmsle: 0.0935 - val_dense_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8961 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.7275 - rmsle: 0.0930 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0564 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.7206 - rmsle: 0.0928 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9800 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.6720 - rmsle: 0.0915 - val_dense_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7455 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.6296 - rmsle: 0.0911 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7586 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.6241 - rmsle: 0.0910 - val_dense_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7594 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.6484 - rmsle: 0.0909 - val_dense_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7436 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.6109 - rmsle: 0.0906 - val_dense_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7187 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06256480688341669\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1611 - msle: 97.4438 - rmsle: 2.1130 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7861 - val_msle: 66.4958 - val_rmsle: 0.7554 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6540 - msle: 59.4450 - rmsle: 0.6273 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2579 - val_msle: 20.1486 - val_rmsle: 0.2400 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2565 - msle: 14.5354 - rmsle: 0.2404 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0919 - val_msle: 5.1081 - val_rmsle: 0.0785 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1488 - msle: 9.4501 - rmsle: 0.1361 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 4.7562 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1382 - msle: 9.1338 - rmsle: 0.1277 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 4.9353 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1309 - msle: 8.9408 - rmsle: 0.1216 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.5971 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1248 - msle: 8.7686 - rmsle: 0.1165 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.9311 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1206 - msle: 8.6112 - rmsle: 0.1130 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.3355 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1169 - msle: 8.4941 - rmsle: 0.1098 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.7778 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1136 - msle: 8.4193 - rmsle: 0.1071 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.6500 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1116 - msle: 8.3179 - rmsle: 0.1055 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.5252 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1077 - msle: 8.1518 - rmsle: 0.1019 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.1947 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1060 - msle: 8.1002 - rmsle: 0.1009 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.2630 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1051 - msle: 8.0913 - rmsle: 0.1003 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.4549 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1042 - msle: 8.0515 - rmsle: 0.0997 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.9990 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1035 - msle: 8.0177 - rmsle: 0.0991 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0313 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1025 - msle: 7.9906 - rmsle: 0.0983 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9997 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1021 - msle: 7.9929 - rmsle: 0.0980 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0977 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1012 - msle: 7.9265 - rmsle: 0.0973 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2198 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.8837 - rmsle: 0.0958 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8816 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.8334 - rmsle: 0.0951 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8399 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.8405 - rmsle: 0.0948 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8598 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.8326 - rmsle: 0.0947 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8711 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0977 - msle: 7.8124 - rmsle: 0.0944 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8425 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.7917 - rmsle: 0.0941 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8705 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0972 - msle: 7.8026 - rmsle: 0.0940 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8576 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.7832 - rmsle: 0.0934 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8528 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0957 - msle: 7.7478 - rmsle: 0.0927 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8853 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.7652 - rmsle: 0.0927 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8521 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.7588 - rmsle: 0.0924 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8838 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.7553 - rmsle: 0.0922 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7980 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 312.11383056640625\n",
            "Fold 1 RMSLE: 0.06226999706880842\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1604 - msle: 97.4094 - rmsle: 2.1128 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7942 - val_msle: 66.5088 - val_rmsle: 0.7645 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6065 - msle: 56.3955 - rmsle: 0.5803 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2269 - val_msle: 12.0958 - val_rmsle: 0.2092 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2336 - msle: 12.8067 - rmsle: 0.2177 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1073 - val_msle: 4.7570 - val_rmsle: 0.0941 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1458 - msle: 9.4477 - rmsle: 0.1334 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0922 - val_msle: 5.5311 - val_rmsle: 0.0816 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1369 - msle: 9.2094 - rmsle: 0.1267 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 4.3780 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1294 - msle: 9.0156 - rmsle: 0.1205 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.3677 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1235 - msle: 8.8352 - rmsle: 0.1155 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 3.9308 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1194 - msle: 8.6848 - rmsle: 0.1119 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.1371 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1153 - msle: 8.5400 - rmsle: 0.1084 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0852 - val_msle: 5.6561 - val_rmsle: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.4604 - rmsle: 0.1061 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.4759 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1083 - msle: 8.2795 - rmsle: 0.1024 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.7562 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1069 - msle: 8.2505 - rmsle: 0.1016 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 3.7361 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1059 - msle: 8.2182 - rmsle: 0.1010 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.7382 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1046 - msle: 8.1598 - rmsle: 0.0999 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.7492 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.1425 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.0411 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1031 - msle: 8.1069 - rmsle: 0.0988 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.7705 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1021 - msle: 8.0585 - rmsle: 0.0979 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7549 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1013 - msle: 8.0316 - rmsle: 0.0972 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.0393 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.9868 - rmsle: 0.0967 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9210 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.9811 - rmsle: 0.0961 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7671 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.9239 - rmsle: 0.0954 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9800 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.9191 - rmsle: 0.0950 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8902 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.8715 - rmsle: 0.0946 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0934 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.8138 - rmsle: 0.0930 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9131 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.8139 - rmsle: 0.0928 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.8849 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.7962 - rmsle: 0.0923 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0342 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.7732 - rmsle: 0.0917 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.6514 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0946 - msle: 7.7749 - rmsle: 0.0916 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.6896 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.7560 - rmsle: 0.0913 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.6781 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0941 - msle: 7.7409 - rmsle: 0.0913 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6859 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0936 - msle: 7.7221 - rmsle: 0.0908 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6738 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.062150165472658864\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1593 - msle: 97.4665 - rmsle: 2.1115 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7790 - val_msle: 65.5477 - val_rmsle: 0.7490 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6385 - msle: 58.5751 - rmsle: 0.6124 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2335 - val_msle: 15.2521 - val_rmsle: 0.2159 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2492 - msle: 13.1176 - rmsle: 0.2334 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 4.9485 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1489 - msle: 9.5126 - rmsle: 0.1367 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0815 - val_msle: 4.3904 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1375 - msle: 9.2023 - rmsle: 0.1272 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.2668 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1309 - msle: 9.0360 - rmsle: 0.1218 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.2676 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1249 - msle: 8.8343 - rmsle: 0.1167 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.1508 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1203 - msle: 8.6778 - rmsle: 0.1126 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.1428 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1162 - msle: 8.5525 - rmsle: 0.1092 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.3434 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1134 - msle: 8.4527 - rmsle: 0.1068 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.1817 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1108 - msle: 8.3646 - rmsle: 0.1047 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.1191 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.2829 - rmsle: 0.1030 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0839 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1068 - msle: 8.2044 - rmsle: 0.1013 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.7316 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1054 - msle: 8.1052 - rmsle: 0.1001 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.1380 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1043 - msle: 8.0823 - rmsle: 0.0992 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.3682 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1020 - msle: 8.0004 - rmsle: 0.0972 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.8885 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.9615 - rmsle: 0.0966 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.5171 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1001 - msle: 7.9408 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.4877 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.9150 - rmsle: 0.0956 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.4990 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.8863 - rmsle: 0.0950 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.0926 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.8841 - rmsle: 0.0946 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.4822 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.8198 - rmsle: 0.0943 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.1304 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.7937 - rmsle: 0.0939 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0319 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.8074 - rmsle: 0.0935 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.3676 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.7821 - rmsle: 0.0933 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9493 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.7602 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9904 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.7562 - rmsle: 0.0925 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2479 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.7157 - rmsle: 0.0921 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0379 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0952 - msle: 7.6857 - rmsle: 0.0919 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1876 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0943 - msle: 7.6577 - rmsle: 0.0911 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1628 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.6159 - rmsle: 0.0907 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.2242 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06335864581683698\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1623 - msle: 97.6128 - rmsle: 2.1145 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7868 - val_msle: 66.1776 - val_rmsle: 0.7573 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6456 - msle: 59.0905 - rmsle: 0.6199 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2344 - val_msle: 16.0249 - val_rmsle: 0.2174 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2440 - msle: 14.1598 - rmsle: 0.2285 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1145 - val_msle: 5.7126 - val_rmsle: 0.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1467 - msle: 9.3910 - rmsle: 0.1345 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 5.8645 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1360 - msle: 9.1089 - rmsle: 0.1258 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0902 - val_msle: 6.1546 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1291 - msle: 8.8815 - rmsle: 0.1203 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 6.1325 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1237 - msle: 8.7839 - rmsle: 0.1157 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0845 - val_msle: 6.8289 - val_rmsle: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1184 - msle: 8.5990 - rmsle: 0.1111 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 6.4483 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1147 - msle: 8.4674 - rmsle: 0.1079 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 5.1026 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1116 - msle: 8.3736 - rmsle: 0.1053 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 6.2937 - val_rmsle: 0.0750 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1095 - msle: 8.2451 - rmsle: 0.1035 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.5626 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1072 - msle: 8.1707 - rmsle: 0.1015 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.9582 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1053 - msle: 8.1006 - rmsle: 0.1000 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.8012 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.0485 - rmsle: 0.0987 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 5.5888 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.9620 - rmsle: 0.0977 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 5.1476 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1012 - msle: 7.9270 - rmsle: 0.0963 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 5.3635 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0991 - msle: 7.7948 - rmsle: 0.0946 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7541 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.7843 - rmsle: 0.0943 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7014 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.7279 - rmsle: 0.0936 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7009 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.7282 - rmsle: 0.0931 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7179 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.6861 - rmsle: 0.0929 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7451 - val_rmsle: 0.0616 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.6845 - rmsle: 0.0927 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.6876 - val_rmsle: 0.0613 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.6506 - rmsle: 0.0920 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7204 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.6015 - rmsle: 0.0919 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7239 - val_rmsle: 0.0615 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.6135 - rmsle: 0.0914 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8201 - val_rmsle: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.5271 - rmsle: 0.0906 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7845 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.5325 - rmsle: 0.0901 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7810 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.4797 - rmsle: 0.0897 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6968 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.5056 - rmsle: 0.0898 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7427 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.4975 - rmsle: 0.0895 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7000 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.4751 - rmsle: 0.0894 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6977 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.061650947006089384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:23:33,945] Trial 23 finished with value: 0.06239891244956206 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00010001356287977584, 'do_rate': 0.4642367345915417, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.2131 - msle: 99.3155 - rmsle: 2.1194 - val_dense_loss: 0.0000e+00 - val_loss: 0.7720 - val_msle: 72.2120 - val_rmsle: 0.7184 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5981 - msle: 74.5655 - rmsle: 0.5493 - val_dense_loss: 0.0000e+00 - val_loss: 0.2486 - val_msle: 48.5413 - val_rmsle: 0.2098 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2811 - msle: 53.3143 - rmsle: 0.2454 - val_dense_loss: 0.0000e+00 - val_loss: 0.2265 - val_msle: 34.6889 - val_rmsle: 0.1986 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2539 - msle: 38.6441 - rmsle: 0.2286 - val_dense_loss: 0.0000e+00 - val_loss: 0.2166 - val_msle: 22.0711 - val_rmsle: 0.1975 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2376 - msle: 23.1644 - rmsle: 0.2201 - val_dense_loss: 0.0000e+00 - val_loss: 0.0952 - val_msle: 5.2049 - val_rmsle: 0.0787 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1432 - msle: 10.1813 - rmsle: 0.1274 - val_dense_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 4.6551 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1330 - msle: 9.8637 - rmsle: 0.1196 - val_dense_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.6046 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1274 - msle: 9.7165 - rmsle: 0.1158 - val_dense_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 4.6772 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1227 - msle: 9.5187 - rmsle: 0.1123 - val_dense_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.9455 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1201 - msle: 9.3306 - rmsle: 0.1107 - val_dense_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.2927 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1177 - msle: 9.2472 - rmsle: 0.1088 - val_dense_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.4640 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1158 - msle: 9.0765 - rmsle: 0.1074 - val_dense_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 3.8782 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1139 - msle: 8.9530 - rmsle: 0.1059 - val_dense_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.5990 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.8558 - rmsle: 0.1050 - val_dense_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.1686 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1105 - msle: 8.7509 - rmsle: 0.1032 - val_dense_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.4236 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1098 - msle: 8.6329 - rmsle: 0.1028 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.4489 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1081 - msle: 8.5397 - rmsle: 0.1014 - val_dense_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.7998 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1071 - msle: 8.4764 - rmsle: 0.1006 - val_dense_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.6244 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1060 - msle: 8.3926 - rmsle: 0.0996 - val_dense_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.1098 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1047 - msle: 8.3887 - rmsle: 0.0985 - val_dense_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.7643 - val_rmsle: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1044 - msle: 8.3506 - rmsle: 0.0983 - val_dense_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.8211 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1032 - msle: 8.2075 - rmsle: 0.0972 - val_dense_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.1964 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1025 - msle: 8.1533 - rmsle: 0.0966 - val_dense_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 3.8704 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1001 - msle: 8.0576 - rmsle: 0.0945 - val_dense_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1326 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0990 - msle: 8.0107 - rmsle: 0.0940 - val_dense_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.7331 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0986 - msle: 8.0187 - rmsle: 0.0938 - val_dense_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.9181 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.9893 - rmsle: 0.0934 - val_dense_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9410 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.9311 - rmsle: 0.0931 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7903 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0974 - msle: 7.9246 - rmsle: 0.0930 - val_dense_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.8096 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.9050 - rmsle: 0.0928 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7454 - val_rmsle: 0.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.8670 - rmsle: 0.0921 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.8354 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 314.2864990234375\n",
            "Fold 0 RMSLE: 0.06261608523324469\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2172 - msle: 99.2478 - rmsle: 2.1232 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7696 - val_msle: 74.8917 - val_rmsle: 0.7144 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5890 - msle: 73.1517 - rmsle: 0.5388 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2700 - val_msle: 51.4124 - val_rmsle: 0.2300 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2820 - msle: 53.1276 - rmsle: 0.2455 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2369 - val_msle: 46.0110 - val_rmsle: 0.2092 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2462 - msle: 39.3073 - rmsle: 0.2207 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0969 - val_msle: 5.1609 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1538 - msle: 10.3148 - rmsle: 0.1325 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 4.5911 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1414 - msle: 10.0843 - rmsle: 0.1242 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.2302 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1324 - msle: 9.8361 - rmsle: 0.1183 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.2447 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1281 - msle: 9.7176 - rmsle: 0.1159 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 3.9670 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1240 - msle: 9.4825 - rmsle: 0.1132 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 3.9464 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1208 - msle: 9.4216 - rmsle: 0.1110 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.1135 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1177 - msle: 9.2233 - rmsle: 0.1086 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 3.9671 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1161 - msle: 9.0799 - rmsle: 0.1076 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.1706 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1141 - msle: 8.9621 - rmsle: 0.1060 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 5.0260 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1120 - msle: 8.8490 - rmsle: 0.1044 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.4476 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1112 - msle: 8.7824 - rmsle: 0.1038 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.2972 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1073 - msle: 8.5392 - rmsle: 0.1004 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 4.7182 - val_rmsle: 0.0727 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1060 - msle: 8.5241 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.4121 - val_rmsle: 0.0710 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1051 - msle: 8.4915 - rmsle: 0.0994 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.5655 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1025 - msle: 8.3165 - rmsle: 0.0970 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.3989 - val_rmsle: 0.0662 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.2689 - rmsle: 0.0964 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.3710 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.2436 - rmsle: 0.0962 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4005 - val_rmsle: 0.0662 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.2390 - rmsle: 0.0964 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.1197 - val_rmsle: 0.0657 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 312.6176452636719\n",
            "Fold 1 RMSLE: 0.06408114325889133\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2232 - msle: 99.1823 - rmsle: 2.1292 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7521 - val_msle: 70.2684 - val_rmsle: 0.6983 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5908 - msle: 73.7708 - rmsle: 0.5418 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2706 - val_msle: 50.1376 - val_rmsle: 0.2317 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2798 - msle: 55.1968 - rmsle: 0.2443 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2407 - val_msle: 45.1873 - val_rmsle: 0.2140 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2526 - msle: 43.2735 - rmsle: 0.2284 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2272 - val_msle: 25.4461 - val_rmsle: 0.2089 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2399 - msle: 24.2315 - rmsle: 0.2231 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2190 - val_msle: 12.4434 - val_rmsle: 0.2059 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2065 - msle: 14.3796 - rmsle: 0.1937 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.4376 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1326 - msle: 9.9136 - rmsle: 0.1198 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0892 - val_msle: 4.7498 - val_rmsle: 0.0777 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1259 - msle: 9.6779 - rmsle: 0.1147 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0930 - val_msle: 4.4593 - val_rmsle: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1222 - msle: 9.5220 - rmsle: 0.1121 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 5.5824 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1171 - msle: 9.2336 - rmsle: 0.1080 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 4.2952 - val_rmsle: 0.0718 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1143 - msle: 9.1161 - rmsle: 0.1063 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 4.5719 - val_rmsle: 0.0755 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1138 - msle: 9.0481 - rmsle: 0.1063 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 4.1713 - val_rmsle: 0.0741 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1102 - msle: 8.8948 - rmsle: 0.1032 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 3.9766 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1092 - msle: 8.8364 - rmsle: 0.1027 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.4017 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1084 - msle: 8.8202 - rmsle: 0.1023 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.0487 - val_rmsle: 0.0692 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1077 - msle: 8.7929 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 3.9544 - val_rmsle: 0.0660 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1069 - msle: 8.7536 - rmsle: 0.1012 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.0937 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.6677 - rmsle: 0.1000 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.6922 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1046 - msle: 8.6159 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7014 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1043 - msle: 8.6184 - rmsle: 0.0992 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7229 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1037 - msle: 8.5945 - rmsle: 0.0987 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7692 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1033 - msle: 8.5780 - rmsle: 0.0985 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.7041 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.5356 - rmsle: 0.0981 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7467 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1026 - msle: 8.5347 - rmsle: 0.0979 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7065 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1025 - msle: 8.5464 - rmsle: 0.0979 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.6950 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1021 - msle: 8.5070 - rmsle: 0.0976 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7364 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.4658 - rmsle: 0.0966 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7202 - val_rmsle: 0.0621 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1006 - msle: 8.4463 - rmsle: 0.0963 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7046 - val_rmsle: 0.0624 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1009 - msle: 8.4399 - rmsle: 0.0967 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.6926 - val_rmsle: 0.0622 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1002 - msle: 8.4146 - rmsle: 0.0960 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.6830 - val_rmsle: 0.0615 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0998 - msle: 8.3908 - rmsle: 0.0956 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.6671 - val_rmsle: 0.0613 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 304.0944519042969\n",
            "Fold 2 RMSLE: 0.06186872858371025\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2178 - msle: 99.2538 - rmsle: 2.1239 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7336 - val_msle: 70.7555 - val_rmsle: 0.6802 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5946 - msle: 74.7648 - rmsle: 0.5465 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2547 - val_msle: 59.2025 - val_rmsle: 0.2183 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2783 - msle: 56.9535 - rmsle: 0.2449 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2254 - val_msle: 44.3596 - val_rmsle: 0.2004 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2525 - msle: 44.4770 - rmsle: 0.2296 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2164 - val_msle: 26.7101 - val_rmsle: 0.1989 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2404 - msle: 27.5296 - rmsle: 0.2244 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2105 - val_msle: 12.1365 - val_rmsle: 0.1979 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2070 - msle: 14.9603 - rmsle: 0.1945 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 4.3138 - val_rmsle: 0.0755 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1339 - msle: 9.9131 - rmsle: 0.1211 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.8797 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1276 - msle: 9.7137 - rmsle: 0.1164 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.9887 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1235 - msle: 9.5087 - rmsle: 0.1134 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 4.9465 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1206 - msle: 9.3661 - rmsle: 0.1112 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.3453 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1182 - msle: 9.1966 - rmsle: 0.1095 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 4.4197 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1158 - msle: 9.1299 - rmsle: 0.1076 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.0450 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1141 - msle: 8.9738 - rmsle: 0.1064 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 4.5515 - val_rmsle: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1127 - msle: 8.8577 - rmsle: 0.1052 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.8326 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1109 - msle: 8.7844 - rmsle: 0.1037 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.8485 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1093 - msle: 8.6434 - rmsle: 0.1023 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.2562 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1090 - msle: 8.6588 - rmsle: 0.1022 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.9573 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1072 - msle: 8.5410 - rmsle: 0.1006 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.2189 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1063 - msle: 8.4710 - rmsle: 0.0998 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.7892 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1053 - msle: 8.3866 - rmsle: 0.0989 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 3.8947 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1050 - msle: 8.3534 - rmsle: 0.0986 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 3.9175 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1040 - msle: 8.2490 - rmsle: 0.0977 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 3.9480 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1011 - msle: 8.0736 - rmsle: 0.0951 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 5.5359 - val_rmsle: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1000 - msle: 8.0530 - rmsle: 0.0949 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6577 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.0600 - rmsle: 0.0946 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.0269 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0988 - msle: 8.0185 - rmsle: 0.0941 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9087 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0987 - msle: 8.0003 - rmsle: 0.0941 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.5391 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.9582 - rmsle: 0.0934 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2632 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.9495 - rmsle: 0.0934 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.0923 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0974 - msle: 7.9163 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1057 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.8867 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1825 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 300.466552734375\n",
            "Fold 3 RMSLE: 0.06351689658720062\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2209 - msle: 99.4242 - rmsle: 2.1270 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8051 - val_msle: 74.3710 - val_rmsle: 0.7521 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6081 - msle: 75.7450 - rmsle: 0.5599 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2731 - val_msle: 51.1493 - val_rmsle: 0.2353 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2817 - msle: 56.8907 - rmsle: 0.2467 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2467 - val_msle: 46.8326 - val_rmsle: 0.2201 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2552 - msle: 44.9906 - rmsle: 0.2305 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2285 - val_msle: 25.9472 - val_rmsle: 0.2102 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2412 - msle: 28.6793 - rmsle: 0.2243 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2169 - val_msle: 13.0334 - val_rmsle: 0.2036 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2336 - msle: 16.9298 - rmsle: 0.2212 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1839 - val_msle: 20.8133 - val_rmsle: 0.1711 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1387 - msle: 10.0652 - rmsle: 0.1259 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1058 - val_msle: 5.5962 - val_rmsle: 0.0940 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1272 - msle: 9.6806 - rmsle: 0.1160 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0985 - val_msle: 5.9931 - val_rmsle: 0.0882 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1232 - msle: 9.4882 - rmsle: 0.1132 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 5.0529 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1194 - msle: 9.2986 - rmsle: 0.1102 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0952 - val_msle: 6.1827 - val_rmsle: 0.0865 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1164 - msle: 9.1523 - rmsle: 0.1079 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0864 - val_msle: 5.3954 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1150 - msle: 9.0849 - rmsle: 0.1069 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 5.6131 - val_rmsle: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1125 - msle: 8.8693 - rmsle: 0.1049 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 5.3595 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1109 - msle: 8.8131 - rmsle: 0.1038 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0851 - val_msle: 5.8419 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.7194 - rmsle: 0.1030 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.9419 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1083 - msle: 8.6307 - rmsle: 0.1017 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0860 - val_msle: 6.3514 - val_rmsle: 0.0794 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1074 - msle: 8.5546 - rmsle: 0.1008 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0887 - val_msle: 6.6606 - val_rmsle: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.4512 - rmsle: 0.0999 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0895 - val_msle: 7.0378 - val_rmsle: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.2411 - rmsle: 0.0969 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.8051 - val_rmsle: 0.0716 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 8.1758 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.8231 - val_rmsle: 0.0706 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.1550 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.5570 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1000 - msle: 8.1021 - rmsle: 0.0952 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.5369 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.0733 - rmsle: 0.0947 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.7812 - val_rmsle: 0.0668 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0989 - msle: 8.0378 - rmsle: 0.0942 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.4224 - val_rmsle: 0.0683 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0989 - msle: 8.0113 - rmsle: 0.0943 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.3748 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0984 - msle: 8.0196 - rmsle: 0.0939 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.5781 - val_rmsle: 0.0697 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.9009 - rmsle: 0.0926 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9709 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.8385 - rmsle: 0.0921 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.2358 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.8281 - rmsle: 0.0916 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9546 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0954 - msle: 7.8063 - rmsle: 0.0915 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8802 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0952 - msle: 7.7946 - rmsle: 0.0914 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7441 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06243849649191374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:30:47,027] Trial 24 finished with value: 0.06290427003099212 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00010106883106377464, 'do_rate': 0.4622905929814005, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 1.9020 - msle: 93.0021 - rmsle: 1.7698 - val_dense_loss: 0.0000e+00 - val_loss: 0.6012 - val_msle: 49.8447 - val_rmsle: 0.5579 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3805 - msle: 31.9375 - rmsle: 0.3446 - val_dense_loss: 0.0000e+00 - val_loss: 0.2022 - val_msle: 14.7160 - val_rmsle: 0.1778 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1696 - msle: 9.1854 - rmsle: 0.1458 - val_dense_loss: 0.0000e+00 - val_loss: 0.0975 - val_msle: 4.4909 - val_rmsle: 0.0770 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1484 - msle: 8.7315 - rmsle: 0.1289 - val_dense_loss: 0.0000e+00 - val_loss: 0.0923 - val_msle: 4.2211 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1387 - msle: 8.5201 - rmsle: 0.1218 - val_dense_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 4.2551 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1340 - msle: 8.2999 - rmsle: 0.1188 - val_dense_loss: 0.0000e+00 - val_loss: 0.0909 - val_msle: 4.0574 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1295 - msle: 8.1858 - rmsle: 0.1154 - val_dense_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 4.0867 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1247 - msle: 8.0167 - rmsle: 0.1116 - val_dense_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 4.3782 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1211 - msle: 7.8758 - rmsle: 0.1089 - val_dense_loss: 0.0000e+00 - val_loss: 0.0849 - val_msle: 4.4628 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1179 - msle: 7.7276 - rmsle: 0.1063 - val_dense_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.1476 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1139 - msle: 7.6036 - rmsle: 0.1032 - val_dense_loss: 0.0000e+00 - val_loss: 0.0851 - val_msle: 4.7990 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1123 - msle: 7.5378 - rmsle: 0.1021 - val_dense_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 3.9640 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1090 - msle: 7.4040 - rmsle: 0.0995 - val_dense_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.2759 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1076 - msle: 7.3730 - rmsle: 0.0986 - val_dense_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 4.7598 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1060 - msle: 7.3283 - rmsle: 0.0971 - val_dense_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.0744 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1047 - msle: 7.2819 - rmsle: 0.0963 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.2232 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1034 - msle: 7.2369 - rmsle: 0.0952 - val_dense_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.2337 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1020 - msle: 7.1581 - rmsle: 0.0941 - val_dense_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 3.8924 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.0934 - rmsle: 0.0919 - val_dense_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 3.7858 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.0706 - rmsle: 0.0914 - val_dense_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.9945 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.0568 - rmsle: 0.0909 - val_dense_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.1009 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.0562 - rmsle: 0.0910 - val_dense_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.3908 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0944 - msle: 6.9648 - rmsle: 0.0890 - val_dense_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.8878 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0941 - msle: 6.9505 - rmsle: 0.0893 - val_dense_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9308 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0937 - msle: 6.9471 - rmsle: 0.0891 - val_dense_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8741 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0931 - msle: 6.9527 - rmsle: 0.0887 - val_dense_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0210 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0931 - msle: 6.9589 - rmsle: 0.0888 - val_dense_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1663 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0931 - msle: 6.9544 - rmsle: 0.0889 - val_dense_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9594 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0914 - msle: 6.8703 - rmsle: 0.0872 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7912 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0907 - msle: 6.8682 - rmsle: 0.0868 - val_dense_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7623 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0905 - msle: 6.8612 - rmsle: 0.0868 - val_dense_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7520 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06280091024699531\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_1_loss: 0.0000e+00 - loss: 1.8970 - msle: 92.8333 - rmsle: 1.7642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.5062 - val_msle: 47.7801 - val_rmsle: 0.4607 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3485 - msle: 28.2052 - rmsle: 0.3120 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1369 - val_msle: 9.5199 - val_rmsle: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1656 - msle: 9.0109 - rmsle: 0.1418 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0949 - val_msle: 6.1402 - val_rmsle: 0.0746 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1464 - msle: 8.6918 - rmsle: 0.1273 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0885 - val_msle: 4.9494 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1387 - msle: 8.5193 - rmsle: 0.1223 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 5.7281 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1330 - msle: 8.3056 - rmsle: 0.1182 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0938 - val_msle: 5.5498 - val_rmsle: 0.0793 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1280 - msle: 8.0862 - rmsle: 0.1140 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0861 - val_msle: 4.9151 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1236 - msle: 7.9407 - rmsle: 0.1108 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0845 - val_msle: 5.1694 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1197 - msle: 7.8169 - rmsle: 0.1078 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.7241 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1171 - msle: 7.6841 - rmsle: 0.1059 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.4121 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1132 - msle: 7.5452 - rmsle: 0.1028 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 5.2256 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1112 - msle: 7.4940 - rmsle: 0.1013 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 5.0033 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1086 - msle: 7.4099 - rmsle: 0.0993 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.1470 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1067 - msle: 7.3292 - rmsle: 0.0979 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 3.9654 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1051 - msle: 7.2690 - rmsle: 0.0966 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 3.9858 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1041 - msle: 7.2527 - rmsle: 0.0959 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.0717 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1028 - msle: 7.1936 - rmsle: 0.0949 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.3152 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.0450 - rmsle: 0.0923 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 5.2727 - val_rmsle: 0.0723 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.0985 - rmsle: 0.0922 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 5.1552 - val_rmsle: 0.0724 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.0567 - rmsle: 0.0914 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.7986 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0952 - msle: 6.9315 - rmsle: 0.0896 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.7284 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0940 - msle: 6.9301 - rmsle: 0.0892 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.3811 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0938 - msle: 6.9335 - rmsle: 0.0892 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.2318 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0931 - msle: 6.9130 - rmsle: 0.0887 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.3712 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0928 - msle: 6.9309 - rmsle: 0.0885 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.1863 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0925 - msle: 6.9248 - rmsle: 0.0883 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1016 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0924 - msle: 6.9100 - rmsle: 0.0883 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0171 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0920 - msle: 6.8840 - rmsle: 0.0879 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.3337 - val_rmsle: 0.0652 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0919 - msle: 6.9068 - rmsle: 0.0879 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1204 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0920 - msle: 6.8851 - rmsle: 0.0880 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.9197 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0915 - msle: 6.8738 - rmsle: 0.0876 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9920 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 311.9311218261719\n",
            "Fold 1 RMSLE: 0.06311187728500939\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 1.9002 - msle: 92.8908 - rmsle: 1.7687 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.4790 - val_msle: 45.3665 - val_rmsle: 0.4354 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3568 - msle: 29.4086 - rmsle: 0.3208 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1624 - val_msle: 7.8815 - val_rmsle: 0.1378 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1650 - msle: 9.1344 - rmsle: 0.1416 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1008 - val_msle: 6.7797 - val_rmsle: 0.0813 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1456 - msle: 8.6744 - rmsle: 0.1269 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 4.6042 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1371 - msle: 8.3928 - rmsle: 0.1206 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.7248 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1299 - msle: 8.2231 - rmsle: 0.1153 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 4.6678 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1263 - msle: 8.0826 - rmsle: 0.1128 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0984 - val_msle: 6.9279 - val_rmsle: 0.0855 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1211 - msle: 7.8793 - rmsle: 0.1086 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0855 - val_msle: 5.7104 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1178 - msle: 7.7653 - rmsle: 0.1062 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 5.9917 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.4887 - rmsle: 0.1004 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 5.1448 - val_rmsle: 0.0718 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1081 - msle: 7.4428 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 4.9571 - val_rmsle: 0.0744 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1075 - msle: 7.4493 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 5.0859 - val_rmsle: 0.0731 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1035 - msle: 7.3001 - rmsle: 0.0960 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 3.9644 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1028 - msle: 7.3124 - rmsle: 0.0961 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.0409 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1017 - msle: 7.2533 - rmsle: 0.0954 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 5.0656 - val_rmsle: 0.0716 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1008 - msle: 7.2541 - rmsle: 0.0948 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 3.9439 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 299.0465087890625\n",
            "Fold 2 RMSLE: 0.06624676504855931\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_3_loss: 0.0000e+00 - loss: 1.9008 - msle: 92.9274 - rmsle: 1.7687 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.4873 - val_msle: 45.6923 - val_rmsle: 0.4427 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3528 - msle: 28.6645 - rmsle: 0.3157 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1205 - val_msle: 8.0061 - val_rmsle: 0.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1689 - msle: 9.1055 - rmsle: 0.1439 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1033 - val_msle: 5.0140 - val_rmsle: 0.0828 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1481 - msle: 8.7635 - rmsle: 0.1286 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1013 - val_msle: 5.5477 - val_rmsle: 0.0837 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1403 - msle: 8.5537 - rmsle: 0.1234 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 4.9045 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1338 - msle: 8.3681 - rmsle: 0.1187 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 4.4748 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1273 - msle: 8.1539 - rmsle: 0.1136 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 4.5477 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1242 - msle: 7.9964 - rmsle: 0.1112 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 4.2691 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1194 - msle: 7.8248 - rmsle: 0.1074 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.2464 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1162 - msle: 7.6865 - rmsle: 0.1052 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.3975 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1127 - msle: 7.5781 - rmsle: 0.1024 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.0811 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.5029 - rmsle: 0.1008 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.1704 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1080 - msle: 7.4371 - rmsle: 0.0989 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.0064 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1069 - msle: 7.4154 - rmsle: 0.0980 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.0638 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1063 - msle: 7.3402 - rmsle: 0.0976 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 3.9499 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1048 - msle: 7.3017 - rmsle: 0.0964 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.0701 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1033 - msle: 7.2199 - rmsle: 0.0951 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 3.8732 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1025 - msle: 7.1856 - rmsle: 0.0944 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 3.9694 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1014 - msle: 7.1535 - rmsle: 0.0935 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 3.8372 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.1178 - rmsle: 0.0930 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 3.9038 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1001 - msle: 7.0819 - rmsle: 0.0923 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 3.9949 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0997 - msle: 7.0618 - rmsle: 0.0921 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 3.9334 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.0056 - rmsle: 0.0910 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.2107 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 6.9870 - rmsle: 0.0908 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.0920 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 6.9613 - rmsle: 0.0908 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 3.8283 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0972 - msle: 6.9579 - rmsle: 0.0900 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 3.8401 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0969 - msle: 6.9329 - rmsle: 0.0898 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 3.8371 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0966 - msle: 6.9136 - rmsle: 0.0895 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.1135 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0960 - msle: 6.8677 - rmsle: 0.0890 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.0775 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 6.7934 - rmsle: 0.0874 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.4085 - val_rmsle: 0.0688 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0922 - msle: 6.7581 - rmsle: 0.0869 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 5.3902 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06447395062883214\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_4_loss: 0.0000e+00 - loss: 1.8979 - msle: 93.1543 - rmsle: 1.7660 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.5873 - val_msle: 49.3870 - val_rmsle: 0.5449 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3575 - msle: 32.9184 - rmsle: 0.3202 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1208 - val_msle: 5.3027 - val_rmsle: 0.0932 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1613 - msle: 8.7330 - rmsle: 0.1361 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1144 - val_msle: 7.8978 - val_rmsle: 0.0936 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1476 - msle: 8.5800 - rmsle: 0.1277 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1000 - val_msle: 5.6203 - val_rmsle: 0.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1366 - msle: 8.3085 - rmsle: 0.1200 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.0737 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1320 - msle: 8.2079 - rmsle: 0.1169 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 4.2553 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1261 - msle: 7.9747 - rmsle: 0.1121 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 5.1220 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1222 - msle: 7.8613 - rmsle: 0.1093 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 5.2349 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1144 - msle: 7.5016 - rmsle: 0.1030 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 7.0832 - val_rmsle: 0.0770 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1114 - msle: 7.4933 - rmsle: 0.1019 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 6.2471 - val_rmsle: 0.0794 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1104 - msle: 7.4930 - rmsle: 0.1016 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0911 - val_msle: 7.6554 - val_rmsle: 0.0826 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1059 - msle: 7.3087 - rmsle: 0.0978 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.8318 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1040 - msle: 7.2545 - rmsle: 0.0968 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.4065 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1028 - msle: 7.2470 - rmsle: 0.0961 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.1522 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1022 - msle: 7.2214 - rmsle: 0.0958 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.3116 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.2090 - rmsle: 0.0951 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.1963 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1012 - msle: 7.2261 - rmsle: 0.0953 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0674 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.1155 - rmsle: 0.0935 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.7272 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.1127 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8009 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.1107 - rmsle: 0.0934 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7627 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.0868 - rmsle: 0.0932 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7358 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0978 - msle: 7.0946 - rmsle: 0.0928 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.7525 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.0751 - rmsle: 0.0926 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7271 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.0779 - rmsle: 0.0925 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7228 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.0456 - rmsle: 0.0920 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7375 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.0639 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7287 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.0383 - rmsle: 0.0919 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7808 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.0764 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7150 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.0468 - rmsle: 0.0917 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7144 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0959 - msle: 7.0184 - rmsle: 0.0915 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7404 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0954 - msle: 7.0287 - rmsle: 0.0911 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7279 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.0617980960566914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:37:19,943] Trial 25 finished with value: 0.06368631985321752 and parameters: {'units': 1024, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0001745018608654567, 'do_rate': 0.49815599080886164, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 9ms/step - dense_loss: 0.0000e+00 - loss: 2.4428 - msle: 98.3678 - rmsle: 2.4251 - val_dense_loss: 0.0000e+00 - val_loss: 0.7433 - val_msle: 64.9325 - val_rmsle: 0.7289 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5220 - msle: 50.9920 - rmsle: 0.5075 - val_dense_loss: 0.0000e+00 - val_loss: 0.1412 - val_msle: 10.9291 - val_rmsle: 0.1275 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1744 - msle: 10.3754 - rmsle: 0.1613 - val_dense_loss: 0.0000e+00 - val_loss: 0.1047 - val_msle: 6.8779 - val_rmsle: 0.0931 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1553 - msle: 8.9253 - rmsle: 0.1442 - val_dense_loss: 0.0000e+00 - val_loss: 0.0948 - val_msle: 6.2998 - val_rmsle: 0.0845 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1451 - msle: 8.7689 - rmsle: 0.1351 - val_dense_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 5.6341 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1364 - msle: 8.5915 - rmsle: 0.1273 - val_dense_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 5.4010 - val_rmsle: 0.0788 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1295 - msle: 8.4887 - rmsle: 0.1211 - val_dense_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 5.0764 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1234 - msle: 8.3366 - rmsle: 0.1156 - val_dense_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.0540 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1176 - msle: 8.1885 - rmsle: 0.1103 - val_dense_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 5.0664 - val_rmsle: 0.0684 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1146 - msle: 8.1435 - rmsle: 0.1076 - val_dense_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 5.1479 - val_rmsle: 0.0720 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.0759 - rmsle: 0.1058 - val_dense_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 5.1740 - val_rmsle: 0.0727 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1104 - msle: 7.9997 - rmsle: 0.1039 - val_dense_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.9277 - val_rmsle: 0.0683 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1086 - msle: 7.9170 - rmsle: 0.1024 - val_dense_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.9475 - val_rmsle: 0.0715 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1071 - msle: 7.8833 - rmsle: 0.1012 - val_dense_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.8338 - val_rmsle: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1051 - msle: 7.8287 - rmsle: 0.0994 - val_dense_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.7439 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1036 - msle: 7.7569 - rmsle: 0.0981 - val_dense_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.7556 - val_rmsle: 0.0669 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.7324 - rmsle: 0.0972 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.8049 - val_rmsle: 0.0682 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1018 - msle: 7.6967 - rmsle: 0.0967 - val_dense_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.7608 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1015 - msle: 7.6547 - rmsle: 0.0965 - val_dense_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.7241 - val_rmsle: 0.0685 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.6396 - rmsle: 0.0958 - val_dense_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.6844 - val_rmsle: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1002 - msle: 7.6126 - rmsle: 0.0954 - val_dense_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.7233 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.5736 - rmsle: 0.0950 - val_dense_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.6380 - val_rmsle: 0.0674 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.5748 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.6502 - val_rmsle: 0.0669 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.5340 - rmsle: 0.0940 - val_dense_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.6542 - val_rmsle: 0.0655 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0981 - msle: 7.5204 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.6258 - val_rmsle: 0.0655 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.5228 - rmsle: 0.0936 - val_dense_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.6403 - val_rmsle: 0.0655 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.4869 - rmsle: 0.0934 - val_dense_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.6195 - val_rmsle: 0.0652 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0972 - msle: 7.5003 - rmsle: 0.0931 - val_dense_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.5969 - val_rmsle: 0.0655 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.4864 - rmsle: 0.0929 - val_dense_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.5916 - val_rmsle: 0.0651 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.4930 - rmsle: 0.0930 - val_dense_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.5878 - val_rmsle: 0.0652 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.4722 - rmsle: 0.0926 - val_dense_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.5780 - val_rmsle: 0.0654 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0189536809921265\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06584818868105594\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_1_loss: 0.0000e+00 - loss: 2.4396 - msle: 98.3365 - rmsle: 2.4218 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7469 - val_msle: 65.0935 - val_rmsle: 0.7323 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5232 - msle: 51.0120 - rmsle: 0.5086 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1172 - val_msle: 12.2036 - val_rmsle: 0.1035 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1766 - msle: 10.4782 - rmsle: 0.1635 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0904 - val_msle: 7.1345 - val_rmsle: 0.0788 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1563 - msle: 8.9468 - rmsle: 0.1452 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 6.7484 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1458 - msle: 8.7999 - rmsle: 0.1358 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 6.3185 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1367 - msle: 8.6285 - rmsle: 0.1276 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 6.0682 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1295 - msle: 8.5021 - rmsle: 0.1212 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 5.8736 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1233 - msle: 8.3802 - rmsle: 0.1154 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 5.3420 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1181 - msle: 8.2250 - rmsle: 0.1107 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 5.2450 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1136 - msle: 8.1151 - rmsle: 0.1067 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 5.1620 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1097 - msle: 7.9768 - rmsle: 0.1032 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.8542 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1067 - msle: 7.8817 - rmsle: 0.1005 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.8467 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1044 - msle: 7.7691 - rmsle: 0.0987 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 4.7783 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1023 - msle: 7.7138 - rmsle: 0.0969 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.7177 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1006 - msle: 7.6041 - rmsle: 0.0955 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.6887 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.5369 - rmsle: 0.0948 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.6475 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.4715 - rmsle: 0.0935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.6074 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.3759 - rmsle: 0.0924 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.6045 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.3210 - rmsle: 0.0916 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.5545 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0943 - msle: 7.2516 - rmsle: 0.0905 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.5292 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.1475 - rmsle: 0.0888 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6123 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.1109 - rmsle: 0.0884 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.6116 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0916 - msle: 7.0782 - rmsle: 0.0882 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.4871 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.0501 - rmsle: 0.0879 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.5291 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0906 - msle: 7.0227 - rmsle: 0.0875 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.5276 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0897 - msle: 6.9719 - rmsle: 0.0867 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.5576 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0896 - msle: 6.9459 - rmsle: 0.0866 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.5414 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0893 - msle: 6.9395 - rmsle: 0.0864 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.5537 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0891 - msle: 6.9154 - rmsle: 0.0863 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.5376 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0888 - msle: 6.8971 - rmsle: 0.0860 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.5439 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0887 - msle: 6.9020 - rmsle: 0.0859 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.5960 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 303.87396240234375\n",
            "Fold 1 RMSLE: 0.06450082106251104\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_2_loss: 0.0000e+00 - loss: 2.4436 - msle: 98.2931 - rmsle: 2.4258 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7485 - val_msle: 65.0833 - val_rmsle: 0.7342 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5235 - msle: 51.0033 - rmsle: 0.5090 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1226 - val_msle: 11.0661 - val_rmsle: 0.1089 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1716 - msle: 10.3745 - rmsle: 0.1586 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1076 - val_msle: 6.5282 - val_rmsle: 0.0961 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1538 - msle: 8.9271 - rmsle: 0.1427 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1030 - val_msle: 6.0667 - val_rmsle: 0.0928 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1443 - msle: 8.7729 - rmsle: 0.1345 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 5.3705 - val_rmsle: 0.0835 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1358 - msle: 8.6614 - rmsle: 0.1269 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 5.2374 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1281 - msle: 8.4894 - rmsle: 0.1198 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0885 - val_msle: 5.1107 - val_rmsle: 0.0805 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1232 - msle: 8.3547 - rmsle: 0.1154 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.9265 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1172 - msle: 8.2209 - rmsle: 0.1100 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 4.8450 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.0821 - rmsle: 0.1057 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.7820 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1089 - msle: 8.0063 - rmsle: 0.1025 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.8197 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1056 - msle: 7.8446 - rmsle: 0.0996 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 4.6467 - val_rmsle: 0.0719 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1040 - msle: 7.7871 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.6508 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1027 - msle: 7.7143 - rmsle: 0.0972 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.6632 - val_rmsle: 0.0708 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1015 - msle: 7.6582 - rmsle: 0.0962 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.5829 - val_rmsle: 0.0702 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.6431 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.5311 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.5591 - rmsle: 0.0944 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.4662 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.5298 - rmsle: 0.0941 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.4919 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.4403 - rmsle: 0.0932 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.4898 - val_rmsle: 0.0668 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.4483 - rmsle: 0.0929 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.4302 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.4165 - rmsle: 0.0921 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.3747 - val_rmsle: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.3520 - rmsle: 0.0916 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.3652 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.3055 - rmsle: 0.0910 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.3140 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.2642 - rmsle: 0.0903 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2830 - val_rmsle: 0.0694 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.2474 - rmsle: 0.0902 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2765 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.2059 - rmsle: 0.0900 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.2555 - val_rmsle: 0.0668 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.1575 - rmsle: 0.0894 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2701 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.1493 - rmsle: 0.0891 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.2169 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.1135 - rmsle: 0.0887 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2187 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.0704 - rmsle: 0.0882 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1759 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0902 - msle: 7.0023 - rmsle: 0.0872 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2035 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.203683853149414\n",
            "Pred Max: 310.5642395019531\n",
            "Fold 2 RMSLE: 0.06500453317076436\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_3_loss: 0.0000e+00 - loss: 2.4411 - msle: 98.3533 - rmsle: 2.4233 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7447 - val_msle: 64.8409 - val_rmsle: 0.7303 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5239 - msle: 51.0248 - rmsle: 0.5095 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1251 - val_msle: 11.8012 - val_rmsle: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1752 - msle: 10.5494 - rmsle: 0.1622 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1001 - val_msle: 7.0785 - val_rmsle: 0.0886 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1568 - msle: 9.0107 - rmsle: 0.1457 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0920 - val_msle: 6.4186 - val_rmsle: 0.0819 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1467 - msle: 8.8690 - rmsle: 0.1368 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0895 - val_msle: 6.2208 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1379 - msle: 8.6987 - rmsle: 0.1288 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 5.9914 - val_rmsle: 0.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1302 - msle: 8.5356 - rmsle: 0.1218 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0824 - val_msle: 5.5514 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1240 - msle: 8.4199 - rmsle: 0.1161 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0840 - val_msle: 5.3935 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1186 - msle: 8.2698 - rmsle: 0.1112 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0879 - val_msle: 5.6971 - val_rmsle: 0.0807 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1145 - msle: 8.1613 - rmsle: 0.1075 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 5.6926 - val_rmsle: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1102 - msle: 8.0403 - rmsle: 0.1036 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 5.5004 - val_rmsle: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1082 - msle: 7.9868 - rmsle: 0.1019 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 5.3542 - val_rmsle: 0.0696 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1068 - msle: 7.9241 - rmsle: 0.1008 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 5.1537 - val_rmsle: 0.0684 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1049 - msle: 7.8396 - rmsle: 0.0992 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 5.2853 - val_rmsle: 0.0696 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1040 - msle: 7.8204 - rmsle: 0.0985 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.9898 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1029 - msle: 7.7702 - rmsle: 0.0976 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 5.0260 - val_rmsle: 0.0688 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1016 - msle: 7.7123 - rmsle: 0.0965 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 5.0698 - val_rmsle: 0.0699 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1010 - msle: 7.6809 - rmsle: 0.0962 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.9946 - val_rmsle: 0.0698 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0991 - msle: 7.5894 - rmsle: 0.0945 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.9255 - val_rmsle: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.5752 - rmsle: 0.0939 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.9180 - val_rmsle: 0.0669 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.5641 - rmsle: 0.0938 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.8692 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.5434 - rmsle: 0.0934 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.8548 - val_rmsle: 0.0662 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.5041 - rmsle: 0.0933 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.8045 - val_rmsle: 0.0658 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.4981 - rmsle: 0.0931 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.8137 - val_rmsle: 0.0661 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.4732 - rmsle: 0.0926 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.7468 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.4576 - rmsle: 0.0923 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.7516 - val_rmsle: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.4003 - rmsle: 0.0918 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.7627 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0959 - msle: 7.4409 - rmsle: 0.0922 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.7779 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.4166 - rmsle: 0.0911 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.6388 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.3768 - rmsle: 0.0913 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.6785 - val_rmsle: 0.0652 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0945 - msle: 7.3580 - rmsle: 0.0911 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.6636 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 310.1545104980469\n",
            "Fold 3 RMSLE: 0.0660042345430429\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_4_loss: 0.0000e+00 - loss: 2.4437 - msle: 98.4782 - rmsle: 2.4260 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7441 - val_msle: 64.6391 - val_rmsle: 0.7298 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5224 - msle: 51.0170 - rmsle: 0.5078 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1155 - val_msle: 11.4192 - val_rmsle: 0.1017 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1753 - msle: 10.4332 - rmsle: 0.1621 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0974 - val_msle: 6.3350 - val_rmsle: 0.0857 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1561 - msle: 8.9126 - rmsle: 0.1449 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0981 - val_msle: 5.9935 - val_rmsle: 0.0877 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1461 - msle: 8.7533 - rmsle: 0.1360 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0885 - val_msle: 5.3893 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1377 - msle: 8.6043 - rmsle: 0.1285 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0901 - val_msle: 5.2062 - val_rmsle: 0.0812 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1306 - msle: 8.4304 - rmsle: 0.1220 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 5.0615 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1237 - msle: 8.3230 - rmsle: 0.1156 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 5.3121 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1193 - msle: 8.2206 - rmsle: 0.1117 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 5.2453 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1141 - msle: 8.0980 - rmsle: 0.1070 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 5.1499 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1107 - msle: 8.0198 - rmsle: 0.1040 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 5.1720 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1073 - msle: 7.8671 - rmsle: 0.1010 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.0323 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1047 - msle: 7.7924 - rmsle: 0.0988 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 5.2347 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1027 - msle: 7.6849 - rmsle: 0.0972 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 5.3851 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.5931 - rmsle: 0.0956 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 5.3155 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.5381 - rmsle: 0.0946 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 5.2057 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.4676 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.3241 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.4007 - rmsle: 0.0925 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 5.2094 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0947 - msle: 7.2569 - rmsle: 0.0905 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.6034 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.2174 - rmsle: 0.0899 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.6112 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0931 - msle: 7.1957 - rmsle: 0.0894 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.5271 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.1384 - rmsle: 0.0891 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.5046 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.1085 - rmsle: 0.0888 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.5269 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.0908 - rmsle: 0.0884 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.5944 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.0650 - rmsle: 0.0881 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.5231 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0907 - msle: 7.0252 - rmsle: 0.0875 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3953 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0904 - msle: 6.9734 - rmsle: 0.0873 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.3902 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0900 - msle: 6.9581 - rmsle: 0.0870 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.4103 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0895 - msle: 6.9356 - rmsle: 0.0866 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.4471 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0891 - msle: 6.9056 - rmsle: 0.0862 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.3995 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0889 - msle: 6.8680 - rmsle: 0.0861 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.4287 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06418700309904228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:43:38,954] Trial 26 finished with value: 0.0651089561112833 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0007571978267496025, 'do_rate': 0.42779646924463055, 'hidden_layers': 1}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.2746 - msle: 97.1335 - rmsle: 1.9677 - val_dense_loss: 0.0000e+00 - val_loss: 0.7969 - val_msle: 68.6374 - val_rmsle: 0.6703 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.7021 - msle: 73.9315 - rmsle: 0.5874 - val_dense_loss: 0.0000e+00 - val_loss: 0.3409 - val_msle: 10.8991 - val_rmsle: 0.2538 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3691 - msle: 15.4758 - rmsle: 0.2917 - val_dense_loss: 0.0000e+00 - val_loss: 0.1712 - val_msle: 6.7242 - val_rmsle: 0.1187 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3064 - msle: 11.1995 - rmsle: 0.2595 - val_dense_loss: 0.0000e+00 - val_loss: 0.1680 - val_msle: 6.6097 - val_rmsle: 0.1336 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2760 - msle: 10.8359 - rmsle: 0.2441 - val_dense_loss: 0.0000e+00 - val_loss: 0.1622 - val_msle: 7.6338 - val_rmsle: 0.1363 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2570 - msle: 10.4810 - rmsle: 0.2320 - val_dense_loss: 0.0000e+00 - val_loss: 0.1186 - val_msle: 5.2426 - val_rmsle: 0.0955 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2421 - msle: 10.4615 - rmsle: 0.2196 - val_dense_loss: 0.0000e+00 - val_loss: 0.1129 - val_msle: 6.2062 - val_rmsle: 0.0904 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2245 - msle: 10.5329 - rmsle: 0.2019 - val_dense_loss: 0.0000e+00 - val_loss: 0.1098 - val_msle: 6.4005 - val_rmsle: 0.0873 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2094 - msle: 10.0691 - rmsle: 0.1875 - val_dense_loss: 0.0000e+00 - val_loss: 0.1382 - val_msle: 5.3562 - val_rmsle: 0.1172 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1992 - msle: 9.7964 - rmsle: 0.1788 - val_dense_loss: 0.0000e+00 - val_loss: 0.1562 - val_msle: 6.0820 - val_rmsle: 0.1368 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1920 - msle: 9.6003 - rmsle: 0.1728 - val_dense_loss: 0.0000e+00 - val_loss: 0.0943 - val_msle: 5.0561 - val_rmsle: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1830 - msle: 9.3432 - rmsle: 0.1651 - val_dense_loss: 0.0000e+00 - val_loss: 0.1063 - val_msle: 4.8666 - val_rmsle: 0.0890 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1802 - msle: 9.2840 - rmsle: 0.1632 - val_dense_loss: 0.0000e+00 - val_loss: 0.1445 - val_msle: 7.2502 - val_rmsle: 0.1289 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1723 - msle: 9.1390 - rmsle: 0.1569 - val_dense_loss: 0.0000e+00 - val_loss: 0.0939 - val_msle: 5.4257 - val_rmsle: 0.0793 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1684 - msle: 9.0233 - rmsle: 0.1540 - val_dense_loss: 0.0000e+00 - val_loss: 0.1059 - val_msle: 6.2662 - val_rmsle: 0.0923 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1638 - msle: 8.9026 - rmsle: 0.1503 - val_dense_loss: 0.0000e+00 - val_loss: 0.0920 - val_msle: 5.3440 - val_rmsle: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1597 - msle: 8.9058 - rmsle: 0.1466 - val_dense_loss: 0.0000e+00 - val_loss: 0.1119 - val_msle: 6.3108 - val_rmsle: 0.0992 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1580 - msle: 8.8409 - rmsle: 0.1455 - val_dense_loss: 0.0000e+00 - val_loss: 0.1082 - val_msle: 5.4803 - val_rmsle: 0.0962 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1559 - msle: 8.7902 - rmsle: 0.1438 - val_dense_loss: 0.0000e+00 - val_loss: 0.1003 - val_msle: 6.6605 - val_rmsle: 0.0883 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1499 - msle: 8.6164 - rmsle: 0.1389 - val_dense_loss: 0.0000e+00 - val_loss: 0.1065 - val_msle: 6.8398 - val_rmsle: 0.0971 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1473 - msle: 8.5556 - rmsle: 0.1384 - val_dense_loss: 0.0000e+00 - val_loss: 0.0966 - val_msle: 6.6609 - val_rmsle: 0.0881 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.07591983687537171\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2667 - msle: 97.1586 - rmsle: 1.9612 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7653 - val_msle: 67.9938 - val_rmsle: 0.6434 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.7030 - msle: 76.5085 - rmsle: 0.5935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.4153 - val_msle: 16.2778 - val_rmsle: 0.3291 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3790 - msle: 16.6190 - rmsle: 0.3013 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2324 - val_msle: 8.4625 - val_rmsle: 0.1798 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3089 - msle: 11.4408 - rmsle: 0.2618 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2086 - val_msle: 9.9262 - val_rmsle: 0.1739 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2786 - msle: 11.0230 - rmsle: 0.2467 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1727 - val_msle: 9.3338 - val_rmsle: 0.1465 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2572 - msle: 10.7436 - rmsle: 0.2322 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1614 - val_msle: 7.5103 - val_rmsle: 0.1384 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2420 - msle: 10.8428 - rmsle: 0.2186 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1544 - val_msle: 5.5125 - val_rmsle: 0.1302 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2220 - msle: 10.6231 - rmsle: 0.1985 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1413 - val_msle: 5.3568 - val_rmsle: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2096 - msle: 10.2232 - rmsle: 0.1874 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1801 - val_msle: 7.7509 - val_rmsle: 0.1594 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2009 - msle: 9.9874 - rmsle: 0.1805 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1146 - val_msle: 6.5480 - val_rmsle: 0.0954 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1936 - msle: 9.7600 - rmsle: 0.1745 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1100 - val_msle: 5.2176 - val_rmsle: 0.0918 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1885 - msle: 9.5540 - rmsle: 0.1705 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1344 - val_msle: 5.0728 - val_rmsle: 0.1172 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1808 - msle: 9.3738 - rmsle: 0.1639 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1050 - val_msle: 5.0222 - val_rmsle: 0.0888 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1767 - msle: 9.2364 - rmsle: 0.1607 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0971 - val_msle: 5.3922 - val_rmsle: 0.0817 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1688 - msle: 9.0952 - rmsle: 0.1539 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1308 - val_msle: 5.2754 - val_rmsle: 0.1164 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1690 - msle: 9.1659 - rmsle: 0.1545 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1206 - val_msle: 7.1890 - val_rmsle: 0.1072 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1639 - msle: 9.0176 - rmsle: 0.1506 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1246 - val_msle: 7.9038 - val_rmsle: 0.1121 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1563 - msle: 8.7972 - rmsle: 0.1446 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1293 - val_msle: 6.4440 - val_rmsle: 0.1192 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1531 - msle: 8.7844 - rmsle: 0.1431 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1100 - val_msle: 7.0656 - val_rmsle: 0.1004 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1508 - msle: 8.6987 - rmsle: 0.1414 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1092 - val_msle: 6.8823 - val_rmsle: 0.1000 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1469 - msle: 8.6219 - rmsle: 0.1382 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1232 - val_msle: 7.8128 - val_rmsle: 0.1153 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1456 - msle: 8.5338 - rmsle: 0.1379 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1254 - val_msle: 8.3083 - val_rmsle: 0.1181 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1441 - msle: 8.5196 - rmsle: 0.1369 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1102 - val_msle: 7.5536 - val_rmsle: 0.1033 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1417 - msle: 8.4858 - rmsle: 0.1350 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1058 - val_msle: 6.8852 - val_rmsle: 0.0995 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 306.7314147949219\n",
            "Fold 1 RMSLE: 0.08206049814527595\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2689 - msle: 97.1035 - rmsle: 1.9630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7922 - val_msle: 65.8179 - val_rmsle: 0.6665 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6999 - msle: 75.8564 - rmsle: 0.5868 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3487 - val_msle: 28.2006 - val_rmsle: 0.2619 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3871 - msle: 19.2935 - rmsle: 0.3085 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2209 - val_msle: 9.2143 - val_rmsle: 0.1673 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3112 - msle: 11.4077 - rmsle: 0.2634 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1926 - val_msle: 6.7623 - val_rmsle: 0.1576 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2769 - msle: 10.9192 - rmsle: 0.2449 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1702 - val_msle: 6.7881 - val_rmsle: 0.1441 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2569 - msle: 10.5755 - rmsle: 0.2319 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1403 - val_msle: 5.3944 - val_rmsle: 0.1171 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2427 - msle: 10.5026 - rmsle: 0.2201 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1308 - val_msle: 5.9999 - val_rmsle: 0.1081 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2238 - msle: 10.5328 - rmsle: 0.2010 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1546 - val_msle: 5.0963 - val_rmsle: 0.1320 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2097 - msle: 10.1315 - rmsle: 0.1875 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1508 - val_msle: 5.3195 - val_rmsle: 0.1299 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2039 - msle: 10.0066 - rmsle: 0.1830 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1290 - val_msle: 5.0067 - val_rmsle: 0.1098 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1947 - msle: 9.6687 - rmsle: 0.1758 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1488 - val_msle: 5.4308 - val_rmsle: 0.1311 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1852 - msle: 9.4350 - rmsle: 0.1676 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1396 - val_msle: 5.5546 - val_rmsle: 0.1229 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1791 - msle: 9.3076 - rmsle: 0.1625 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1061 - val_msle: 4.9772 - val_rmsle: 0.0901 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1726 - msle: 9.0861 - rmsle: 0.1569 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1236 - val_msle: 4.8984 - val_rmsle: 0.1086 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1681 - msle: 9.1056 - rmsle: 0.1534 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1134 - val_msle: 5.3997 - val_rmsle: 0.0997 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1641 - msle: 9.0192 - rmsle: 0.1504 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1211 - val_msle: 5.8914 - val_rmsle: 0.1081 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1566 - msle: 8.8264 - rmsle: 0.1446 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1097 - val_msle: 7.0575 - val_rmsle: 0.0995 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1536 - msle: 8.7664 - rmsle: 0.1434 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0960 - val_msle: 5.7088 - val_rmsle: 0.0864 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1511 - msle: 8.7056 - rmsle: 0.1416 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1000 - val_msle: 5.2061 - val_rmsle: 0.0907 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1509 - msle: 8.6800 - rmsle: 0.1416 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 4.7848 - val_rmsle: 0.0716 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1478 - msle: 8.6401 - rmsle: 0.1389 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 4.6318 - val_rmsle: 0.0784 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1477 - msle: 8.6364 - rmsle: 0.1389 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0942 - val_msle: 5.4192 - val_rmsle: 0.0856 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1456 - msle: 8.5831 - rmsle: 0.1371 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0849 - val_msle: 5.4536 - val_rmsle: 0.0765 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1432 - msle: 8.4768 - rmsle: 0.1351 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0972 - val_msle: 5.9838 - val_rmsle: 0.0899 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1411 - msle: 8.4564 - rmsle: 0.1339 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 6.1796 - val_rmsle: 0.0821 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1394 - msle: 8.4105 - rmsle: 0.1327 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.2793 - val_rmsle: 0.0764 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1386 - msle: 8.3593 - rmsle: 0.1323 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 5.5957 - val_rmsle: 0.0819 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1377 - msle: 8.3583 - rmsle: 0.1319 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0853 - val_msle: 5.4745 - val_rmsle: 0.0797 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1374 - msle: 8.3096 - rmsle: 0.1319 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 5.5002 - val_rmsle: 0.0790 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1357 - msle: 8.2945 - rmsle: 0.1305 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 4.9586 - val_rmsle: 0.0788 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 295.7547607421875\n",
            "Fold 2 RMSLE: 0.07193270493007527\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2679 - msle: 97.2297 - rmsle: 1.9618 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7578 - val_msle: 64.2649 - val_rmsle: 0.6351 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6994 - msle: 77.3550 - rmsle: 0.5887 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3038 - val_msle: 11.2451 - val_rmsle: 0.2182 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3802 - msle: 16.3870 - rmsle: 0.3033 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2312 - val_msle: 8.0104 - val_rmsle: 0.1794 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3116 - msle: 11.4422 - rmsle: 0.2653 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1896 - val_msle: 8.3566 - val_rmsle: 0.1560 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2781 - msle: 10.9243 - rmsle: 0.2470 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1638 - val_msle: 8.3181 - val_rmsle: 0.1388 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2573 - msle: 10.6508 - rmsle: 0.2333 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1467 - val_msle: 5.9576 - val_rmsle: 0.1249 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2424 - msle: 10.6125 - rmsle: 0.2207 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1299 - val_msle: 5.3538 - val_rmsle: 0.1076 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2261 - msle: 10.6756 - rmsle: 0.2039 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2052 - val_msle: 8.3585 - val_rmsle: 0.1826 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2114 - msle: 10.3236 - rmsle: 0.1895 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1578 - val_msle: 6.7166 - val_rmsle: 0.1365 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2018 - msle: 10.0654 - rmsle: 0.1812 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1727 - val_msle: 9.9284 - val_rmsle: 0.1537 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1884 - msle: 9.6636 - rmsle: 0.1706 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1892 - val_msle: 9.7284 - val_rmsle: 0.1736 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1820 - msle: 9.5424 - rmsle: 0.1667 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1513 - val_msle: 8.4921 - val_rmsle: 0.1367 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1791 - msle: 9.4365 - rmsle: 0.1648 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1307 - val_msle: 8.4146 - val_rmsle: 0.1169 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1717 - msle: 9.2353 - rmsle: 0.1585 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1437 - val_msle: 7.6000 - val_rmsle: 0.1317 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1671 - msle: 9.1443 - rmsle: 0.1554 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1531 - val_msle: 8.1670 - val_rmsle: 0.1420 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1654 - msle: 9.1478 - rmsle: 0.1546 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1464 - val_msle: 7.8712 - val_rmsle: 0.1359 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1628 - msle: 9.0465 - rmsle: 0.1525 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1260 - val_msle: 7.0107 - val_rmsle: 0.1162 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 308.0308837890625\n",
            "Fold 3 RMSLE: 0.10793919471136851\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2620 - msle: 97.3067 - rmsle: 1.9580 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7942 - val_msle: 64.2097 - val_rmsle: 0.6734 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6927 - msle: 76.9553 - rmsle: 0.5843 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3318 - val_msle: 18.8015 - val_rmsle: 0.2480 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3751 - msle: 16.9236 - rmsle: 0.2997 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2413 - val_msle: 9.7177 - val_rmsle: 0.1895 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3083 - msle: 11.4380 - rmsle: 0.2616 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2199 - val_msle: 9.6286 - val_rmsle: 0.1856 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2730 - msle: 10.7945 - rmsle: 0.2413 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1779 - val_msle: 8.5422 - val_rmsle: 0.1522 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2551 - msle: 10.6628 - rmsle: 0.2303 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1374 - val_msle: 5.9716 - val_rmsle: 0.1141 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2417 - msle: 10.7848 - rmsle: 0.2183 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1361 - val_msle: 6.5320 - val_rmsle: 0.1125 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2197 - msle: 10.4905 - rmsle: 0.1959 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1458 - val_msle: 5.1909 - val_rmsle: 0.1226 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2060 - msle: 10.0881 - rmsle: 0.1834 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1306 - val_msle: 6.2548 - val_rmsle: 0.1097 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1971 - msle: 9.8656 - rmsle: 0.1767 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1648 - val_msle: 5.1309 - val_rmsle: 0.1453 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1898 - msle: 9.6715 - rmsle: 0.1706 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1630 - val_msle: 6.4504 - val_rmsle: 0.1451 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1826 - msle: 9.4385 - rmsle: 0.1650 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1407 - val_msle: 5.2681 - val_rmsle: 0.1240 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1728 - msle: 9.1435 - rmsle: 0.1570 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1639 - val_msle: 6.8984 - val_rmsle: 0.1502 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1661 - msle: 9.0167 - rmsle: 0.1528 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1200 - val_msle: 5.9925 - val_rmsle: 0.1075 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1643 - msle: 8.9815 - rmsle: 0.1520 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1443 - val_msle: 6.4102 - val_rmsle: 0.1324 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1640 - msle: 8.9620 - rmsle: 0.1520 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1289 - val_msle: 5.6212 - val_rmsle: 0.1171 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1595 - msle: 8.8737 - rmsle: 0.1480 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1488 - val_msle: 7.0337 - val_rmsle: 0.1380 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1564 - msle: 8.7718 - rmsle: 0.1459 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1067 - val_msle: 6.0726 - val_rmsle: 0.0971 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1531 - msle: 8.7020 - rmsle: 0.1438 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0997 - val_msle: 5.8671 - val_rmsle: 0.0908 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1513 - msle: 8.6524 - rmsle: 0.1427 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0815 - val_msle: 5.1032 - val_rmsle: 0.0729 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1511 - msle: 8.6917 - rmsle: 0.1427 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0905 - val_msle: 4.8680 - val_rmsle: 0.0822 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1493 - msle: 8.6341 - rmsle: 0.1412 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.6648 - val_rmsle: 0.0697 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1492 - msle: 8.6644 - rmsle: 0.1412 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 4.8538 - val_rmsle: 0.0712 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1481 - msle: 8.6531 - rmsle: 0.1402 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 5.5701 - val_rmsle: 0.0733 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1488 - msle: 8.6433 - rmsle: 0.1411 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 4.7644 - val_rmsle: 0.0707 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1451 - msle: 8.6008 - rmsle: 0.1376 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0922 - val_msle: 5.3555 - val_rmsle: 0.0850 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1442 - msle: 8.4903 - rmsle: 0.1372 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.1629 - val_rmsle: 0.0762 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1446 - msle: 8.4626 - rmsle: 0.1381 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.8498 - val_rmsle: 0.0771 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1424 - msle: 8.4566 - rmsle: 0.1361 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 5.3697 - val_rmsle: 0.0749 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1414 - msle: 8.4137 - rmsle: 0.1354 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.3120 - val_rmsle: 0.0752 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1412 - msle: 8.4261 - rmsle: 0.1354 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0866 - val_msle: 5.1188 - val_rmsle: 0.0809 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 308.4507751464844\n",
            "Fold 4 RMSLE: 0.07010946214261263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:49:48,161] Trial 27 finished with value: 0.08159233936094082 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'celu', 'reg': 0.0003960032885407173, 'do_rate': 0.4724442076661731, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 13ms/step - dense_loss: 0.0000e+00 - loss: 2.2714 - msle: 103.1270 - rmsle: 2.0596 - val_dense_loss: 0.0000e+00 - val_loss: 1.5409 - val_msle: 105.9597 - val_rmsle: 1.4257 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 1.3047 - msle: 101.5253 - rmsle: 1.2032 - val_dense_loss: 0.0000e+00 - val_loss: 0.4596 - val_msle: 20.2373 - val_rmsle: 0.3706 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.4817 - msle: 25.2364 - rmsle: 0.3962 - val_dense_loss: 0.0000e+00 - val_loss: 0.2193 - val_msle: 13.6789 - val_rmsle: 0.1457 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.3875 - msle: 18.7833 - rmsle: 0.3172 - val_dense_loss: 0.0000e+00 - val_loss: 0.2037 - val_msle: 13.7122 - val_rmsle: 0.1428 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3545 - msle: 17.8973 - rmsle: 0.2964 - val_dense_loss: 0.0000e+00 - val_loss: 0.2083 - val_msle: 13.6360 - val_rmsle: 0.1575 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3318 - msle: 17.2176 - rmsle: 0.2831 - val_dense_loss: 0.0000e+00 - val_loss: 0.1951 - val_msle: 12.3896 - val_rmsle: 0.1509 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3176 - msle: 17.1260 - rmsle: 0.2751 - val_dense_loss: 0.0000e+00 - val_loss: 0.1895 - val_msle: 11.5442 - val_rmsle: 0.1501 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.3083 - msle: 16.7721 - rmsle: 0.2700 - val_dense_loss: 0.0000e+00 - val_loss: 0.1870 - val_msle: 13.0267 - val_rmsle: 0.1519 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2943 - msle: 16.3051 - rmsle: 0.2599 - val_dense_loss: 0.0000e+00 - val_loss: 0.1646 - val_msle: 12.2331 - val_rmsle: 0.1316 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2849 - msle: 15.8811 - rmsle: 0.2527 - val_dense_loss: 0.0000e+00 - val_loss: 0.1622 - val_msle: 12.0029 - val_rmsle: 0.1312 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2773 - msle: 15.8161 - rmsle: 0.2468 - val_dense_loss: 0.0000e+00 - val_loss: 0.1751 - val_msle: 11.6458 - val_rmsle: 0.1461 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2691 - msle: 15.3525 - rmsle: 0.2402 - val_dense_loss: 0.0000e+00 - val_loss: 0.2025 - val_msle: 12.5619 - val_rmsle: 0.1743 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2629 - msle: 15.1733 - rmsle: 0.2350 - val_dense_loss: 0.0000e+00 - val_loss: 0.1809 - val_msle: 11.8173 - val_rmsle: 0.1535 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2525 - msle: 14.7397 - rmsle: 0.2258 - val_dense_loss: 0.0000e+00 - val_loss: 0.2170 - val_msle: 14.1500 - val_rmsle: 0.1925 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2411 - msle: 14.5448 - rmsle: 0.2172 - val_dense_loss: 0.0000e+00 - val_loss: 0.2082 - val_msle: 12.6522 - val_rmsle: 0.1857 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.2389 - msle: 14.4369 - rmsle: 0.2167 - val_dense_loss: 0.0000e+00 - val_loss: 0.1933 - val_msle: 12.2784 - val_rmsle: 0.1721 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2274 - msle: 14.0193 - rmsle: 0.2066 - val_dense_loss: 0.0000e+00 - val_loss: 0.1886 - val_msle: 12.5556 - val_rmsle: 0.1688 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2239 - msle: 13.8983 - rmsle: 0.2044 - val_dense_loss: 0.0000e+00 - val_loss: 0.1751 - val_msle: 12.1124 - val_rmsle: 0.1565 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2190 - msle: 13.8509 - rmsle: 0.2006 - val_dense_loss: 0.0000e+00 - val_loss: 0.1916 - val_msle: 12.4636 - val_rmsle: 0.1739 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.2156 - msle: 13.7316 - rmsle: 0.1981 - val_dense_loss: 0.0000e+00 - val_loss: 0.1705 - val_msle: 12.1621 - val_rmsle: 0.1533 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 268.77764892578125\n",
            "Fold 0 RMSLE: 0.13129692787568917\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 13ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2703 - msle: 103.0554 - rmsle: 2.0581 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.5264 - val_msle: 101.3544 - val_rmsle: 1.4113 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 1.3020 - msle: 101.8898 - rmsle: 1.2007 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.4622 - val_msle: 19.5308 - val_rmsle: 0.3737 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.4837 - msle: 24.8237 - rmsle: 0.3979 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2615 - val_msle: 15.9897 - val_rmsle: 0.1877 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3972 - msle: 18.8506 - rmsle: 0.3272 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3273 - val_msle: 16.4036 - val_rmsle: 0.2673 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3712 - msle: 18.1648 - rmsle: 0.3137 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3061 - val_msle: 15.6132 - val_rmsle: 0.2557 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3383 - msle: 17.3871 - rmsle: 0.2898 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2281 - val_msle: 14.5697 - val_rmsle: 0.1840 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3219 - msle: 17.0473 - rmsle: 0.2791 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2049 - val_msle: 13.8367 - val_rmsle: 0.1656 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3110 - msle: 16.7534 - rmsle: 0.2727 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2448 - val_msle: 14.1511 - val_rmsle: 0.2091 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2990 - msle: 16.2109 - rmsle: 0.2642 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2297 - val_msle: 14.1170 - val_rmsle: 0.1963 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2885 - msle: 16.0496 - rmsle: 0.2558 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2415 - val_msle: 14.3763 - val_rmsle: 0.2100 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2716 - msle: 15.4010 - rmsle: 0.2412 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2239 - val_msle: 13.6448 - val_rmsle: 0.1964 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2639 - msle: 15.0256 - rmsle: 0.2371 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2245 - val_msle: 13.4826 - val_rmsle: 0.1994 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2557 - msle: 14.8416 - rmsle: 0.2312 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2377 - val_msle: 13.8415 - val_rmsle: 0.2144 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2480 - msle: 14.5788 - rmsle: 0.2251 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1681 - val_msle: 11.9976 - val_rmsle: 0.1463 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2441 - msle: 14.4949 - rmsle: 0.2227 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1648 - val_msle: 11.9531 - val_rmsle: 0.1442 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2403 - msle: 14.4074 - rmsle: 0.2200 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1829 - val_msle: 12.4751 - val_rmsle: 0.1633 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2385 - msle: 14.4319 - rmsle: 0.2192 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1921 - val_msle: 12.7944 - val_rmsle: 0.1735 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2348 - msle: 14.2968 - rmsle: 0.2163 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1790 - val_msle: 12.4356 - val_rmsle: 0.1611 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2289 - msle: 14.2057 - rmsle: 0.2112 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1630 - val_msle: 12.0661 - val_rmsle: 0.1457 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2259 - msle: 14.0819 - rmsle: 0.2087 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1813 - val_msle: 12.5991 - val_rmsle: 0.1645 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2243 - msle: 14.0666 - rmsle: 0.2077 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1757 - val_msle: 12.2073 - val_rmsle: 0.1594 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2225 - msle: 14.0101 - rmsle: 0.2063 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1674 - val_msle: 12.0678 - val_rmsle: 0.1515 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2191 - msle: 13.9641 - rmsle: 0.2033 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1821 - val_msle: 12.6532 - val_rmsle: 0.1665 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2184 - msle: 13.9461 - rmsle: 0.2028 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1730 - val_msle: 12.4057 - val_rmsle: 0.1576 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2168 - msle: 13.9200 - rmsle: 0.2015 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1822 - val_msle: 12.6971 - val_rmsle: 0.1670 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 260.1609191894531\n",
            "Fold 1 RMSLE: 0.14444140074667294\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 13ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2730 - msle: 103.0322 - rmsle: 2.0618 - val_dense_2_loss: 0.0000e+00 - val_loss: 1.5188 - val_msle: 98.1561 - val_rmsle: 1.4061 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 1.2994 - msle: 101.6950 - rmsle: 1.2003 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.6757 - val_msle: 19.3707 - val_rmsle: 0.5886 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.4761 - msle: 25.1485 - rmsle: 0.3930 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2241 - val_msle: 14.2414 - val_rmsle: 0.1525 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3847 - msle: 18.7132 - rmsle: 0.3165 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2115 - val_msle: 14.1404 - val_rmsle: 0.1527 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3560 - msle: 18.1012 - rmsle: 0.2997 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2919 - val_msle: 15.8449 - val_rmsle: 0.2426 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3319 - msle: 17.4298 - rmsle: 0.2844 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2677 - val_msle: 15.3555 - val_rmsle: 0.2251 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3189 - msle: 17.1484 - rmsle: 0.2774 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1671 - val_msle: 12.2645 - val_rmsle: 0.1285 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3071 - msle: 16.8356 - rmsle: 0.2692 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3291 - val_msle: 16.9163 - val_rmsle: 0.2943 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3003 - msle: 16.6420 - rmsle: 0.2658 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2692 - val_msle: 14.8655 - val_rmsle: 0.2361 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2862 - msle: 16.1634 - rmsle: 0.2536 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2717 - val_msle: 14.7716 - val_rmsle: 0.2412 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2690 - msle: 15.4903 - rmsle: 0.2394 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1998 - val_msle: 13.2177 - val_rmsle: 0.1725 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2584 - msle: 15.0738 - rmsle: 0.2318 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2282 - val_msle: 13.9046 - val_rmsle: 0.2035 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2541 - msle: 14.9920 - rmsle: 0.2298 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1436 - val_msle: 10.9998 - val_rmsle: 0.1203 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2509 - msle: 14.9548 - rmsle: 0.2279 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1744 - val_msle: 11.4315 - val_rmsle: 0.1524 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2439 - msle: 14.6602 - rmsle: 0.2222 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1876 - val_msle: 12.0771 - val_rmsle: 0.1665 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2404 - msle: 14.6242 - rmsle: 0.2193 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1519 - val_msle: 10.6074 - val_rmsle: 0.1315 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2320 - msle: 14.2677 - rmsle: 0.2119 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1505 - val_msle: 11.3305 - val_rmsle: 0.1313 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2286 - msle: 14.1880 - rmsle: 0.2095 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1528 - val_msle: 10.8685 - val_rmsle: 0.1345 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2271 - msle: 14.1384 - rmsle: 0.2089 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1303 - val_msle: 10.0523 - val_rmsle: 0.1126 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2233 - msle: 14.1132 - rmsle: 0.2057 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1450 - val_msle: 10.7405 - val_rmsle: 0.1279 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2205 - msle: 13.9733 - rmsle: 0.2035 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1367 - val_msle: 10.4080 - val_rmsle: 0.1202 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2188 - msle: 13.8977 - rmsle: 0.2023 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1335 - val_msle: 10.0488 - val_rmsle: 0.1174 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2151 - msle: 13.8273 - rmsle: 0.1990 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1591 - val_msle: 11.2426 - val_rmsle: 0.1434 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2121 - msle: 13.7979 - rmsle: 0.1965 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1562 - val_msle: 11.1134 - val_rmsle: 0.1409 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2098 - msle: 13.7651 - rmsle: 0.1946 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1610 - val_msle: 11.4300 - val_rmsle: 0.1461 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2076 - msle: 13.7466 - rmsle: 0.1927 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1614 - val_msle: 11.7208 - val_rmsle: 0.1468 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2060 - msle: 13.7444 - rmsle: 0.1914 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1523 - val_msle: 11.1330 - val_rmsle: 0.1379 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2051 - msle: 13.7214 - rmsle: 0.1907 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1509 - val_msle: 11.3431 - val_rmsle: 0.1367 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2036 - msle: 13.7392 - rmsle: 0.1894 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1416 - val_msle: 10.7685 - val_rmsle: 0.1276 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 265.25396728515625\n",
            "Fold 2 RMSLE: 0.11248934132501642\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 13ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2718 - msle: 103.1053 - rmsle: 2.0608 - val_dense_3_loss: 0.0000e+00 - val_loss: 1.5109 - val_msle: 98.3976 - val_rmsle: 1.3986 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 1.3007 - msle: 101.3691 - rmsle: 1.2016 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.4614 - val_msle: 20.8432 - val_rmsle: 0.3744 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.4948 - msle: 25.4748 - rmsle: 0.4116 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3088 - val_msle: 16.5676 - val_rmsle: 0.2365 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3939 - msle: 19.3351 - rmsle: 0.3249 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2004 - val_msle: 14.1599 - val_rmsle: 0.1409 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3589 - msle: 18.1974 - rmsle: 0.3019 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2817 - val_msle: 15.4639 - val_rmsle: 0.2317 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3372 - msle: 17.5500 - rmsle: 0.2892 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2284 - val_msle: 14.1965 - val_rmsle: 0.1850 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3211 - msle: 17.2307 - rmsle: 0.2792 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2135 - val_msle: 13.9280 - val_rmsle: 0.1749 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3012 - msle: 16.7414 - rmsle: 0.2637 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3127 - val_msle: 16.8519 - val_rmsle: 0.2783 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2905 - msle: 16.3266 - rmsle: 0.2571 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2822 - val_msle: 15.6259 - val_rmsle: 0.2509 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2834 - msle: 16.0496 - rmsle: 0.2530 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2590 - val_msle: 15.1660 - val_rmsle: 0.2303 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2736 - msle: 15.9103 - rmsle: 0.2453 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2576 - val_msle: 15.2229 - val_rmsle: 0.2306 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2674 - msle: 15.5845 - rmsle: 0.2409 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2192 - val_msle: 14.1674 - val_rmsle: 0.1936 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2636 - msle: 15.4876 - rmsle: 0.2384 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2491 - val_msle: 14.5540 - val_rmsle: 0.2247 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2582 - msle: 15.3923 - rmsle: 0.2341 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2488 - val_msle: 15.0320 - val_rmsle: 0.2253 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 245.88858032226562\n",
            "Fold 3 RMSLE: 0.13722617197138726\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 13ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2822 - msle: 103.2266 - rmsle: 2.0712 - val_dense_4_loss: 0.0000e+00 - val_loss: 1.5141 - val_msle: 100.2771 - val_rmsle: 1.4015 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 1.2995 - msle: 102.0363 - rmsle: 1.2008 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3860 - val_msle: 23.2932 - val_rmsle: 0.2990 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.4706 - msle: 24.7703 - rmsle: 0.3871 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2735 - val_msle: 15.9088 - val_rmsle: 0.2025 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3883 - msle: 18.7401 - rmsle: 0.3209 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.4025 - val_msle: 18.5880 - val_rmsle: 0.3450 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3602 - msle: 18.1042 - rmsle: 0.3049 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3929 - val_msle: 18.9408 - val_rmsle: 0.3446 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3322 - msle: 17.5083 - rmsle: 0.2855 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1783 - val_msle: 13.0138 - val_rmsle: 0.1361 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3165 - msle: 17.1364 - rmsle: 0.2752 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3104 - val_msle: 16.7063 - val_rmsle: 0.2729 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3055 - msle: 16.7798 - rmsle: 0.2687 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3591 - val_msle: 17.5734 - val_rmsle: 0.3244 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2916 - msle: 16.2099 - rmsle: 0.2576 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2641 - val_msle: 14.7637 - val_rmsle: 0.2320 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2786 - msle: 15.8878 - rmsle: 0.2473 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2495 - val_msle: 14.5079 - val_rmsle: 0.2204 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2683 - msle: 15.5809 - rmsle: 0.2399 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2094 - val_msle: 13.4594 - val_rmsle: 0.1826 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2625 - msle: 15.2358 - rmsle: 0.2361 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2299 - val_msle: 14.2120 - val_rmsle: 0.2050 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2498 - msle: 14.9378 - rmsle: 0.2253 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1986 - val_msle: 13.3256 - val_rmsle: 0.1754 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2457 - msle: 14.7495 - rmsle: 0.2229 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2112 - val_msle: 13.3916 - val_rmsle: 0.1894 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2439 - msle: 14.7312 - rmsle: 0.2224 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1743 - val_msle: 12.4814 - val_rmsle: 0.1536 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2400 - msle: 14.6036 - rmsle: 0.2195 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1683 - val_msle: 12.2481 - val_rmsle: 0.1484 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 255.20077514648438\n",
            "Fold 4 RMSLE: 0.1349650355163906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 22:55:43,271] Trial 28 finished with value: 0.13208377548703126 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'gelu', 'reg': 0.00015664139047782735, 'do_rate': 0.45314272767537633, 'hidden_layers': 4}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.2305 - msle: 97.4417 - rmsle: 2.1128 - val_dense_loss: 0.0000e+00 - val_loss: 0.8118 - val_msle: 66.9404 - val_rmsle: 0.7731 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6274 - msle: 57.5592 - rmsle: 0.5963 - val_dense_loss: 0.0000e+00 - val_loss: 0.1458 - val_msle: 6.4667 - val_rmsle: 0.1249 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1760 - msle: 11.1531 - rmsle: 0.1565 - val_dense_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 5.0809 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1534 - msle: 9.7249 - rmsle: 0.1378 - val_dense_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 5.9233 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1443 - msle: 9.5048 - rmsle: 0.1310 - val_dense_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.2696 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1373 - msle: 9.3013 - rmsle: 0.1255 - val_dense_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 5.0042 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1309 - msle: 9.1260 - rmsle: 0.1202 - val_dense_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.1176 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1248 - msle: 8.9218 - rmsle: 0.1151 - val_dense_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.6668 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1216 - msle: 8.8264 - rmsle: 0.1126 - val_dense_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.0751 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1192 - msle: 8.7380 - rmsle: 0.1107 - val_dense_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.0790 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1157 - msle: 8.5817 - rmsle: 0.1077 - val_dense_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 3.9354 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1137 - msle: 8.5370 - rmsle: 0.1061 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 3.9587 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1117 - msle: 8.4494 - rmsle: 0.1045 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 3.9791 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1096 - msle: 8.3370 - rmsle: 0.1027 - val_dense_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.1329 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1079 - msle: 8.2827 - rmsle: 0.1013 - val_dense_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.3215 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.1594 - rmsle: 0.0994 - val_dense_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.8037 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1044 - msle: 8.1301 - rmsle: 0.0990 - val_dense_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.9773 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.1084 - rmsle: 0.0986 - val_dense_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.9676 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.0634 - rmsle: 0.0978 - val_dense_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.1963 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1005 - msle: 8.0193 - rmsle: 0.0958 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8703 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0998 - msle: 7.9958 - rmsle: 0.0955 - val_dense_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.7677 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.9868 - rmsle: 0.0955 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7887 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.9627 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7597 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0989 - msle: 7.9323 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7900 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.9566 - rmsle: 0.0948 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8655 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.9498 - rmsle: 0.0946 - val_dense_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8319 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.9067 - rmsle: 0.0936 - val_dense_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7834 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.8780 - rmsle: 0.0932 - val_dense_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7745 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.8764 - rmsle: 0.0934 - val_dense_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8160 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.9186 - rmsle: 0.0933 - val_dense_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8201 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.8695 - rmsle: 0.0930 - val_dense_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7470 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06256544683596504\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2312 - msle: 97.4181 - rmsle: 2.1120 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8260 - val_msle: 68.0215 - val_rmsle: 0.7853 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6129 - msle: 56.2558 - rmsle: 0.5800 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2426 - val_msle: 17.1741 - val_rmsle: 0.2237 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2417 - msle: 12.5382 - rmsle: 0.2245 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0950 - val_msle: 5.1421 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1559 - msle: 9.9052 - rmsle: 0.1406 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.3869 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1451 - msle: 9.5905 - rmsle: 0.1320 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 5.2108 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1377 - msle: 9.4146 - rmsle: 0.1261 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.4208 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1308 - msle: 9.1871 - rmsle: 0.1203 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 4.2696 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1263 - msle: 9.0058 - rmsle: 0.1165 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.1162 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1221 - msle: 8.8425 - rmsle: 0.1130 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.4233 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1192 - msle: 8.7681 - rmsle: 0.1107 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.3157 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1166 - msle: 8.6185 - rmsle: 0.1086 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.5768 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1145 - msle: 8.5476 - rmsle: 0.1068 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.2986 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1122 - msle: 8.4677 - rmsle: 0.1048 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.4599 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1084 - msle: 8.3256 - rmsle: 0.1017 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 5.2953 - val_rmsle: 0.0735 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1071 - msle: 8.3094 - rmsle: 0.1013 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.5198 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1065 - msle: 8.2667 - rmsle: 0.1010 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4003 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1051 - msle: 8.2183 - rmsle: 0.0998 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.5347 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1048 - msle: 8.2177 - rmsle: 0.0997 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.8703 - val_rmsle: 0.0699 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 311.44921875\n",
            "Fold 1 RMSLE: 0.06554682833645244\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2294 - msle: 97.3639 - rmsle: 2.1121 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.8021 - val_msle: 65.4605 - val_rmsle: 0.7628 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6484 - msle: 58.2625 - rmsle: 0.6172 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2443 - val_msle: 15.3555 - val_rmsle: 0.2255 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2385 - msle: 13.5122 - rmsle: 0.2213 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0948 - val_msle: 5.1714 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1536 - msle: 9.8406 - rmsle: 0.1385 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0926 - val_msle: 6.1369 - val_rmsle: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1434 - msle: 9.6037 - rmsle: 0.1304 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 5.3737 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1357 - msle: 9.3734 - rmsle: 0.1240 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0876 - val_msle: 5.8312 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1298 - msle: 9.1724 - rmsle: 0.1192 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0840 - val_msle: 4.9101 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1246 - msle: 9.0083 - rmsle: 0.1148 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0885 - val_msle: 5.7408 - val_rmsle: 0.0793 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1205 - msle: 8.8369 - rmsle: 0.1115 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0896 - val_msle: 6.1133 - val_rmsle: 0.0811 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1177 - msle: 8.7345 - rmsle: 0.1092 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 5.5267 - val_rmsle: 0.0770 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1125 - msle: 8.5239 - rmsle: 0.1049 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.9445 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1110 - msle: 8.4939 - rmsle: 0.1044 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.7081 - val_rmsle: 0.0755 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1096 - msle: 8.4577 - rmsle: 0.1035 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 3.8530 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1083 - msle: 8.3845 - rmsle: 0.1024 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.2855 - val_rmsle: 0.0721 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1075 - msle: 8.3865 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 3.7828 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1068 - msle: 8.3549 - rmsle: 0.1013 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 3.7792 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1059 - msle: 8.2897 - rmsle: 0.1005 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 3.8088 - val_rmsle: 0.0672 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1048 - msle: 8.2574 - rmsle: 0.0996 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.0033 - val_rmsle: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.1559 - rmsle: 0.0977 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.8428 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.1451 - rmsle: 0.0969 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.7642 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1011 - msle: 8.1211 - rmsle: 0.0967 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8162 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1006 - msle: 8.1428 - rmsle: 0.0964 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.8681 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1003 - msle: 8.0775 - rmsle: 0.0963 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.1307 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0997 - msle: 8.0946 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0064 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.0942 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.9712 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0993 - msle: 8.0671 - rmsle: 0.0955 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1403 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0990 - msle: 8.0523 - rmsle: 0.0952 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9127 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0982 - msle: 8.0375 - rmsle: 0.0945 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8751 - val_rmsle: 0.0628 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0974 - msle: 8.0093 - rmsle: 0.0938 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8545 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.9877 - rmsle: 0.0938 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9357 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06320648433416087\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2286 - msle: 97.4608 - rmsle: 2.1110 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8252 - val_msle: 68.1686 - val_rmsle: 0.7866 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6544 - msle: 59.0148 - rmsle: 0.6235 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1251 - val_msle: 8.6553 - val_rmsle: 0.1001 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1853 - msle: 12.5128 - rmsle: 0.1627 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0947 - val_msle: 5.5429 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1545 - msle: 9.8131 - rmsle: 0.1382 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 4.7491 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1426 - msle: 9.5170 - rmsle: 0.1290 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.3305 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1359 - msle: 9.4047 - rmsle: 0.1241 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.5460 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1302 - msle: 9.1915 - rmsle: 0.1194 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.0656 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1252 - msle: 9.0227 - rmsle: 0.1153 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.0496 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1213 - msle: 8.8380 - rmsle: 0.1120 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.3245 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1184 - msle: 8.7332 - rmsle: 0.1099 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 4.0937 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1155 - msle: 8.6315 - rmsle: 0.1074 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 3.9816 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1134 - msle: 8.5145 - rmsle: 0.1057 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 3.9815 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1112 - msle: 8.4446 - rmsle: 0.1038 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.4623 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.3317 - rmsle: 0.1027 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.0763 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1087 - msle: 8.3058 - rmsle: 0.1018 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.1770 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1070 - msle: 8.2433 - rmsle: 0.1005 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.2871 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1057 - msle: 8.1694 - rmsle: 0.0993 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.1808 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1049 - msle: 8.1169 - rmsle: 0.0987 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.3418 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1021 - msle: 8.0084 - rmsle: 0.0964 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 5.5371 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.9661 - rmsle: 0.0957 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.4585 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1001 - msle: 7.9584 - rmsle: 0.0955 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.7853 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.8856 - rmsle: 0.0941 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.3423 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.8555 - rmsle: 0.0939 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2421 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.8685 - rmsle: 0.0935 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.4326 - val_rmsle: 0.0652 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0972 - msle: 7.8484 - rmsle: 0.0935 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.0800 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.8568 - rmsle: 0.0930 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1803 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.8506 - rmsle: 0.0930 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2883 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.8376 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.2302 - val_rmsle: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.7790 - rmsle: 0.0922 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.1371 - val_rmsle: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0951 - msle: 7.7672 - rmsle: 0.0919 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0565 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.7754 - rmsle: 0.0919 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0672 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06394255624171322\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2287 - msle: 97.5343 - rmsle: 2.1112 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8136 - val_msle: 67.1466 - val_rmsle: 0.7752 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6193 - msle: 56.5354 - rmsle: 0.5877 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2332 - val_msle: 12.9623 - val_rmsle: 0.2140 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2392 - msle: 12.7224 - rmsle: 0.2215 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1157 - val_msle: 6.6608 - val_rmsle: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1552 - msle: 9.8803 - rmsle: 0.1396 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0903 - val_msle: 5.2302 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1441 - msle: 9.5684 - rmsle: 0.1310 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 4.6000 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1377 - msle: 9.3587 - rmsle: 0.1257 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0853 - val_msle: 5.5646 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1310 - msle: 9.1989 - rmsle: 0.1202 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0958 - val_msle: 7.8968 - val_rmsle: 0.0856 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1261 - msle: 9.0140 - rmsle: 0.1161 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0960 - val_msle: 7.2182 - val_rmsle: 0.0867 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1187 - msle: 8.7567 - rmsle: 0.1099 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 5.0000 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1161 - msle: 8.7416 - rmsle: 0.1083 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.7995 - val_rmsle: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1144 - msle: 8.6248 - rmsle: 0.1072 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.5676 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1129 - msle: 8.6104 - rmsle: 0.1061 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.4870 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1114 - msle: 8.5437 - rmsle: 0.1049 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.4926 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1101 - msle: 8.5071 - rmsle: 0.1038 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 5.4262 - val_rmsle: 0.0723 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1091 - msle: 8.4241 - rmsle: 0.1031 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4664 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1079 - msle: 8.4163 - rmsle: 0.1020 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.7992 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1073 - msle: 8.3703 - rmsle: 0.1016 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.2715 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.3339 - rmsle: 0.1008 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0671 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1051 - msle: 8.2798 - rmsle: 0.0997 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.1311 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1043 - msle: 8.2632 - rmsle: 0.0991 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.1867 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1039 - msle: 8.2047 - rmsle: 0.0987 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.3124 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1023 - msle: 8.1553 - rmsle: 0.0973 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7582 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 8.1228 - rmsle: 0.0967 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7380 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1012 - msle: 8.0662 - rmsle: 0.0967 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7284 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1005 - msle: 8.0870 - rmsle: 0.0962 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7326 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1005 - msle: 8.0557 - rmsle: 0.0963 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7412 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0999 - msle: 8.0292 - rmsle: 0.0957 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7261 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.9918 - rmsle: 0.0954 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8307 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.9964 - rmsle: 0.0953 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8023 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.9679 - rmsle: 0.0947 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7863 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.9209 - rmsle: 0.0940 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7893 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.062302898627522064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:02:09,214] Trial 29 finished with value: 0.06351284287516273 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00029640255130309164, 'do_rate': 0.48600211990580794, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1785 - msle: 95.6029 - rmsle: 2.0007 - val_dense_loss: 0.0000e+00 - val_loss: 0.7433 - val_msle: 62.1153 - val_rmsle: 0.7035 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5613 - msle: 50.7888 - rmsle: 0.5298 - val_dense_loss: 0.0000e+00 - val_loss: 0.1440 - val_msle: 5.4146 - val_rmsle: 0.1212 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1661 - msle: 9.8915 - rmsle: 0.1450 - val_dense_loss: 0.0000e+00 - val_loss: 0.1123 - val_msle: 4.8651 - val_rmsle: 0.0945 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1471 - msle: 8.9809 - rmsle: 0.1304 - val_dense_loss: 0.0000e+00 - val_loss: 0.0982 - val_msle: 5.0038 - val_rmsle: 0.0833 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1378 - msle: 8.8115 - rmsle: 0.1236 - val_dense_loss: 0.0000e+00 - val_loss: 0.0979 - val_msle: 4.6715 - val_rmsle: 0.0846 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1335 - msle: 8.6792 - rmsle: 0.1204 - val_dense_loss: 0.0000e+00 - val_loss: 0.0895 - val_msle: 4.6857 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1267 - msle: 8.4628 - rmsle: 0.1149 - val_dense_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 4.1657 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1219 - msle: 8.3312 - rmsle: 0.1112 - val_dense_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.3065 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1188 - msle: 8.1950 - rmsle: 0.1089 - val_dense_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.1837 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.0876 - rmsle: 0.1071 - val_dense_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.3897 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1136 - msle: 7.9510 - rmsle: 0.1049 - val_dense_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.0752 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1118 - msle: 7.9066 - rmsle: 0.1034 - val_dense_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 3.9615 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1095 - msle: 7.8292 - rmsle: 0.1015 - val_dense_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.1836 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1083 - msle: 7.7661 - rmsle: 0.1006 - val_dense_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 3.9742 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1067 - msle: 7.7139 - rmsle: 0.0993 - val_dense_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.2910 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1039 - msle: 7.5914 - rmsle: 0.0971 - val_dense_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 3.9076 - val_rmsle: 0.0668 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1023 - msle: 7.5748 - rmsle: 0.0963 - val_dense_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 3.9014 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1020 - msle: 7.5502 - rmsle: 0.0963 - val_dense_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 3.8120 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1012 - msle: 7.5311 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.2283 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1000 - msle: 7.5149 - rmsle: 0.0946 - val_dense_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0525 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.4789 - rmsle: 0.0946 - val_dense_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 3.9907 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.4797 - rmsle: 0.0942 - val_dense_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.0202 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.4351 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.9061 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.3612 - rmsle: 0.0923 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7743 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.3780 - rmsle: 0.0922 - val_dense_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8136 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.3836 - rmsle: 0.0922 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7903 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0960 - msle: 7.3460 - rmsle: 0.0920 - val_dense_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8223 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.3555 - rmsle: 0.0918 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7651 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.3216 - rmsle: 0.0918 - val_dense_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7843 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.3542 - rmsle: 0.0915 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7990 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.3279 - rmsle: 0.0914 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8109 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0629294910304204\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1796 - msle: 95.5320 - rmsle: 2.0011 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7516 - val_msle: 63.6159 - val_rmsle: 0.7116 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5349 - msle: 48.6773 - rmsle: 0.5028 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2311 - val_msle: 10.7909 - val_rmsle: 0.2114 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2239 - msle: 10.7043 - rmsle: 0.2056 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1051 - val_msle: 7.7830 - val_rmsle: 0.0875 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1500 - msle: 9.1913 - rmsle: 0.1331 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0928 - val_msle: 6.5058 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1406 - msle: 8.9227 - rmsle: 0.1258 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0931 - val_msle: 6.8771 - val_rmsle: 0.0796 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1340 - msle: 8.7242 - rmsle: 0.1208 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 5.4691 - val_rmsle: 0.0714 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1285 - msle: 8.5509 - rmsle: 0.1164 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0814 - val_msle: 5.4566 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1246 - msle: 8.4022 - rmsle: 0.1135 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.2374 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1206 - msle: 8.2297 - rmsle: 0.1104 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.8210 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1167 - msle: 8.1336 - rmsle: 0.1073 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.1845 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1146 - msle: 8.0159 - rmsle: 0.1058 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.0471 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1125 - msle: 7.9287 - rmsle: 0.1039 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.1080 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1101 - msle: 7.8360 - rmsle: 0.1020 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.1487 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1089 - msle: 7.7923 - rmsle: 0.1011 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.7739 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1075 - msle: 7.7501 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.3033 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1062 - msle: 7.6960 - rmsle: 0.0989 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.3706 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1054 - msle: 7.6568 - rmsle: 0.0983 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.5937 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1045 - msle: 7.6418 - rmsle: 0.0975 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 5.0541 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.4855 - rmsle: 0.0945 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 5.3807 - val_rmsle: 0.0715 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.4800 - rmsle: 0.0944 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 5.1425 - val_rmsle: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0998 - msle: 7.4400 - rmsle: 0.0945 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.6508 - val_rmsle: 0.0710 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.3714 - rmsle: 0.0920 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2332 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.3444 - rmsle: 0.0918 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9826 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.3408 - rmsle: 0.0914 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0720 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.3043 - rmsle: 0.0914 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1610 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.3425 - rmsle: 0.0912 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9988 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.2987 - rmsle: 0.0901 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9650 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0932 - msle: 7.3006 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8755 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0931 - msle: 7.2832 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8781 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2937 - rmsle: 0.0898 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8766 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.2829 - rmsle: 0.0894 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8480 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 305.8974609375\n",
            "Fold 1 RMSLE: 0.06274216114576132\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1764 - msle: 95.4759 - rmsle: 1.9999 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7355 - val_msle: 62.2328 - val_rmsle: 0.6978 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5860 - msle: 52.0497 - rmsle: 0.5566 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1225 - val_msle: 5.8463 - val_rmsle: 0.1006 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1675 - msle: 10.2130 - rmsle: 0.1469 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1085 - val_msle: 7.1298 - val_rmsle: 0.0910 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1456 - msle: 8.9141 - rmsle: 0.1290 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0940 - val_msle: 6.8114 - val_rmsle: 0.0796 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1369 - msle: 8.7699 - rmsle: 0.1228 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 5.0001 - val_rmsle: 0.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1298 - msle: 8.5611 - rmsle: 0.1171 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 4.2888 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1250 - msle: 8.4133 - rmsle: 0.1134 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 4.9922 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1205 - msle: 8.2547 - rmsle: 0.1100 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 4.8356 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1165 - msle: 8.1032 - rmsle: 0.1067 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0890 - val_msle: 5.5638 - val_rmsle: 0.0796 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1117 - msle: 7.9550 - rmsle: 0.1029 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 5.0913 - val_rmsle: 0.0726 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1094 - msle: 7.8940 - rmsle: 0.1019 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 5.0606 - val_rmsle: 0.0728 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1088 - msle: 7.8893 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 4.6527 - val_rmsle: 0.0786 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1075 - msle: 7.8201 - rmsle: 0.1007 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.3732 - val_rmsle: 0.0714 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1065 - msle: 7.7916 - rmsle: 0.0999 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 4.4398 - val_rmsle: 0.0765 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1056 - msle: 7.7672 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 4.5652 - val_rmsle: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1046 - msle: 7.7101 - rmsle: 0.0985 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 3.9398 - val_rmsle: 0.0721 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 299.4903259277344\n",
            "Fold 2 RMSLE: 0.06878062628802928\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1807 - msle: 95.5623 - rmsle: 2.0026 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7590 - val_msle: 63.9299 - val_rmsle: 0.7199 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5546 - msle: 50.0487 - rmsle: 0.5233 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1178 - val_msle: 6.4089 - val_rmsle: 0.0953 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1680 - msle: 10.1133 - rmsle: 0.1469 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0891 - val_msle: 5.3212 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1483 - msle: 9.1408 - rmsle: 0.1318 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0908 - val_msle: 5.3433 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1386 - msle: 8.8857 - rmsle: 0.1242 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 4.3573 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1326 - msle: 8.7682 - rmsle: 0.1197 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0880 - val_msle: 4.4872 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1274 - msle: 8.5676 - rmsle: 0.1157 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 4.3348 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1228 - msle: 8.4036 - rmsle: 0.1120 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.1846 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.1864 - rmsle: 0.1068 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.4725 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1140 - msle: 8.1335 - rmsle: 0.1055 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.1886 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1124 - msle: 8.0629 - rmsle: 0.1045 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.2844 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1112 - msle: 8.0011 - rmsle: 0.1036 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.1430 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1097 - msle: 7.9388 - rmsle: 0.1024 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.6596 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1087 - msle: 7.8864 - rmsle: 0.1017 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.2512 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1079 - msle: 7.8831 - rmsle: 0.1011 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.5657 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1055 - msle: 7.7948 - rmsle: 0.0991 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 5.2288 - val_rmsle: 0.0678 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1042 - msle: 7.7711 - rmsle: 0.0984 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.2246 - val_rmsle: 0.0670 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1037 - msle: 7.7603 - rmsle: 0.0982 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.9163 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1025 - msle: 7.7182 - rmsle: 0.0972 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2186 - val_rmsle: 0.0638 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1015 - msle: 7.6977 - rmsle: 0.0965 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2530 - val_rmsle: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.7047 - rmsle: 0.0965 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.3389 - val_rmsle: 0.0644 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.6646 - rmsle: 0.0963 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.1335 - val_rmsle: 0.0639 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1011 - msle: 7.6609 - rmsle: 0.0966 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1676 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1005 - msle: 7.6869 - rmsle: 0.0960 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.3376 - val_rmsle: 0.0644 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1002 - msle: 7.6700 - rmsle: 0.0958 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0640 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.6595 - rmsle: 0.0956 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2319 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.6749 - rmsle: 0.0956 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.3035 - val_rmsle: 0.0646 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.6510 - rmsle: 0.0954 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3093 - val_rmsle: 0.0645 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.6105 - rmsle: 0.0946 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9775 - val_rmsle: 0.0630 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.6130 - rmsle: 0.0947 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8915 - val_rmsle: 0.0625 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.6017 - rmsle: 0.0943 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0437 - val_rmsle: 0.0634 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 308.89697265625\n",
            "Fold 3 RMSLE: 0.06332055769945306\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1790 - msle: 95.6991 - rmsle: 2.0014 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7586 - val_msle: 63.3835 - val_rmsle: 0.7194 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5585 - msle: 50.2931 - rmsle: 0.5276 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2300 - val_msle: 11.4238 - val_rmsle: 0.2111 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2286 - msle: 11.1096 - rmsle: 0.2104 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1134 - val_msle: 5.3331 - val_rmsle: 0.0956 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1485 - msle: 9.0967 - rmsle: 0.1317 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 4.4724 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1380 - msle: 8.8637 - rmsle: 0.1235 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 4.5577 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1329 - msle: 8.7085 - rmsle: 0.1195 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 5.1924 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1280 - msle: 8.5728 - rmsle: 0.1157 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0979 - val_msle: 6.8363 - val_rmsle: 0.0864 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1237 - msle: 8.3668 - rmsle: 0.1124 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0824 - val_msle: 6.0352 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1189 - msle: 8.1885 - rmsle: 0.1086 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0946 - val_msle: 6.5555 - val_rmsle: 0.0847 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1165 - msle: 8.1433 - rmsle: 0.1068 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1053 - val_msle: 8.3521 - val_rmsle: 0.0961 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1143 - msle: 8.0143 - rmsle: 0.1052 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0975 - val_msle: 6.6574 - val_rmsle: 0.0889 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1088 - msle: 7.8093 - rmsle: 0.1008 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 5.4069 - val_rmsle: 0.0709 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1064 - msle: 7.7584 - rmsle: 0.0994 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.2502 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1056 - msle: 7.7531 - rmsle: 0.0991 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 5.6847 - val_rmsle: 0.0756 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1047 - msle: 7.7083 - rmsle: 0.0983 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 5.5927 - val_rmsle: 0.0717 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1039 - msle: 7.7028 - rmsle: 0.0978 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 5.6354 - val_rmsle: 0.0703 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.5923 - rmsle: 0.0955 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.8240 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.5993 - rmsle: 0.0955 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.7861 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1002 - msle: 7.5371 - rmsle: 0.0950 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.7975 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0996 - msle: 7.5756 - rmsle: 0.0946 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8185 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.5435 - rmsle: 0.0944 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.7803 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0991 - msle: 7.5391 - rmsle: 0.0944 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.8710 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.4776 - rmsle: 0.0935 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8370 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.4662 - rmsle: 0.0937 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8763 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.4597 - rmsle: 0.0926 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7387 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.4444 - rmsle: 0.0926 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7390 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.4381 - rmsle: 0.0925 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7450 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.4000 - rmsle: 0.0922 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7607 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.4323 - rmsle: 0.0923 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7665 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0957 - msle: 7.4108 - rmsle: 0.0919 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7631 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0954 - msle: 7.3949 - rmsle: 0.0917 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7358 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.061774958236665505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:08:32,596] Trial 30 finished with value: 0.06390955888006591 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'mish', 'reg': 0.0005021834412306193, 'do_rate': 0.4291059018687493, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1417 - msle: 97.5148 - rmsle: 2.0942 - val_dense_loss: 0.0000e+00 - val_loss: 0.7766 - val_msle: 65.8933 - val_rmsle: 0.7474 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6493 - msle: 59.9679 - rmsle: 0.6239 - val_dense_loss: 0.0000e+00 - val_loss: 0.4492 - val_msle: 37.5267 - val_rmsle: 0.4339 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.4420 - msle: 38.7850 - rmsle: 0.4288 - val_dense_loss: 0.0000e+00 - val_loss: 0.2516 - val_msle: 20.9471 - val_rmsle: 0.2399 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1467 - msle: 9.3456 - rmsle: 0.1353 - val_dense_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 5.4238 - val_rmsle: 0.0776 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1291 - msle: 8.4343 - rmsle: 0.1195 - val_dense_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.7471 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1226 - msle: 8.2581 - rmsle: 0.1140 - val_dense_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 5.1025 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1177 - msle: 8.1054 - rmsle: 0.1100 - val_dense_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.7231 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1131 - msle: 7.9618 - rmsle: 0.1061 - val_dense_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.2139 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1100 - msle: 7.8507 - rmsle: 0.1035 - val_dense_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.7791 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1080 - msle: 7.7822 - rmsle: 0.1018 - val_dense_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.6583 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1057 - msle: 7.6815 - rmsle: 0.0998 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.1329 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1038 - msle: 7.6101 - rmsle: 0.0983 - val_dense_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.0268 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.5741 - rmsle: 0.0974 - val_dense_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.2329 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.5155 - rmsle: 0.0959 - val_dense_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.5534 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.4715 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.5588 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0977 - msle: 7.3506 - rmsle: 0.0931 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7573 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.3412 - rmsle: 0.0928 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7921 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.3209 - rmsle: 0.0929 - val_dense_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8603 - val_rmsle: 0.0625 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.3040 - rmsle: 0.0924 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2989 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0939 - msle: 7.2619 - rmsle: 0.0903 - val_dense_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7700 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.2473 - rmsle: 0.0903 - val_dense_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7324 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.2506 - rmsle: 0.0900 - val_dense_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7367 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0931 - msle: 7.1965 - rmsle: 0.0899 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7422 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.2156 - rmsle: 0.0896 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7674 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0917 - msle: 7.1923 - rmsle: 0.0887 - val_dense_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7679 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.1905 - rmsle: 0.0886 - val_dense_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7555 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.1796 - rmsle: 0.0886 - val_dense_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7418 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.1807 - rmsle: 0.0886 - val_dense_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7386 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.1664 - rmsle: 0.0883 - val_dense_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7632 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.1937 - rmsle: 0.0884 - val_dense_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7432 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0904 - msle: 7.1440 - rmsle: 0.0878 - val_dense_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7219 - val_rmsle: 0.0615 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06234031248450914\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1447 - msle: 97.4875 - rmsle: 2.0970 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7889 - val_msle: 67.4369 - val_rmsle: 0.7595 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6529 - msle: 60.8793 - rmsle: 0.6276 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.4550 - val_msle: 43.0303 - val_rmsle: 0.4399 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.4369 - msle: 39.3802 - rmsle: 0.4238 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1588 - val_msle: 9.9744 - val_rmsle: 0.1471 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1406 - msle: 8.9031 - rmsle: 0.1293 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0815 - val_msle: 4.5498 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1285 - msle: 8.4203 - rmsle: 0.1190 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.6193 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1218 - msle: 8.2307 - rmsle: 0.1134 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.5963 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1165 - msle: 8.0955 - rmsle: 0.1089 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.5269 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1134 - msle: 7.9600 - rmsle: 0.1064 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.0747 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.8459 - rmsle: 0.1041 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.5583 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1077 - msle: 7.7830 - rmsle: 0.1016 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.2568 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1057 - msle: 7.6939 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.0684 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1042 - msle: 7.5930 - rmsle: 0.0987 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.1574 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.5592 - rmsle: 0.0974 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.7488 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1014 - msle: 7.5226 - rmsle: 0.0963 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.9024 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.3940 - rmsle: 0.0937 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.3311 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.3528 - rmsle: 0.0933 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2706 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.3433 - rmsle: 0.0928 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0254 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.3408 - rmsle: 0.0926 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1046 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.2983 - rmsle: 0.0919 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.3424 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.3024 - rmsle: 0.0914 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1829 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0936 - msle: 7.2202 - rmsle: 0.0901 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8421 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2253 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8321 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.2176 - rmsle: 0.0895 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8018 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.2016 - rmsle: 0.0894 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8667 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.1705 - rmsle: 0.0892 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8824 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.1871 - rmsle: 0.0890 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8166 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.1664 - rmsle: 0.0882 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8741 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0909 - msle: 7.1556 - rmsle: 0.0882 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8385 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0909 - msle: 7.1815 - rmsle: 0.0883 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7855 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.1508 - rmsle: 0.0879 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.8040 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0902 - msle: 7.1566 - rmsle: 0.0877 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7769 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 312.5736083984375\n",
            "Fold 1 RMSLE: 0.06207170378276438\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1435 - msle: 97.3882 - rmsle: 2.0959 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7874 - val_msle: 66.0603 - val_rmsle: 0.7584 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6506 - msle: 60.0939 - rmsle: 0.6256 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1975 - val_msle: 15.3858 - val_rmsle: 0.1801 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1728 - msle: 13.6780 - rmsle: 0.1565 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1049 - val_msle: 4.4467 - val_rmsle: 0.0920 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1349 - msle: 8.4891 - rmsle: 0.1227 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 6.3404 - val_rmsle: 0.0812 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1260 - msle: 8.2866 - rmsle: 0.1163 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 5.0996 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1199 - msle: 8.1274 - rmsle: 0.1115 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.9239 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1152 - msle: 7.9692 - rmsle: 0.1077 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.6238 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1117 - msle: 7.8419 - rmsle: 0.1049 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.5740 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1082 - msle: 7.7164 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 5.3559 - val_rmsle: 0.0779 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1059 - msle: 7.6589 - rmsle: 0.1000 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.5637 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1038 - msle: 7.5742 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 5.0414 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.4858 - rmsle: 0.0955 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.7884 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0994 - msle: 7.4543 - rmsle: 0.0948 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.6840 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.4266 - rmsle: 0.0943 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.7334 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.3941 - rmsle: 0.0938 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.6711 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.3812 - rmsle: 0.0934 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.6539 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.3206 - rmsle: 0.0928 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7625 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0959 - msle: 7.3182 - rmsle: 0.0921 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.8489 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.2837 - rmsle: 0.0918 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7161 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.3043 - rmsle: 0.0914 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8513 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0944 - msle: 7.2578 - rmsle: 0.0909 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8662 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0939 - msle: 7.2572 - rmsle: 0.0904 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7552 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.1518 - rmsle: 0.0889 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.8656 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0916 - msle: 7.1469 - rmsle: 0.0885 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8411 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.1475 - rmsle: 0.0883 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9066 - val_rmsle: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0906 - msle: 7.1343 - rmsle: 0.0876 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6250 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0904 - msle: 7.1283 - rmsle: 0.0876 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6650 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.1378 - rmsle: 0.0875 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6785 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0902 - msle: 7.1284 - rmsle: 0.0875 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7208 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0894 - msle: 7.0820 - rmsle: 0.0868 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6070 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0891 - msle: 7.0702 - rmsle: 0.0865 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6189 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061709824497181535\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1444 - msle: 97.4625 - rmsle: 2.0968 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7828 - val_msle: 66.7636 - val_rmsle: 0.7537 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6300 - msle: 58.9390 - rmsle: 0.6048 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2295 - val_msle: 16.1472 - val_rmsle: 0.2128 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2470 - msle: 13.5432 - rmsle: 0.2323 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1447 - val_msle: 11.7930 - val_rmsle: 0.1339 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1402 - msle: 8.7579 - rmsle: 0.1294 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.3907 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1281 - msle: 8.3826 - rmsle: 0.1187 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.2365 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1218 - msle: 8.2491 - rmsle: 0.1136 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 4.1492 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1178 - msle: 8.0879 - rmsle: 0.1103 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 3.9443 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1132 - msle: 7.9521 - rmsle: 0.1062 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.0371 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1105 - msle: 7.8616 - rmsle: 0.1039 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.0346 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1078 - msle: 7.7840 - rmsle: 0.1015 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.9529 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1057 - msle: 7.6929 - rmsle: 0.0998 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.0874 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1036 - msle: 7.6121 - rmsle: 0.0980 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.9566 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1022 - msle: 7.5325 - rmsle: 0.0969 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.0329 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1010 - msle: 7.4711 - rmsle: 0.0959 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.0234 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.4477 - rmsle: 0.0950 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0300 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0989 - msle: 7.4099 - rmsle: 0.0942 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.2375 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.3791 - rmsle: 0.0933 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.0611 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.3477 - rmsle: 0.0926 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.5895 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.2549 - rmsle: 0.0910 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.5981 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0943 - msle: 7.2336 - rmsle: 0.0904 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.3576 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.2348 - rmsle: 0.0901 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.4949 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.1525 - rmsle: 0.0892 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2734 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.3011474609375\n",
            "Fold 3 RMSLE: 0.06392358833041183\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1451 - msle: 97.6017 - rmsle: 2.0976 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7846 - val_msle: 66.6470 - val_rmsle: 0.7558 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6466 - msle: 59.9804 - rmsle: 0.6215 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1501 - val_msle: 9.7046 - val_rmsle: 0.1327 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1668 - msle: 12.3303 - rmsle: 0.1508 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0946 - val_msle: 6.4876 - val_rmsle: 0.0819 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1342 - msle: 8.4514 - rmsle: 0.1224 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 6.5026 - val_rmsle: 0.0789 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1252 - msle: 8.2453 - rmsle: 0.1158 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 7.5648 - val_rmsle: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1190 - msle: 8.0532 - rmsle: 0.1108 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 6.7690 - val_rmsle: 0.0772 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1144 - msle: 7.9631 - rmsle: 0.1072 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 7.2097 - val_rmsle: 0.0802 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1110 - msle: 7.8366 - rmsle: 0.1044 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 6.9681 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1077 - msle: 7.7146 - rmsle: 0.1016 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 6.4142 - val_rmsle: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1055 - msle: 7.6605 - rmsle: 0.0997 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 6.3140 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1037 - msle: 7.5641 - rmsle: 0.0982 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 5.5149 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1016 - msle: 7.4863 - rmsle: 0.0964 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 5.0791 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.4166 - rmsle: 0.0949 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 5.1048 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.4058 - rmsle: 0.0940 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 5.2145 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0978 - msle: 7.3371 - rmsle: 0.0932 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 5.4667 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0970 - msle: 7.3124 - rmsle: 0.0924 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 5.9617 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0947 - msle: 7.1637 - rmsle: 0.0904 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8245 - val_rmsle: 0.0618 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.1659 - rmsle: 0.0902 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7289 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0935 - msle: 7.1021 - rmsle: 0.0896 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.6918 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.1368 - rmsle: 0.0892 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.6678 - val_rmsle: 0.0610 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.1145 - rmsle: 0.0891 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7402 - val_rmsle: 0.0611 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.1019 - rmsle: 0.0889 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7015 - val_rmsle: 0.0612 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0916 - msle: 7.0656 - rmsle: 0.0881 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.6780 - val_rmsle: 0.0614 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0911 - msle: 6.9904 - rmsle: 0.0877 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8267 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0902 - msle: 7.0037 - rmsle: 0.0870 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7165 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0900 - msle: 6.9794 - rmsle: 0.0870 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6851 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0897 - msle: 6.9674 - rmsle: 0.0868 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7261 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0894 - msle: 6.9472 - rmsle: 0.0866 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6762 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0893 - msle: 6.9709 - rmsle: 0.0866 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7051 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0890 - msle: 6.9537 - rmsle: 0.0863 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6827 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0887 - msle: 6.9327 - rmsle: 0.0860 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0637 - val_msle: 3.7004 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06154375842545924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:15:06,804] Trial 31 finished with value: 0.06231783750406522 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00010016840215891687, 'do_rate': 0.39538206506891804, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1472 - msle: 97.5264 - rmsle: 2.0982 - val_dense_loss: 0.0000e+00 - val_loss: 0.7794 - val_msle: 65.7907 - val_rmsle: 0.7502 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6518 - msle: 61.2903 - rmsle: 0.6264 - val_dense_loss: 0.0000e+00 - val_loss: 0.2326 - val_msle: 16.9270 - val_rmsle: 0.2162 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2528 - msle: 15.3837 - rmsle: 0.2382 - val_dense_loss: 0.0000e+00 - val_loss: 0.1354 - val_msle: 11.4990 - val_rmsle: 0.1242 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1394 - msle: 8.7283 - rmsle: 0.1286 - val_dense_loss: 0.0000e+00 - val_loss: 0.0814 - val_msle: 4.9138 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1277 - msle: 8.3840 - rmsle: 0.1184 - val_dense_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.8519 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1227 - msle: 8.2321 - rmsle: 0.1145 - val_dense_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 4.6480 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1172 - msle: 8.0865 - rmsle: 0.1097 - val_dense_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.5773 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1122 - msle: 7.9430 - rmsle: 0.1055 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.0090 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1094 - msle: 7.8391 - rmsle: 0.1031 - val_dense_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.7458 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1077 - msle: 7.7928 - rmsle: 0.1017 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.3083 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1054 - msle: 7.6836 - rmsle: 0.0997 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.3039 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.5712 - rmsle: 0.0973 - val_dense_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0233 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1018 - msle: 7.5700 - rmsle: 0.0970 - val_dense_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.8878 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.5358 - rmsle: 0.0962 - val_dense_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9582 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.5025 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.1248 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.4730 - rmsle: 0.0948 - val_dense_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0333 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.4571 - rmsle: 0.0944 - val_dense_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9231 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.4146 - rmsle: 0.0943 - val_dense_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0159 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0977 - msle: 7.4125 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.5400 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.3894 - rmsle: 0.0926 - val_dense_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.1753 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0951 - msle: 7.3274 - rmsle: 0.0914 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7281 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0946 - msle: 7.3206 - rmsle: 0.0911 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7275 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0943 - msle: 7.2805 - rmsle: 0.0909 - val_dense_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7419 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.2864 - rmsle: 0.0906 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7703 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0935 - msle: 7.2811 - rmsle: 0.0904 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7538 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.2833 - rmsle: 0.0904 - val_dense_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7261 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2669 - rmsle: 0.0900 - val_dense_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7354 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0929 - msle: 7.2537 - rmsle: 0.0899 - val_dense_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7163 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.2334 - rmsle: 0.0899 - val_dense_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7276 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.2602 - rmsle: 0.0896 - val_dense_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7189 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0922 - msle: 7.2293 - rmsle: 0.0894 - val_dense_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7289 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06251039068509633\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1461 - msle: 97.4859 - rmsle: 2.0970 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7868 - val_msle: 66.6115 - val_rmsle: 0.7572 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6543 - msle: 61.3859 - rmsle: 0.6289 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.4566 - val_msle: 44.1817 - val_rmsle: 0.4414 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.4389 - msle: 40.6640 - rmsle: 0.4260 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1552 - val_msle: 9.5161 - val_rmsle: 0.1434 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1416 - msle: 9.0079 - rmsle: 0.1302 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 4.6256 - val_rmsle: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1280 - msle: 8.4409 - rmsle: 0.1185 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.5317 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1219 - msle: 8.2765 - rmsle: 0.1135 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.3906 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.1220 - rmsle: 0.1088 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.6016 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1133 - msle: 7.9915 - rmsle: 0.1062 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.2778 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.8817 - rmsle: 0.1041 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.5541 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1079 - msle: 7.8221 - rmsle: 0.1018 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.2529 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1058 - msle: 7.7042 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.1083 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1043 - msle: 7.6294 - rmsle: 0.0987 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.1244 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.5905 - rmsle: 0.0973 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.7142 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1015 - msle: 7.5487 - rmsle: 0.0964 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.8336 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.4180 - rmsle: 0.0937 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.3546 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0977 - msle: 7.3791 - rmsle: 0.0935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.2009 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.3746 - rmsle: 0.0929 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1386 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.3722 - rmsle: 0.0928 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.2365 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0957 - msle: 7.3331 - rmsle: 0.0920 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.3913 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.2914 - rmsle: 0.0906 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8626 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0936 - msle: 7.2406 - rmsle: 0.0903 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8786 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0931 - msle: 7.2551 - rmsle: 0.0899 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8409 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2450 - rmsle: 0.0899 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8032 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.2138 - rmsle: 0.0895 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8806 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.2062 - rmsle: 0.0895 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.9083 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.2291 - rmsle: 0.0893 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.8085 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0917 - msle: 7.2012 - rmsle: 0.0889 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.9055 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0916 - msle: 7.1844 - rmsle: 0.0888 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8306 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0917 - msle: 7.2212 - rmsle: 0.0890 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.8374 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.1799 - rmsle: 0.0886 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.8493 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.1660 - rmsle: 0.0883 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7853 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 312.2988586425781\n",
            "Fold 1 RMSLE: 0.06220493148512476\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1461 - msle: 97.4004 - rmsle: 2.0972 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7841 - val_msle: 66.4189 - val_rmsle: 0.7548 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6518 - msle: 60.3321 - rmsle: 0.6268 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2440 - val_msle: 16.1390 - val_rmsle: 0.2277 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2566 - msle: 16.7552 - rmsle: 0.2420 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2136 - val_msle: 6.2331 - val_rmsle: 0.2035 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1576 - msle: 8.7860 - rmsle: 0.1472 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 5.0869 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1275 - msle: 8.3865 - rmsle: 0.1183 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 4.7267 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1216 - msle: 8.2158 - rmsle: 0.1134 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.9930 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1165 - msle: 8.0750 - rmsle: 0.1091 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 3.9437 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1131 - msle: 7.9490 - rmsle: 0.1061 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.4746 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1092 - msle: 7.8320 - rmsle: 0.1027 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 4.9512 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1071 - msle: 7.7627 - rmsle: 0.1011 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.4861 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1046 - msle: 7.6630 - rmsle: 0.0990 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.8807 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1033 - msle: 7.6256 - rmsle: 0.0979 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.9296 - val_rmsle: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1015 - msle: 7.5349 - rmsle: 0.0964 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.4947 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1002 - msle: 7.5002 - rmsle: 0.0953 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0824 - val_msle: 5.1703 - val_rmsle: 0.0776 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.3941 - rmsle: 0.0929 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7398 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.3659 - rmsle: 0.0923 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.6770 - val_rmsle: 0.0619 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0960 - msle: 7.3199 - rmsle: 0.0921 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8826 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.3225 - rmsle: 0.0915 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8766 - val_rmsle: 0.0626 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.2933 - rmsle: 0.0913 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8796 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0932 - msle: 7.2542 - rmsle: 0.0897 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.8755 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.2283 - rmsle: 0.0893 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8705 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0922 - msle: 7.2463 - rmsle: 0.0891 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8497 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.1710 - rmsle: 0.0885 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6368 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.1734 - rmsle: 0.0880 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6632 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0909 - msle: 7.1750 - rmsle: 0.0880 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6426 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0906 - msle: 7.1917 - rmsle: 0.0878 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.6393 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.1802 - rmsle: 0.0878 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7325 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.1987 - rmsle: 0.0878 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6797 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.1819 - rmsle: 0.0877 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7652 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0899 - msle: 7.1518 - rmsle: 0.0873 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0638 - val_msle: 3.6096 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0893 - msle: 7.1266 - rmsle: 0.0868 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0639 - val_msle: 3.6287 - val_rmsle: 0.0613 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06174829020345438\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1469 - msle: 97.4521 - rmsle: 2.0979 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7872 - val_msle: 66.4004 - val_rmsle: 0.7575 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6523 - msle: 60.5485 - rmsle: 0.6268 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.4552 - val_msle: 41.9281 - val_rmsle: 0.4400 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.4411 - msle: 39.7170 - rmsle: 0.4282 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1687 - val_msle: 19.4019 - val_rmsle: 0.1571 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1440 - msle: 9.2488 - rmsle: 0.1327 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.5178 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1295 - msle: 8.5133 - rmsle: 0.1199 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.3012 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1226 - msle: 8.3703 - rmsle: 0.1142 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.1436 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1181 - msle: 8.1910 - rmsle: 0.1104 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.0280 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1137 - msle: 8.0469 - rmsle: 0.1066 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.9917 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1110 - msle: 7.9324 - rmsle: 0.1042 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.2307 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1084 - msle: 7.8622 - rmsle: 0.1020 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 3.9506 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1048 - msle: 7.7117 - rmsle: 0.0988 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.5514 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1030 - msle: 7.6737 - rmsle: 0.0977 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.2389 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1021 - msle: 7.6431 - rmsle: 0.0971 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.4150 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.5975 - rmsle: 0.0966 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.4527 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1005 - msle: 7.5877 - rmsle: 0.0960 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2323 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0997 - msle: 7.5633 - rmsle: 0.0954 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.2719 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.5420 - rmsle: 0.0948 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.3992 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.5309 - rmsle: 0.0944 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6768 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.4692 - rmsle: 0.0937 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2945 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.4683 - rmsle: 0.0933 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1430 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.4727 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.6051 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.4158 - rmsle: 0.0926 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3522 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0951 - msle: 7.3493 - rmsle: 0.0915 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.0799 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0946 - msle: 7.3772 - rmsle: 0.0912 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.3058 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.3666 - rmsle: 0.0909 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0223 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0939 - msle: 7.3605 - rmsle: 0.0907 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1138 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.3599 - rmsle: 0.0906 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1735 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.3384 - rmsle: 0.0903 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.1952 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.2987 - rmsle: 0.0895 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9819 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.2870 - rmsle: 0.0894 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8265 - val_rmsle: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.2687 - rmsle: 0.0891 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0266 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06305713657279947\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 9ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1474 - msle: 97.5942 - rmsle: 2.0985 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7782 - val_msle: 66.0678 - val_rmsle: 0.7494 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6514 - msle: 60.8685 - rmsle: 0.6264 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.4604 - val_msle: 37.4823 - val_rmsle: 0.4455 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2075 - msle: 17.7918 - rmsle: 0.1919 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0981 - val_msle: 6.3285 - val_rmsle: 0.0851 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1358 - msle: 8.5392 - rmsle: 0.1237 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 5.9019 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1262 - msle: 8.2985 - rmsle: 0.1164 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0905 - val_msle: 7.0003 - val_rmsle: 0.0816 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1208 - msle: 8.1512 - rmsle: 0.1123 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 6.5947 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1156 - msle: 8.0271 - rmsle: 0.1080 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 6.2304 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1117 - msle: 7.8869 - rmsle: 0.1048 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 6.7981 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1082 - msle: 7.7658 - rmsle: 0.1018 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0848 - val_msle: 6.6849 - val_rmsle: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1042 - msle: 7.6388 - rmsle: 0.0983 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.4653 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1030 - msle: 7.5787 - rmsle: 0.0977 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.1912 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1016 - msle: 7.5461 - rmsle: 0.0967 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.1921 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.5167 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2310 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0997 - msle: 7.5006 - rmsle: 0.0952 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.3970 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0991 - msle: 7.4557 - rmsle: 0.0947 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0626 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.4451 - rmsle: 0.0940 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.5800 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0974 - msle: 7.3848 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.4902 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.3834 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9421 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.3273 - rmsle: 0.0923 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2020 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.3443 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.0646 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.3215 - rmsle: 0.0917 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.0908 - val_rmsle: 0.0630 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0941 - msle: 7.2625 - rmsle: 0.0905 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7352 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0932 - msle: 7.2132 - rmsle: 0.0898 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.6951 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.1813 - rmsle: 0.0901 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7291 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2176 - rmsle: 0.0897 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.6842 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.1864 - rmsle: 0.0896 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6930 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.1665 - rmsle: 0.0895 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.7091 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.1365 - rmsle: 0.0890 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7027 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.1557 - rmsle: 0.0891 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.7130 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0916 - msle: 7.1428 - rmsle: 0.0886 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7132 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0908 - msle: 7.0880 - rmsle: 0.0879 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.7006 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06172013176778072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:21:56,784] Trial 32 finished with value: 0.06224817614285113 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.000103427172893175, 'do_rate': 0.40056000512858025, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_loss: 0.0000e+00 - loss: 6.4886 - msle: 97.1379 - rmsle: 2.1374 - val_dense_loss: 0.0000e+00 - val_loss: 0.8140 - val_msle: 70.4712 - val_rmsle: 0.7732 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5060 - msle: 47.7374 - rmsle: 0.4602 - val_dense_loss: 0.0000e+00 - val_loss: 0.2776 - val_msle: 14.0756 - val_rmsle: 0.2126 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2491 - msle: 12.0158 - rmsle: 0.1904 - val_dense_loss: 0.0000e+00 - val_loss: 0.1875 - val_msle: 13.7843 - val_rmsle: 0.1427 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2073 - msle: 10.3563 - rmsle: 0.1649 - val_dense_loss: 0.0000e+00 - val_loss: 0.1349 - val_msle: 9.7238 - val_rmsle: 0.0989 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1904 - msle: 10.1402 - rmsle: 0.1549 - val_dense_loss: 0.0000e+00 - val_loss: 0.1298 - val_msle: 8.1304 - val_rmsle: 0.0964 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1791 - msle: 9.8382 - rmsle: 0.1471 - val_dense_loss: 0.0000e+00 - val_loss: 0.1432 - val_msle: 5.5097 - val_rmsle: 0.1117 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1718 - msle: 9.5563 - rmsle: 0.1414 - val_dense_loss: 0.0000e+00 - val_loss: 0.1833 - val_msle: 7.2456 - val_rmsle: 0.1524 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1611 - msle: 9.3191 - rmsle: 0.1338 - val_dense_loss: 0.0000e+00 - val_loss: 0.1234 - val_msle: 9.6239 - val_rmsle: 0.0919 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1552 - msle: 9.2075 - rmsle: 0.1294 - val_dense_loss: 0.0000e+00 - val_loss: 0.1179 - val_msle: 5.7772 - val_rmsle: 0.0910 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1507 - msle: 9.0394 - rmsle: 0.1259 - val_dense_loss: 0.0000e+00 - val_loss: 0.1341 - val_msle: 8.0816 - val_rmsle: 0.1079 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1454 - msle: 8.9006 - rmsle: 0.1218 - val_dense_loss: 0.0000e+00 - val_loss: 0.1276 - val_msle: 6.9884 - val_rmsle: 0.1024 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1435 - msle: 8.7867 - rmsle: 0.1201 - val_dense_loss: 0.0000e+00 - val_loss: 0.0985 - val_msle: 5.5787 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1412 - msle: 8.7143 - rmsle: 0.1175 - val_dense_loss: 0.0000e+00 - val_loss: 0.0999 - val_msle: 4.7598 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1376 - msle: 8.5164 - rmsle: 0.1144 - val_dense_loss: 0.0000e+00 - val_loss: 0.1414 - val_msle: 6.0955 - val_rmsle: 0.1180 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1349 - msle: 8.4058 - rmsle: 0.1123 - val_dense_loss: 0.0000e+00 - val_loss: 0.1164 - val_msle: 6.4341 - val_rmsle: 0.0928 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1242 - msle: 8.0658 - rmsle: 0.1063 - val_dense_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 5.5400 - val_rmsle: 0.0767 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1209 - msle: 8.0450 - rmsle: 0.1057 - val_dense_loss: 0.0000e+00 - val_loss: 0.0975 - val_msle: 8.2519 - val_rmsle: 0.0814 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1203 - msle: 7.9490 - rmsle: 0.1051 - val_dense_loss: 0.0000e+00 - val_loss: 0.1075 - val_msle: 7.8678 - val_rmsle: 0.0913 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1205 - msle: 7.9576 - rmsle: 0.1050 - val_dense_loss: 0.0000e+00 - val_loss: 0.1096 - val_msle: 4.3385 - val_rmsle: 0.0941 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1133 - msle: 7.7114 - rmsle: 0.1005 - val_dense_loss: 0.0000e+00 - val_loss: 0.0844 - val_msle: 4.1822 - val_rmsle: 0.0732 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1117 - msle: 7.6848 - rmsle: 0.1006 - val_dense_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 4.0959 - val_rmsle: 0.0729 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1114 - msle: 7.6851 - rmsle: 0.1003 - val_dense_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.6392 - val_rmsle: 0.0725 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.6415 - rmsle: 0.0999 - val_dense_loss: 0.0000e+00 - val_loss: 0.0852 - val_msle: 4.0963 - val_rmsle: 0.0742 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1097 - msle: 7.5892 - rmsle: 0.0991 - val_dense_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.1177 - val_rmsle: 0.0708 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1096 - msle: 7.5992 - rmsle: 0.0990 - val_dense_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 4.4054 - val_rmsle: 0.0700 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1093 - msle: 7.5971 - rmsle: 0.0989 - val_dense_loss: 0.0000e+00 - val_loss: 0.0876 - val_msle: 4.8920 - val_rmsle: 0.0771 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1093 - msle: 7.5908 - rmsle: 0.0989 - val_dense_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 5.9490 - val_rmsle: 0.0716 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1092 - msle: 7.5523 - rmsle: 0.0988 - val_dense_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 4.8306 - val_rmsle: 0.0706 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1056 - msle: 7.4414 - rmsle: 0.0962 - val_dense_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.1534 - val_rmsle: 0.0693 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1040 - msle: 7.4611 - rmsle: 0.0957 - val_dense_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.0853 - val_rmsle: 0.0668 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1040 - msle: 7.4121 - rmsle: 0.0959 - val_dense_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.0865 - val_rmsle: 0.0679 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0675732832076812\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 6.4916 - msle: 97.0535 - rmsle: 2.1351 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8376 - val_msle: 70.5483 - val_rmsle: 0.7952 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5094 - msle: 48.0555 - rmsle: 0.4637 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3608 - val_msle: 12.5129 - val_rmsle: 0.2999 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2495 - msle: 11.7864 - rmsle: 0.1909 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1539 - val_msle: 10.0739 - val_rmsle: 0.1115 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2076 - msle: 10.4074 - rmsle: 0.1666 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1242 - val_msle: 6.9010 - val_rmsle: 0.0887 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1915 - msle: 10.1441 - rmsle: 0.1553 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1194 - val_msle: 5.6356 - val_rmsle: 0.0846 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1772 - msle: 9.8099 - rmsle: 0.1452 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1373 - val_msle: 6.0066 - val_rmsle: 0.1063 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1680 - msle: 9.5884 - rmsle: 0.1384 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1196 - val_msle: 5.6519 - val_rmsle: 0.0908 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1622 - msle: 9.4244 - rmsle: 0.1342 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1137 - val_msle: 5.1097 - val_rmsle: 0.0863 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1568 - msle: 9.2308 - rmsle: 0.1299 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1134 - val_msle: 5.3103 - val_rmsle: 0.0881 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1540 - msle: 9.1251 - rmsle: 0.1275 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1111 - val_msle: 5.5808 - val_rmsle: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1477 - msle: 8.9957 - rmsle: 0.1226 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1149 - val_msle: 6.8618 - val_rmsle: 0.0881 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1463 - msle: 8.8323 - rmsle: 0.1209 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1116 - val_msle: 4.6675 - val_rmsle: 0.0872 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1406 - msle: 8.7003 - rmsle: 0.1170 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1185 - val_msle: 5.4729 - val_rmsle: 0.0943 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1300 - msle: 8.3507 - rmsle: 0.1113 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0964 - val_msle: 4.6351 - val_rmsle: 0.0798 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1260 - msle: 8.2731 - rmsle: 0.1094 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 4.3213 - val_rmsle: 0.0756 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1239 - msle: 8.1563 - rmsle: 0.1082 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 5.6237 - val_rmsle: 0.0766 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1233 - msle: 8.1284 - rmsle: 0.1074 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0898 - val_msle: 4.2748 - val_rmsle: 0.0741 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1218 - msle: 8.0827 - rmsle: 0.1061 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1003 - val_msle: 5.1192 - val_rmsle: 0.0848 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1204 - msle: 7.9848 - rmsle: 0.1052 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1111 - val_msle: 4.2899 - val_rmsle: 0.0957 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1200 - msle: 7.9696 - rmsle: 0.1048 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0980 - val_msle: 4.5924 - val_rmsle: 0.0833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1130 - msle: 7.7506 - rmsle: 0.1006 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.5447 - val_rmsle: 0.0720 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1118 - msle: 7.7210 - rmsle: 0.1007 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.7339 - val_rmsle: 0.0699 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1118 - msle: 7.7064 - rmsle: 0.1007 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 4.4943 - val_rmsle: 0.0689 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.6502 - rmsle: 0.0998 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.3031 - val_rmsle: 0.0677 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1103 - msle: 7.6103 - rmsle: 0.0997 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0920 - val_msle: 4.1166 - val_rmsle: 0.0814 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1103 - msle: 7.6412 - rmsle: 0.0996 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 4.7574 - val_rmsle: 0.0824 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1102 - msle: 7.6423 - rmsle: 0.0995 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 5.0466 - val_rmsle: 0.0690 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1058 - msle: 7.5047 - rmsle: 0.0964 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 4.0548 - val_rmsle: 0.0735 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1050 - msle: 7.4905 - rmsle: 0.0966 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.0757 - val_rmsle: 0.0667 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1046 - msle: 7.4877 - rmsle: 0.0964 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 3.9858 - val_rmsle: 0.0676 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1042 - msle: 7.4508 - rmsle: 0.0961 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 3.9972 - val_rmsle: 0.0681 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0756962299346924\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06723277629374155\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 6.4876 - msle: 97.0604 - rmsle: 2.1411 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.8332 - val_msle: 70.1723 - val_rmsle: 0.7907 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5193 - msle: 48.5013 - rmsle: 0.4716 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2264 - val_msle: 10.4787 - val_rmsle: 0.1664 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2506 - msle: 11.8631 - rmsle: 0.1920 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1924 - val_msle: 11.7024 - val_rmsle: 0.1452 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2085 - msle: 10.3631 - rmsle: 0.1659 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2048 - val_msle: 9.8046 - val_rmsle: 0.1695 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1882 - msle: 10.0973 - rmsle: 0.1522 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1605 - val_msle: 11.1055 - val_rmsle: 0.1232 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1770 - msle: 9.8485 - rmsle: 0.1445 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1318 - val_msle: 8.3197 - val_rmsle: 0.1039 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1695 - msle: 9.6068 - rmsle: 0.1391 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1263 - val_msle: 10.8472 - val_rmsle: 0.0984 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1634 - msle: 9.4162 - rmsle: 0.1347 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1252 - val_msle: 9.2805 - val_rmsle: 0.1005 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1564 - msle: 9.1584 - rmsle: 0.1299 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1318 - val_msle: 8.5862 - val_rmsle: 0.1061 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1506 - msle: 9.0035 - rmsle: 0.1249 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1381 - val_msle: 11.1291 - val_rmsle: 0.1167 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1461 - msle: 8.8197 - rmsle: 0.1219 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1505 - val_msle: 8.4701 - val_rmsle: 0.1259 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1330 - msle: 8.5078 - rmsle: 0.1138 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1205 - val_msle: 10.0155 - val_rmsle: 0.1033 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1301 - msle: 8.4198 - rmsle: 0.1131 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1043 - val_msle: 5.9941 - val_rmsle: 0.0868 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1285 - msle: 8.3671 - rmsle: 0.1117 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1039 - val_msle: 7.1345 - val_rmsle: 0.0869 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1259 - msle: 8.2489 - rmsle: 0.1093 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1230 - val_msle: 7.8804 - val_rmsle: 0.1057 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1260 - msle: 8.2376 - rmsle: 0.1090 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1138 - val_msle: 8.1665 - val_rmsle: 0.0977 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1238 - msle: 8.1166 - rmsle: 0.1077 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0989 - val_msle: 6.1005 - val_rmsle: 0.0825 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1220 - msle: 8.0518 - rmsle: 0.1060 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1230 - val_msle: 8.3959 - val_rmsle: 0.1079 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1214 - msle: 7.9846 - rmsle: 0.1057 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1096 - val_msle: 7.8873 - val_rmsle: 0.0941 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1202 - msle: 7.9755 - rmsle: 0.1047 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1009 - val_msle: 7.9272 - val_rmsle: 0.0860 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1133 - msle: 7.7664 - rmsle: 0.1005 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.6290 - val_rmsle: 0.0686 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1116 - msle: 7.7435 - rmsle: 0.1000 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.0594 - val_rmsle: 0.0713 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1106 - msle: 7.6554 - rmsle: 0.0994 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 4.2667 - val_rmsle: 0.0715 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1105 - msle: 7.6568 - rmsle: 0.0994 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 5.3227 - val_rmsle: 0.0757 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1071 - msle: 7.5227 - rmsle: 0.0970 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0849 - val_msle: 4.7152 - val_rmsle: 0.0757 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1053 - msle: 7.4952 - rmsle: 0.0963 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0903 - val_msle: 4.9484 - val_rmsle: 0.0814 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1053 - msle: 7.4746 - rmsle: 0.0965 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.1488 - val_rmsle: 0.0762 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1033 - msle: 7.4381 - rmsle: 0.0950 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 3.9958 - val_rmsle: 0.0701 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1023 - msle: 7.3909 - rmsle: 0.0946 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 3.9169 - val_rmsle: 0.0743 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1018 - msle: 7.3394 - rmsle: 0.0944 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 3.9115 - val_rmsle: 0.0700 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1016 - msle: 7.3506 - rmsle: 0.0943 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 3.9113 - val_rmsle: 0.0727 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06911117822608097\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 6.4844 - msle: 97.0826 - rmsle: 2.1372 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8386 - val_msle: 72.0789 - val_rmsle: 0.7957 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5109 - msle: 48.2939 - rmsle: 0.4649 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3143 - val_msle: 9.6247 - val_rmsle: 0.2519 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2432 - msle: 11.8956 - rmsle: 0.1875 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1550 - val_msle: 10.2611 - val_rmsle: 0.1128 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2104 - msle: 10.5201 - rmsle: 0.1669 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1429 - val_msle: 10.0634 - val_rmsle: 0.1075 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1920 - msle: 10.2213 - rmsle: 0.1557 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1376 - val_msle: 5.5497 - val_rmsle: 0.1052 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1787 - msle: 9.9013 - rmsle: 0.1463 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1155 - val_msle: 5.9964 - val_rmsle: 0.0858 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1676 - msle: 9.5714 - rmsle: 0.1388 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1365 - val_msle: 9.1697 - val_rmsle: 0.1096 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1657 - msle: 9.4792 - rmsle: 0.1367 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1845 - val_msle: 10.9279 - val_rmsle: 0.1565 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1570 - msle: 9.2192 - rmsle: 0.1302 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1894 - val_msle: 5.1620 - val_rmsle: 0.1641 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1431 - msle: 8.9409 - rmsle: 0.1225 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1076 - val_msle: 4.8070 - val_rmsle: 0.0884 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1369 - msle: 8.7423 - rmsle: 0.1190 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1024 - val_msle: 4.7331 - val_rmsle: 0.0849 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1350 - msle: 8.6905 - rmsle: 0.1173 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0948 - val_msle: 4.8015 - val_rmsle: 0.0780 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1328 - msle: 8.5647 - rmsle: 0.1157 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1128 - val_msle: 5.0965 - val_rmsle: 0.0957 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1318 - msle: 8.4942 - rmsle: 0.1145 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1175 - val_msle: 4.6625 - val_rmsle: 0.1000 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1306 - msle: 8.4067 - rmsle: 0.1133 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1022 - val_msle: 4.6341 - val_rmsle: 0.0864 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1219 - msle: 8.1532 - rmsle: 0.1078 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.9145 - val_rmsle: 0.0689 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1193 - msle: 8.0742 - rmsle: 0.1065 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 4.3168 - val_rmsle: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1197 - msle: 8.0452 - rmsle: 0.1071 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.8063 - val_rmsle: 0.0704 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1181 - msle: 7.9769 - rmsle: 0.1057 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 4.5357 - val_rmsle: 0.0710 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1173 - msle: 7.9128 - rmsle: 0.1052 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.0687 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 7.9005 - rmsle: 0.1044 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 5.0657 - val_rmsle: 0.0680 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1159 - msle: 7.8855 - rmsle: 0.1042 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 3.9869 - val_rmsle: 0.0670 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1158 - msle: 7.8301 - rmsle: 0.1041 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 4.3167 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1150 - msle: 7.8449 - rmsle: 0.1033 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.8975 - val_rmsle: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1142 - msle: 7.8218 - rmsle: 0.1028 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 4.0829 - val_rmsle: 0.0657 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1133 - msle: 7.7584 - rmsle: 0.1022 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.0936 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1132 - msle: 7.7627 - rmsle: 0.1020 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.1857 - val_rmsle: 0.0661 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1128 - msle: 7.7308 - rmsle: 0.1018 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.1107 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1123 - msle: 7.7223 - rmsle: 0.1014 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.0467 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1122 - msle: 7.7100 - rmsle: 0.1014 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.4271 - val_rmsle: 0.0668 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1116 - msle: 7.6845 - rmsle: 0.1009 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 3.9914 - val_rmsle: 0.0715 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06581660450615001\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 6.4861 - msle: 97.2097 - rmsle: 2.1399 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8449 - val_msle: 71.3717 - val_rmsle: 0.7980 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5136 - msle: 48.5325 - rmsle: 0.4681 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2695 - val_msle: 15.9495 - val_rmsle: 0.2109 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2382 - msle: 11.7795 - rmsle: 0.1831 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1689 - val_msle: 12.0388 - val_rmsle: 0.1261 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2049 - msle: 10.3654 - rmsle: 0.1629 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2307 - val_msle: 7.3491 - val_rmsle: 0.1901 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1857 - msle: 10.0506 - rmsle: 0.1496 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1450 - val_msle: 12.8746 - val_rmsle: 0.1125 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1767 - msle: 9.7470 - rmsle: 0.1451 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1518 - val_msle: 13.2286 - val_rmsle: 0.1198 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1656 - msle: 9.5333 - rmsle: 0.1365 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1233 - val_msle: 6.3765 - val_rmsle: 0.0979 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1607 - msle: 9.3116 - rmsle: 0.1326 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1230 - val_msle: 6.2381 - val_rmsle: 0.0973 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1516 - msle: 9.0890 - rmsle: 0.1258 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1169 - val_msle: 6.8392 - val_rmsle: 0.0912 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1470 - msle: 8.9942 - rmsle: 0.1224 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1226 - val_msle: 5.5860 - val_rmsle: 0.0942 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1451 - msle: 8.8245 - rmsle: 0.1196 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1407 - val_msle: 4.9273 - val_rmsle: 0.1171 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1399 - msle: 8.5847 - rmsle: 0.1163 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1099 - val_msle: 7.7633 - val_rmsle: 0.0863 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1367 - msle: 8.5494 - rmsle: 0.1140 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1094 - val_msle: 5.2870 - val_rmsle: 0.0833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1355 - msle: 8.4510 - rmsle: 0.1120 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1147 - val_msle: 5.9227 - val_rmsle: 0.0883 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1340 - msle: 8.3356 - rmsle: 0.1106 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1052 - val_msle: 6.4990 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1315 - msle: 8.2179 - rmsle: 0.1094 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1152 - val_msle: 4.9319 - val_rmsle: 0.0920 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1300 - msle: 8.1386 - rmsle: 0.1080 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1222 - val_msle: 4.4276 - val_rmsle: 0.0983 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1271 - msle: 7.9961 - rmsle: 0.1053 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1017 - val_msle: 5.8559 - val_rmsle: 0.0785 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1256 - msle: 7.9329 - rmsle: 0.1043 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1039 - val_msle: 6.4976 - val_rmsle: 0.0800 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1257 - msle: 7.9842 - rmsle: 0.1041 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1324 - val_msle: 10.9168 - val_rmsle: 0.1098 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1237 - msle: 7.7823 - rmsle: 0.1027 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0986 - val_msle: 6.6841 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1226 - msle: 7.7302 - rmsle: 0.1016 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1213 - val_msle: 7.5257 - val_rmsle: 0.0982 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1209 - msle: 7.6358 - rmsle: 0.1007 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1200 - val_msle: 9.1200 - val_rmsle: 0.1013 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1193 - msle: 7.5746 - rmsle: 0.1007 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1242 - val_msle: 12.0623 - val_rmsle: 0.1037 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1111 - msle: 7.3872 - rmsle: 0.0969 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1218 - val_msle: 9.0998 - val_rmsle: 0.1103 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1089 - msle: 7.3774 - rmsle: 0.0969 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1173 - val_msle: 8.3456 - val_rmsle: 0.1054 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1085 - msle: 7.3329 - rmsle: 0.0965 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0967 - val_msle: 7.3638 - val_rmsle: 0.0852 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1078 - msle: 7.2753 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0922 - val_msle: 7.5692 - val_rmsle: 0.0809 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1076 - msle: 7.2923 - rmsle: 0.0959 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0984 - val_msle: 6.1138 - val_rmsle: 0.0865 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1071 - msle: 7.2304 - rmsle: 0.0955 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 7.3153 - val_rmsle: 0.0803 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1076 - msle: 7.2367 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0963 - val_msle: 8.8174 - val_rmsle: 0.0856 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.3812475204467773\n",
            "Pred Max: 296.7373046875\n",
            "Fold 4 RMSLE: 0.07628052048709102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:28:46,194] Trial 33 finished with value: 0.06920287254414896 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.03143641529289578, 'do_rate': 0.3916743313302587, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1648 - msle: 97.5569 - rmsle: 2.0903 - val_dense_loss: 0.0000e+00 - val_loss: 0.7996 - val_msle: 67.1238 - val_rmsle: 0.7662 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6286 - msle: 60.1498 - rmsle: 0.6010 - val_dense_loss: 0.0000e+00 - val_loss: 0.2291 - val_msle: 15.3686 - val_rmsle: 0.2122 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2456 - msle: 13.0036 - rmsle: 0.2308 - val_dense_loss: 0.0000e+00 - val_loss: 0.1364 - val_msle: 10.1684 - val_rmsle: 0.1245 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1355 - msle: 8.3931 - rmsle: 0.1240 - val_dense_loss: 0.0000e+00 - val_loss: 0.0997 - val_msle: 4.3352 - val_rmsle: 0.0895 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1261 - msle: 8.1385 - rmsle: 0.1162 - val_dense_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 3.9531 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1214 - msle: 8.0179 - rmsle: 0.1124 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 3.9542 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1161 - msle: 7.8830 - rmsle: 0.1080 - val_dense_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.0631 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1115 - msle: 7.7732 - rmsle: 0.1039 - val_dense_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.0384 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1089 - msle: 7.6458 - rmsle: 0.1019 - val_dense_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.5061 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1072 - msle: 7.5766 - rmsle: 0.1004 - val_dense_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.4416 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1048 - msle: 7.4736 - rmsle: 0.0984 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 3.9319 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1019 - msle: 7.3681 - rmsle: 0.0960 - val_dense_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.9420 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1011 - msle: 7.3721 - rmsle: 0.0958 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.8619 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1000 - msle: 7.3513 - rmsle: 0.0950 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1349 - val_rmsle: 0.0629 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0989 - msle: 7.3207 - rmsle: 0.0941 - val_dense_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.2351 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.2792 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.2119 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.2131 - rmsle: 0.0920 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7544 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.1789 - rmsle: 0.0920 - val_dense_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7525 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.1796 - rmsle: 0.0918 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8011 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.1829 - rmsle: 0.0910 - val_dense_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8277 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.1697 - rmsle: 0.0911 - val_dense_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8136 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0936 - msle: 7.1406 - rmsle: 0.0900 - val_dense_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7623 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0932 - msle: 7.1006 - rmsle: 0.0897 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7921 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.1071 - rmsle: 0.0894 - val_dense_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7306 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.1109 - rmsle: 0.0894 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7481 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.1103 - rmsle: 0.0894 - val_dense_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7482 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.0971 - rmsle: 0.0893 - val_dense_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7217 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.0980 - rmsle: 0.0892 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7472 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0922 - msle: 7.0918 - rmsle: 0.0891 - val_dense_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7423 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.0783 - rmsle: 0.0884 - val_dense_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7327 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.0597 - rmsle: 0.0883 - val_dense_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7305 - val_rmsle: 0.0615 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.062266774725729196\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1669 - msle: 97.5005 - rmsle: 2.0918 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8162 - val_msle: 68.2088 - val_rmsle: 0.7815 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6540 - msle: 61.8359 - rmsle: 0.6256 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.4657 - val_msle: 44.8387 - val_rmsle: 0.4511 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2395 - msle: 21.9912 - rmsle: 0.2237 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0882 - val_msle: 5.1337 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1340 - msle: 8.3691 - rmsle: 0.1213 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.7696 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1247 - msle: 8.0750 - rmsle: 0.1142 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.7545 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1192 - msle: 7.9514 - rmsle: 0.1101 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.5625 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1146 - msle: 7.8300 - rmsle: 0.1064 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.3431 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1114 - msle: 7.6770 - rmsle: 0.1037 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.0322 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1088 - msle: 7.5622 - rmsle: 0.1017 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.6113 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1067 - msle: 7.5278 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.1170 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1045 - msle: 7.4394 - rmsle: 0.0982 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.9803 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1033 - msle: 7.3686 - rmsle: 0.0973 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.5817 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1017 - msle: 7.3233 - rmsle: 0.0959 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.5445 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.2920 - rmsle: 0.0951 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 5.0775 - val_rmsle: 0.0735 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0977 - msle: 7.1535 - rmsle: 0.0925 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 5.0223 - val_rmsle: 0.0685 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.1485 - rmsle: 0.0922 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.6988 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.1178 - rmsle: 0.0918 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.3725 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.1397 - rmsle: 0.0916 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.3993 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0951 - msle: 7.0948 - rmsle: 0.0910 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.7820 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0945 - msle: 7.0787 - rmsle: 0.0905 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.3434 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0941 - msle: 7.0334 - rmsle: 0.0902 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.5021 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.0627 - rmsle: 0.0900 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.1931 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0935 - msle: 7.0230 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0369 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0929 - msle: 6.9982 - rmsle: 0.0892 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.4050 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0927 - msle: 6.9745 - rmsle: 0.0890 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.3997 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0923 - msle: 6.9732 - rmsle: 0.0887 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1686 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0918 - msle: 6.9741 - rmsle: 0.0882 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.1322 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0918 - msle: 6.9585 - rmsle: 0.0883 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2785 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0917 - msle: 6.9607 - rmsle: 0.0882 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1818 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0897 - msle: 6.8686 - rmsle: 0.0864 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.8647 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0892 - msle: 6.8597 - rmsle: 0.0861 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8345 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.1706848144531\n",
            "Fold 1 RMSLE: 0.06223635060828943\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1655 - msle: 97.4093 - rmsle: 2.0908 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7976 - val_msle: 67.4070 - val_rmsle: 0.7634 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6518 - msle: 60.8374 - rmsle: 0.6242 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.4439 - val_msle: 40.5669 - val_rmsle: 0.4296 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3353 - msle: 32.3345 - rmsle: 0.3218 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1039 - val_msle: 4.6253 - val_rmsle: 0.0908 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1317 - msle: 8.2771 - rmsle: 0.1195 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 5.0963 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1235 - msle: 8.0923 - rmsle: 0.1135 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0864 - val_msle: 5.1733 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1183 - msle: 7.9427 - rmsle: 0.1093 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 5.1601 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1138 - msle: 7.7810 - rmsle: 0.1057 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 5.1201 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1108 - msle: 7.6850 - rmsle: 0.1032 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 4.6344 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1073 - msle: 7.5696 - rmsle: 0.1002 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0865 - val_msle: 5.1700 - val_rmsle: 0.0797 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1058 - msle: 7.5252 - rmsle: 0.0991 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.9527 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1034 - msle: 7.4290 - rmsle: 0.0972 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.6300 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1003 - msle: 7.3059 - rmsle: 0.0947 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.4481 - val_rmsle: 0.0701 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.2746 - rmsle: 0.0941 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 3.9450 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0984 - msle: 7.2513 - rmsle: 0.0936 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.3072 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.2301 - rmsle: 0.0930 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.0679 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.2205 - rmsle: 0.0926 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.8009 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0966 - msle: 7.1678 - rmsle: 0.0923 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.7558 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0958 - msle: 7.1760 - rmsle: 0.0916 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 3.7236 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0954 - msle: 7.1355 - rmsle: 0.0912 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.7369 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.1494 - rmsle: 0.0908 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.6995 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.1068 - rmsle: 0.0902 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.7033 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.1122 - rmsle: 0.0899 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.6989 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0919 - msle: 6.9894 - rmsle: 0.0882 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8120 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0912 - msle: 6.9917 - rmsle: 0.0876 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.6378 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0910 - msle: 6.9835 - rmsle: 0.0876 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8002 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0908 - msle: 6.9972 - rmsle: 0.0875 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7287 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0904 - msle: 6.9803 - rmsle: 0.0872 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7150 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0897 - msle: 6.9588 - rmsle: 0.0866 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7204 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0894 - msle: 6.9511 - rmsle: 0.0864 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8212 - val_rmsle: 0.0628 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0892 - msle: 6.9259 - rmsle: 0.0863 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7264 - val_rmsle: 0.0621 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0888 - msle: 6.9366 - rmsle: 0.0860 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8542 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06196772420042303\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1655 - msle: 97.4779 - rmsle: 2.0907 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8051 - val_msle: 67.7816 - val_rmsle: 0.7707 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6510 - msle: 61.1388 - rmsle: 0.6229 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.4556 - val_msle: 42.4221 - val_rmsle: 0.4410 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.4378 - msle: 40.6854 - rmsle: 0.4256 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1661 - val_msle: 18.1769 - val_rmsle: 0.1527 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1410 - msle: 8.7998 - rmsle: 0.1283 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.3503 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1265 - msle: 8.2166 - rmsle: 0.1161 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.3376 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1211 - msle: 8.1013 - rmsle: 0.1120 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.1848 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1161 - msle: 7.9194 - rmsle: 0.1079 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.0810 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1125 - msle: 7.8079 - rmsle: 0.1049 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.1030 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1101 - msle: 7.7019 - rmsle: 0.1028 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.0974 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1075 - msle: 7.6362 - rmsle: 0.1005 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.0008 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1056 - msle: 7.5375 - rmsle: 0.0989 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.0243 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1035 - msle: 7.4509 - rmsle: 0.0972 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.9690 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1021 - msle: 7.3786 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.1946 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1009 - msle: 7.3264 - rmsle: 0.0952 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 3.8652 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1000 - msle: 7.3005 - rmsle: 0.0944 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 3.9923 - val_rmsle: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0989 - msle: 7.2523 - rmsle: 0.0935 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.0758 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.2259 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.0138 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0974 - msle: 7.1874 - rmsle: 0.0923 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.0907 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.0808 - rmsle: 0.0902 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 5.0647 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.0735 - rmsle: 0.0898 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.3564 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.0821 - rmsle: 0.0893 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.5545 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.0396 - rmsle: 0.0892 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.5436 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.0178 - rmsle: 0.0891 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.4490 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.0583 - rmsle: 0.0888 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.4842 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.0152 - rmsle: 0.0885 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.2394 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.0002 - rmsle: 0.0879 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.3679 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0912 - msle: 7.0072 - rmsle: 0.0878 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.2900 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0910 - msle: 6.9761 - rmsle: 0.0876 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1936 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0907 - msle: 6.9625 - rmsle: 0.0874 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0323 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0908 - msle: 6.9428 - rmsle: 0.0875 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.4071 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0906 - msle: 6.9402 - rmsle: 0.0872 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.5799 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06414833075762068\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1665 - msle: 97.5746 - rmsle: 2.0919 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7926 - val_msle: 66.9434 - val_rmsle: 0.7588 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6541 - msle: 61.7365 - rmsle: 0.6264 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.4613 - val_msle: 44.0265 - val_rmsle: 0.4470 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.4422 - msle: 41.5067 - rmsle: 0.4301 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2777 - val_msle: 17.5026 - val_rmsle: 0.2672 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1498 - msle: 9.9119 - rmsle: 0.1382 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 4.7325 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1262 - msle: 8.1555 - rmsle: 0.1159 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 5.7912 - val_rmsle: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1196 - msle: 7.9694 - rmsle: 0.1105 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 5.6701 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1159 - msle: 7.9087 - rmsle: 0.1076 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0893 - val_msle: 6.0088 - val_rmsle: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1120 - msle: 7.7145 - rmsle: 0.1043 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 6.1211 - val_rmsle: 0.0799 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1087 - msle: 7.6333 - rmsle: 0.1016 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0863 - val_msle: 5.9418 - val_rmsle: 0.0794 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1041 - msle: 7.4355 - rmsle: 0.0975 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 5.0446 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1025 - msle: 7.3880 - rmsle: 0.0966 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.7951 - val_rmsle: 0.0684 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.3759 - rmsle: 0.0958 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.3072 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1001 - msle: 7.3424 - rmsle: 0.0948 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.4862 - val_rmsle: 0.0658 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0991 - msle: 7.3270 - rmsle: 0.0941 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.7132 - val_rmsle: 0.0689 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.2833 - rmsle: 0.0938 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.9201 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.2117 - rmsle: 0.0921 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7345 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0961 - msle: 7.1578 - rmsle: 0.0917 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7194 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0960 - msle: 7.1851 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7859 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.1197 - rmsle: 0.0912 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7237 - val_rmsle: 0.0610 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.1505 - rmsle: 0.0907 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7199 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0947 - msle: 7.1378 - rmsle: 0.0908 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7001 - val_rmsle: 0.0609 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0944 - msle: 7.1372 - rmsle: 0.0906 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7011 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.1085 - rmsle: 0.0899 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.6849 - val_rmsle: 0.0611 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.0890 - rmsle: 0.0903 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7557 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.0587 - rmsle: 0.0892 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6869 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.0251 - rmsle: 0.0889 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6861 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.0397 - rmsle: 0.0889 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.7125 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.0102 - rmsle: 0.0885 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.6991 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.0314 - rmsle: 0.0887 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.6942 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.0365 - rmsle: 0.0883 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6723 - val_rmsle: 0.0607 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.0154 - rmsle: 0.0882 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0641 - val_msle: 3.7006 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06142327463850106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:35:36,862] Trial 34 finished with value: 0.062408490986112675 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00017059785798002538, 'do_rate': 0.3733127784757884, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_loss: 0.0000e+00 - loss: 2.0426 - msle: 93.2358 - rmsle: 2.0337 - val_dense_loss: 0.0000e+00 - val_loss: 0.3332 - val_msle: 36.5351 - val_rmsle: 0.3208 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.2523 - msle: 23.8392 - rmsle: 0.2397 - val_dense_loss: 0.0000e+00 - val_loss: 0.1546 - val_msle: 7.3324 - val_rmsle: 0.1424 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1680 - msle: 8.0199 - rmsle: 0.1562 - val_dense_loss: 0.0000e+00 - val_loss: 0.1239 - val_msle: 6.8835 - val_rmsle: 0.1128 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1575 - msle: 7.7987 - rmsle: 0.1466 - val_dense_loss: 0.0000e+00 - val_loss: 0.1313 - val_msle: 6.4784 - val_rmsle: 0.1209 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1495 - msle: 7.7139 - rmsle: 0.1394 - val_dense_loss: 0.0000e+00 - val_loss: 0.1139 - val_msle: 6.1172 - val_rmsle: 0.1040 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1421 - msle: 7.5840 - rmsle: 0.1325 - val_dense_loss: 0.0000e+00 - val_loss: 0.1077 - val_msle: 5.7411 - val_rmsle: 0.0983 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1362 - msle: 7.5025 - rmsle: 0.1270 - val_dense_loss: 0.0000e+00 - val_loss: 0.0962 - val_msle: 5.5837 - val_rmsle: 0.0872 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1294 - msle: 7.4038 - rmsle: 0.1206 - val_dense_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 5.4573 - val_rmsle: 0.0789 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1246 - msle: 7.3180 - rmsle: 0.1162 - val_dense_loss: 0.0000e+00 - val_loss: 0.0898 - val_msle: 5.2662 - val_rmsle: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1195 - msle: 7.2531 - rmsle: 0.1115 - val_dense_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 5.0009 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1153 - msle: 7.2079 - rmsle: 0.1075 - val_dense_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 4.9501 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1114 - msle: 7.1123 - rmsle: 0.1040 - val_dense_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.7904 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1081 - msle: 7.0699 - rmsle: 0.1011 - val_dense_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.6753 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1044 - msle: 6.9681 - rmsle: 0.0976 - val_dense_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 4.9694 - val_rmsle: 0.0701 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1027 - msle: 6.9462 - rmsle: 0.0961 - val_dense_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.9784 - val_rmsle: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1012 - msle: 6.9014 - rmsle: 0.0949 - val_dense_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 4.8900 - val_rmsle: 0.0706 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1004 - msle: 6.8543 - rmsle: 0.0943 - val_dense_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.8624 - val_rmsle: 0.0712 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0992 - msle: 6.8366 - rmsle: 0.0933 - val_dense_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.6890 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0978 - msle: 6.7959 - rmsle: 0.0922 - val_dense_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.5824 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0969 - msle: 6.7583 - rmsle: 0.0914 - val_dense_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.5713 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0959 - msle: 6.7291 - rmsle: 0.0906 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.4720 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0950 - msle: 6.6893 - rmsle: 0.0899 - val_dense_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.5239 - val_rmsle: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0945 - msle: 6.6497 - rmsle: 0.0895 - val_dense_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.3834 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0936 - msle: 6.6239 - rmsle: 0.0887 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.3690 - val_rmsle: 0.0674 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0928 - msle: 6.5932 - rmsle: 0.0882 - val_dense_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.3389 - val_rmsle: 0.0673 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0925 - msle: 6.5470 - rmsle: 0.0880 - val_dense_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.3146 - val_rmsle: 0.0671 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0919 - msle: 6.5294 - rmsle: 0.0875 - val_dense_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.2875 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0910 - msle: 6.4980 - rmsle: 0.0867 - val_dense_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.2772 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0905 - msle: 6.4663 - rmsle: 0.0863 - val_dense_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.2646 - val_rmsle: 0.0674 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0902 - msle: 6.4221 - rmsle: 0.0862 - val_dense_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2387 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0896 - msle: 6.4231 - rmsle: 0.0856 - val_dense_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.2316 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.2309558391571045\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0658075293921034\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 9ms/step - dense_1_loss: 0.0000e+00 - loss: 2.0403 - msle: 93.2795 - rmsle: 2.0315 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3321 - val_msle: 37.1735 - val_rmsle: 0.3197 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2572 - msle: 24.4039 - rmsle: 0.2445 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1025 - val_msle: 6.9188 - val_rmsle: 0.0904 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1678 - msle: 8.0077 - rmsle: 0.1560 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0965 - val_msle: 6.9786 - val_rmsle: 0.0854 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1573 - msle: 7.8342 - rmsle: 0.1465 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0883 - val_msle: 6.3160 - val_rmsle: 0.0779 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1492 - msle: 7.6995 - rmsle: 0.1391 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 6.1431 - val_rmsle: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1431 - msle: 7.6090 - rmsle: 0.1335 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0855 - val_msle: 6.0100 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1356 - msle: 7.5585 - rmsle: 0.1264 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 5.6706 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1299 - msle: 7.4111 - rmsle: 0.1211 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 5.5248 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1250 - msle: 7.3330 - rmsle: 0.1166 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 5.4081 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1201 - msle: 7.2804 - rmsle: 0.1121 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 5.3787 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1155 - msle: 7.1806 - rmsle: 0.1078 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 5.3707 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1116 - msle: 7.1285 - rmsle: 0.1042 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.9994 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1091 - msle: 7.0689 - rmsle: 0.1021 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.9293 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1055 - msle: 6.9799 - rmsle: 0.0988 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.7721 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1027 - msle: 6.9485 - rmsle: 0.0963 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.6748 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1009 - msle: 6.8930 - rmsle: 0.0948 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.5945 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0987 - msle: 6.8163 - rmsle: 0.0929 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.5570 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0968 - msle: 6.7483 - rmsle: 0.0912 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.5086 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0955 - msle: 6.7065 - rmsle: 0.0902 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.4896 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0942 - msle: 6.6377 - rmsle: 0.0891 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.4581 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0929 - msle: 6.5732 - rmsle: 0.0881 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.5202 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0910 - msle: 6.4977 - rmsle: 0.0863 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.5451 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0901 - msle: 6.4458 - rmsle: 0.0857 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.4048 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0895 - msle: 6.3991 - rmsle: 0.0852 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.4058 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0893 - msle: 6.3857 - rmsle: 0.0851 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.3969 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0887 - msle: 6.3547 - rmsle: 0.0847 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.3402 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0875 - msle: 6.2990 - rmsle: 0.0837 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.4820 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0871 - msle: 6.2926 - rmsle: 0.0833 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.5078 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0870 - msle: 6.2637 - rmsle: 0.0833 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.4377 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0868 - msle: 6.2341 - rmsle: 0.0831 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.3831 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0865 - msle: 6.2254 - rmsle: 0.0829 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.3970 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 310.51947021484375\n",
            "Fold 1 RMSLE: 0.06437897228404797\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_2_loss: 0.0000e+00 - loss: 2.0391 - msle: 93.1422 - rmsle: 2.0302 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3256 - val_msle: 35.9833 - val_rmsle: 0.3130 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2476 - msle: 23.4598 - rmsle: 0.2348 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1484 - val_msle: 6.4023 - val_rmsle: 0.1363 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1641 - msle: 7.9507 - rmsle: 0.1523 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1491 - val_msle: 5.5863 - val_rmsle: 0.1379 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1552 - msle: 7.7970 - rmsle: 0.1443 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1295 - val_msle: 5.5102 - val_rmsle: 0.1190 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1469 - msle: 7.6758 - rmsle: 0.1367 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1301 - val_msle: 5.6712 - val_rmsle: 0.1202 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1416 - msle: 7.6166 - rmsle: 0.1318 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1068 - val_msle: 5.2122 - val_rmsle: 0.0973 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1335 - msle: 7.5050 - rmsle: 0.1243 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0958 - val_msle: 5.1476 - val_rmsle: 0.0868 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1274 - msle: 7.4114 - rmsle: 0.1186 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 5.0221 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1222 - msle: 7.3158 - rmsle: 0.1137 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1018 - val_msle: 5.0790 - val_rmsle: 0.0936 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1188 - msle: 7.2811 - rmsle: 0.1107 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 5.0334 - val_rmsle: 0.0789 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1139 - msle: 7.1842 - rmsle: 0.1062 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 4.8512 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1104 - msle: 7.1348 - rmsle: 0.1030 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.8729 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1075 - msle: 7.0507 - rmsle: 0.1004 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.6390 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1046 - msle: 6.9979 - rmsle: 0.0979 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 4.7048 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1022 - msle: 6.9467 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 4.7771 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1003 - msle: 6.8983 - rmsle: 0.0942 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.4666 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0985 - msle: 6.8188 - rmsle: 0.0926 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.5459 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0968 - msle: 6.7680 - rmsle: 0.0912 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.5302 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0949 - msle: 6.6914 - rmsle: 0.0895 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.4592 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0941 - msle: 6.6325 - rmsle: 0.0889 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.4255 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0927 - msle: 6.5727 - rmsle: 0.0877 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.4518 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0916 - msle: 6.5066 - rmsle: 0.0869 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.3905 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0895 - msle: 6.4039 - rmsle: 0.0850 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.3120 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0889 - msle: 6.3570 - rmsle: 0.0845 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.2629 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0885 - msle: 6.3462 - rmsle: 0.0843 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.1754 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0881 - msle: 6.3105 - rmsle: 0.0840 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.1434 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0878 - msle: 6.3048 - rmsle: 0.0838 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.1053 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0873 - msle: 6.2724 - rmsle: 0.0835 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1249 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0862 - msle: 6.1990 - rmsle: 0.0825 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.0429 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0856 - msle: 6.1815 - rmsle: 0.0820 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.0350 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0855 - msle: 6.1569 - rmsle: 0.0819 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.0135 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.3572838306427002\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06531939746676796\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_3_loss: 0.0000e+00 - loss: 2.0428 - msle: 93.3509 - rmsle: 2.0340 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3244 - val_msle: 36.4236 - val_rmsle: 0.3119 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2539 - msle: 24.2736 - rmsle: 0.2411 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0973 - val_msle: 6.9563 - val_rmsle: 0.0852 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1696 - msle: 8.0673 - rmsle: 0.1578 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0919 - val_msle: 6.5226 - val_rmsle: 0.0807 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1592 - msle: 7.9364 - rmsle: 0.1483 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 6.1618 - val_rmsle: 0.0770 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1509 - msle: 7.7982 - rmsle: 0.1406 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0876 - val_msle: 5.9957 - val_rmsle: 0.0776 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1443 - msle: 7.6983 - rmsle: 0.1345 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 5.6945 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1365 - msle: 7.6200 - rmsle: 0.1272 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0823 - val_msle: 5.9642 - val_rmsle: 0.0732 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1318 - msle: 7.5179 - rmsle: 0.1229 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 5.6069 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1266 - msle: 7.4437 - rmsle: 0.1180 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 5.5003 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1214 - msle: 7.3569 - rmsle: 0.1131 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 5.4815 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1173 - msle: 7.2986 - rmsle: 0.1094 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 5.2435 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1113 - msle: 7.1296 - rmsle: 0.1037 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 5.2077 - val_rmsle: 0.0734 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1092 - msle: 7.1007 - rmsle: 0.1019 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 5.3569 - val_rmsle: 0.0701 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1077 - msle: 7.0736 - rmsle: 0.1006 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 5.2178 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1062 - msle: 7.0400 - rmsle: 0.0994 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 5.1819 - val_rmsle: 0.0686 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1043 - msle: 7.0139 - rmsle: 0.0977 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 5.1068 - val_rmsle: 0.0673 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1033 - msle: 6.9732 - rmsle: 0.0969 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.0038 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1017 - msle: 6.9219 - rmsle: 0.0955 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.8472 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1004 - msle: 6.8873 - rmsle: 0.0945 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.9180 - val_rmsle: 0.0672 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0995 - msle: 6.8519 - rmsle: 0.0937 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 5.2593 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0980 - msle: 6.8544 - rmsle: 0.0924 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.8887 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0962 - msle: 6.7758 - rmsle: 0.0907 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.7148 - val_rmsle: 0.0676 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0956 - msle: 6.7242 - rmsle: 0.0903 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.7674 - val_rmsle: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0950 - msle: 6.7352 - rmsle: 0.0898 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.6982 - val_rmsle: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0945 - msle: 6.7110 - rmsle: 0.0894 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.6693 - val_rmsle: 0.0661 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0940 - msle: 6.6759 - rmsle: 0.0890 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.6757 - val_rmsle: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 6.6667 - rmsle: 0.0888 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.6082 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0933 - msle: 6.6443 - rmsle: 0.0885 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.6861 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0925 - msle: 6.6218 - rmsle: 0.0877 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.4392 - val_rmsle: 0.0645 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0923 - msle: 6.6086 - rmsle: 0.0876 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.4159 - val_rmsle: 0.0646 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0920 - msle: 6.6010 - rmsle: 0.0874 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.4494 - val_rmsle: 0.0647 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.7345275878906\n",
            "Fold 3 RMSLE: 0.06534748029727368\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 7ms/step - dense_4_loss: 0.0000e+00 - loss: 2.0414 - msle: 93.4356 - rmsle: 2.0325 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3288 - val_msle: 36.5221 - val_rmsle: 0.3163 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2542 - msle: 24.2737 - rmsle: 0.2415 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1022 - val_msle: 6.5719 - val_rmsle: 0.0900 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1672 - msle: 7.9781 - rmsle: 0.1554 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1195 - val_msle: 5.9037 - val_rmsle: 0.1082 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1567 - msle: 7.7688 - rmsle: 0.1457 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0995 - val_msle: 5.4854 - val_rmsle: 0.0890 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1492 - msle: 7.6759 - rmsle: 0.1389 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1033 - val_msle: 5.3603 - val_rmsle: 0.0933 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1419 - msle: 7.5636 - rmsle: 0.1321 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1012 - val_msle: 5.3521 - val_rmsle: 0.0916 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1355 - msle: 7.4835 - rmsle: 0.1261 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 5.2831 - val_rmsle: 0.0797 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1290 - msle: 7.3966 - rmsle: 0.1200 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 4.9932 - val_rmsle: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1249 - msle: 7.3146 - rmsle: 0.1163 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 5.0550 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1201 - msle: 7.2317 - rmsle: 0.1119 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 5.0171 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1162 - msle: 7.1756 - rmsle: 0.1083 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 4.9558 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1122 - msle: 7.0982 - rmsle: 0.1047 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 4.9303 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1091 - msle: 7.0484 - rmsle: 0.1019 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.8302 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1057 - msle: 6.9574 - rmsle: 0.0987 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 5.0817 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1040 - msle: 6.9382 - rmsle: 0.0974 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.9986 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 6.8615 - rmsle: 0.0950 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 5.0433 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0995 - msle: 6.8184 - rmsle: 0.0935 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 5.1202 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0976 - msle: 6.7570 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.9622 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0963 - msle: 6.7011 - rmsle: 0.0908 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.0782 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0949 - msle: 6.6315 - rmsle: 0.0896 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 5.0373 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0934 - msle: 6.5674 - rmsle: 0.0883 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 5.2531 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0926 - msle: 6.5156 - rmsle: 0.0877 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.2004 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0916 - msle: 6.4781 - rmsle: 0.0870 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.1748 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0892 - msle: 6.3716 - rmsle: 0.0848 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.4731 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0890 - msle: 6.3168 - rmsle: 0.0847 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.3352 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0883 - msle: 6.2677 - rmsle: 0.0842 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3895 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0876 - msle: 6.2449 - rmsle: 0.0836 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.2736 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0876 - msle: 6.2314 - rmsle: 0.0837 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.3843 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0869 - msle: 6.2120 - rmsle: 0.0832 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.3412 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0866 - msle: 6.1882 - rmsle: 0.0830 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3338 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0863 - msle: 6.1644 - rmsle: 0.0827 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3306 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06428711606062519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:41:49,630] Trial 35 finished with value: 0.06502809910016363 and parameters: {'units': 1024, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0003051197674310691, 'do_rate': 0.43873993490106994, 'hidden_layers': 1}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.4187 - msle: 98.7008 - rmsle: 2.3350 - val_dense_loss: 0.0000e+00 - val_loss: 0.7873 - val_msle: 68.8559 - val_rmsle: 0.7391 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5506 - msle: 53.8235 - rmsle: 0.5112 - val_dense_loss: 0.0000e+00 - val_loss: 0.1314 - val_msle: 13.8980 - val_rmsle: 0.1081 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1676 - msle: 13.7420 - rmsle: 0.1464 - val_dense_loss: 0.0000e+00 - val_loss: 0.0999 - val_msle: 6.9712 - val_rmsle: 0.0836 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1373 - msle: 10.5650 - rmsle: 0.1220 - val_dense_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 4.8182 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1281 - msle: 10.1545 - rmsle: 0.1157 - val_dense_loss: 0.0000e+00 - val_loss: 0.0933 - val_msle: 4.5682 - val_rmsle: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1229 - msle: 9.8866 - rmsle: 0.1122 - val_dense_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 4.1442 - val_rmsle: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1191 - msle: 9.6892 - rmsle: 0.1096 - val_dense_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 4.8177 - val_rmsle: 0.0752 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1166 - msle: 9.5526 - rmsle: 0.1079 - val_dense_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 4.2095 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1149 - msle: 9.4616 - rmsle: 0.1067 - val_dense_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 4.5359 - val_rmsle: 0.0691 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1131 - msle: 9.3455 - rmsle: 0.1053 - val_dense_loss: 0.0000e+00 - val_loss: 0.0861 - val_msle: 5.5230 - val_rmsle: 0.0785 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1114 - msle: 9.2937 - rmsle: 0.1040 - val_dense_loss: 0.0000e+00 - val_loss: 0.0840 - val_msle: 5.5691 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1104 - msle: 9.2445 - rmsle: 0.1032 - val_dense_loss: 0.0000e+00 - val_loss: 0.0908 - val_msle: 4.0840 - val_rmsle: 0.0837 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1069 - msle: 9.1229 - rmsle: 0.1001 - val_dense_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 3.8953 - val_rmsle: 0.0667 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1057 - msle: 9.0619 - rmsle: 0.0995 - val_dense_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 3.9935 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1045 - msle: 9.0164 - rmsle: 0.0986 - val_dense_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 3.9185 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1039 - msle: 8.9856 - rmsle: 0.0983 - val_dense_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 3.9134 - val_rmsle: 0.0672 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1034 - msle: 8.9792 - rmsle: 0.0980 - val_dense_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 3.8412 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1030 - msle: 8.9693 - rmsle: 0.0977 - val_dense_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.5463 - val_rmsle: 0.0677 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.9183 - rmsle: 0.0964 - val_dense_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.8287 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.9282 - rmsle: 0.0962 - val_dense_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 3.9414 - val_rmsle: 0.0657 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1002 - msle: 8.8723 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9728 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1001 - msle: 8.8633 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 3.8821 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.8267 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.8181 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0990 - msle: 8.8429 - rmsle: 0.0948 - val_dense_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 3.9849 - val_rmsle: 0.0661 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0992 - msle: 8.8474 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0617 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0985 - msle: 8.8174 - rmsle: 0.0945 - val_dense_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.8841 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.7763 - rmsle: 0.0936 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8111 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0974 - msle: 8.7844 - rmsle: 0.0935 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8042 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0968 - msle: 8.7183 - rmsle: 0.0930 - val_dense_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8111 - val_rmsle: 0.0631 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0968 - msle: 8.7222 - rmsle: 0.0931 - val_dense_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8175 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0965 - msle: 8.7468 - rmsle: 0.0929 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8635 - val_rmsle: 0.0628 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06277273455121814\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.4122 - msle: 98.6153 - rmsle: 2.3285 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7828 - val_msle: 68.4658 - val_rmsle: 0.7347 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5490 - msle: 53.7383 - rmsle: 0.5097 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1398 - val_msle: 14.6118 - val_rmsle: 0.1166 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1663 - msle: 13.6066 - rmsle: 0.1453 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1195 - val_msle: 8.1225 - val_rmsle: 0.1032 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1374 - msle: 10.5575 - rmsle: 0.1221 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1053 - val_msle: 7.2868 - val_rmsle: 0.0922 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1285 - msle: 10.1565 - rmsle: 0.1161 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0944 - val_msle: 6.8313 - val_rmsle: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1236 - msle: 9.9034 - rmsle: 0.1127 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0904 - val_msle: 5.7694 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1195 - msle: 9.7373 - rmsle: 0.1098 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 4.8816 - val_rmsle: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1172 - msle: 9.5832 - rmsle: 0.1082 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0930 - val_msle: 7.7349 - val_rmsle: 0.0844 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1149 - msle: 9.5189 - rmsle: 0.1065 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0928 - val_msle: 5.9707 - val_rmsle: 0.0845 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1135 - msle: 9.4351 - rmsle: 0.1054 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 6.9617 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1120 - msle: 9.3149 - rmsle: 0.1043 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 5.9744 - val_rmsle: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1101 - msle: 9.2322 - rmsle: 0.1027 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 4.4941 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1097 - msle: 9.2307 - rmsle: 0.1026 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 5.4877 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1092 - msle: 9.1772 - rmsle: 0.1022 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 5.6200 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1078 - msle: 9.1136 - rmsle: 0.1010 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.4870 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1071 - msle: 9.0606 - rmsle: 0.1004 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.0218 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1061 - msle: 9.0841 - rmsle: 0.0996 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.4294 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1060 - msle: 9.0386 - rmsle: 0.0995 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.6279 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1062 - msle: 9.0422 - rmsle: 0.0997 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.2839 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1030 - msle: 8.9141 - rmsle: 0.0968 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 5.3764 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1022 - msle: 8.8925 - rmsle: 0.0965 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 5.0194 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.8557 - rmsle: 0.0961 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 5.6528 - val_rmsle: 0.0702 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0993 - msle: 8.7836 - rmsle: 0.0941 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.6955 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0986 - msle: 8.7779 - rmsle: 0.0938 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0578 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0984 - msle: 8.7450 - rmsle: 0.0939 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1515 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0978 - msle: 8.7212 - rmsle: 0.0934 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3449 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.7392 - rmsle: 0.0933 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.3500 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0974 - msle: 8.7304 - rmsle: 0.0934 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.1911 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.7101 - rmsle: 0.0931 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.1518 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.6916 - rmsle: 0.0928 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.5222 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0964 - msle: 8.6741 - rmsle: 0.0926 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.4368 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06300525796994395\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.4186 - msle: 98.5525 - rmsle: 2.3349 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7640 - val_msle: 67.3885 - val_rmsle: 0.7157 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5438 - msle: 53.1050 - rmsle: 0.5042 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1244 - val_msle: 10.9777 - val_rmsle: 0.1012 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1640 - msle: 13.3201 - rmsle: 0.1430 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0995 - val_msle: 6.9287 - val_rmsle: 0.0835 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1351 - msle: 10.4825 - rmsle: 0.1201 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1005 - val_msle: 7.6892 - val_rmsle: 0.0878 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1274 - msle: 10.1231 - rmsle: 0.1152 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0910 - val_msle: 6.2894 - val_rmsle: 0.0800 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1223 - msle: 9.8703 - rmsle: 0.1117 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 4.8133 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1189 - msle: 9.6723 - rmsle: 0.1094 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 5.0485 - val_rmsle: 0.0799 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1159 - msle: 9.5408 - rmsle: 0.1071 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 5.9216 - val_rmsle: 0.0763 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1140 - msle: 9.4165 - rmsle: 0.1058 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 6.2167 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1118 - msle: 9.3215 - rmsle: 0.1040 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 5.3404 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1106 - msle: 9.2535 - rmsle: 0.1032 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 5.0886 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1093 - msle: 9.2098 - rmsle: 0.1022 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.1455 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1085 - msle: 9.1652 - rmsle: 0.1015 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 4.2592 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1077 - msle: 9.1086 - rmsle: 0.1009 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 3.9088 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1065 - msle: 9.0776 - rmsle: 0.0999 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.9776 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1063 - msle: 9.0259 - rmsle: 0.0998 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.3192 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1058 - msle: 9.0151 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.5020 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.8587 - rmsle: 0.0967 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.7954 - val_rmsle: 0.0673 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1018 - msle: 8.8436 - rmsle: 0.0961 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 3.7846 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.8457 - rmsle: 0.0962 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.0576 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1006 - msle: 8.7896 - rmsle: 0.0955 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.5428 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.8019 - rmsle: 0.0955 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 3.8676 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0984 - msle: 8.7349 - rmsle: 0.0936 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.6326 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0977 - msle: 8.6991 - rmsle: 0.0932 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.6190 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0974 - msle: 8.7113 - rmsle: 0.0931 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.6465 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.6722 - rmsle: 0.0929 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.6339 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.6931 - rmsle: 0.0927 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.6590 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0964 - msle: 8.6365 - rmsle: 0.0924 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.6606 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0962 - msle: 8.6591 - rmsle: 0.0923 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.6686 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0962 - msle: 8.6447 - rmsle: 0.0924 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.8229 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0948 - msle: 8.6046 - rmsle: 0.0912 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.6273 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061748848799680865\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.4128 - msle: 98.6023 - rmsle: 2.3291 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7678 - val_msle: 67.6000 - val_rmsle: 0.7198 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5381 - msle: 52.8497 - rmsle: 0.4989 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1416 - val_msle: 15.8380 - val_rmsle: 0.1189 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1631 - msle: 13.2621 - rmsle: 0.1426 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1197 - val_msle: 10.2004 - val_rmsle: 0.1039 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1359 - msle: 10.4958 - rmsle: 0.1211 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0941 - val_msle: 7.0792 - val_rmsle: 0.0816 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1274 - msle: 10.1001 - rmsle: 0.1154 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0864 - val_msle: 5.8217 - val_rmsle: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1222 - msle: 9.8017 - rmsle: 0.1119 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 4.5365 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1187 - msle: 9.6668 - rmsle: 0.1094 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0942 - val_msle: 6.1800 - val_rmsle: 0.0854 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1159 - msle: 9.5189 - rmsle: 0.1073 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 5.3205 - val_rmsle: 0.0795 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1125 - msle: 9.3390 - rmsle: 0.1044 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 5.7265 - val_rmsle: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1108 - msle: 9.2701 - rmsle: 0.1035 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 5.3452 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1095 - msle: 9.2082 - rmsle: 0.1027 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.5858 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1085 - msle: 9.2224 - rmsle: 0.1020 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.1571 - val_rmsle: 0.0658 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1077 - msle: 9.1907 - rmsle: 0.1015 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.3596 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1066 - msle: 9.1259 - rmsle: 0.1007 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 5.1437 - val_rmsle: 0.0680 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1060 - msle: 9.0722 - rmsle: 0.1002 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.1057 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1056 - msle: 9.0947 - rmsle: 0.1000 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.1332 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1050 - msle: 9.0572 - rmsle: 0.0996 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.6293 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1043 - msle: 9.0048 - rmsle: 0.0989 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.1821 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1038 - msle: 9.0149 - rmsle: 0.0986 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.7063 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1032 - msle: 8.9762 - rmsle: 0.0981 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.0993 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1032 - msle: 8.9651 - rmsle: 0.0981 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.2474 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1012 - msle: 8.8888 - rmsle: 0.0963 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.7756 - val_rmsle: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1008 - msle: 8.8156 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.5889 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.8644 - rmsle: 0.0959 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.4711 - val_rmsle: 0.0652 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0997 - msle: 8.8317 - rmsle: 0.0953 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.3514 - val_rmsle: 0.0644 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 8.8074 - rmsle: 0.0947 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9553 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0985 - msle: 8.7634 - rmsle: 0.0943 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1276 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 8.7527 - rmsle: 0.0942 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0836 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 8.7639 - rmsle: 0.0943 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.2540 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0974 - msle: 8.7602 - rmsle: 0.0936 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8516 - val_rmsle: 0.0621 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0970 - msle: 8.7337 - rmsle: 0.0932 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7868 - val_rmsle: 0.0621 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06286910979117442\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.4234 - msle: 98.7684 - rmsle: 2.3396 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7704 - val_msle: 66.6742 - val_rmsle: 0.7217 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5464 - msle: 53.3025 - rmsle: 0.5065 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1532 - val_msle: 16.2329 - val_rmsle: 0.1297 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1639 - msle: 13.4071 - rmsle: 0.1428 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1074 - val_msle: 7.5869 - val_rmsle: 0.0913 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1354 - msle: 10.4559 - rmsle: 0.1204 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1001 - val_msle: 6.3853 - val_rmsle: 0.0873 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1272 - msle: 10.0527 - rmsle: 0.1151 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0996 - val_msle: 6.4868 - val_rmsle: 0.0887 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1219 - msle: 9.7887 - rmsle: 0.1114 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 4.9896 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1185 - msle: 9.6307 - rmsle: 0.1091 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 5.7175 - val_rmsle: 0.0785 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.4832 - rmsle: 0.1069 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 5.6813 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1143 - msle: 9.4102 - rmsle: 0.1062 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.0670 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1120 - msle: 9.2879 - rmsle: 0.1043 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.3376 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1109 - msle: 9.2364 - rmsle: 0.1034 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 6.1085 - val_rmsle: 0.0735 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1095 - msle: 9.1182 - rmsle: 0.1024 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.8408 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1087 - msle: 9.1089 - rmsle: 0.1018 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.3992 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.9842 - rmsle: 0.0989 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 5.4222 - val_rmsle: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1040 - msle: 8.9276 - rmsle: 0.0980 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.8944 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1037 - msle: 8.9088 - rmsle: 0.0980 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 5.3243 - val_rmsle: 0.0707 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1019 - msle: 8.8227 - rmsle: 0.0965 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.2306 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.7840 - rmsle: 0.0959 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9180 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1009 - msle: 8.8406 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.0995 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.7888 - rmsle: 0.0957 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8936 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.7441 - rmsle: 0.0951 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.8760 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0994 - msle: 8.7753 - rmsle: 0.0950 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.5391 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0992 - msle: 8.7612 - rmsle: 0.0949 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1593 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0982 - msle: 8.7093 - rmsle: 0.0940 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7310 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0978 - msle: 8.6655 - rmsle: 0.0937 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7461 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.6883 - rmsle: 0.0935 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7223 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.6993 - rmsle: 0.0936 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7086 - val_rmsle: 0.0615 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.6819 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7512 - val_rmsle: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0969 - msle: 8.6500 - rmsle: 0.0932 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7948 - val_rmsle: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0963 - msle: 8.6475 - rmsle: 0.0926 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7571 - val_rmsle: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0959 - msle: 8.6408 - rmsle: 0.0923 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.6819 - val_rmsle: 0.0608 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.061312695797585984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:49:19,617] Trial 36 finished with value: 0.062341729381920674 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.0001714849436554508, 'do_rate': 0.4035739446101512, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 17.5377 - msle: 100.0418 - rmsle: 2.4535 - val_dense_loss: 0.0000e+00 - val_loss: 1.2299 - val_msle: 85.6455 - val_rmsle: 1.1998 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.7090 - msle: 64.5009 - rmsle: 0.6781 - val_dense_loss: 0.0000e+00 - val_loss: 0.3735 - val_msle: 37.1268 - val_rmsle: 0.3352 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2852 - msle: 26.0692 - rmsle: 0.2368 - val_dense_loss: 0.0000e+00 - val_loss: 0.2881 - val_msle: 21.3531 - val_rmsle: 0.2347 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2244 - msle: 13.9430 - rmsle: 0.1706 - val_dense_loss: 0.0000e+00 - val_loss: 0.2539 - val_msle: 22.5498 - val_rmsle: 0.2037 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2093 - msle: 13.3182 - rmsle: 0.1616 - val_dense_loss: 0.0000e+00 - val_loss: 0.1902 - val_msle: 14.5812 - val_rmsle: 0.1488 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2011 - msle: 13.0107 - rmsle: 0.1573 - val_dense_loss: 0.0000e+00 - val_loss: 0.2091 - val_msle: 15.0507 - val_rmsle: 0.1704 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1972 - msle: 12.8480 - rmsle: 0.1548 - val_dense_loss: 0.0000e+00 - val_loss: 0.1957 - val_msle: 11.7932 - val_rmsle: 0.1555 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1915 - msle: 12.6337 - rmsle: 0.1521 - val_dense_loss: 0.0000e+00 - val_loss: 0.2027 - val_msle: 19.2885 - val_rmsle: 0.1692 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1676 - msle: 11.9767 - rmsle: 0.1401 - val_dense_loss: 0.0000e+00 - val_loss: 0.1593 - val_msle: 14.2040 - val_rmsle: 0.1345 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1628 - msle: 11.7946 - rmsle: 0.1379 - val_dense_loss: 0.0000e+00 - val_loss: 0.1353 - val_msle: 9.1609 - val_rmsle: 0.1099 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1634 - msle: 11.8307 - rmsle: 0.1387 - val_dense_loss: 0.0000e+00 - val_loss: 0.1358 - val_msle: 7.7221 - val_rmsle: 0.1116 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1641 - msle: 11.7303 - rmsle: 0.1391 - val_dense_loss: 0.0000e+00 - val_loss: 0.1506 - val_msle: 10.7646 - val_rmsle: 0.1259 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1601 - msle: 11.6600 - rmsle: 0.1361 - val_dense_loss: 0.0000e+00 - val_loss: 0.1349 - val_msle: 12.0608 - val_rmsle: 0.1116 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1589 - msle: 11.5603 - rmsle: 0.1356 - val_dense_loss: 0.0000e+00 - val_loss: 0.1389 - val_msle: 11.9162 - val_rmsle: 0.1160 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1574 - msle: 11.4114 - rmsle: 0.1342 - val_dense_loss: 0.0000e+00 - val_loss: 0.1452 - val_msle: 14.9981 - val_rmsle: 0.1224 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1570 - msle: 11.2915 - rmsle: 0.1338 - val_dense_loss: 0.0000e+00 - val_loss: 0.1273 - val_msle: 9.7113 - val_rmsle: 0.1027 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1562 - msle: 11.1606 - rmsle: 0.1331 - val_dense_loss: 0.0000e+00 - val_loss: 0.1378 - val_msle: 11.3273 - val_rmsle: 0.1143 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1536 - msle: 11.0008 - rmsle: 0.1310 - val_dense_loss: 0.0000e+00 - val_loss: 0.1561 - val_msle: 4.4151 - val_rmsle: 0.1319 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1532 - msle: 10.8641 - rmsle: 0.1305 - val_dense_loss: 0.0000e+00 - val_loss: 0.1401 - val_msle: 5.8789 - val_rmsle: 0.1164 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1416 - msle: 10.3951 - rmsle: 0.1226 - val_dense_loss: 0.0000e+00 - val_loss: 0.1144 - val_msle: 6.6401 - val_rmsle: 0.0968 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1379 - msle: 10.3146 - rmsle: 0.1215 - val_dense_loss: 0.0000e+00 - val_loss: 0.1092 - val_msle: 4.5278 - val_rmsle: 0.0927 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1369 - msle: 10.2898 - rmsle: 0.1210 - val_dense_loss: 0.0000e+00 - val_loss: 0.1138 - val_msle: 7.7856 - val_rmsle: 0.0978 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1363 - msle: 10.1766 - rmsle: 0.1206 - val_dense_loss: 0.0000e+00 - val_loss: 0.1094 - val_msle: 7.2796 - val_rmsle: 0.0935 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1332 - msle: 10.0877 - rmsle: 0.1179 - val_dense_loss: 0.0000e+00 - val_loss: 0.1184 - val_msle: 4.8479 - val_rmsle: 0.1027 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1269 - msle: 9.7452 - rmsle: 0.1127 - val_dense_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 5.1960 - val_rmsle: 0.0803 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1232 - msle: 9.6251 - rmsle: 0.1106 - val_dense_loss: 0.0000e+00 - val_loss: 0.1047 - val_msle: 4.3541 - val_rmsle: 0.0921 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1223 - msle: 9.5255 - rmsle: 0.1101 - val_dense_loss: 0.0000e+00 - val_loss: 0.1024 - val_msle: 4.0448 - val_rmsle: 0.0900 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1223 - msle: 9.5470 - rmsle: 0.1103 - val_dense_loss: 0.0000e+00 - val_loss: 0.1033 - val_msle: 4.3345 - val_rmsle: 0.0914 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1175 - msle: 9.3460 - rmsle: 0.1060 - val_dense_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.9167 - val_rmsle: 0.0741 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1164 - msle: 9.3137 - rmsle: 0.1057 - val_dense_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.2226 - val_rmsle: 0.0662 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.2622 - rmsle: 0.1051 - val_dense_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.0589 - val_rmsle: 0.0739 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0663638655520632\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 17.5368 - msle: 99.9725 - rmsle: 2.4511 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.2109 - val_msle: 85.1516 - val_rmsle: 1.1805 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.7057 - msle: 64.2856 - rmsle: 0.6750 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3165 - val_msle: 33.7915 - val_rmsle: 0.2792 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2839 - msle: 25.9467 - rmsle: 0.2355 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2850 - val_msle: 13.6001 - val_rmsle: 0.2339 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2214 - msle: 13.8444 - rmsle: 0.1690 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2740 - val_msle: 6.5513 - val_rmsle: 0.2247 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2054 - msle: 13.2948 - rmsle: 0.1603 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2584 - val_msle: 9.2864 - val_rmsle: 0.2153 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1975 - msle: 12.9206 - rmsle: 0.1551 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2186 - val_msle: 6.7019 - val_rmsle: 0.1810 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1928 - msle: 12.8295 - rmsle: 0.1519 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1870 - val_msle: 6.8347 - val_rmsle: 0.1489 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1898 - msle: 12.5577 - rmsle: 0.1506 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1637 - val_msle: 10.7619 - val_rmsle: 0.1270 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1888 - msle: 12.3960 - rmsle: 0.1494 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1823 - val_msle: 5.3450 - val_rmsle: 0.1454 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1861 - msle: 12.1909 - rmsle: 0.1483 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1716 - val_msle: 8.2410 - val_rmsle: 0.1375 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1844 - msle: 12.0104 - rmsle: 0.1475 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1533 - val_msle: 12.4493 - val_rmsle: 0.1173 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1805 - msle: 11.7301 - rmsle: 0.1443 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1834 - val_msle: 9.2162 - val_rmsle: 0.1456 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1777 - msle: 11.5915 - rmsle: 0.1422 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1592 - val_msle: 6.5536 - val_rmsle: 0.1212 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1754 - msle: 11.2304 - rmsle: 0.1409 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1612 - val_msle: 6.4769 - val_rmsle: 0.1307 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1548 - msle: 10.6051 - rmsle: 0.1304 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1097 - val_msle: 4.7438 - val_rmsle: 0.0874 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1503 - msle: 10.5285 - rmsle: 0.1284 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1293 - val_msle: 11.7531 - val_rmsle: 0.1080 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1491 - msle: 10.5122 - rmsle: 0.1276 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1205 - val_msle: 8.1142 - val_rmsle: 0.0991 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1458 - msle: 10.3739 - rmsle: 0.1252 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1141 - val_msle: 9.3581 - val_rmsle: 0.0937 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1355 - msle: 9.9533 - rmsle: 0.1183 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0970 - val_msle: 4.7049 - val_rmsle: 0.0813 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1311 - msle: 9.7912 - rmsle: 0.1162 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0982 - val_msle: 4.4367 - val_rmsle: 0.0831 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1296 - msle: 9.7473 - rmsle: 0.1152 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1050 - val_msle: 4.4429 - val_rmsle: 0.0905 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1277 - msle: 9.6593 - rmsle: 0.1137 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 4.6159 - val_rmsle: 0.0773 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1275 - msle: 9.6595 - rmsle: 0.1139 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.9933 - val_rmsle: 0.0695 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1267 - msle: 9.7016 - rmsle: 0.1135 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0844 - val_msle: 5.2894 - val_rmsle: 0.0711 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1252 - msle: 9.6099 - rmsle: 0.1123 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0843 - val_msle: 4.4757 - val_rmsle: 0.0716 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1254 - msle: 9.6628 - rmsle: 0.1127 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0903 - val_msle: 5.0075 - val_rmsle: 0.0772 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1187 - msle: 9.3819 - rmsle: 0.1070 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0878 - val_msle: 5.9590 - val_rmsle: 0.0767 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1170 - msle: 9.2921 - rmsle: 0.1063 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0887 - val_msle: 6.9705 - val_rmsle: 0.0781 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1161 - msle: 9.3135 - rmsle: 0.1058 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 6.2750 - val_rmsle: 0.0716 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1160 - msle: 9.3120 - rmsle: 0.1059 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 6.1588 - val_rmsle: 0.0717 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.2583 - rmsle: 0.1056 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0887 - val_msle: 8.1246 - val_rmsle: 0.0786 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.0699477434222803\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 17.5382 - msle: 99.9068 - rmsle: 2.4522 - val_dense_2_loss: 0.0000e+00 - val_loss: 1.2138 - val_msle: 85.2573 - val_rmsle: 1.1834 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.7051 - msle: 64.2532 - rmsle: 0.6744 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3611 - val_msle: 34.2788 - val_rmsle: 0.3232 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2815 - msle: 25.8901 - rmsle: 0.2345 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3209 - val_msle: 23.5897 - val_rmsle: 0.2688 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2191 - msle: 13.7732 - rmsle: 0.1672 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2206 - val_msle: 14.5338 - val_rmsle: 0.1775 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2040 - msle: 13.3082 - rmsle: 0.1588 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2284 - val_msle: 14.4044 - val_rmsle: 0.1891 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1919 - msle: 12.8943 - rmsle: 0.1519 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2439 - val_msle: 14.5710 - val_rmsle: 0.2089 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1868 - msle: 12.7142 - rmsle: 0.1490 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2970 - val_msle: 7.4009 - val_rmsle: 0.2615 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1664 - msle: 12.1059 - rmsle: 0.1387 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1963 - val_msle: 6.4109 - val_rmsle: 0.1689 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1646 - msle: 12.0311 - rmsle: 0.1389 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1330 - val_msle: 4.9479 - val_rmsle: 0.1066 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1630 - msle: 11.9880 - rmsle: 0.1378 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1423 - val_msle: 5.2947 - val_rmsle: 0.1166 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1598 - msle: 11.7405 - rmsle: 0.1354 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1927 - val_msle: 5.3231 - val_rmsle: 0.1680 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1578 - msle: 11.6650 - rmsle: 0.1341 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1679 - val_msle: 5.4405 - val_rmsle: 0.1426 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1473 - msle: 11.2658 - rmsle: 0.1272 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1277 - val_msle: 9.0677 - val_rmsle: 0.1107 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1450 - msle: 11.2351 - rmsle: 0.1279 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1122 - val_msle: 8.6512 - val_rmsle: 0.0957 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1426 - msle: 11.0993 - rmsle: 0.1261 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1214 - val_msle: 10.0685 - val_rmsle: 0.1057 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1415 - msle: 11.0593 - rmsle: 0.1253 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1172 - val_msle: 6.4145 - val_rmsle: 0.1008 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1413 - msle: 11.0224 - rmsle: 0.1251 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1161 - val_msle: 5.8757 - val_rmsle: 0.1002 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1333 - msle: 10.6214 - rmsle: 0.1187 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0968 - val_msle: 9.3710 - val_rmsle: 0.0835 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1312 - msle: 10.5079 - rmsle: 0.1179 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1043 - val_msle: 9.8931 - val_rmsle: 0.0915 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1299 - msle: 10.4152 - rmsle: 0.1170 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0962 - val_msle: 7.5839 - val_rmsle: 0.0836 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1289 - msle: 10.3334 - rmsle: 0.1164 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 5.4846 - val_rmsle: 0.0789 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1288 - msle: 10.3272 - rmsle: 0.1163 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0876 - val_msle: 5.3027 - val_rmsle: 0.0753 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1277 - msle: 10.2805 - rmsle: 0.1155 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0895 - val_msle: 6.2841 - val_rmsle: 0.0773 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1273 - msle: 10.2691 - rmsle: 0.1152 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0929 - val_msle: 7.1640 - val_rmsle: 0.0809 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1269 - msle: 10.1568 - rmsle: 0.1149 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0890 - val_msle: 6.4064 - val_rmsle: 0.0769 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1233 - msle: 10.0213 - rmsle: 0.1115 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 5.3157 - val_rmsle: 0.0690 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1220 - msle: 9.9000 - rmsle: 0.1109 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 5.7331 - val_rmsle: 0.0709 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1211 - msle: 9.8695 - rmsle: 0.1103 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 5.9981 - val_rmsle: 0.0696 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1208 - msle: 9.8462 - rmsle: 0.1101 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 6.9997 - val_rmsle: 0.0740 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1182 - msle: 9.7315 - rmsle: 0.1076 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.1347 - val_rmsle: 0.0643 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1177 - msle: 9.6557 - rmsle: 0.1074 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 3.9144 - val_rmsle: 0.0637 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06398399681211225\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 17.5353 - msle: 99.9883 - rmsle: 2.4508 - val_dense_3_loss: 0.0000e+00 - val_loss: 1.2013 - val_msle: 84.7162 - val_rmsle: 1.1709 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.7042 - msle: 64.1478 - rmsle: 0.6733 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2719 - val_msle: 22.2400 - val_rmsle: 0.2317 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2830 - msle: 25.7841 - rmsle: 0.2347 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2360 - val_msle: 23.7490 - val_rmsle: 0.1878 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2202 - msle: 13.8797 - rmsle: 0.1682 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2429 - val_msle: 16.3867 - val_rmsle: 0.1926 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2043 - msle: 13.2953 - rmsle: 0.1589 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1916 - val_msle: 13.6941 - val_rmsle: 0.1485 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1941 - msle: 12.8832 - rmsle: 0.1533 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2362 - val_msle: 7.5819 - val_rmsle: 0.1959 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1879 - msle: 12.7113 - rmsle: 0.1498 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2211 - val_msle: 17.4716 - val_rmsle: 0.1861 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1888 - msle: 12.6379 - rmsle: 0.1505 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2367 - val_msle: 21.9880 - val_rmsle: 0.2029 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1689 - msle: 11.9714 - rmsle: 0.1407 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1375 - val_msle: 6.1770 - val_rmsle: 0.1136 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1633 - msle: 11.8875 - rmsle: 0.1384 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1902 - val_msle: 8.8675 - val_rmsle: 0.1640 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1625 - msle: 11.7761 - rmsle: 0.1374 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1617 - val_msle: 8.5395 - val_rmsle: 0.1382 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1596 - msle: 11.6785 - rmsle: 0.1362 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2003 - val_msle: 5.3466 - val_rmsle: 0.1757 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1494 - msle: 11.2277 - rmsle: 0.1290 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1401 - val_msle: 4.7844 - val_rmsle: 0.1226 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1441 - msle: 11.1067 - rmsle: 0.1270 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1240 - val_msle: 4.6645 - val_rmsle: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1432 - msle: 11.0853 - rmsle: 0.1264 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1302 - val_msle: 4.7372 - val_rmsle: 0.1134 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1429 - msle: 11.0642 - rmsle: 0.1265 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1277 - val_msle: 5.1526 - val_rmsle: 0.1116 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1402 - msle: 10.9099 - rmsle: 0.1242 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1196 - val_msle: 4.4541 - val_rmsle: 0.1035 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1406 - msle: 10.8837 - rmsle: 0.1246 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1228 - val_msle: 9.8235 - val_rmsle: 0.1067 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1401 - msle: 10.8094 - rmsle: 0.1241 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1313 - val_msle: 8.9456 - val_rmsle: 0.1147 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1398 - msle: 10.7449 - rmsle: 0.1237 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1241 - val_msle: 10.0984 - val_rmsle: 0.1081 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1323 - msle: 10.3792 - rmsle: 0.1176 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0973 - val_msle: 4.1214 - val_rmsle: 0.0840 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1296 - msle: 10.2138 - rmsle: 0.1164 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0852 - val_msle: 4.3334 - val_rmsle: 0.0723 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1285 - msle: 10.1258 - rmsle: 0.1157 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 4.1310 - val_rmsle: 0.0790 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1282 - msle: 10.1216 - rmsle: 0.1156 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0954 - val_msle: 4.3298 - val_rmsle: 0.0830 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1276 - msle: 10.0961 - rmsle: 0.1151 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0925 - val_msle: 4.2321 - val_rmsle: 0.0802 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1231 - msle: 9.8975 - rmsle: 0.1112 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 4.0243 - val_rmsle: 0.0667 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1222 - msle: 9.7901 - rmsle: 0.1108 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.0384 - val_rmsle: 0.0663 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1219 - msle: 9.7894 - rmsle: 0.1107 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 3.9719 - val_rmsle: 0.0661 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1212 - msle: 9.7445 - rmsle: 0.1101 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 4.0145 - val_rmsle: 0.0677 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1206 - msle: 9.7310 - rmsle: 0.1097 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 3.9933 - val_rmsle: 0.0661 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1196 - msle: 9.6794 - rmsle: 0.1089 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.0240 - val_rmsle: 0.0663 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06651351810045888\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 17.5391 - msle: 100.1202 - rmsle: 2.4538 - val_dense_4_loss: 0.0000e+00 - val_loss: 1.1934 - val_msle: 84.4934 - val_rmsle: 1.1629 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.7076 - msle: 64.4956 - rmsle: 0.6769 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2248 - val_msle: 21.1173 - val_rmsle: 0.1807 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2796 - msle: 25.9477 - rmsle: 0.2332 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2565 - val_msle: 7.4538 - val_rmsle: 0.1957 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2209 - msle: 13.8606 - rmsle: 0.1670 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2817 - val_msle: 11.8475 - val_rmsle: 0.2344 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2027 - msle: 13.2586 - rmsle: 0.1580 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2454 - val_msle: 16.3249 - val_rmsle: 0.2049 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1721 - msle: 12.4364 - rmsle: 0.1414 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1989 - val_msle: 5.7292 - val_rmsle: 0.1702 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1660 - msle: 12.3424 - rmsle: 0.1398 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1914 - val_msle: 7.8349 - val_rmsle: 0.1637 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1638 - msle: 12.2041 - rmsle: 0.1382 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1742 - val_msle: 14.0802 - val_rmsle: 0.1496 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1624 - msle: 12.0822 - rmsle: 0.1379 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1765 - val_msle: 9.6721 - val_rmsle: 0.1522 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1610 - msle: 11.9481 - rmsle: 0.1368 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1630 - val_msle: 4.6948 - val_rmsle: 0.1368 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1608 - msle: 11.9217 - rmsle: 0.1362 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1713 - val_msle: 7.8811 - val_rmsle: 0.1474 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1566 - msle: 11.6403 - rmsle: 0.1334 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2034 - val_msle: 5.4710 - val_rmsle: 0.1785 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1591 - msle: 11.6532 - rmsle: 0.1351 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2095 - val_msle: 6.5094 - val_rmsle: 0.1856 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1478 - msle: 11.1589 - rmsle: 0.1278 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1393 - val_msle: 4.7794 - val_rmsle: 0.1211 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1451 - msle: 11.1135 - rmsle: 0.1273 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1376 - val_msle: 6.0589 - val_rmsle: 0.1206 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1423 - msle: 10.9187 - rmsle: 0.1255 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1433 - val_msle: 6.9612 - val_rmsle: 0.1261 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1423 - msle: 10.9079 - rmsle: 0.1254 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1491 - val_msle: 4.8478 - val_rmsle: 0.1326 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1409 - msle: 10.8228 - rmsle: 0.1245 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1542 - val_msle: 5.6629 - val_rmsle: 0.1375 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1334 - msle: 10.4924 - rmsle: 0.1182 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0897 - val_msle: 5.8827 - val_rmsle: 0.0762 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1312 - msle: 10.3157 - rmsle: 0.1176 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0909 - val_msle: 6.5272 - val_rmsle: 0.0778 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1302 - msle: 10.2954 - rmsle: 0.1171 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0955 - val_msle: 6.3786 - val_rmsle: 0.0826 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1293 - msle: 10.2128 - rmsle: 0.1163 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0944 - val_msle: 7.0516 - val_rmsle: 0.0817 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1253 - msle: 10.0105 - rmsle: 0.1129 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 7.1275 - val_rmsle: 0.0739 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1239 - msle: 9.9380 - rmsle: 0.1121 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 7.3613 - val_rmsle: 0.0751 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1228 - msle: 9.8384 - rmsle: 0.1113 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 8.3929 - val_rmsle: 0.0785 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1223 - msle: 9.8496 - rmsle: 0.1109 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 7.0685 - val_rmsle: 0.0729 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1220 - msle: 9.8182 - rmsle: 0.1108 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 6.0693 - val_rmsle: 0.0720 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1217 - msle: 9.8224 - rmsle: 0.1106 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.8613 - val_rmsle: 0.0731 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1210 - msle: 9.7264 - rmsle: 0.1100 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 7.1208 - val_rmsle: 0.0757 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1207 - msle: 9.7220 - rmsle: 0.1098 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0825 - val_msle: 6.4021 - val_rmsle: 0.0717 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1204 - msle: 9.7215 - rmsle: 0.1095 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 5.3604 - val_rmsle: 0.0705 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.07038487263031656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 23:57:03,238] Trial 37 finished with value: 0.06743879930344623 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.08923112872646002, 'do_rate': 0.4029385050664301, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.3918 - msle: 98.5412 - rmsle: 2.3140 - val_dense_loss: 0.0000e+00 - val_loss: 0.7545 - val_msle: 66.7352 - val_rmsle: 0.7084 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5287 - msle: 52.4036 - rmsle: 0.4907 - val_dense_loss: 0.0000e+00 - val_loss: 0.1286 - val_msle: 12.8001 - val_rmsle: 0.1057 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1548 - msle: 12.2948 - rmsle: 0.1342 - val_dense_loss: 0.0000e+00 - val_loss: 0.1016 - val_msle: 6.9775 - val_rmsle: 0.0859 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1297 - msle: 9.7972 - rmsle: 0.1151 - val_dense_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 4.8356 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1219 - msle: 9.3980 - rmsle: 0.1101 - val_dense_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 4.2896 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1171 - msle: 9.1819 - rmsle: 0.1070 - val_dense_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 4.1482 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1136 - msle: 9.0116 - rmsle: 0.1045 - val_dense_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 4.4596 - val_rmsle: 0.0798 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1092 - msle: 8.8352 - rmsle: 0.1009 - val_dense_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.1376 - val_rmsle: 0.0677 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1070 - msle: 8.7285 - rmsle: 0.0995 - val_dense_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.1730 - val_rmsle: 0.0705 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.6622 - rmsle: 0.0986 - val_dense_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 3.9694 - val_rmsle: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1047 - msle: 8.6173 - rmsle: 0.0982 - val_dense_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 3.9657 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.5669 - rmsle: 0.0966 - val_dense_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 3.9279 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1018 - msle: 8.5179 - rmsle: 0.0960 - val_dense_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 3.8887 - val_rmsle: 0.0679 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.4872 - rmsle: 0.0959 - val_dense_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.9081 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1009 - msle: 8.4873 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.8806 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1000 - msle: 8.4453 - rmsle: 0.0949 - val_dense_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 3.8348 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.4473 - rmsle: 0.0946 - val_dense_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 3.8526 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0991 - msle: 8.4201 - rmsle: 0.0943 - val_dense_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.8652 - val_rmsle: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0983 - msle: 8.4131 - rmsle: 0.0936 - val_dense_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.8926 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0978 - msle: 8.3972 - rmsle: 0.0932 - val_dense_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.8551 - val_rmsle: 0.0642 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.3643 - rmsle: 0.0930 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9063 - val_rmsle: 0.0634 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.3406 - rmsle: 0.0927 - val_dense_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8690 - val_rmsle: 0.0642 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0970 - msle: 8.3471 - rmsle: 0.0928 - val_dense_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8267 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.3396 - rmsle: 0.0925 - val_dense_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8113 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.3565 - rmsle: 0.0926 - val_dense_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8230 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0963 - msle: 8.3601 - rmsle: 0.0923 - val_dense_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8053 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0960 - msle: 8.3043 - rmsle: 0.0921 - val_dense_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9185 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0960 - msle: 8.3099 - rmsle: 0.0921 - val_dense_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9051 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0956 - msle: 8.2841 - rmsle: 0.0918 - val_dense_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.7972 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0954 - msle: 8.2810 - rmsle: 0.0916 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.8502 - val_rmsle: 0.0623 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0948 - msle: 8.2534 - rmsle: 0.0911 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8026 - val_rmsle: 0.0623 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06313433787430245\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.3872 - msle: 98.4795 - rmsle: 2.3093 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7623 - val_msle: 67.5544 - val_rmsle: 0.7164 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5309 - msle: 52.7205 - rmsle: 0.4930 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1327 - val_msle: 12.4120 - val_rmsle: 0.1097 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1560 - msle: 12.4599 - rmsle: 0.1352 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1198 - val_msle: 8.1238 - val_rmsle: 0.1038 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1304 - msle: 9.8505 - rmsle: 0.1155 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1013 - val_msle: 7.2037 - val_rmsle: 0.0885 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1221 - msle: 9.4667 - rmsle: 0.1099 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0992 - val_msle: 5.4595 - val_rmsle: 0.0882 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1174 - msle: 9.2174 - rmsle: 0.1069 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0978 - val_msle: 5.2203 - val_rmsle: 0.0880 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1145 - msle: 9.0950 - rmsle: 0.1050 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0938 - val_msle: 5.1850 - val_rmsle: 0.0848 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1124 - msle: 8.9753 - rmsle: 0.1037 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0865 - val_msle: 6.9494 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1100 - msle: 8.8801 - rmsle: 0.1019 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 5.1083 - val_rmsle: 0.0834 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1085 - msle: 8.8192 - rmsle: 0.1008 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 6.1702 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1072 - msle: 8.7205 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 6.1216 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.6552 - rmsle: 0.0984 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 4.1050 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1052 - msle: 8.6174 - rmsle: 0.0983 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0861 - val_msle: 7.1831 - val_rmsle: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1025 - msle: 8.5110 - rmsle: 0.0958 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 5.2091 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1011 - msle: 8.4394 - rmsle: 0.0951 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 5.2948 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.4200 - rmsle: 0.0947 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.4126 - val_rmsle: 0.0686 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.4166 - rmsle: 0.0942 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 5.6449 - val_rmsle: 0.0698 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0993 - msle: 8.4112 - rmsle: 0.0941 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.0952 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0992 - msle: 8.4235 - rmsle: 0.0941 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.9993 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0985 - msle: 8.3954 - rmsle: 0.0935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.7082 - val_rmsle: 0.0667 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0983 - msle: 8.3612 - rmsle: 0.0934 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.9901 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0963 - msle: 8.2761 - rmsle: 0.0916 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.1863 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0956 - msle: 8.2357 - rmsle: 0.0911 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.4256 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0955 - msle: 8.2603 - rmsle: 0.0912 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.6296 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0955 - msle: 8.2482 - rmsle: 0.0913 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.1553 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.2484 - rmsle: 0.0909 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.1588 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0946 - msle: 8.2497 - rmsle: 0.0907 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.3009 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0944 - msle: 8.2280 - rmsle: 0.0905 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.2682 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0943 - msle: 8.2113 - rmsle: 0.0905 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1965 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0932 - msle: 8.1720 - rmsle: 0.0895 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 4.0082 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0927 - msle: 8.1516 - rmsle: 0.0890 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.0085 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06218913413349972\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.3889 - msle: 98.3657 - rmsle: 2.3111 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7413 - val_msle: 66.0473 - val_rmsle: 0.6955 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5244 - msle: 51.9879 - rmsle: 0.4866 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1290 - val_msle: 12.7967 - val_rmsle: 0.1066 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1531 - msle: 12.0727 - rmsle: 0.1328 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0993 - val_msle: 7.3071 - val_rmsle: 0.0839 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1287 - msle: 9.7600 - rmsle: 0.1143 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1029 - val_msle: 7.8004 - val_rmsle: 0.0907 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1212 - msle: 9.3850 - rmsle: 0.1095 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0936 - val_msle: 6.6031 - val_rmsle: 0.0831 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1165 - msle: 9.1576 - rmsle: 0.1063 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0866 - val_msle: 6.3153 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1130 - msle: 8.9804 - rmsle: 0.1038 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 5.0684 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1112 - msle: 8.8895 - rmsle: 0.1027 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0833 - val_msle: 6.3793 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1086 - msle: 8.7374 - rmsle: 0.1007 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 6.2091 - val_rmsle: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1069 - msle: 8.6899 - rmsle: 0.0993 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.7686 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1036 - msle: 8.5210 - rmsle: 0.0966 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.2364 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1022 - msle: 8.4554 - rmsle: 0.0958 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 3.9369 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.4371 - rmsle: 0.0953 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0737 - val_msle: 4.0230 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1008 - msle: 8.4193 - rmsle: 0.0951 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.7836 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1002 - msle: 8.4195 - rmsle: 0.0947 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.3978 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0999 - msle: 8.3792 - rmsle: 0.0946 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 3.9422 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.3840 - rmsle: 0.0943 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.3857 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0972 - msle: 8.2605 - rmsle: 0.0922 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.6717 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0966 - msle: 8.2373 - rmsle: 0.0918 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.6632 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0966 - msle: 8.2265 - rmsle: 0.0920 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.7210 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0957 - msle: 8.1955 - rmsle: 0.0913 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9136 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0959 - msle: 8.2116 - rmsle: 0.0916 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.6460 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0952 - msle: 8.1931 - rmsle: 0.0910 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0533 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.1821 - rmsle: 0.0909 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.6428 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0949 - msle: 8.2010 - rmsle: 0.0909 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.6586 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0944 - msle: 8.1659 - rmsle: 0.0905 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7566 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0943 - msle: 8.1917 - rmsle: 0.0905 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7909 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0933 - msle: 8.1109 - rmsle: 0.0895 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7366 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0930 - msle: 8.1214 - rmsle: 0.0893 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.6341 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0929 - msle: 8.1104 - rmsle: 0.0893 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7181 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0927 - msle: 8.1023 - rmsle: 0.0891 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8698 - val_rmsle: 0.0625 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.061775915465250145\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.3879 - msle: 98.4685 - rmsle: 2.3102 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7575 - val_msle: 66.2998 - val_rmsle: 0.7117 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5260 - msle: 52.0935 - rmsle: 0.4882 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1309 - val_msle: 14.3532 - val_rmsle: 0.1084 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1536 - msle: 12.1870 - rmsle: 0.1333 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1212 - val_msle: 10.7269 - val_rmsle: 0.1056 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1296 - msle: 9.8037 - rmsle: 0.1151 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1048 - val_msle: 8.5032 - val_rmsle: 0.0925 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1222 - msle: 9.4394 - rmsle: 0.1104 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0888 - val_msle: 5.8860 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1168 - msle: 9.1586 - rmsle: 0.1066 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 4.7256 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1140 - msle: 9.0216 - rmsle: 0.1049 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 5.8371 - val_rmsle: 0.0734 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1110 - msle: 8.8950 - rmsle: 0.1026 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0898 - val_msle: 6.5249 - val_rmsle: 0.0817 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1098 - msle: 8.8292 - rmsle: 0.1019 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0881 - val_msle: 4.7280 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.6391 - rmsle: 0.0990 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 5.5731 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1046 - msle: 8.5731 - rmsle: 0.0978 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.4755 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1036 - msle: 8.5943 - rmsle: 0.0972 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.9090 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1030 - msle: 8.5717 - rmsle: 0.0970 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.0055 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1022 - msle: 8.5206 - rmsle: 0.0964 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.3838 - val_rmsle: 0.0667 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.4966 - rmsle: 0.0960 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.5641 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1011 - msle: 8.5037 - rmsle: 0.0957 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.3695 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0997 - msle: 8.4069 - rmsle: 0.0944 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.6735 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0983 - msle: 8.3632 - rmsle: 0.0933 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2687 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0981 - msle: 8.3713 - rmsle: 0.0934 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.2990 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0976 - msle: 8.3285 - rmsle: 0.0930 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.9361 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0972 - msle: 8.3384 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.9241 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0970 - msle: 8.3391 - rmsle: 0.0926 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.2194 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0970 - msle: 8.2942 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.4066 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0959 - msle: 8.2995 - rmsle: 0.0918 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.3741 - val_rmsle: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0958 - msle: 8.2791 - rmsle: 0.0918 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2545 - val_rmsle: 0.0640 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0954 - msle: 8.2631 - rmsle: 0.0914 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0354 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0944 - msle: 8.1964 - rmsle: 0.0905 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8122 - val_rmsle: 0.0622 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0942 - msle: 8.2138 - rmsle: 0.0904 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.8919 - val_rmsle: 0.0625 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0943 - msle: 8.2187 - rmsle: 0.0905 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9045 - val_rmsle: 0.0620 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0939 - msle: 8.2103 - rmsle: 0.0902 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9797 - val_rmsle: 0.0624 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 8.2064 - rmsle: 0.0901 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7304 - val_rmsle: 0.0621 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06282900139008316\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.3886 - msle: 98.5708 - rmsle: 2.3108 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7368 - val_msle: 65.3600 - val_rmsle: 0.6908 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5231 - msle: 51.9920 - rmsle: 0.4852 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1304 - val_msle: 12.3923 - val_rmsle: 0.1077 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1536 - msle: 12.1569 - rmsle: 0.1331 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1154 - val_msle: 9.6651 - val_rmsle: 0.0998 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1283 - msle: 9.7373 - rmsle: 0.1138 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1010 - val_msle: 7.0073 - val_rmsle: 0.0886 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1210 - msle: 9.3682 - rmsle: 0.1092 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 6.6724 - val_rmsle: 0.0821 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1161 - msle: 9.1176 - rmsle: 0.1059 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0810 - val_msle: 4.9815 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1131 - msle: 9.0144 - rmsle: 0.1040 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 4.8504 - val_rmsle: 0.0775 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1108 - msle: 8.8388 - rmsle: 0.1023 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 5.3920 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1093 - msle: 8.7775 - rmsle: 0.1014 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.1217 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1076 - msle: 8.6962 - rmsle: 0.1001 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.1451 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1062 - msle: 8.6557 - rmsle: 0.0990 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.9591 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1053 - msle: 8.5480 - rmsle: 0.0983 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.2883 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1041 - msle: 8.5222 - rmsle: 0.0974 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.2928 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1034 - msle: 8.4725 - rmsle: 0.0968 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.2348 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1026 - msle: 8.4468 - rmsle: 0.0962 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.4197 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1022 - msle: 8.4164 - rmsle: 0.0959 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 6.4284 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0992 - msle: 8.2690 - rmsle: 0.0932 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 5.2588 - val_rmsle: 0.0712 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0980 - msle: 8.2253 - rmsle: 0.0925 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.4056 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0979 - msle: 8.2739 - rmsle: 0.0927 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.3626 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.2337 - rmsle: 0.0925 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1766 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.1843 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.8415 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0964 - msle: 8.1889 - rmsle: 0.0917 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.3192 - val_rmsle: 0.0631 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0961 - msle: 8.1667 - rmsle: 0.0915 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1178 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0959 - msle: 8.1445 - rmsle: 0.0914 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.4287 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0957 - msle: 8.1390 - rmsle: 0.0913 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.1719 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0953 - msle: 8.1661 - rmsle: 0.0909 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1330 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0952 - msle: 8.1608 - rmsle: 0.0909 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6603 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.1178 - rmsle: 0.0907 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.6592 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0934 - msle: 8.0185 - rmsle: 0.0892 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.3958 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0927 - msle: 8.0397 - rmsle: 0.0886 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 5.2727 - val_rmsle: 0.0654 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0925 - msle: 8.0193 - rmsle: 0.0886 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9186 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06333917235720621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:04:36,917] Trial 38 finished with value: 0.06265351224406834 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.00015848958576634598, 'do_rate': 0.3599242085771337, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.7234 - msle: 98.4359 - rmsle: 2.3095 - val_dense_loss: 0.0000e+00 - val_loss: 0.8749 - val_msle: 73.8438 - val_rmsle: 0.8404 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5167 - msle: 52.5486 - rmsle: 0.4917 - val_dense_loss: 0.0000e+00 - val_loss: 0.1508 - val_msle: 7.1267 - val_rmsle: 0.1300 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1578 - msle: 12.7149 - rmsle: 0.1381 - val_dense_loss: 0.0000e+00 - val_loss: 0.1321 - val_msle: 4.8267 - val_rmsle: 0.1144 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1383 - msle: 10.2352 - rmsle: 0.1212 - val_dense_loss: 0.0000e+00 - val_loss: 0.0989 - val_msle: 4.7134 - val_rmsle: 0.0830 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1313 - msle: 9.8861 - rmsle: 0.1161 - val_dense_loss: 0.0000e+00 - val_loss: 0.0960 - val_msle: 6.2564 - val_rmsle: 0.0812 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1291 - msle: 9.6726 - rmsle: 0.1148 - val_dense_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 4.1386 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1253 - msle: 9.4737 - rmsle: 0.1118 - val_dense_loss: 0.0000e+00 - val_loss: 0.0978 - val_msle: 4.1892 - val_rmsle: 0.0846 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1240 - msle: 9.4295 - rmsle: 0.1111 - val_dense_loss: 0.0000e+00 - val_loss: 0.0910 - val_msle: 4.0463 - val_rmsle: 0.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1222 - msle: 9.3188 - rmsle: 0.1098 - val_dense_loss: 0.0000e+00 - val_loss: 0.1001 - val_msle: 5.5672 - val_rmsle: 0.0880 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1151 - msle: 9.0593 - rmsle: 0.1039 - val_dense_loss: 0.0000e+00 - val_loss: 0.0849 - val_msle: 3.9918 - val_rmsle: 0.0752 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1131 - msle: 9.0524 - rmsle: 0.1038 - val_dense_loss: 0.0000e+00 - val_loss: 0.1041 - val_msle: 5.0703 - val_rmsle: 0.0950 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1122 - msle: 8.9971 - rmsle: 0.1034 - val_dense_loss: 0.0000e+00 - val_loss: 0.1029 - val_msle: 6.2395 - val_rmsle: 0.0942 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1112 - msle: 8.9934 - rmsle: 0.1027 - val_dense_loss: 0.0000e+00 - val_loss: 0.0886 - val_msle: 4.3101 - val_rmsle: 0.0801 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1080 - msle: 8.8180 - rmsle: 0.0999 - val_dense_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 3.9811 - val_rmsle: 0.0687 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1059 - msle: 8.7893 - rmsle: 0.0988 - val_dense_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 3.8713 - val_rmsle: 0.0709 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1050 - msle: 8.7577 - rmsle: 0.0983 - val_dense_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 3.9827 - val_rmsle: 0.0714 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1051 - msle: 8.7652 - rmsle: 0.0987 - val_dense_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.1330 - val_rmsle: 0.0754 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1026 - msle: 8.7096 - rmsle: 0.0965 - val_dense_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 3.9954 - val_rmsle: 0.0670 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1019 - msle: 8.6831 - rmsle: 0.0962 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 3.9197 - val_rmsle: 0.0666 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1017 - msle: 8.7165 - rmsle: 0.0962 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 3.9827 - val_rmsle: 0.0663 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1009 - msle: 8.6538 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.3069 - val_rmsle: 0.0657 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1007 - msle: 8.6576 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 3.8240 - val_rmsle: 0.0665 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1003 - msle: 8.6112 - rmsle: 0.0953 - val_dense_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.8491 - val_rmsle: 0.0653 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1001 - msle: 8.6367 - rmsle: 0.0953 - val_dense_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 3.9705 - val_rmsle: 0.0683 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0998 - msle: 8.6313 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.1372 - val_rmsle: 0.0657 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0994 - msle: 8.6427 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 3.7984 - val_rmsle: 0.0660 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0985 - msle: 8.5639 - rmsle: 0.0939 - val_dense_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.7619 - val_rmsle: 0.0628 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0981 - msle: 8.5652 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.7777 - val_rmsle: 0.0643 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0977 - msle: 8.5399 - rmsle: 0.0934 - val_dense_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.7915 - val_rmsle: 0.0659 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0977 - msle: 8.5642 - rmsle: 0.0935 - val_dense_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.8450 - val_rmsle: 0.0645 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.5203 - rmsle: 0.0925 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8960 - val_rmsle: 0.0621 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06291299243024341\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.7223 - msle: 98.3834 - rmsle: 2.3079 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8801 - val_msle: 74.3564 - val_rmsle: 0.8454 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5200 - msle: 52.9025 - rmsle: 0.4950 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1295 - val_msle: 7.0530 - val_rmsle: 0.1096 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1580 - msle: 12.8602 - rmsle: 0.1383 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1301 - val_msle: 8.9487 - val_rmsle: 0.1123 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1383 - msle: 10.2545 - rmsle: 0.1212 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1103 - val_msle: 4.8196 - val_rmsle: 0.0941 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1326 - msle: 9.9627 - rmsle: 0.1170 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1070 - val_msle: 4.7642 - val_rmsle: 0.0921 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1285 - msle: 9.7090 - rmsle: 0.1140 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 4.5078 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1252 - msle: 9.5877 - rmsle: 0.1116 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1032 - val_msle: 4.2269 - val_rmsle: 0.0899 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1235 - msle: 9.4556 - rmsle: 0.1105 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0930 - val_msle: 4.4251 - val_rmsle: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1212 - msle: 9.3836 - rmsle: 0.1089 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0926 - val_msle: 4.1193 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1161 - msle: 9.1479 - rmsle: 0.1048 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 6.4228 - val_rmsle: 0.0756 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1136 - msle: 9.0847 - rmsle: 0.1040 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0844 - val_msle: 4.8653 - val_rmsle: 0.0751 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1114 - msle: 8.9941 - rmsle: 0.1024 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 3.9708 - val_rmsle: 0.0787 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1112 - msle: 9.0371 - rmsle: 0.1026 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 4.0960 - val_rmsle: 0.0744 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1103 - msle: 8.9529 - rmsle: 0.1018 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0827 - val_msle: 4.0082 - val_rmsle: 0.0744 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1097 - msle: 8.9351 - rmsle: 0.1015 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0884 - val_msle: 4.1100 - val_rmsle: 0.0802 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.8840 - rmsle: 0.1008 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.1045 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1086 - msle: 8.9022 - rmsle: 0.1007 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 4.6241 - val_rmsle: 0.0778 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1079 - msle: 8.8611 - rmsle: 0.1001 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 4.0090 - val_rmsle: 0.0728 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1083 - msle: 8.8975 - rmsle: 0.1004 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.1580 - val_rmsle: 0.0661 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1072 - msle: 8.8578 - rmsle: 0.0995 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 3.9460 - val_rmsle: 0.0708 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1066 - msle: 8.8196 - rmsle: 0.0990 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0824 - val_msle: 4.3172 - val_rmsle: 0.0746 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1061 - msle: 8.7666 - rmsle: 0.0986 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 3.9398 - val_rmsle: 0.0726 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1033 - msle: 8.6597 - rmsle: 0.0961 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 5.4858 - val_rmsle: 0.0714 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1027 - msle: 8.6958 - rmsle: 0.0963 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0739 - val_msle: 4.9318 - val_rmsle: 0.0677 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1022 - msle: 8.6372 - rmsle: 0.0961 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 5.4093 - val_rmsle: 0.0679 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1017 - msle: 8.6523 - rmsle: 0.0958 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.9377 - val_rmsle: 0.0670 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.6375 - rmsle: 0.0953 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.4528 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1011 - msle: 8.6468 - rmsle: 0.0955 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 5.1692 - val_rmsle: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1000 - msle: 8.5826 - rmsle: 0.0946 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 5.0354 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1003 - msle: 8.5996 - rmsle: 0.0949 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.3603 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0997 - msle: 8.5640 - rmsle: 0.0944 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.4052 - val_rmsle: 0.0668 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 312.3585510253906\n",
            "Fold 1 RMSLE: 0.0657320883596822\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.7245 - msle: 98.2922 - rmsle: 2.3084 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.8733 - val_msle: 73.9751 - val_rmsle: 0.8384 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5153 - msle: 52.4162 - rmsle: 0.4902 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1662 - val_msle: 11.0458 - val_rmsle: 0.1464 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1551 - msle: 12.5602 - rmsle: 0.1360 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1305 - val_msle: 10.2297 - val_rmsle: 0.1140 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1365 - msle: 10.2136 - rmsle: 0.1202 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1396 - val_msle: 5.1367 - val_rmsle: 0.1245 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1300 - msle: 9.9029 - rmsle: 0.1154 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1076 - val_msle: 7.6969 - val_rmsle: 0.0935 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1275 - msle: 9.7243 - rmsle: 0.1137 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0898 - val_msle: 5.1871 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1242 - msle: 9.5377 - rmsle: 0.1112 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0903 - val_msle: 4.4638 - val_rmsle: 0.0777 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1230 - msle: 9.4697 - rmsle: 0.1103 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0840 - val_msle: 4.5114 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1198 - msle: 9.3052 - rmsle: 0.1079 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 4.0016 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1186 - msle: 9.2465 - rmsle: 0.1071 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0931 - val_msle: 4.5662 - val_rmsle: 0.0820 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1174 - msle: 9.1636 - rmsle: 0.1062 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 4.5276 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.1138 - rmsle: 0.1048 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0948 - val_msle: 4.0181 - val_rmsle: 0.0840 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1110 - msle: 8.9436 - rmsle: 0.1010 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 4.1435 - val_rmsle: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.8917 - rmsle: 0.1004 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 3.9931 - val_rmsle: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1078 - msle: 8.8842 - rmsle: 0.0998 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 3.9842 - val_rmsle: 0.0708 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1076 - msle: 8.8341 - rmsle: 0.0998 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0873 - val_msle: 4.3502 - val_rmsle: 0.0797 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.8109 - rmsle: 0.0989 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 4.3445 - val_rmsle: 0.0737 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1059 - msle: 8.7708 - rmsle: 0.0985 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.6643 - val_rmsle: 0.0705 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1056 - msle: 8.7559 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.0155 - val_rmsle: 0.0694 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1052 - msle: 8.7299 - rmsle: 0.0980 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.4737 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1045 - msle: 8.7081 - rmsle: 0.0973 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 3.8679 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1042 - msle: 8.7066 - rmsle: 0.0972 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 6.2647 - val_rmsle: 0.0726 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.7069 - rmsle: 0.0969 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 4.2760 - val_rmsle: 0.0718 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1035 - msle: 8.6593 - rmsle: 0.0966 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 4.4726 - val_rmsle: 0.0708 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.5897 - rmsle: 0.0948 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 5.4925 - val_rmsle: 0.0736 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1001 - msle: 8.5506 - rmsle: 0.0942 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.3911 - val_rmsle: 0.0694 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1001 - msle: 8.5851 - rmsle: 0.0945 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.0279 - val_rmsle: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.5203 - rmsle: 0.0941 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.2660 - val_rmsle: 0.0661 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0989 - msle: 8.5070 - rmsle: 0.0936 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.7179 - val_rmsle: 0.0693 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0992 - msle: 8.5400 - rmsle: 0.0940 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.0723 - val_rmsle: 0.0683 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.4448 - rmsle: 0.0921 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0421 - val_rmsle: 0.0648 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06515434472172776\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.7229 - msle: 98.4082 - rmsle: 2.3080 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8628 - val_msle: 73.3812 - val_rmsle: 0.8282 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5158 - msle: 52.5165 - rmsle: 0.4907 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1436 - val_msle: 8.5726 - val_rmsle: 0.1234 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1567 - msle: 12.7116 - rmsle: 0.1371 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1147 - val_msle: 11.4982 - val_rmsle: 0.0974 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1382 - msle: 10.2714 - rmsle: 0.1215 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1070 - val_msle: 6.2332 - val_rmsle: 0.0918 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1311 - msle: 9.9162 - rmsle: 0.1162 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1018 - val_msle: 7.1489 - val_rmsle: 0.0878 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1273 - msle: 9.6819 - rmsle: 0.1135 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1199 - val_msle: 5.3954 - val_rmsle: 0.1067 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1250 - msle: 9.5800 - rmsle: 0.1120 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0936 - val_msle: 5.5344 - val_rmsle: 0.0809 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1226 - msle: 9.4720 - rmsle: 0.1101 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1181 - val_msle: 4.5801 - val_rmsle: 0.1060 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1211 - msle: 9.3729 - rmsle: 0.1091 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1051 - val_msle: 5.3777 - val_rmsle: 0.0935 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1196 - msle: 9.2833 - rmsle: 0.1080 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0935 - val_msle: 6.3503 - val_rmsle: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1179 - msle: 9.2067 - rmsle: 0.1067 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0979 - val_msle: 4.0870 - val_rmsle: 0.0868 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1171 - msle: 9.2102 - rmsle: 0.1060 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1011 - val_msle: 4.4992 - val_rmsle: 0.0903 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 9.1438 - rmsle: 0.1057 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0935 - val_msle: 4.8333 - val_rmsle: 0.0828 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1122 - msle: 8.9488 - rmsle: 0.1022 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0919 - val_msle: 6.4360 - val_rmsle: 0.0833 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.8972 - rmsle: 0.1015 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 5.0089 - val_rmsle: 0.0777 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1084 - msle: 8.9095 - rmsle: 0.1004 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0879 - val_msle: 5.6009 - val_rmsle: 0.0801 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1079 - msle: 8.8759 - rmsle: 0.1002 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.6854 - val_rmsle: 0.0774 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1066 - msle: 8.8079 - rmsle: 0.0991 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0892 - val_msle: 4.7969 - val_rmsle: 0.0818 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1070 - msle: 8.8411 - rmsle: 0.0996 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 5.0344 - val_rmsle: 0.0700 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1057 - msle: 8.7694 - rmsle: 0.0985 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 4.7635 - val_rmsle: 0.0745 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1058 - msle: 8.7909 - rmsle: 0.0986 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 5.1546 - val_rmsle: 0.0759 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1059 - msle: 8.7797 - rmsle: 0.0987 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 5.6790 - val_rmsle: 0.0722 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1029 - msle: 8.6104 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 5.4262 - val_rmsle: 0.0689 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1017 - msle: 8.6454 - rmsle: 0.0956 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.7716 - val_rmsle: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.6229 - rmsle: 0.0956 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.3270 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.6045 - rmsle: 0.0949 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 3.7700 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1005 - msle: 8.5700 - rmsle: 0.0951 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.4661 - val_rmsle: 0.0663 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0999 - msle: 8.5639 - rmsle: 0.0946 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.0853 - val_rmsle: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.5521 - rmsle: 0.0944 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.5897 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0979 - msle: 8.5018 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 5.1169 - val_rmsle: 0.0652 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0972 - msle: 8.4911 - rmsle: 0.0925 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.4225 - val_rmsle: 0.0638 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06447435454792601\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.7242 - msle: 98.4956 - rmsle: 2.3095 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8682 - val_msle: 73.6613 - val_rmsle: 0.8335 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5160 - msle: 52.6355 - rmsle: 0.4909 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1570 - val_msle: 13.7814 - val_rmsle: 0.1373 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1561 - msle: 12.7212 - rmsle: 0.1367 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1542 - val_msle: 8.3738 - val_rmsle: 0.1362 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1373 - msle: 10.2842 - rmsle: 0.1200 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1314 - val_msle: 4.7512 - val_rmsle: 0.1159 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1313 - msle: 9.9580 - rmsle: 0.1162 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1211 - val_msle: 5.1769 - val_rmsle: 0.1065 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1268 - msle: 9.6588 - rmsle: 0.1127 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1101 - val_msle: 4.6485 - val_rmsle: 0.0965 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1239 - msle: 9.5157 - rmsle: 0.1108 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1102 - val_msle: 4.1187 - val_rmsle: 0.0968 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1226 - msle: 9.4173 - rmsle: 0.1096 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1023 - val_msle: 6.5912 - val_rmsle: 0.0896 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1209 - msle: 9.3511 - rmsle: 0.1086 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1194 - val_msle: 4.0952 - val_rmsle: 0.1070 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1192 - msle: 9.2524 - rmsle: 0.1073 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 4.5318 - val_rmsle: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1182 - msle: 9.2209 - rmsle: 0.1066 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0949 - val_msle: 6.7116 - val_rmsle: 0.0836 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1169 - msle: 9.1329 - rmsle: 0.1059 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0924 - val_msle: 5.6921 - val_rmsle: 0.0811 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1158 - msle: 9.1073 - rmsle: 0.1049 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0891 - val_msle: 4.0397 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1112 - msle: 8.9099 - rmsle: 0.1011 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0844 - val_msle: 6.8943 - val_rmsle: 0.0757 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1087 - msle: 8.8655 - rmsle: 0.1002 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 5.1164 - val_rmsle: 0.0717 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1082 - msle: 8.8524 - rmsle: 0.1002 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.6968 - val_rmsle: 0.0678 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1073 - msle: 8.8223 - rmsle: 0.0996 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.3136 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1065 - msle: 8.7795 - rmsle: 0.0989 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 5.5985 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1065 - msle: 8.8023 - rmsle: 0.0990 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.3379 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1057 - msle: 8.7604 - rmsle: 0.0984 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.6759 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.7267 - rmsle: 0.0983 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 3.9865 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1053 - msle: 8.7423 - rmsle: 0.0982 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 6.2097 - val_rmsle: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1019 - msle: 8.5945 - rmsle: 0.0951 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 5.2511 - val_rmsle: 0.0696 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1009 - msle: 8.5604 - rmsle: 0.0948 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.8156 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1006 - msle: 8.5399 - rmsle: 0.0949 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.4716 - val_rmsle: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0998 - msle: 8.5687 - rmsle: 0.0943 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.1008 - val_rmsle: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.5555 - rmsle: 0.0942 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0697 - val_msle: 4.4596 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0980 - msle: 8.4585 - rmsle: 0.0928 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.4553 - val_rmsle: 0.0658 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.4229 - rmsle: 0.0922 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.7886 - val_rmsle: 0.0637 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0966 - msle: 8.4345 - rmsle: 0.0920 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.0816 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0962 - msle: 8.4324 - rmsle: 0.0918 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.7444 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06347926983103606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:12:12,390] Trial 39 finished with value: 0.06435060997812309 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.001243250807070294, 'do_rate': 0.38337843404644, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 18s 14ms/step - dense_loss: 0.0000e+00 - loss: 4.3555 - msle: 98.7020 - rmsle: 2.2867 - val_dense_loss: 0.0000e+00 - val_loss: 0.9963 - val_msle: 79.1582 - val_rmsle: 0.9590 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6244 - msle: 59.4606 - rmsle: 0.5926 - val_dense_loss: 0.0000e+00 - val_loss: 0.2435 - val_msle: 25.0046 - val_rmsle: 0.2085 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2297 - msle: 20.5457 - rmsle: 0.1931 - val_dense_loss: 0.0000e+00 - val_loss: 0.1348 - val_msle: 7.2048 - val_rmsle: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1812 - msle: 12.5926 - rmsle: 0.1477 - val_dense_loss: 0.0000e+00 - val_loss: 0.1540 - val_msle: 12.7392 - val_rmsle: 0.1231 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1712 - msle: 12.1630 - rmsle: 0.1410 - val_dense_loss: 0.0000e+00 - val_loss: 0.1413 - val_msle: 8.9957 - val_rmsle: 0.1140 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1648 - msle: 11.8729 - rmsle: 0.1373 - val_dense_loss: 0.0000e+00 - val_loss: 0.1395 - val_msle: 6.0695 - val_rmsle: 0.1123 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1505 - msle: 11.3253 - rmsle: 0.1277 - val_dense_loss: 0.0000e+00 - val_loss: 0.1037 - val_msle: 5.2566 - val_rmsle: 0.0846 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1454 - msle: 11.1070 - rmsle: 0.1267 - val_dense_loss: 0.0000e+00 - val_loss: 0.1142 - val_msle: 4.6909 - val_rmsle: 0.0958 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1429 - msle: 10.9547 - rmsle: 0.1249 - val_dense_loss: 0.0000e+00 - val_loss: 0.0975 - val_msle: 7.3686 - val_rmsle: 0.0800 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1412 - msle: 10.8668 - rmsle: 0.1239 - val_dense_loss: 0.0000e+00 - val_loss: 0.1137 - val_msle: 8.5203 - val_rmsle: 0.0965 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1407 - msle: 10.8331 - rmsle: 0.1236 - val_dense_loss: 0.0000e+00 - val_loss: 0.1067 - val_msle: 6.5208 - val_rmsle: 0.0898 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1382 - msle: 10.6798 - rmsle: 0.1217 - val_dense_loss: 0.0000e+00 - val_loss: 0.1039 - val_msle: 4.7842 - val_rmsle: 0.0873 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1307 - msle: 10.3503 - rmsle: 0.1158 - val_dense_loss: 0.0000e+00 - val_loss: 0.1132 - val_msle: 6.0239 - val_rmsle: 0.1004 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1273 - msle: 10.2890 - rmsle: 0.1149 - val_dense_loss: 0.0000e+00 - val_loss: 0.1010 - val_msle: 4.1159 - val_rmsle: 0.0888 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1260 - msle: 10.2333 - rmsle: 0.1142 - val_dense_loss: 0.0000e+00 - val_loss: 0.1041 - val_msle: 4.9093 - val_rmsle: 0.0923 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1209 - msle: 10.0291 - rmsle: 0.1099 - val_dense_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 6.7441 - val_rmsle: 0.0801 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1189 - msle: 9.9361 - rmsle: 0.1093 - val_dense_loss: 0.0000e+00 - val_loss: 0.0868 - val_msle: 5.6233 - val_rmsle: 0.0776 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1178 - msle: 9.8815 - rmsle: 0.1088 - val_dense_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 4.3558 - val_rmsle: 0.0722 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1172 - msle: 9.8839 - rmsle: 0.1085 - val_dense_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 4.4957 - val_rmsle: 0.0749 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1164 - msle: 9.8479 - rmsle: 0.1080 - val_dense_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 3.9937 - val_rmsle: 0.0716 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.7998 - rmsle: 0.1074 - val_dense_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 5.2095 - val_rmsle: 0.0738 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1151 - msle: 9.7947 - rmsle: 0.1070 - val_dense_loss: 0.0000e+00 - val_loss: 0.0866 - val_msle: 4.5263 - val_rmsle: 0.0785 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1154 - msle: 9.7888 - rmsle: 0.1074 - val_dense_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 4.5025 - val_rmsle: 0.0741 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1126 - msle: 9.6614 - rmsle: 0.1048 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.1449 - val_rmsle: 0.0661 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1113 - msle: 9.6224 - rmsle: 0.1041 - val_dense_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.3743 - val_rmsle: 0.0679 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1107 - msle: 9.5592 - rmsle: 0.1038 - val_dense_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.8356 - val_rmsle: 0.0658 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1103 - msle: 9.5930 - rmsle: 0.1036 - val_dense_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 3.8109 - val_rmsle: 0.0665 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1096 - msle: 9.5507 - rmsle: 0.1031 - val_dense_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.9123 - val_rmsle: 0.0646 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1093 - msle: 9.5134 - rmsle: 0.1030 - val_dense_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.7926 - val_rmsle: 0.0663 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1090 - msle: 9.5011 - rmsle: 0.1028 - val_dense_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.0481 - val_rmsle: 0.0651 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1086 - msle: 9.4985 - rmsle: 0.1024 - val_dense_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.1294 - val_rmsle: 0.0674 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0652821451420771\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 13ms/step - dense_1_loss: 0.0000e+00 - loss: 4.3531 - msle: 98.6354 - rmsle: 2.2864 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.0364 - val_msle: 80.4196 - val_rmsle: 0.9977 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6307 - msle: 59.6876 - rmsle: 0.5975 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1851 - val_msle: 17.4159 - val_rmsle: 0.1513 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2313 - msle: 21.0961 - rmsle: 0.1951 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1804 - val_msle: 12.9140 - val_rmsle: 0.1478 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1780 - msle: 12.5810 - rmsle: 0.1460 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1607 - val_msle: 7.0760 - val_rmsle: 0.1313 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1684 - msle: 12.2447 - rmsle: 0.1398 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1221 - val_msle: 4.7730 - val_rmsle: 0.0939 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1650 - msle: 12.0069 - rmsle: 0.1376 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1532 - val_msle: 9.1349 - val_rmsle: 0.1263 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1600 - msle: 11.8035 - rmsle: 0.1338 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1580 - val_msle: 4.8383 - val_rmsle: 0.1337 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1571 - msle: 11.5958 - rmsle: 0.1324 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1244 - val_msle: 6.8910 - val_rmsle: 0.0995 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1456 - msle: 11.0391 - rmsle: 0.1245 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0924 - val_msle: 4.4326 - val_rmsle: 0.0739 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1404 - msle: 10.8854 - rmsle: 0.1227 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0969 - val_msle: 4.4628 - val_rmsle: 0.0796 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1401 - msle: 10.8688 - rmsle: 0.1229 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0979 - val_msle: 7.7520 - val_rmsle: 0.0819 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1379 - msle: 10.7476 - rmsle: 0.1216 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 5.5310 - val_rmsle: 0.0755 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1375 - msle: 10.7666 - rmsle: 0.1212 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0971 - val_msle: 7.4194 - val_rmsle: 0.0806 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1362 - msle: 10.6625 - rmsle: 0.1200 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0913 - val_msle: 6.2723 - val_rmsle: 0.0754 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1346 - msle: 10.5665 - rmsle: 0.1189 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0975 - val_msle: 5.6849 - val_rmsle: 0.0816 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1361 - msle: 10.5553 - rmsle: 0.1201 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 5.3195 - val_rmsle: 0.0759 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1337 - msle: 10.4797 - rmsle: 0.1182 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1004 - val_msle: 6.9600 - val_rmsle: 0.0847 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1262 - msle: 10.1343 - rmsle: 0.1122 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0927 - val_msle: 6.9933 - val_rmsle: 0.0810 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1233 - msle: 10.0590 - rmsle: 0.1118 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0810 - val_msle: 5.6357 - val_rmsle: 0.0699 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1226 - msle: 10.0689 - rmsle: 0.1115 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.5970 - val_rmsle: 0.0654 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1216 - msle: 10.0313 - rmsle: 0.1108 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 3.9483 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1213 - msle: 10.0170 - rmsle: 0.1107 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.4147 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1202 - msle: 9.9716 - rmsle: 0.1099 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 5.2052 - val_rmsle: 0.0723 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1199 - msle: 9.9296 - rmsle: 0.1097 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.0260 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1194 - msle: 9.9821 - rmsle: 0.1092 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.1634 - val_rmsle: 0.0681 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.7611 - rmsle: 0.1060 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.8673 - val_rmsle: 0.0682 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1143 - msle: 9.7742 - rmsle: 0.1058 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 6.0415 - val_rmsle: 0.0718 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1137 - msle: 9.7197 - rmsle: 0.1057 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 5.0330 - val_rmsle: 0.0702 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1106 - msle: 9.5749 - rmsle: 0.1029 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.5133 - val_rmsle: 0.0653 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1097 - msle: 9.5238 - rmsle: 0.1027 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.1661 - val_rmsle: 0.0646 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1089 - msle: 9.4927 - rmsle: 0.1022 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.2549 - val_rmsle: 0.0646 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 310.0730285644531\n",
            "Fold 1 RMSLE: 0.06479784140431363\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 13ms/step - dense_2_loss: 0.0000e+00 - loss: 4.3608 - msle: 98.6059 - rmsle: 2.2911 - val_dense_2_loss: 0.0000e+00 - val_loss: 1.0331 - val_msle: 80.2083 - val_rmsle: 0.9931 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6314 - msle: 59.7880 - rmsle: 0.5992 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2271 - val_msle: 21.9898 - val_rmsle: 0.1940 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2321 - msle: 21.0953 - rmsle: 0.1960 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1690 - val_msle: 4.9801 - val_rmsle: 0.1345 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1785 - msle: 12.7147 - rmsle: 0.1459 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1975 - val_msle: 11.4807 - val_rmsle: 0.1675 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1684 - msle: 12.3661 - rmsle: 0.1399 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1596 - val_msle: 5.4443 - val_rmsle: 0.1329 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1624 - msle: 11.9748 - rmsle: 0.1362 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1476 - val_msle: 10.2130 - val_rmsle: 0.1221 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1595 - msle: 11.8941 - rmsle: 0.1344 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1156 - val_msle: 6.3232 - val_rmsle: 0.0909 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1573 - msle: 11.7530 - rmsle: 0.1324 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1125 - val_msle: 6.7362 - val_rmsle: 0.0875 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1561 - msle: 11.5195 - rmsle: 0.1316 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1190 - val_msle: 8.7984 - val_rmsle: 0.0959 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1534 - msle: 11.3560 - rmsle: 0.1300 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1062 - val_msle: 7.5239 - val_rmsle: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1503 - msle: 11.2812 - rmsle: 0.1273 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1243 - val_msle: 7.5090 - val_rmsle: 0.1018 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1492 - msle: 11.1279 - rmsle: 0.1267 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1190 - val_msle: 7.6827 - val_rmsle: 0.0968 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1475 - msle: 11.0276 - rmsle: 0.1254 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1045 - val_msle: 7.1062 - val_rmsle: 0.0825 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1442 - msle: 10.8324 - rmsle: 0.1226 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1303 - val_msle: 11.9103 - val_rmsle: 0.1084 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1438 - msle: 10.8052 - rmsle: 0.1223 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1199 - val_msle: 9.3859 - val_rmsle: 0.0982 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1416 - msle: 10.6585 - rmsle: 0.1207 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1169 - val_msle: 8.2186 - val_rmsle: 0.0963 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1306 - msle: 10.3159 - rmsle: 0.1135 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0882 - val_msle: 5.2016 - val_rmsle: 0.0739 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1267 - msle: 10.1877 - rmsle: 0.1126 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 4.2105 - val_rmsle: 0.0705 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1253 - msle: 10.1286 - rmsle: 0.1119 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0866 - val_msle: 4.6046 - val_rmsle: 0.0733 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1246 - msle: 10.0651 - rmsle: 0.1113 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0881 - val_msle: 4.4422 - val_rmsle: 0.0744 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1236 - msle: 10.0188 - rmsle: 0.1103 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1304 - val_msle: 16.9920 - val_rmsle: 0.1171 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1184 - msle: 9.8496 - rmsle: 0.1064 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 6.8141 - val_rmsle: 0.0771 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1156 - msle: 9.7798 - rmsle: 0.1056 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 4.1652 - val_rmsle: 0.0739 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1145 - msle: 9.7286 - rmsle: 0.1050 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 5.1573 - val_rmsle: 0.0748 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1144 - msle: 9.7920 - rmsle: 0.1052 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 4.2687 - val_rmsle: 0.0716 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1134 - msle: 9.7145 - rmsle: 0.1044 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 4.0608 - val_rmsle: 0.0695 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1132 - msle: 9.7092 - rmsle: 0.1042 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 3.9492 - val_rmsle: 0.0722 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1128 - msle: 9.6925 - rmsle: 0.1040 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 3.9402 - val_rmsle: 0.0667 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1125 - msle: 9.6891 - rmsle: 0.1037 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0845 - val_msle: 4.6687 - val_rmsle: 0.0758 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1123 - msle: 9.6480 - rmsle: 0.1036 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 3.7702 - val_rmsle: 0.0669 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1118 - msle: 9.6740 - rmsle: 0.1032 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.2502 - val_rmsle: 0.0713 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06672436199909373\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 17s 13ms/step - dense_3_loss: 0.0000e+00 - loss: 4.3587 - msle: 98.6869 - rmsle: 2.2905 - val_dense_3_loss: 0.0000e+00 - val_loss: 1.0140 - val_msle: 79.8848 - val_rmsle: 0.9775 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.6288 - msle: 59.8529 - rmsle: 0.5979 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2331 - val_msle: 26.4605 - val_rmsle: 0.1990 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2353 - msle: 21.3839 - rmsle: 0.1982 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1898 - val_msle: 11.6801 - val_rmsle: 0.1564 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1806 - msle: 12.7816 - rmsle: 0.1482 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1867 - val_msle: 5.6673 - val_rmsle: 0.1556 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1684 - msle: 12.3456 - rmsle: 0.1399 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1431 - val_msle: 9.7001 - val_rmsle: 0.1169 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1623 - msle: 12.0230 - rmsle: 0.1361 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1462 - val_msle: 9.9405 - val_rmsle: 0.1208 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1612 - msle: 11.8180 - rmsle: 0.1352 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1452 - val_msle: 5.6696 - val_rmsle: 0.1192 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1578 - msle: 11.6558 - rmsle: 0.1327 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1938 - val_msle: 11.2704 - val_rmsle: 0.1692 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1454 - msle: 11.1719 - rmsle: 0.1244 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1140 - val_msle: 4.4640 - val_rmsle: 0.0957 - learning_rate: 2.5000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1399 - msle: 10.9732 - rmsle: 0.1226 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1098 - val_msle: 4.5435 - val_rmsle: 0.0927 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1394 - msle: 10.9358 - rmsle: 0.1226 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1200 - val_msle: 6.7252 - val_rmsle: 0.1033 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1361 - msle: 10.7685 - rmsle: 0.1201 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1234 - val_msle: 4.9311 - val_rmsle: 0.1073 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1351 - msle: 10.7043 - rmsle: 0.1195 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1320 - val_msle: 6.9473 - val_rmsle: 0.1163 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1301 - msle: 10.3788 - rmsle: 0.1157 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 6.0457 - val_rmsle: 0.0806 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1265 - msle: 10.2820 - rmsle: 0.1143 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0923 - val_msle: 6.6528 - val_rmsle: 0.0804 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1252 - msle: 10.2335 - rmsle: 0.1136 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 5.9390 - val_rmsle: 0.0801 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1245 - msle: 10.2473 - rmsle: 0.1131 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1012 - val_msle: 5.2068 - val_rmsle: 0.0902 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1240 - msle: 10.1729 - rmsle: 0.1130 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 4.7709 - val_rmsle: 0.0746 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1228 - msle: 10.1031 - rmsle: 0.1120 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0828 - val_msle: 4.9072 - val_rmsle: 0.0719 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1227 - msle: 10.1268 - rmsle: 0.1119 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0853 - val_msle: 4.1719 - val_rmsle: 0.0743 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1221 - msle: 10.1363 - rmsle: 0.1113 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0899 - val_msle: 5.4590 - val_rmsle: 0.0791 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1223 - msle: 10.0738 - rmsle: 0.1116 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 4.0320 - val_rmsle: 0.0723 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1177 - msle: 9.8105 - rmsle: 0.1076 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0793 - val_msle: 4.2482 - val_rmsle: 0.0702 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1155 - msle: 9.7810 - rmsle: 0.1067 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 5.1514 - val_rmsle: 0.0714 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1148 - msle: 9.7667 - rmsle: 0.1065 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.7956 - val_rmsle: 0.0699 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1142 - msle: 9.7309 - rmsle: 0.1062 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 5.8332 - val_rmsle: 0.0715 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1138 - msle: 9.7514 - rmsle: 0.1059 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 3.8388 - val_rmsle: 0.0662 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1131 - msle: 9.7280 - rmsle: 0.1053 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.1574 - val_rmsle: 0.0677 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1134 - msle: 9.7203 - rmsle: 0.1058 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.0560 - val_rmsle: 0.0663 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1125 - msle: 9.6882 - rmsle: 0.1050 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 5.5030 - val_rmsle: 0.0692 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1122 - msle: 9.6586 - rmsle: 0.1047 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 5.1461 - val_rmsle: 0.0695 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.0668920609896593\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 16s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 4.3522 - msle: 98.7960 - rmsle: 2.2895 - val_dense_4_loss: 0.0000e+00 - val_loss: 1.0427 - val_msle: 80.4625 - val_rmsle: 1.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6313 - msle: 59.9269 - rmsle: 0.5991 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2703 - val_msle: 26.4074 - val_rmsle: 0.2359 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2315 - msle: 21.1122 - rmsle: 0.1953 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2052 - val_msle: 16.0598 - val_rmsle: 0.1717 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1773 - msle: 12.6285 - rmsle: 0.1454 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1989 - val_msle: 7.1346 - val_rmsle: 0.1688 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1686 - msle: 12.1829 - rmsle: 0.1396 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2091 - val_msle: 9.1096 - val_rmsle: 0.1794 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1629 - msle: 11.8971 - rmsle: 0.1354 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1326 - val_msle: 8.6381 - val_rmsle: 0.1035 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1604 - msle: 11.6773 - rmsle: 0.1335 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1807 - val_msle: 12.2496 - val_rmsle: 0.1532 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1562 - msle: 11.4260 - rmsle: 0.1310 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1982 - val_msle: 14.9047 - val_rmsle: 0.1712 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1556 - msle: 11.2653 - rmsle: 0.1302 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1771 - val_msle: 8.3297 - val_rmsle: 0.1505 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1436 - msle: 10.8449 - rmsle: 0.1219 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1018 - val_msle: 6.3315 - val_rmsle: 0.0843 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1367 - msle: 10.6117 - rmsle: 0.1198 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1082 - val_msle: 10.1096 - val_rmsle: 0.0916 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1349 - msle: 10.5311 - rmsle: 0.1188 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0991 - val_msle: 8.1280 - val_rmsle: 0.0827 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1350 - msle: 10.5625 - rmsle: 0.1189 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.3060 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1334 - msle: 10.4506 - rmsle: 0.1178 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0983 - val_msle: 6.6217 - val_rmsle: 0.0821 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1340 - msle: 10.4060 - rmsle: 0.1181 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0893 - val_msle: 4.0066 - val_rmsle: 0.0735 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1322 - msle: 10.3917 - rmsle: 0.1167 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0908 - val_msle: 4.5256 - val_rmsle: 0.0752 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1251 - msle: 10.1207 - rmsle: 0.1112 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0953 - val_msle: 6.8131 - val_rmsle: 0.0836 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1216 - msle: 9.9729 - rmsle: 0.1102 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 5.9599 - val_rmsle: 0.0728 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1209 - msle: 9.9965 - rmsle: 0.1100 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.1527 - val_rmsle: 0.0658 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1195 - msle: 9.9190 - rmsle: 0.1090 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.1118 - val_rmsle: 0.0696 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1192 - msle: 9.9211 - rmsle: 0.1090 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 5.6557 - val_rmsle: 0.0716 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1178 - msle: 9.8903 - rmsle: 0.1078 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 3.9716 - val_rmsle: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1178 - msle: 9.8766 - rmsle: 0.1079 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 5.3156 - val_rmsle: 0.0738 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1180 - msle: 9.8427 - rmsle: 0.1081 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.4708 - val_rmsle: 0.0667 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1175 - msle: 9.8461 - rmsle: 0.1077 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.0911 - val_rmsle: 0.0700 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1133 - msle: 9.6291 - rmsle: 0.1040 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.3344 - val_rmsle: 0.0689 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1116 - msle: 9.6014 - rmsle: 0.1035 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 5.9581 - val_rmsle: 0.0706 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1112 - msle: 9.5518 - rmsle: 0.1035 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.4302 - val_rmsle: 0.0669 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1107 - msle: 9.6249 - rmsle: 0.1032 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 5.7896 - val_rmsle: 0.0723 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.0662363164010269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:20:14,802] Trial 40 finished with value: 0.06598654518723414 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.006765897049474696, 'do_rate': 0.40516580732698926, 'hidden_layers': 4}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.3860 - msle: 98.2153 - rmsle: 2.3510 - val_dense_loss: 0.0000e+00 - val_loss: 1.1324 - val_msle: 76.8501 - val_rmsle: 1.1054 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.9839 - msle: 72.2996 - rmsle: 0.9581 - val_dense_loss: 0.0000e+00 - val_loss: 0.3306 - val_msle: 33.4616 - val_rmsle: 0.3078 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3518 - msle: 26.8534 - rmsle: 0.3299 - val_dense_loss: 0.0000e+00 - val_loss: 0.1592 - val_msle: 9.0414 - val_rmsle: 0.1402 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2834 - msle: 13.3176 - rmsle: 0.2650 - val_dense_loss: 0.0000e+00 - val_loss: 0.1636 - val_msle: 6.8865 - val_rmsle: 0.1470 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2564 - msle: 12.0635 - rmsle: 0.2403 - val_dense_loss: 0.0000e+00 - val_loss: 0.1626 - val_msle: 6.9729 - val_rmsle: 0.1475 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2349 - msle: 11.5855 - rmsle: 0.2201 - val_dense_loss: 0.0000e+00 - val_loss: 0.1143 - val_msle: 6.5234 - val_rmsle: 0.1003 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2203 - msle: 11.3483 - rmsle: 0.2066 - val_dense_loss: 0.0000e+00 - val_loss: 0.1195 - val_msle: 7.0009 - val_rmsle: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2097 - msle: 11.1468 - rmsle: 0.1970 - val_dense_loss: 0.0000e+00 - val_loss: 0.1257 - val_msle: 7.1579 - val_rmsle: 0.1136 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2002 - msle: 10.9180 - rmsle: 0.1884 - val_dense_loss: 0.0000e+00 - val_loss: 0.1025 - val_msle: 6.4287 - val_rmsle: 0.0912 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1927 - msle: 10.6990 - rmsle: 0.1818 - val_dense_loss: 0.0000e+00 - val_loss: 0.1121 - val_msle: 6.7035 - val_rmsle: 0.1018 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1870 - msle: 10.5833 - rmsle: 0.1769 - val_dense_loss: 0.0000e+00 - val_loss: 0.1075 - val_msle: 6.7166 - val_rmsle: 0.0978 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1815 - msle: 10.4885 - rmsle: 0.1721 - val_dense_loss: 0.0000e+00 - val_loss: 0.1201 - val_msle: 6.8481 - val_rmsle: 0.1112 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1744 - msle: 10.3794 - rmsle: 0.1657 - val_dense_loss: 0.0000e+00 - val_loss: 0.1187 - val_msle: 7.2157 - val_rmsle: 0.1102 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1742 - msle: 10.3713 - rmsle: 0.1659 - val_dense_loss: 0.0000e+00 - val_loss: 0.1105 - val_msle: 7.1303 - val_rmsle: 0.1025 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1703 - msle: 10.2657 - rmsle: 0.1624 - val_dense_loss: 0.0000e+00 - val_loss: 0.1178 - val_msle: 7.2321 - val_rmsle: 0.1101 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1670 - msle: 10.2479 - rmsle: 0.1594 - val_dense_loss: 0.0000e+00 - val_loss: 0.1021 - val_msle: 7.1337 - val_rmsle: 0.0946 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1652 - msle: 10.1920 - rmsle: 0.1579 - val_dense_loss: 0.0000e+00 - val_loss: 0.1014 - val_msle: 6.8614 - val_rmsle: 0.0942 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1654 - msle: 10.1812 - rmsle: 0.1583 - val_dense_loss: 0.0000e+00 - val_loss: 0.0948 - val_msle: 6.7339 - val_rmsle: 0.0878 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1637 - msle: 10.1383 - rmsle: 0.1568 - val_dense_loss: 0.0000e+00 - val_loss: 0.0991 - val_msle: 6.8425 - val_rmsle: 0.0923 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1619 - msle: 10.0948 - rmsle: 0.1553 - val_dense_loss: 0.0000e+00 - val_loss: 0.0881 - val_msle: 6.9476 - val_rmsle: 0.0814 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1609 - msle: 10.0988 - rmsle: 0.1543 - val_dense_loss: 0.0000e+00 - val_loss: 0.1010 - val_msle: 6.9767 - val_rmsle: 0.0945 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1598 - msle: 10.0787 - rmsle: 0.1534 - val_dense_loss: 0.0000e+00 - val_loss: 0.0973 - val_msle: 6.8820 - val_rmsle: 0.0910 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1586 - msle: 10.0771 - rmsle: 0.1524 - val_dense_loss: 0.0000e+00 - val_loss: 0.0961 - val_msle: 6.8047 - val_rmsle: 0.0899 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1579 - msle: 10.0084 - rmsle: 0.1518 - val_dense_loss: 0.0000e+00 - val_loss: 0.0896 - val_msle: 6.6846 - val_rmsle: 0.0835 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1577 - msle: 10.0091 - rmsle: 0.1517 - val_dense_loss: 0.0000e+00 - val_loss: 0.0941 - val_msle: 6.7005 - val_rmsle: 0.0881 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1569 - msle: 10.0193 - rmsle: 0.1510 - val_dense_loss: 0.0000e+00 - val_loss: 0.0942 - val_msle: 6.6481 - val_rmsle: 0.0882 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1553 - msle: 10.0145 - rmsle: 0.1495 - val_dense_loss: 0.0000e+00 - val_loss: 0.0898 - val_msle: 6.4740 - val_rmsle: 0.0840 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1546 - msle: 9.9482 - rmsle: 0.1488 - val_dense_loss: 0.0000e+00 - val_loss: 0.0924 - val_msle: 6.5238 - val_rmsle: 0.0865 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1547 - msle: 9.9559 - rmsle: 0.1490 - val_dense_loss: 0.0000e+00 - val_loss: 0.0911 - val_msle: 6.4177 - val_rmsle: 0.0853 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1547 - msle: 9.9420 - rmsle: 0.1490 - val_dense_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 6.3326 - val_rmsle: 0.0809 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1543 - msle: 9.9306 - rmsle: 0.1486 - val_dense_loss: 0.0000e+00 - val_loss: 0.0890 - val_msle: 6.4074 - val_rmsle: 0.0833 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 311.0899963378906\n",
            "Fold 0 RMSLE: 0.08134704214392194\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.3851 - msle: 98.1384 - rmsle: 2.3501 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.1433 - val_msle: 76.5993 - val_rmsle: 1.1161 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.9887 - msle: 72.4652 - rmsle: 0.9631 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3001 - val_msle: 31.9139 - val_rmsle: 0.2775 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3476 - msle: 26.7350 - rmsle: 0.3259 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1407 - val_msle: 8.7585 - val_rmsle: 0.1214 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2802 - msle: 13.3172 - rmsle: 0.2617 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1464 - val_msle: 6.7052 - val_rmsle: 0.1297 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2543 - msle: 11.9409 - rmsle: 0.2380 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1370 - val_msle: 7.0593 - val_rmsle: 0.1217 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2340 - msle: 11.5259 - rmsle: 0.2190 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1402 - val_msle: 7.6217 - val_rmsle: 0.1261 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2187 - msle: 11.2084 - rmsle: 0.2049 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1289 - val_msle: 7.4724 - val_rmsle: 0.1158 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2086 - msle: 11.0274 - rmsle: 0.1959 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1360 - val_msle: 7.5812 - val_rmsle: 0.1241 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2000 - msle: 10.9259 - rmsle: 0.1884 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1117 - val_msle: 7.4134 - val_rmsle: 0.1005 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1934 - msle: 10.7443 - rmsle: 0.1825 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1277 - val_msle: 7.6381 - val_rmsle: 0.1175 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1880 - msle: 10.6033 - rmsle: 0.1780 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1236 - val_msle: 7.5758 - val_rmsle: 0.1141 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1820 - msle: 10.4896 - rmsle: 0.1727 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1227 - val_msle: 7.1560 - val_rmsle: 0.1138 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1754 - msle: 10.3470 - rmsle: 0.1666 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1239 - val_msle: 8.0367 - val_rmsle: 0.1155 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1731 - msle: 10.3270 - rmsle: 0.1649 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1187 - val_msle: 7.3110 - val_rmsle: 0.1108 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1696 - msle: 10.2211 - rmsle: 0.1618 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0990 - val_msle: 7.2876 - val_rmsle: 0.0914 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1682 - msle: 10.2098 - rmsle: 0.1607 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1157 - val_msle: 7.7316 - val_rmsle: 0.1084 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1656 - msle: 10.1496 - rmsle: 0.1584 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0993 - val_msle: 6.9736 - val_rmsle: 0.0922 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1647 - msle: 10.1570 - rmsle: 0.1578 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0987 - val_msle: 7.1673 - val_rmsle: 0.0919 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1629 - msle: 10.0840 - rmsle: 0.1562 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1037 - val_msle: 7.4535 - val_rmsle: 0.0971 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1605 - msle: 10.0105 - rmsle: 0.1541 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0969 - val_msle: 6.8572 - val_rmsle: 0.0905 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1593 - msle: 10.0104 - rmsle: 0.1530 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0999 - val_msle: 7.6475 - val_rmsle: 0.0937 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1569 - msle: 9.9592 - rmsle: 0.1508 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1003 - val_msle: 6.7792 - val_rmsle: 0.0943 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1570 - msle: 9.9766 - rmsle: 0.1510 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1049 - val_msle: 7.1397 - val_rmsle: 0.0990 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1532 - msle: 9.8909 - rmsle: 0.1474 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1016 - val_msle: 6.7356 - val_rmsle: 0.0959 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1530 - msle: 9.8532 - rmsle: 0.1474 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1049 - val_msle: 6.5988 - val_rmsle: 0.0993 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1511 - msle: 9.8531 - rmsle: 0.1456 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1045 - val_msle: 6.3373 - val_rmsle: 0.0990 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1501 - msle: 9.8306 - rmsle: 0.1446 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1052 - val_msle: 6.3115 - val_rmsle: 0.0998 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1500 - msle: 9.7928 - rmsle: 0.1446 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0999 - val_msle: 6.3426 - val_rmsle: 0.0945 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1496 - msle: 9.7582 - rmsle: 0.1443 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1005 - val_msle: 6.5465 - val_rmsle: 0.0952 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1475 - msle: 9.7392 - rmsle: 0.1423 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0922 - val_msle: 6.1946 - val_rmsle: 0.0869 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1468 - msle: 9.7274 - rmsle: 0.1417 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0919 - val_msle: 6.0903 - val_rmsle: 0.0867 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 296.73199462890625\n",
            "Fold 1 RMSLE: 0.0870625557572766\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.3820 - msle: 98.1559 - rmsle: 2.3471 - val_dense_2_loss: 0.0000e+00 - val_loss: 1.1091 - val_msle: 77.1151 - val_rmsle: 1.0821 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.9853 - msle: 72.3087 - rmsle: 0.9597 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3192 - val_msle: 30.2803 - val_rmsle: 0.2966 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3500 - msle: 26.9196 - rmsle: 0.3281 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1386 - val_msle: 8.6663 - val_rmsle: 0.1191 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2817 - msle: 13.4722 - rmsle: 0.2630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1290 - val_msle: 6.9018 - val_rmsle: 0.1122 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2547 - msle: 11.9437 - rmsle: 0.2383 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1126 - val_msle: 6.1194 - val_rmsle: 0.0973 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2329 - msle: 11.4520 - rmsle: 0.2179 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1036 - val_msle: 6.3540 - val_rmsle: 0.0894 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2182 - msle: 11.2096 - rmsle: 0.2043 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1154 - val_msle: 6.4488 - val_rmsle: 0.1024 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2070 - msle: 11.0027 - rmsle: 0.1943 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1050 - val_msle: 6.7548 - val_rmsle: 0.0930 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2004 - msle: 10.8240 - rmsle: 0.1886 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0949 - val_msle: 6.7809 - val_rmsle: 0.0838 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1919 - msle: 10.6705 - rmsle: 0.1810 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1035 - val_msle: 6.8347 - val_rmsle: 0.0933 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1867 - msle: 10.5364 - rmsle: 0.1766 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0949 - val_msle: 6.3795 - val_rmsle: 0.0853 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1807 - msle: 10.4278 - rmsle: 0.1712 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1099 - val_msle: 6.3819 - val_rmsle: 0.1010 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1732 - msle: 10.2904 - rmsle: 0.1644 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1115 - val_msle: 6.6417 - val_rmsle: 0.1031 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1712 - msle: 10.2130 - rmsle: 0.1630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1117 - val_msle: 6.2985 - val_rmsle: 0.1037 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1695 - msle: 10.1871 - rmsle: 0.1616 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1000 - val_msle: 6.5674 - val_rmsle: 0.0924 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1661 - msle: 10.1136 - rmsle: 0.1586 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1049 - val_msle: 6.4296 - val_rmsle: 0.0976 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1645 - msle: 10.0224 - rmsle: 0.1572 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0976 - val_msle: 6.2055 - val_rmsle: 0.0905 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1624 - msle: 10.0812 - rmsle: 0.1554 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0974 - val_msle: 6.1432 - val_rmsle: 0.0905 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1615 - msle: 10.0316 - rmsle: 0.1547 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0936 - val_msle: 6.1639 - val_rmsle: 0.0869 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 295.76068115234375\n",
            "Fold 2 RMSLE: 0.08334642368296602\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 11s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.3810 - msle: 98.2080 - rmsle: 2.3461 - val_dense_3_loss: 0.0000e+00 - val_loss: 1.1433 - val_msle: 77.4433 - val_rmsle: 1.1164 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.9991 - msle: 72.9073 - rmsle: 0.9734 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3031 - val_msle: 32.6424 - val_rmsle: 0.2804 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3518 - msle: 27.1614 - rmsle: 0.3300 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1488 - val_msle: 9.4900 - val_rmsle: 0.1292 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2814 - msle: 13.5010 - rmsle: 0.2625 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1642 - val_msle: 7.4847 - val_rmsle: 0.1470 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2560 - msle: 12.1006 - rmsle: 0.2392 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1480 - val_msle: 7.1710 - val_rmsle: 0.1322 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2358 - msle: 11.6529 - rmsle: 0.2203 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1329 - val_msle: 7.6573 - val_rmsle: 0.1183 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2190 - msle: 11.3283 - rmsle: 0.2048 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1695 - val_msle: 8.0784 - val_rmsle: 0.1562 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2121 - msle: 11.1424 - rmsle: 0.1990 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1843 - val_msle: 8.6544 - val_rmsle: 0.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2029 - msle: 11.0033 - rmsle: 0.1906 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1746 - val_msle: 8.3062 - val_rmsle: 0.1631 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1938 - msle: 10.8725 - rmsle: 0.1825 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1215 - val_msle: 7.3800 - val_rmsle: 0.1107 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1906 - msle: 10.7261 - rmsle: 0.1800 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1404 - val_msle: 7.6861 - val_rmsle: 0.1301 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1880 - msle: 10.6020 - rmsle: 0.1779 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1379 - val_msle: 6.8956 - val_rmsle: 0.1281 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1845 - msle: 10.6089 - rmsle: 0.1749 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1544 - val_msle: 7.8851 - val_rmsle: 0.1451 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1805 - msle: 10.5101 - rmsle: 0.1713 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1161 - val_msle: 6.8161 - val_rmsle: 0.1070 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1780 - msle: 10.4874 - rmsle: 0.1691 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1319 - val_msle: 6.8692 - val_rmsle: 0.1232 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1772 - msle: 10.4154 - rmsle: 0.1686 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1156 - val_msle: 6.7307 - val_rmsle: 0.1072 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1754 - msle: 10.3848 - rmsle: 0.1671 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1150 - val_msle: 6.7008 - val_rmsle: 0.1068 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1744 - msle: 10.3933 - rmsle: 0.1663 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1231 - val_msle: 6.6992 - val_rmsle: 0.1152 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1738 - msle: 10.3825 - rmsle: 0.1660 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1141 - val_msle: 6.9352 - val_rmsle: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1725 - msle: 10.3216 - rmsle: 0.1648 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1180 - val_msle: 6.5329 - val_rmsle: 0.1105 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1706 - msle: 10.3175 - rmsle: 0.1631 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1114 - val_msle: 6.8494 - val_rmsle: 0.1040 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1688 - msle: 10.2928 - rmsle: 0.1616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1127 - val_msle: 6.6542 - val_rmsle: 0.1055 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1687 - msle: 10.2532 - rmsle: 0.1616 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1223 - val_msle: 6.8008 - val_rmsle: 0.1152 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1677 - msle: 10.2674 - rmsle: 0.1608 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1169 - val_msle: 6.8069 - val_rmsle: 0.1100 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1660 - msle: 10.2020 - rmsle: 0.1592 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1080 - val_msle: 6.3266 - val_rmsle: 0.1012 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1653 - msle: 10.1917 - rmsle: 0.1585 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1082 - val_msle: 6.3713 - val_rmsle: 0.1015 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1642 - msle: 10.2025 - rmsle: 0.1576 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1051 - val_msle: 6.3662 - val_rmsle: 0.0985 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1631 - msle: 10.1243 - rmsle: 0.1565 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1089 - val_msle: 6.3094 - val_rmsle: 0.1023 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1635 - msle: 10.1517 - rmsle: 0.1570 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1029 - val_msle: 6.1363 - val_rmsle: 0.0965 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1628 - msle: 10.1701 - rmsle: 0.1564 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0987 - val_msle: 6.1517 - val_rmsle: 0.0923 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1625 - msle: 10.1368 - rmsle: 0.1561 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0999 - val_msle: 6.1424 - val_rmsle: 0.0936 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 303.2299499511719\n",
            "Fold 3 RMSLE: 0.09272487855330153\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.3852 - msle: 98.2758 - rmsle: 2.3503 - val_dense_4_loss: 0.0000e+00 - val_loss: 1.1432 - val_msle: 76.6176 - val_rmsle: 1.1161 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.9953 - msle: 72.5847 - rmsle: 0.9696 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3349 - val_msle: 34.7637 - val_rmsle: 0.3121 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3581 - msle: 27.5634 - rmsle: 0.3361 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1915 - val_msle: 8.7179 - val_rmsle: 0.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2825 - msle: 13.2732 - rmsle: 0.2636 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1429 - val_msle: 6.0773 - val_rmsle: 0.1259 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2581 - msle: 11.8929 - rmsle: 0.2416 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1451 - val_msle: 6.6791 - val_rmsle: 0.1297 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2355 - msle: 11.4433 - rmsle: 0.2204 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1069 - val_msle: 6.0261 - val_rmsle: 0.0923 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2193 - msle: 11.1749 - rmsle: 0.2051 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1297 - val_msle: 6.4874 - val_rmsle: 0.1163 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2083 - msle: 10.9419 - rmsle: 0.1952 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0951 - val_msle: 5.7619 - val_rmsle: 0.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2005 - msle: 10.7820 - rmsle: 0.1884 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1053 - val_msle: 6.0450 - val_rmsle: 0.0939 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1922 - msle: 10.6423 - rmsle: 0.1811 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1384 - val_msle: 6.7371 - val_rmsle: 0.1278 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1865 - msle: 10.4822 - rmsle: 0.1762 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1129 - val_msle: 5.7313 - val_rmsle: 0.1031 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1785 - msle: 10.3139 - rmsle: 0.1690 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1084 - val_msle: 6.0229 - val_rmsle: 0.0993 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1744 - msle: 10.2415 - rmsle: 0.1655 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1058 - val_msle: 6.1694 - val_rmsle: 0.0972 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1715 - msle: 10.2213 - rmsle: 0.1630 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1063 - val_msle: 6.1165 - val_rmsle: 0.0981 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1685 - msle: 10.1638 - rmsle: 0.1604 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0958 - val_msle: 6.4176 - val_rmsle: 0.0879 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1668 - msle: 10.1164 - rmsle: 0.1590 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0939 - val_msle: 6.2750 - val_rmsle: 0.0863 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1659 - msle: 10.0794 - rmsle: 0.1584 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0965 - val_msle: 6.4121 - val_rmsle: 0.0891 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1653 - msle: 10.0845 - rmsle: 0.1580 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0923 - val_msle: 6.2978 - val_rmsle: 0.0851 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.08163978319935775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:26:09,150] Trial 41 finished with value: 0.08522413666736477 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'celu', 'reg': 0.00013158704922745375, 'do_rate': 0.4435388071281556, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.2623 - msle: 99.3405 - rmsle: 2.0821 - val_dense_loss: 0.0000e+00 - val_loss: 0.8162 - val_msle: 74.3426 - val_rmsle: 0.7599 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6025 - msle: 80.2754 - rmsle: 0.5570 - val_dense_loss: 0.0000e+00 - val_loss: 0.2581 - val_msle: 61.5432 - val_rmsle: 0.2240 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2664 - msle: 65.7016 - rmsle: 0.2361 - val_dense_loss: 0.0000e+00 - val_loss: 0.2254 - val_msle: 51.9760 - val_rmsle: 0.2045 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2408 - msle: 56.5899 - rmsle: 0.2220 - val_dense_loss: 0.0000e+00 - val_loss: 0.2232 - val_msle: 41.2223 - val_rmsle: 0.2087 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2327 - msle: 36.8568 - rmsle: 0.2191 - val_dense_loss: 0.0000e+00 - val_loss: 0.2175 - val_msle: 22.8929 - val_rmsle: 0.2066 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2261 - msle: 23.2720 - rmsle: 0.2160 - val_dense_loss: 0.0000e+00 - val_loss: 0.2560 - val_msle: 39.4156 - val_rmsle: 0.2432 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1271 - msle: 8.6564 - rmsle: 0.1142 - val_dense_loss: 0.0000e+00 - val_loss: 0.0874 - val_msle: 6.5567 - val_rmsle: 0.0752 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1176 - msle: 8.5299 - rmsle: 0.1059 - val_dense_loss: 0.0000e+00 - val_loss: 0.0832 - val_msle: 5.6198 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1136 - msle: 8.3831 - rmsle: 0.1029 - val_dense_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 4.7229 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1116 - msle: 8.2690 - rmsle: 0.1016 - val_dense_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 5.9584 - val_rmsle: 0.0752 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.1905 - rmsle: 0.1004 - val_dense_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 5.8901 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1082 - msle: 8.0718 - rmsle: 0.0991 - val_dense_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 4.9750 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1069 - msle: 7.9870 - rmsle: 0.0982 - val_dense_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 6.6241 - val_rmsle: 0.0734 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1060 - msle: 7.9283 - rmsle: 0.0976 - val_dense_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 6.8169 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1051 - msle: 7.8920 - rmsle: 0.0971 - val_dense_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 5.2617 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1037 - msle: 7.7495 - rmsle: 0.0960 - val_dense_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 5.2351 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1031 - msle: 7.7053 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0800 - val_msle: 6.1302 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1017 - msle: 7.6216 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 6.1611 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1012 - msle: 7.5821 - rmsle: 0.0942 - val_dense_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 5.8835 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0999 - msle: 7.5390 - rmsle: 0.0932 - val_dense_loss: 0.0000e+00 - val_loss: 0.0766 - val_msle: 4.4383 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0998 - msle: 7.4993 - rmsle: 0.0932 - val_dense_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 4.5912 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0991 - msle: 7.4099 - rmsle: 0.0925 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.3384 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0986 - msle: 7.3365 - rmsle: 0.0922 - val_dense_loss: 0.0000e+00 - val_loss: 0.0780 - val_msle: 4.4508 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.3491 - rmsle: 0.0916 - val_dense_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.0714 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.3182 - rmsle: 0.0911 - val_dense_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 3.9372 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0945 - msle: 7.1667 - rmsle: 0.0887 - val_dense_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 5.0922 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.1620 - rmsle: 0.0885 - val_dense_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.2177 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.1257 - rmsle: 0.0881 - val_dense_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1850 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0928 - msle: 7.1141 - rmsle: 0.0882 - val_dense_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1827 - val_rmsle: 0.0628 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0922 - msle: 7.1129 - rmsle: 0.0877 - val_dense_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8877 - val_rmsle: 0.0620 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.0732 - rmsle: 0.0875 - val_dense_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0730 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06287731088627774\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2590 - msle: 99.2472 - rmsle: 2.0786 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7205 - val_msle: 71.0979 - val_rmsle: 0.6574 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5465 - msle: 75.5759 - rmsle: 0.4931 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2570 - val_msle: 55.1132 - val_rmsle: 0.2202 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2675 - msle: 61.3986 - rmsle: 0.2348 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2264 - val_msle: 48.2241 - val_rmsle: 0.2011 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2437 - msle: 49.7442 - rmsle: 0.2216 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2257 - val_msle: 21.4787 - val_rmsle: 0.2091 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2349 - msle: 29.1992 - rmsle: 0.2197 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2158 - val_msle: 17.6772 - val_rmsle: 0.2041 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2287 - msle: 20.3931 - rmsle: 0.2177 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2124 - val_msle: 13.3905 - val_rmsle: 0.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2050 - msle: 13.0795 - rmsle: 0.1955 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0989 - val_msle: 4.4550 - val_rmsle: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1213 - msle: 8.5802 - rmsle: 0.1094 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 4.0922 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1162 - msle: 8.3673 - rmsle: 0.1054 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0801 - val_msle: 4.3612 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1137 - msle: 8.2976 - rmsle: 0.1037 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.8960 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1121 - msle: 8.1886 - rmsle: 0.1025 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.2661 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1094 - msle: 8.0264 - rmsle: 0.1005 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.2731 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1085 - msle: 8.0270 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.4820 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1065 - msle: 7.8884 - rmsle: 0.0984 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 3.8610 - val_rmsle: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1059 - msle: 7.8522 - rmsle: 0.0981 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.2429 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1041 - msle: 7.7105 - rmsle: 0.0967 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.2093 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1032 - msle: 7.7025 - rmsle: 0.0962 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 3.9279 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.5171 - rmsle: 0.0930 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 5.6513 - val_rmsle: 0.0710 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.4412 - rmsle: 0.0922 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.8527 - val_rmsle: 0.0699 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0973 - msle: 7.4074 - rmsle: 0.0918 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.4845 - val_rmsle: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.2698 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0777 - val_msle: 5.5129 - val_rmsle: 0.0728 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0946 - msle: 7.3175 - rmsle: 0.0899 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.7707 - val_rmsle: 0.0681 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.2822 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.7023 - val_rmsle: 0.0690 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.1572 - rmsle: 0.0879 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.1011 - val_rmsle: 0.0634 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 310.5073547363281\n",
            "Fold 1 RMSLE: 0.06329992152566052\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2659 - msle: 99.1426 - rmsle: 2.0860 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.8200 - val_msle: 75.1727 - val_rmsle: 0.7625 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5785 - msle: 78.0563 - rmsle: 0.5301 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2465 - val_msle: 55.6195 - val_rmsle: 0.2111 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2674 - msle: 61.5333 - rmsle: 0.2356 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2253 - val_msle: 49.0168 - val_rmsle: 0.2045 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2414 - msle: 53.1763 - rmsle: 0.2222 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2194 - val_msle: 32.1673 - val_rmsle: 0.2048 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2328 - msle: 31.4070 - rmsle: 0.2188 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2140 - val_msle: 16.2526 - val_rmsle: 0.2030 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2247 - msle: 19.7551 - rmsle: 0.2147 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2110 - val_msle: 11.4068 - val_rmsle: 0.2026 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1728 - msle: 11.5751 - rmsle: 0.1627 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 4.3756 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1171 - msle: 8.4906 - rmsle: 0.1060 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0854 - val_msle: 4.2371 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1133 - msle: 8.3429 - rmsle: 0.1030 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 3.9820 - val_rmsle: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1105 - msle: 8.2414 - rmsle: 0.1009 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 3.8451 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1081 - msle: 8.0845 - rmsle: 0.0990 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 3.8198 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1073 - msle: 8.0064 - rmsle: 0.0986 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 3.7225 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1052 - msle: 7.8808 - rmsle: 0.0970 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 3.9963 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1019 - msle: 7.7080 - rmsle: 0.0943 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0906 - val_msle: 4.5859 - val_rmsle: 0.0838 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.6846 - rmsle: 0.0940 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.1042 - val_rmsle: 0.0744 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0995 - msle: 7.6295 - rmsle: 0.0931 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0790 - val_msle: 4.0994 - val_rmsle: 0.0727 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0974 - msle: 7.4650 - rmsle: 0.0914 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0787 - val_msle: 4.7493 - val_rmsle: 0.0731 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.4962 - rmsle: 0.0914 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0744 - val_msle: 4.0482 - val_rmsle: 0.0691 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0960 - msle: 7.4663 - rmsle: 0.0908 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.2754 - val_rmsle: 0.0693 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0959 - msle: 7.4505 - rmsle: 0.0908 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 3.9293 - val_rmsle: 0.0690 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.1353459358215332\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.0664077976551224\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2654 - msle: 99.2372 - rmsle: 2.0848 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8286 - val_msle: 75.2694 - val_rmsle: 0.7701 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5774 - msle: 77.4239 - rmsle: 0.5267 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2536 - val_msle: 52.8026 - val_rmsle: 0.2183 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2643 - msle: 64.0640 - rmsle: 0.2332 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2228 - val_msle: 50.3524 - val_rmsle: 0.2016 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2413 - msle: 53.6725 - rmsle: 0.2221 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2146 - val_msle: 37.5655 - val_rmsle: 0.2002 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2313 - msle: 36.2834 - rmsle: 0.2181 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2079 - val_msle: 22.7271 - val_rmsle: 0.1976 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1862 - msle: 19.3969 - rmsle: 0.1743 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0889 - val_msle: 4.9532 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1210 - msle: 8.5651 - rmsle: 0.1082 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 4.7072 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.4902 - rmsle: 0.1052 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 5.0744 - val_rmsle: 0.0751 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1133 - msle: 8.3634 - rmsle: 0.1029 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 3.8447 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1119 - msle: 8.2687 - rmsle: 0.1021 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 3.9740 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1095 - msle: 8.1846 - rmsle: 0.1001 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.2110 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1084 - msle: 8.1349 - rmsle: 0.0994 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 4.1335 - val_rmsle: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1068 - msle: 7.9952 - rmsle: 0.0983 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.1923 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1066 - msle: 7.9646 - rmsle: 0.0984 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 5.0307 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1050 - msle: 7.9111 - rmsle: 0.0971 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.5594 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1014 - msle: 7.6549 - rmsle: 0.0941 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 4.1382 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1003 - msle: 7.6300 - rmsle: 0.0938 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.1363 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.5775 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.2052 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.5595 - rmsle: 0.0928 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.2535 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.5222 - rmsle: 0.0925 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.5816 - val_rmsle: 0.0652 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.4210 - rmsle: 0.0908 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.2671 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0952 - msle: 7.3758 - rmsle: 0.0902 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.9105 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0945 - msle: 7.3292 - rmsle: 0.0897 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9492 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.3499 - rmsle: 0.0896 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.8052 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0941 - msle: 7.3317 - rmsle: 0.0895 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7922 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.3250 - rmsle: 0.0893 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.0078 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.2980 - rmsle: 0.0889 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7077 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2888 - rmsle: 0.0887 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.7090 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.2053 - rmsle: 0.0877 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0779 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.2304 - rmsle: 0.0871 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1113 - val_rmsle: 0.0623 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.1904 - rmsle: 0.0872 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7298 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 302.2226257324219\n",
            "Fold 3 RMSLE: 0.06267775052602083\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2644 - msle: 99.4038 - rmsle: 2.0843 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8186 - val_msle: 73.2153 - val_rmsle: 0.7625 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6035 - msle: 79.5632 - rmsle: 0.5581 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2737 - val_msle: 63.8258 - val_rmsle: 0.2408 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2608 - msle: 67.3344 - rmsle: 0.2322 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2254 - val_msle: 55.0062 - val_rmsle: 0.2038 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2425 - msle: 55.6622 - rmsle: 0.2231 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2181 - val_msle: 38.1480 - val_rmsle: 0.2035 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2318 - msle: 41.0915 - rmsle: 0.2184 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2122 - val_msle: 27.1593 - val_rmsle: 0.2013 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2266 - msle: 26.9904 - rmsle: 0.2163 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2122 - val_msle: 20.0022 - val_rmsle: 0.2033 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2194 - msle: 17.8514 - rmsle: 0.2106 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1093 - val_msle: 9.9000 - val_rmsle: 0.0972 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1208 - msle: 8.5813 - rmsle: 0.1092 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0853 - val_msle: 4.1626 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.4301 - rmsle: 0.1056 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0841 - val_msle: 4.4009 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.3081 - rmsle: 0.1025 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0858 - val_msle: 4.1359 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1103 - msle: 8.1344 - rmsle: 0.1009 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 4.2902 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1090 - msle: 8.0915 - rmsle: 0.0999 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 4.4989 - val_rmsle: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1072 - msle: 8.0114 - rmsle: 0.0985 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0904 - val_msle: 4.8249 - val_rmsle: 0.0821 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1054 - msle: 7.9038 - rmsle: 0.0972 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0939 - val_msle: 5.7645 - val_rmsle: 0.0860 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1014 - msle: 7.5684 - rmsle: 0.0940 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 6.1058 - val_rmsle: 0.0773 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1000 - msle: 7.5873 - rmsle: 0.0936 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 6.3261 - val_rmsle: 0.0775 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.5462 - rmsle: 0.0932 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 6.3035 - val_rmsle: 0.0814 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.3649 - rmsle: 0.0910 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.7006 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0953 - msle: 7.2984 - rmsle: 0.0902 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.4633 - val_rmsle: 0.0679 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.3103 - rmsle: 0.0900 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.8847 - val_rmsle: 0.0687 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.3170 - rmsle: 0.0902 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2379 - val_rmsle: 0.0684 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2141 - rmsle: 0.0885 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8940 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.2037 - rmsle: 0.0882 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8559 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.1758 - rmsle: 0.0879 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.8928 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.1918 - rmsle: 0.0880 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.8073 - val_rmsle: 0.0640 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.1178 - rmsle: 0.0872 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.6440 - val_rmsle: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0907 - msle: 7.0930 - rmsle: 0.0868 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.6636 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.0918 - rmsle: 0.0868 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6538 - val_rmsle: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.0915 - rmsle: 0.0866 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0642 - val_msle: 3.6445 - val_rmsle: 0.0604 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0902 - msle: 7.0775 - rmsle: 0.0865 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6397 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0900 - msle: 7.0677 - rmsle: 0.0864 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0640 - val_msle: 3.6376 - val_rmsle: 0.0603 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.0609419663567165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:32:48,201] Trial 42 finished with value: 0.0632409493899596 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00022289152879535065, 'do_rate': 0.34997092282734454, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1531 - msle: 97.4879 - rmsle: 2.1194 - val_dense_loss: 0.0000e+00 - val_loss: 0.7587 - val_msle: 68.1378 - val_rmsle: 0.7376 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5436 - msle: 55.1592 - rmsle: 0.5256 - val_dense_loss: 0.0000e+00 - val_loss: 0.2135 - val_msle: 14.0045 - val_rmsle: 0.2012 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1531 - msle: 14.1678 - rmsle: 0.1415 - val_dense_loss: 0.0000e+00 - val_loss: 0.1354 - val_msle: 4.4880 - val_rmsle: 0.1253 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1221 - msle: 9.4651 - rmsle: 0.1125 - val_dense_loss: 0.0000e+00 - val_loss: 0.1162 - val_msle: 4.3035 - val_rmsle: 0.1075 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1162 - msle: 9.1140 - rmsle: 0.1079 - val_dense_loss: 0.0000e+00 - val_loss: 0.1063 - val_msle: 4.1111 - val_rmsle: 0.0985 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1118 - msle: 8.8571 - rmsle: 0.1044 - val_dense_loss: 0.0000e+00 - val_loss: 0.1123 - val_msle: 3.9886 - val_rmsle: 0.1052 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1095 - msle: 8.7328 - rmsle: 0.1026 - val_dense_loss: 0.0000e+00 - val_loss: 0.0940 - val_msle: 4.2734 - val_rmsle: 0.0874 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1070 - msle: 8.6070 - rmsle: 0.1006 - val_dense_loss: 0.0000e+00 - val_loss: 0.0980 - val_msle: 3.8304 - val_rmsle: 0.0918 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1051 - msle: 8.5137 - rmsle: 0.0991 - val_dense_loss: 0.0000e+00 - val_loss: 0.0972 - val_msle: 3.9243 - val_rmsle: 0.0913 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.4733 - rmsle: 0.0981 - val_dense_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 3.9813 - val_rmsle: 0.0876 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1023 - msle: 8.4026 - rmsle: 0.0969 - val_dense_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 3.8142 - val_rmsle: 0.0846 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.3575 - rmsle: 0.0962 - val_dense_loss: 0.0000e+00 - val_loss: 0.0811 - val_msle: 3.8761 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1007 - msle: 8.3004 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0798 - val_msle: 3.8812 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.2401 - rmsle: 0.0946 - val_dense_loss: 0.0000e+00 - val_loss: 0.0850 - val_msle: 4.2605 - val_rmsle: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0987 - msle: 8.2101 - rmsle: 0.0939 - val_dense_loss: 0.0000e+00 - val_loss: 0.0807 - val_msle: 3.9163 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0982 - msle: 8.1949 - rmsle: 0.0935 - val_dense_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 3.8155 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0964 - msle: 8.1146 - rmsle: 0.0919 - val_dense_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 3.8804 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0955 - msle: 8.1049 - rmsle: 0.0912 - val_dense_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 3.7817 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0949 - msle: 8.0701 - rmsle: 0.0909 - val_dense_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.8109 - val_rmsle: 0.0659 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0946 - msle: 8.0566 - rmsle: 0.0908 - val_dense_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.7703 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0940 - msle: 8.0288 - rmsle: 0.0903 - val_dense_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.8259 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0937 - msle: 8.0546 - rmsle: 0.0900 - val_dense_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.8602 - val_rmsle: 0.0651 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0935 - msle: 8.0047 - rmsle: 0.0900 - val_dense_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.9498 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.9712 - rmsle: 0.0890 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7429 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.9663 - rmsle: 0.0888 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8054 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.9559 - rmsle: 0.0886 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7397 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.9172 - rmsle: 0.0882 - val_dense_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7377 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0912 - msle: 7.9290 - rmsle: 0.0881 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7303 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.9075 - rmsle: 0.0881 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7477 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0909 - msle: 7.9380 - rmsle: 0.0879 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7664 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.8691 - rmsle: 0.0874 - val_dense_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7151 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0633195076894769\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1493 - msle: 97.3709 - rmsle: 2.1157 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7538 - val_msle: 67.9134 - val_rmsle: 0.7329 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5392 - msle: 54.8913 - rmsle: 0.5214 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1944 - val_msle: 14.7051 - val_rmsle: 0.1823 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1519 - msle: 13.9583 - rmsle: 0.1405 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1133 - val_msle: 4.2651 - val_rmsle: 0.1033 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1224 - msle: 9.4862 - rmsle: 0.1129 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0957 - val_msle: 4.7926 - val_rmsle: 0.0871 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1166 - msle: 9.0854 - rmsle: 0.1084 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 4.1818 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1128 - msle: 8.8742 - rmsle: 0.1054 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 4.3874 - val_rmsle: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1094 - msle: 8.6621 - rmsle: 0.1026 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.1783 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1072 - msle: 8.5930 - rmsle: 0.1008 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.1706 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1057 - msle: 8.5001 - rmsle: 0.0997 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.8308 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1041 - msle: 8.4568 - rmsle: 0.0983 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.5906 - val_rmsle: 0.0704 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.3533 - rmsle: 0.0973 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.8365 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1003 - msle: 8.2853 - rmsle: 0.0951 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 3.8452 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0988 - msle: 8.2113 - rmsle: 0.0939 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 3.9497 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0981 - msle: 8.1939 - rmsle: 0.0935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 3.8620 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.1736 - rmsle: 0.0931 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.0165 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.1590 - rmsle: 0.0928 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9810 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0966 - msle: 8.1510 - rmsle: 0.0925 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.9783 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0961 - msle: 8.1099 - rmsle: 0.0921 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 3.8239 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0949 - msle: 8.0878 - rmsle: 0.0911 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.1007 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0942 - msle: 8.0205 - rmsle: 0.0905 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.7932 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0936 - msle: 8.0137 - rmsle: 0.0900 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.8429 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0935 - msle: 7.9857 - rmsle: 0.0900 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.8560 - val_rmsle: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0931 - msle: 7.9982 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.8338 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0932 - msle: 8.0003 - rmsle: 0.0899 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.8061 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0929 - msle: 7.9667 - rmsle: 0.0897 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8081 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.9879 - rmsle: 0.0894 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.8090 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0926 - msle: 8.0020 - rmsle: 0.0894 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7853 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.9538 - rmsle: 0.0890 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8322 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.9573 - rmsle: 0.0889 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8030 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.9324 - rmsle: 0.0888 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8089 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0917 - msle: 7.9376 - rmsle: 0.0887 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7824 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06293008349819657\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1555 - msle: 97.4285 - rmsle: 2.1218 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7568 - val_msle: 68.2348 - val_rmsle: 0.7357 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5461 - msle: 55.2834 - rmsle: 0.5281 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1736 - val_msle: 13.6423 - val_rmsle: 0.1615 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1520 - msle: 14.2041 - rmsle: 0.1406 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0933 - val_msle: 4.1075 - val_rmsle: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1210 - msle: 9.4249 - rmsle: 0.1114 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0900 - val_msle: 3.9727 - val_rmsle: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1149 - msle: 9.0802 - rmsle: 0.1066 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0848 - val_msle: 3.9794 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1110 - msle: 8.8435 - rmsle: 0.1036 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0796 - val_msle: 3.8100 - val_rmsle: 0.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1083 - msle: 8.7259 - rmsle: 0.1015 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 3.7135 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1061 - msle: 8.5761 - rmsle: 0.0997 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 3.7342 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1041 - msle: 8.4806 - rmsle: 0.0981 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 3.7762 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1030 - msle: 8.4398 - rmsle: 0.0972 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 3.7366 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1017 - msle: 8.3813 - rmsle: 0.0962 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 3.6953 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.3034 - rmsle: 0.0951 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.6774 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0994 - msle: 8.2796 - rmsle: 0.0943 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.7645 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0986 - msle: 8.2234 - rmsle: 0.0936 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.0602 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0982 - msle: 8.1941 - rmsle: 0.0934 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.3289 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.1531 - rmsle: 0.0928 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.7021 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0969 - msle: 8.1138 - rmsle: 0.0922 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.7632 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0962 - msle: 8.0952 - rmsle: 0.0916 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.8521 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0955 - msle: 8.0543 - rmsle: 0.0910 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.8739 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0952 - msle: 8.0593 - rmsle: 0.0908 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.6199 - val_rmsle: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0951 - msle: 8.0099 - rmsle: 0.0907 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 3.8706 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0944 - msle: 7.9766 - rmsle: 0.0902 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.6519 - val_rmsle: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.9430 - rmsle: 0.0898 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1466 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0922 - msle: 7.9009 - rmsle: 0.0880 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 3.6266 - val_rmsle: 0.0669 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.8641 - rmsle: 0.0875 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.6104 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0912 - msle: 7.8854 - rmsle: 0.0876 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.6924 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0901 - msle: 7.8275 - rmsle: 0.0866 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9848 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0898 - msle: 7.8245 - rmsle: 0.0864 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.6974 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0893 - msle: 7.8085 - rmsle: 0.0861 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9792 - val_rmsle: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0888 - msle: 7.8128 - rmsle: 0.0857 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.6545 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0883 - msle: 7.7578 - rmsle: 0.0853 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.5807 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06290215480196235\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1542 - msle: 97.4933 - rmsle: 2.1205 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7693 - val_msle: 68.8703 - val_rmsle: 0.7482 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5451 - msle: 55.3079 - rmsle: 0.5271 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1950 - val_msle: 13.8211 - val_rmsle: 0.1829 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1542 - msle: 14.2976 - rmsle: 0.1427 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1212 - val_msle: 6.3504 - val_rmsle: 0.1111 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1236 - msle: 9.5818 - rmsle: 0.1140 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1050 - val_msle: 5.7838 - val_rmsle: 0.0964 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1169 - msle: 9.1391 - rmsle: 0.1086 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0940 - val_msle: 5.2067 - val_rmsle: 0.0862 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1130 - msle: 8.8896 - rmsle: 0.1055 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0954 - val_msle: 4.7427 - val_rmsle: 0.0882 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1104 - msle: 8.7647 - rmsle: 0.1035 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0894 - val_msle: 5.1779 - val_rmsle: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1081 - msle: 8.6567 - rmsle: 0.1015 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0828 - val_msle: 4.1001 - val_rmsle: 0.0764 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.5800 - rmsle: 0.1002 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.2734 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1047 - msle: 8.4841 - rmsle: 0.0988 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.5344 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1033 - msle: 8.4172 - rmsle: 0.0977 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.2755 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1024 - msle: 8.3717 - rmsle: 0.0970 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 4.0539 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1013 - msle: 8.3527 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.5234 - val_rmsle: 0.0722 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1003 - msle: 8.2653 - rmsle: 0.0952 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.2615 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0996 - msle: 8.2772 - rmsle: 0.0946 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.2201 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 8.2542 - rmsle: 0.0942 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 3.8396 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0983 - msle: 8.1843 - rmsle: 0.0936 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 3.8831 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0977 - msle: 8.1354 - rmsle: 0.0931 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 3.8447 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0973 - msle: 8.1307 - rmsle: 0.0927 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 3.8895 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0967 - msle: 8.1003 - rmsle: 0.0922 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 3.9701 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0963 - msle: 8.0608 - rmsle: 0.0919 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.6978 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0958 - msle: 8.0603 - rmsle: 0.0914 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 3.7411 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0954 - msle: 8.0149 - rmsle: 0.0911 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.7551 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.9952 - rmsle: 0.0908 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 3.7397 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0947 - msle: 7.9984 - rmsle: 0.0906 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7407 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0945 - msle: 7.9506 - rmsle: 0.0904 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.7279 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.9538 - rmsle: 0.0900 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.7960 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.9126 - rmsle: 0.0898 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.6737 - val_rmsle: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0937 - msle: 7.9143 - rmsle: 0.0898 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.7404 - val_rmsle: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.8868 - rmsle: 0.0893 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.6937 - val_rmsle: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.8646 - rmsle: 0.0891 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.6534 - val_rmsle: 0.0616 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06244024613779007\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1545 - msle: 97.6062 - rmsle: 2.1208 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7658 - val_msle: 68.2347 - val_rmsle: 0.7446 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5463 - msle: 55.3261 - rmsle: 0.5282 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1593 - val_msle: 13.2559 - val_rmsle: 0.1471 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1539 - msle: 14.2964 - rmsle: 0.1424 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1117 - val_msle: 4.3577 - val_rmsle: 0.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1216 - msle: 9.4835 - rmsle: 0.1120 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0897 - val_msle: 4.5808 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1160 - msle: 9.0778 - rmsle: 0.1077 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0905 - val_msle: 4.6534 - val_rmsle: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1121 - msle: 8.8184 - rmsle: 0.1045 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0906 - val_msle: 4.1863 - val_rmsle: 0.0835 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1085 - msle: 8.6634 - rmsle: 0.1016 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 4.1059 - val_rmsle: 0.0793 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1063 - msle: 8.5040 - rmsle: 0.0998 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0845 - val_msle: 4.6931 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1049 - msle: 8.4698 - rmsle: 0.0988 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0791 - val_msle: 4.4662 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.3892 - rmsle: 0.0971 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 3.8753 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1021 - msle: 8.3899 - rmsle: 0.0966 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.0715 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1008 - msle: 8.2748 - rmsle: 0.0954 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.3653 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0998 - msle: 8.2519 - rmsle: 0.0946 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.0268 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0988 - msle: 8.1999 - rmsle: 0.0938 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.5295 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0981 - msle: 8.1779 - rmsle: 0.0932 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.2437 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.1291 - rmsle: 0.0928 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 3.8468 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0968 - msle: 8.0812 - rmsle: 0.0922 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.0717 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0964 - msle: 8.0659 - rmsle: 0.0919 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.0355 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0959 - msle: 8.0531 - rmsle: 0.0915 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.6948 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.9501 - rmsle: 0.0897 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.9198 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.9282 - rmsle: 0.0892 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.7270 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0932 - msle: 7.9037 - rmsle: 0.0893 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 3.8370 - val_rmsle: 0.0655 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.8636 - rmsle: 0.0881 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9636 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.8176 - rmsle: 0.0877 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8583 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.8191 - rmsle: 0.0876 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9240 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0908 - msle: 7.8444 - rmsle: 0.0874 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.7081 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.8078 - rmsle: 0.0872 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7325 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.8028 - rmsle: 0.0871 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.7225 - val_rmsle: 0.0640 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0901 - msle: 7.8100 - rmsle: 0.0870 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7120 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0901 - msle: 7.7644 - rmsle: 0.0870 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7418 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0893 - msle: 7.7713 - rmsle: 0.0863 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.6877 - val_rmsle: 0.0627 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06248703255526642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:39:45,944] Trial 43 finished with value: 0.06281580493653846 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.00013195929346934942, 'do_rate': 0.36741364991145603, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.3304 - msle: 99.2918 - rmsle: 2.1041 - val_dense_loss: 0.0000e+00 - val_loss: 0.7857 - val_msle: 76.6873 - val_rmsle: 0.7234 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5809 - msle: 74.3140 - rmsle: 0.5251 - val_dense_loss: 0.0000e+00 - val_loss: 0.2521 - val_msle: 45.3721 - val_rmsle: 0.2091 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2776 - msle: 56.9853 - rmsle: 0.2404 - val_dense_loss: 0.0000e+00 - val_loss: 0.2361 - val_msle: 42.7323 - val_rmsle: 0.2100 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2520 - msle: 41.9506 - rmsle: 0.2285 - val_dense_loss: 0.0000e+00 - val_loss: 0.2317 - val_msle: 22.6979 - val_rmsle: 0.2144 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2334 - msle: 22.5677 - rmsle: 0.2171 - val_dense_loss: 0.0000e+00 - val_loss: 0.0921 - val_msle: 4.6104 - val_rmsle: 0.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1404 - msle: 9.7674 - rmsle: 0.1226 - val_dense_loss: 0.0000e+00 - val_loss: 0.1005 - val_msle: 7.4207 - val_rmsle: 0.0850 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1315 - msle: 9.5604 - rmsle: 0.1166 - val_dense_loss: 0.0000e+00 - val_loss: 0.0925 - val_msle: 7.2462 - val_rmsle: 0.0788 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1268 - msle: 9.3826 - rmsle: 0.1135 - val_dense_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 6.5409 - val_rmsle: 0.0790 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1231 - msle: 9.2249 - rmsle: 0.1109 - val_dense_loss: 0.0000e+00 - val_loss: 0.0937 - val_msle: 5.1852 - val_rmsle: 0.0820 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1210 - msle: 9.0746 - rmsle: 0.1096 - val_dense_loss: 0.0000e+00 - val_loss: 0.0839 - val_msle: 6.6675 - val_rmsle: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1182 - msle: 8.9731 - rmsle: 0.1076 - val_dense_loss: 0.0000e+00 - val_loss: 0.0865 - val_msle: 7.0371 - val_rmsle: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1163 - msle: 8.8398 - rmsle: 0.1063 - val_dense_loss: 0.0000e+00 - val_loss: 0.0818 - val_msle: 4.5949 - val_rmsle: 0.0718 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1150 - msle: 8.7110 - rmsle: 0.1053 - val_dense_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 6.3064 - val_rmsle: 0.0749 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1136 - msle: 8.6694 - rmsle: 0.1045 - val_dense_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.1838 - val_rmsle: 0.0717 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1119 - msle: 8.5672 - rmsle: 0.1033 - val_dense_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 5.3675 - val_rmsle: 0.0736 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1106 - msle: 8.4004 - rmsle: 0.1023 - val_dense_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.1453 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1098 - msle: 8.3384 - rmsle: 0.1017 - val_dense_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 5.4762 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1084 - msle: 8.2572 - rmsle: 0.1006 - val_dense_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.5597 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1074 - msle: 8.1830 - rmsle: 0.0997 - val_dense_loss: 0.0000e+00 - val_loss: 0.0762 - val_msle: 4.8755 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1062 - msle: 8.1663 - rmsle: 0.0987 - val_dense_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 5.0420 - val_rmsle: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1061 - msle: 8.1193 - rmsle: 0.0986 - val_dense_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 5.0112 - val_rmsle: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1050 - msle: 8.0211 - rmsle: 0.0976 - val_dense_loss: 0.0000e+00 - val_loss: 0.0816 - val_msle: 4.4025 - val_rmsle: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1015 - msle: 7.8363 - rmsle: 0.0948 - val_dense_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.0695 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1003 - msle: 7.8768 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 3.8644 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.8186 - rmsle: 0.0939 - val_dense_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 3.9096 - val_rmsle: 0.0627 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.7768 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.1388 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0986 - msle: 7.7599 - rmsle: 0.0934 - val_dense_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.8518 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.7321 - rmsle: 0.0932 - val_dense_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 3.8812 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0963 - msle: 7.5934 - rmsle: 0.0914 - val_dense_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.8861 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0957 - msle: 7.6266 - rmsle: 0.0914 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7303 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0951 - msle: 7.5911 - rmsle: 0.0910 - val_dense_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7389 - val_rmsle: 0.0616 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06245173235688454\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.3298 - msle: 99.2174 - rmsle: 2.1034 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7619 - val_msle: 67.8114 - val_rmsle: 0.7047 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5915 - msle: 75.4359 - rmsle: 0.5385 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2636 - val_msle: 45.6792 - val_rmsle: 0.2235 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2870 - msle: 53.7679 - rmsle: 0.2482 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2349 - val_msle: 37.0506 - val_rmsle: 0.2056 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2542 - msle: 39.7218 - rmsle: 0.2282 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2310 - val_msle: 21.2911 - val_rmsle: 0.2126 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2399 - msle: 23.6647 - rmsle: 0.2228 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1225 - val_msle: 10.1768 - val_rmsle: 0.1035 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1452 - msle: 9.8382 - rmsle: 0.1267 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0961 - val_msle: 6.7679 - val_rmsle: 0.0799 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1339 - msle: 9.6125 - rmsle: 0.1183 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0961 - val_msle: 5.7751 - val_rmsle: 0.0820 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1290 - msle: 9.4411 - rmsle: 0.1152 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0837 - val_msle: 5.2080 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1250 - msle: 9.2844 - rmsle: 0.1125 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 5.3652 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1220 - msle: 9.2006 - rmsle: 0.1104 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 5.1273 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1202 - msle: 9.0575 - rmsle: 0.1093 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0770 - val_msle: 5.0083 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1177 - msle: 8.9075 - rmsle: 0.1076 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 4.1353 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1158 - msle: 8.7968 - rmsle: 0.1063 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 4.0506 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1139 - msle: 8.6762 - rmsle: 0.1048 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.2581 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1129 - msle: 8.6638 - rmsle: 0.1041 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.4357 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1111 - msle: 8.5139 - rmsle: 0.1027 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.5890 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.3995 - rmsle: 0.1018 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.2033 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1091 - msle: 8.3716 - rmsle: 0.1011 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 5.8061 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1049 - msle: 8.1300 - rmsle: 0.0977 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 6.6136 - val_rmsle: 0.0797 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1035 - msle: 8.1026 - rmsle: 0.0971 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 5.6184 - val_rmsle: 0.0707 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1023 - msle: 8.0551 - rmsle: 0.0963 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.6148 - val_rmsle: 0.0694 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1002 - msle: 7.9277 - rmsle: 0.0944 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0799 - val_msle: 6.2495 - val_rmsle: 0.0747 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0997 - msle: 7.9112 - rmsle: 0.0946 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 5.5714 - val_rmsle: 0.0710 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06480577465041253\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.3363 - msle: 99.1449 - rmsle: 2.1098 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7646 - val_msle: 71.5306 - val_rmsle: 0.7041 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5883 - msle: 74.8487 - rmsle: 0.5356 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2781 - val_msle: 55.8107 - val_rmsle: 0.2394 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2783 - msle: 55.0105 - rmsle: 0.2429 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2442 - val_msle: 34.8377 - val_rmsle: 0.2181 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2505 - msle: 41.0045 - rmsle: 0.2272 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2265 - val_msle: 22.9858 - val_rmsle: 0.2099 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1999 - msle: 18.8115 - rmsle: 0.1820 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0916 - val_msle: 4.7612 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1373 - msle: 9.6903 - rmsle: 0.1204 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0815 - val_msle: 4.3260 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1297 - msle: 9.5293 - rmsle: 0.1152 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 4.0180 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1257 - msle: 9.4167 - rmsle: 0.1126 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0806 - val_msle: 4.3326 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1219 - msle: 9.1830 - rmsle: 0.1098 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 3.9462 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1195 - msle: 9.0548 - rmsle: 0.1081 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 4.0043 - val_rmsle: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1142 - msle: 8.8204 - rmsle: 0.1039 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 4.6687 - val_rmsle: 0.0746 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1124 - msle: 8.7454 - rmsle: 0.1034 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 3.8247 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1103 - msle: 8.6559 - rmsle: 0.1020 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 3.8221 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.6459 - rmsle: 0.1019 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 3.8415 - val_rmsle: 0.0716 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.5639 - rmsle: 0.1011 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.1623 - val_rmsle: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1076 - msle: 8.5124 - rmsle: 0.1002 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 3.9825 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1054 - msle: 8.3680 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0809 - val_msle: 4.4285 - val_rmsle: 0.0743 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1048 - msle: 8.3129 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0769 - val_msle: 4.0167 - val_rmsle: 0.0706 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1037 - msle: 8.3070 - rmsle: 0.0975 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 3.9399 - val_rmsle: 0.0693 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1020 - msle: 8.2267 - rmsle: 0.0961 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.0054 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.2065 - rmsle: 0.0955 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.4522 - val_rmsle: 0.0650 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.1931 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.2575 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1008 - msle: 8.1860 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2382 - val_rmsle: 0.0630 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1002 - msle: 8.1591 - rmsle: 0.0952 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.0169 - val_rmsle: 0.0645 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0999 - msle: 8.1557 - rmsle: 0.0950 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.9893 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0995 - msle: 8.1458 - rmsle: 0.0947 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.1365 - val_rmsle: 0.0639 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0983 - msle: 8.0842 - rmsle: 0.0937 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.6430 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0980 - msle: 8.0660 - rmsle: 0.0935 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.6283 - val_rmsle: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0977 - msle: 8.0581 - rmsle: 0.0932 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.6436 - val_rmsle: 0.0616 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0975 - msle: 8.0165 - rmsle: 0.0931 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7946 - val_rmsle: 0.0615 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0973 - msle: 8.0304 - rmsle: 0.0930 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7109 - val_rmsle: 0.0612 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 304.87225341796875\n",
            "Fold 2 RMSLE: 0.06171235707913697\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_3_loss: 0.0000e+00 - loss: 2.3327 - msle: 99.2202 - rmsle: 2.1057 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7599 - val_msle: 70.2275 - val_rmsle: 0.7008 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5876 - msle: 74.7239 - rmsle: 0.5330 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2508 - val_msle: 53.2502 - val_rmsle: 0.2134 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2813 - msle: 55.7722 - rmsle: 0.2460 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2290 - val_msle: 35.1801 - val_rmsle: 0.2038 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2494 - msle: 39.9456 - rmsle: 0.2268 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1855 - val_msle: 19.7737 - val_rmsle: 0.1636 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1504 - msle: 9.9856 - rmsle: 0.1297 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0873 - val_msle: 5.1240 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1360 - msle: 9.6888 - rmsle: 0.1195 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0901 - val_msle: 5.1199 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1306 - msle: 9.5737 - rmsle: 0.1162 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0826 - val_msle: 5.1804 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1255 - msle: 9.3923 - rmsle: 0.1125 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.2464 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1227 - msle: 9.2889 - rmsle: 0.1108 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.2073 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1203 - msle: 9.0799 - rmsle: 0.1090 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0767 - val_msle: 4.4399 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1180 - msle: 8.9928 - rmsle: 0.1074 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.5320 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.8727 - rmsle: 0.1064 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 4.0046 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1153 - msle: 8.8356 - rmsle: 0.1057 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 3.9305 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1135 - msle: 8.6863 - rmsle: 0.1045 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.5882 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1124 - msle: 8.7039 - rmsle: 0.1037 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.5641 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1079 - msle: 8.3222 - rmsle: 0.1001 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.3170 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1068 - msle: 8.3511 - rmsle: 0.0997 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.0235 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1055 - msle: 8.2821 - rmsle: 0.0988 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.0425 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1046 - msle: 8.2194 - rmsle: 0.0982 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.7761 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1042 - msle: 8.1764 - rmsle: 0.0979 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 3.8617 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1040 - msle: 8.1724 - rmsle: 0.0978 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 3.8155 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1034 - msle: 8.0963 - rmsle: 0.0972 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 3.8613 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1008 - msle: 7.9365 - rmsle: 0.0948 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 5.7837 - val_rmsle: 0.0691 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1000 - msle: 7.9400 - rmsle: 0.0947 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2891 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.9281 - rmsle: 0.0943 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.0937 - val_rmsle: 0.0626 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0989 - msle: 7.9048 - rmsle: 0.0941 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9226 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0986 - msle: 7.8620 - rmsle: 0.0938 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2677 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.8556 - rmsle: 0.0936 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.0530 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0980 - msle: 7.8261 - rmsle: 0.0934 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8938 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.8192 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.3330 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0975 - msle: 7.8028 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.8501 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 303.4357604980469\n",
            "Fold 3 RMSLE: 0.06294806987815275\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.3338 - msle: 99.3289 - rmsle: 2.1072 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8121 - val_msle: 72.9141 - val_rmsle: 0.7546 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5849 - msle: 75.5758 - rmsle: 0.5337 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2696 - val_msle: 48.2447 - val_rmsle: 0.2333 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2749 - msle: 57.6912 - rmsle: 0.2418 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2332 - val_msle: 41.5366 - val_rmsle: 0.2093 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2491 - msle: 44.2985 - rmsle: 0.2275 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2211 - val_msle: 25.2193 - val_rmsle: 0.2053 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2379 - msle: 28.1731 - rmsle: 0.2231 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2141 - val_msle: 15.5903 - val_rmsle: 0.2021 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2072 - msle: 15.9855 - rmsle: 0.1947 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 4.1753 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1340 - msle: 9.6604 - rmsle: 0.1191 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0971 - val_msle: 4.7372 - val_rmsle: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1276 - msle: 9.4146 - rmsle: 0.1141 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0887 - val_msle: 4.0395 - val_rmsle: 0.0760 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1246 - msle: 9.2715 - rmsle: 0.1121 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0890 - val_msle: 4.4918 - val_rmsle: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1174 - msle: 8.8379 - rmsle: 0.1062 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0974 - val_msle: 5.8966 - val_rmsle: 0.0875 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1142 - msle: 8.7752 - rmsle: 0.1047 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 5.5628 - val_rmsle: 0.0740 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1135 - msle: 8.7651 - rmsle: 0.1046 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0852 - val_msle: 5.3027 - val_rmsle: 0.0766 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1120 - msle: 8.6858 - rmsle: 0.1036 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0869 - val_msle: 5.4792 - val_rmsle: 0.0787 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1108 - msle: 8.6480 - rmsle: 0.1028 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 5.0157 - val_rmsle: 0.0752 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1077 - msle: 8.4059 - rmsle: 0.1001 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0819 - val_msle: 5.1679 - val_rmsle: 0.0749 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1067 - msle: 8.4080 - rmsle: 0.0999 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0781 - val_msle: 4.9525 - val_rmsle: 0.0715 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 298.6748352050781\n",
            "Fold 4 RMSLE: 0.06937094489353543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:46:14,090] Trial 44 finished with value: 0.06425777577162443 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.00029721226511733134, 'do_rate': 0.4278807862363875, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.2721 - msle: 110.2751 - rmsle: 1.8958 - val_dense_loss: 0.0000e+00 - val_loss: 0.9397 - val_msle: 51.6275 - val_rmsle: 0.8748 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5615 - msle: 38.2526 - rmsle: 0.4962 - val_dense_loss: 0.0000e+00 - val_loss: 0.2248 - val_msle: 13.5735 - val_rmsle: 0.1628 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.4044 - msle: 16.4202 - rmsle: 0.3453 - val_dense_loss: 0.0000e+00 - val_loss: 0.2726 - val_msle: 13.4860 - val_rmsle: 0.2199 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3359 - msle: 14.6718 - rmsle: 0.2841 - val_dense_loss: 0.0000e+00 - val_loss: 0.2456 - val_msle: 12.6824 - val_rmsle: 0.1993 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3050 - msle: 14.0324 - rmsle: 0.2606 - val_dense_loss: 0.0000e+00 - val_loss: 0.1956 - val_msle: 11.1208 - val_rmsle: 0.1553 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2938 - msle: 13.8136 - rmsle: 0.2538 - val_dense_loss: 0.0000e+00 - val_loss: 0.2634 - val_msle: 12.5202 - val_rmsle: 0.2270 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2776 - msle: 13.3166 - rmsle: 0.2404 - val_dense_loss: 0.0000e+00 - val_loss: 0.1724 - val_msle: 11.0122 - val_rmsle: 0.1372 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2601 - msle: 13.0303 - rmsle: 0.2254 - val_dense_loss: 0.0000e+00 - val_loss: 0.1637 - val_msle: 10.9298 - val_rmsle: 0.1302 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2546 - msle: 12.7960 - rmsle: 0.2210 - val_dense_loss: 0.0000e+00 - val_loss: 0.1506 - val_msle: 10.1808 - val_rmsle: 0.1178 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2508 - msle: 12.7029 - rmsle: 0.2186 - val_dense_loss: 0.0000e+00 - val_loss: 0.1468 - val_msle: 10.3030 - val_rmsle: 0.1155 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2437 - msle: 12.4057 - rmsle: 0.2127 - val_dense_loss: 0.0000e+00 - val_loss: 0.1772 - val_msle: 10.7356 - val_rmsle: 0.1468 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2400 - msle: 12.2707 - rmsle: 0.2101 - val_dense_loss: 0.0000e+00 - val_loss: 0.1442 - val_msle: 10.0388 - val_rmsle: 0.1153 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2329 - msle: 12.0445 - rmsle: 0.2040 - val_dense_loss: 0.0000e+00 - val_loss: 0.1606 - val_msle: 9.8753 - val_rmsle: 0.1319 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2264 - msle: 11.8851 - rmsle: 0.1987 - val_dense_loss: 0.0000e+00 - val_loss: 0.1537 - val_msle: 9.0437 - val_rmsle: 0.1262 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2236 - msle: 11.7028 - rmsle: 0.1964 - val_dense_loss: 0.0000e+00 - val_loss: 0.1591 - val_msle: 10.9274 - val_rmsle: 0.1326 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2117 - msle: 11.6398 - rmsle: 0.1876 - val_dense_loss: 0.0000e+00 - val_loss: 0.1536 - val_msle: 11.1842 - val_rmsle: 0.1325 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2004 - msle: 11.5328 - rmsle: 0.1804 - val_dense_loss: 0.0000e+00 - val_loss: 0.1568 - val_msle: 9.5151 - val_rmsle: 0.1365 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2037 - msle: 11.4632 - rmsle: 0.1837 - val_dense_loss: 0.0000e+00 - val_loss: 0.1401 - val_msle: 9.7511 - val_rmsle: 0.1203 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1970 - msle: 11.4361 - rmsle: 0.1781 - val_dense_loss: 0.0000e+00 - val_loss: 0.1280 - val_msle: 9.7058 - val_rmsle: 0.1092 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1989 - msle: 11.4113 - rmsle: 0.1803 - val_dense_loss: 0.0000e+00 - val_loss: 0.1456 - val_msle: 9.4958 - val_rmsle: 0.1275 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1990 - msle: 11.3534 - rmsle: 0.1809 - val_dense_loss: 0.0000e+00 - val_loss: 0.1333 - val_msle: 10.1495 - val_rmsle: 0.1158 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1946 - msle: 11.3144 - rmsle: 0.1772 - val_dense_loss: 0.0000e+00 - val_loss: 0.1271 - val_msle: 9.7334 - val_rmsle: 0.1098 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1944 - msle: 11.2727 - rmsle: 0.1771 - val_dense_loss: 0.0000e+00 - val_loss: 0.1294 - val_msle: 9.8624 - val_rmsle: 0.1128 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1916 - msle: 11.2352 - rmsle: 0.1751 - val_dense_loss: 0.0000e+00 - val_loss: 0.1254 - val_msle: 9.6852 - val_rmsle: 0.1090 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1879 - msle: 11.1483 - rmsle: 0.1718 - val_dense_loss: 0.0000e+00 - val_loss: 0.1673 - val_msle: 9.3489 - val_rmsle: 0.1510 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1898 - msle: 11.1256 - rmsle: 0.1737 - val_dense_loss: 0.0000e+00 - val_loss: 0.1355 - val_msle: 9.1453 - val_rmsle: 0.1198 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1879 - msle: 11.1475 - rmsle: 0.1722 - val_dense_loss: 0.0000e+00 - val_loss: 0.1352 - val_msle: 10.4563 - val_rmsle: 0.1200 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1828 - msle: 11.0161 - rmsle: 0.1686 - val_dense_loss: 0.0000e+00 - val_loss: 0.1442 - val_msle: 10.5742 - val_rmsle: 0.1315 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1777 - msle: 11.0051 - rmsle: 0.1654 - val_dense_loss: 0.0000e+00 - val_loss: 0.1333 - val_msle: 10.3492 - val_rmsle: 0.1215 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1784 - msle: 11.0300 - rmsle: 0.1667 - val_dense_loss: 0.0000e+00 - val_loss: 0.1285 - val_msle: 10.0298 - val_rmsle: 0.1168 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1749 - msle: 11.0700 - rmsle: 0.1637 - val_dense_loss: 0.0000e+00 - val_loss: 0.1299 - val_msle: 10.2511 - val_rmsle: 0.1196 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 280.9250183105469\n",
            "Fold 0 RMSLE: 0.10896230225142531\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2602 - msle: 110.0312 - rmsle: 1.8840 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.6995 - val_msle: 51.8867 - val_rmsle: 0.6357 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5591 - msle: 37.3498 - rmsle: 0.4919 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3414 - val_msle: 15.8192 - val_rmsle: 0.2794 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.4043 - msle: 16.2958 - rmsle: 0.3451 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2508 - val_msle: 13.2850 - val_rmsle: 0.1990 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3357 - msle: 14.6789 - rmsle: 0.2853 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3236 - val_msle: 13.3334 - val_rmsle: 0.2769 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3083 - msle: 14.1546 - rmsle: 0.2629 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2101 - val_msle: 12.5620 - val_rmsle: 0.1683 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2914 - msle: 13.7001 - rmsle: 0.2516 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3189 - val_msle: 13.7431 - val_rmsle: 0.2815 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2835 - msle: 13.4096 - rmsle: 0.2464 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2297 - val_msle: 11.9996 - val_rmsle: 0.1936 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2787 - msle: 13.1982 - rmsle: 0.2419 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1606 - val_msle: 10.5432 - val_rmsle: 0.1254 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2627 - msle: 12.9114 - rmsle: 0.2285 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2573 - val_msle: 12.2799 - val_rmsle: 0.2246 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2579 - msle: 12.5808 - rmsle: 0.2256 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1855 - val_msle: 11.4316 - val_rmsle: 0.1537 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2516 - msle: 12.3759 - rmsle: 0.2201 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1892 - val_msle: 10.6664 - val_rmsle: 0.1585 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2310 - msle: 12.1233 - rmsle: 0.2034 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2510 - val_msle: 12.4351 - val_rmsle: 0.2276 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2269 - msle: 11.9374 - rmsle: 0.2036 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1996 - val_msle: 10.9644 - val_rmsle: 0.1778 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2221 - msle: 11.8486 - rmsle: 0.2000 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1617 - val_msle: 10.1792 - val_rmsle: 0.1401 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2098 - msle: 11.7967 - rmsle: 0.1890 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1768 - val_msle: 11.1665 - val_rmsle: 0.1581 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2044 - msle: 11.6399 - rmsle: 0.1859 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1951 - val_msle: 11.5068 - val_rmsle: 0.1776 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2028 - msle: 11.5890 - rmsle: 0.1854 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1866 - val_msle: 11.1804 - val_rmsle: 0.1697 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1954 - msle: 11.4864 - rmsle: 0.1789 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1640 - val_msle: 11.2378 - val_rmsle: 0.1483 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 269.1062927246094\n",
            "Fold 1 RMSLE: 0.12568855865249237\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2621 - msle: 109.9283 - rmsle: 1.8842 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7992 - val_msle: 46.7152 - val_rmsle: 0.7365 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5497 - msle: 36.2980 - rmsle: 0.4824 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3118 - val_msle: 15.5507 - val_rmsle: 0.2502 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3911 - msle: 16.1998 - rmsle: 0.3311 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3704 - val_msle: 14.7944 - val_rmsle: 0.3190 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3264 - msle: 14.6351 - rmsle: 0.2764 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2528 - val_msle: 12.5036 - val_rmsle: 0.2093 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2977 - msle: 14.0967 - rmsle: 0.2540 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2666 - val_msle: 12.5404 - val_rmsle: 0.2272 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2883 - msle: 13.7888 - rmsle: 0.2487 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2032 - val_msle: 11.8013 - val_rmsle: 0.1679 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2768 - msle: 13.4062 - rmsle: 0.2401 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3011 - val_msle: 12.7527 - val_rmsle: 0.2659 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2667 - msle: 13.1342 - rmsle: 0.2316 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2721 - val_msle: 12.5746 - val_rmsle: 0.2389 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2546 - msle: 12.7908 - rmsle: 0.2218 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1982 - val_msle: 10.3194 - val_rmsle: 0.1665 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2544 - msle: 12.7213 - rmsle: 0.2221 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2601 - val_msle: 11.9476 - val_rmsle: 0.2293 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2510 - msle: 12.7239 - rmsle: 0.2193 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2605 - val_msle: 11.8716 - val_rmsle: 0.2303 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2375 - msle: 12.2688 - rmsle: 0.2075 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2465 - val_msle: 11.0802 - val_rmsle: 0.2192 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2205 - msle: 11.9134 - rmsle: 0.1950 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1935 - val_msle: 10.6666 - val_rmsle: 0.1707 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2178 - msle: 11.8875 - rmsle: 0.1950 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2015 - val_msle: 10.7773 - val_rmsle: 0.1797 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2117 - msle: 11.8211 - rmsle: 0.1900 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2192 - val_msle: 11.2011 - val_rmsle: 0.1984 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2086 - msle: 11.8152 - rmsle: 0.1878 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1998 - val_msle: 11.0309 - val_rmsle: 0.1797 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2012 - msle: 11.6668 - rmsle: 0.1816 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1546 - val_msle: 10.5104 - val_rmsle: 0.1369 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1935 - msle: 11.5485 - rmsle: 0.1760 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1311 - val_msle: 9.8418 - val_rmsle: 0.1144 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1934 - msle: 11.4994 - rmsle: 0.1766 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1303 - val_msle: 9.8898 - val_rmsle: 0.1142 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1926 - msle: 11.4664 - rmsle: 0.1763 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1450 - val_msle: 10.0278 - val_rmsle: 0.1292 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1919 - msle: 11.4576 - rmsle: 0.1760 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1238 - val_msle: 9.4485 - val_rmsle: 0.1082 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1905 - msle: 11.3797 - rmsle: 0.1748 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1463 - val_msle: 10.0550 - val_rmsle: 0.1311 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1911 - msle: 11.4679 - rmsle: 0.1757 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1365 - val_msle: 9.9945 - val_rmsle: 0.1214 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1862 - msle: 11.4033 - rmsle: 0.1711 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1263 - val_msle: 9.5912 - val_rmsle: 0.1115 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1831 - msle: 11.3325 - rmsle: 0.1686 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1323 - val_msle: 10.1307 - val_rmsle: 0.1184 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1826 - msle: 11.3060 - rmsle: 0.1687 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1362 - val_msle: 10.1899 - val_rmsle: 0.1229 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1797 - msle: 11.2654 - rmsle: 0.1665 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1360 - val_msle: 10.2490 - val_rmsle: 0.1230 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1762 - msle: 11.2710 - rmsle: 0.1633 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1622 - val_msle: 11.0866 - val_rmsle: 0.1499 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1753 - msle: 11.2908 - rmsle: 0.1630 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1476 - val_msle: 10.6714 - val_rmsle: 0.1357 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1741 - msle: 11.2693 - rmsle: 0.1622 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1570 - val_msle: 10.8707 - val_rmsle: 0.1454 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1720 - msle: 11.2596 - rmsle: 0.1605 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1420 - val_msle: 10.6529 - val_rmsle: 0.1307 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 268.3466491699219\n",
            "Fold 2 RMSLE: 0.10760378556099835\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2857 - msle: 109.7347 - rmsle: 1.9007 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.6727 - val_msle: 52.7026 - val_rmsle: 0.6078 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5580 - msle: 37.6100 - rmsle: 0.4904 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3044 - val_msle: 15.4220 - val_rmsle: 0.2409 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3985 - msle: 16.5340 - rmsle: 0.3380 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2773 - val_msle: 13.6464 - val_rmsle: 0.2259 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3307 - msle: 14.8643 - rmsle: 0.2816 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1992 - val_msle: 11.7676 - val_rmsle: 0.1555 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3033 - msle: 14.2923 - rmsle: 0.2607 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1820 - val_msle: 11.3609 - val_rmsle: 0.1430 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2853 - msle: 13.8088 - rmsle: 0.2461 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2220 - val_msle: 11.6134 - val_rmsle: 0.1841 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2787 - msle: 13.6565 - rmsle: 0.2414 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1594 - val_msle: 10.6957 - val_rmsle: 0.1228 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2677 - msle: 13.4142 - rmsle: 0.2323 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2518 - val_msle: 12.4981 - val_rmsle: 0.2183 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2647 - msle: 13.0971 - rmsle: 0.2309 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1593 - val_msle: 10.4218 - val_rmsle: 0.1269 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2534 - msle: 12.7834 - rmsle: 0.2211 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2281 - val_msle: 9.7635 - val_rmsle: 0.1958 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2554 - msle: 12.6954 - rmsle: 0.2230 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1792 - val_msle: 10.4049 - val_rmsle: 0.1488 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2447 - msle: 12.3967 - rmsle: 0.2142 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1895 - val_msle: 9.9647 - val_rmsle: 0.1594 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2279 - msle: 12.1035 - rmsle: 0.2007 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2770 - val_msle: 13.2941 - val_rmsle: 0.2528 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2245 - msle: 12.0585 - rmsle: 0.2008 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2672 - val_msle: 12.8321 - val_rmsle: 0.2437 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2191 - msle: 12.0346 - rmsle: 0.1966 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2238 - val_msle: 11.7187 - val_rmsle: 0.2015 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2125 - msle: 11.9929 - rmsle: 0.1916 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2655 - val_msle: 13.6963 - val_rmsle: 0.2470 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2080 - msle: 11.8037 - rmsle: 0.1898 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2395 - val_msle: 12.5272 - val_rmsle: 0.2219 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 263.22906494140625\n",
            "Fold 3 RMSLE: 0.11846806852226255\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2693 - msle: 110.7132 - rmsle: 1.8902 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.6925 - val_msle: 58.9694 - val_rmsle: 0.6302 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5740 - msle: 39.5533 - rmsle: 0.5067 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2461 - val_msle: 14.1777 - val_rmsle: 0.1821 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3985 - msle: 16.2485 - rmsle: 0.3367 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2934 - val_msle: 12.8059 - val_rmsle: 0.2368 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3241 - msle: 14.5547 - rmsle: 0.2717 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2802 - val_msle: 12.6052 - val_rmsle: 0.2370 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2927 - msle: 13.8818 - rmsle: 0.2502 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2876 - val_msle: 12.1357 - val_rmsle: 0.2479 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2652 - msle: 13.3858 - rmsle: 0.2283 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3466 - val_msle: 14.5637 - val_rmsle: 0.3148 - learning_rate: 2.5000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2490 - msle: 13.0284 - rmsle: 0.2181 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2704 - val_msle: 12.7506 - val_rmsle: 0.2409 - learning_rate: 2.5000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2432 - msle: 12.9076 - rmsle: 0.2141 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2817 - val_msle: 13.1560 - val_rmsle: 0.2538 - learning_rate: 2.5000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2370 - msle: 12.7206 - rmsle: 0.2098 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2903 - val_msle: 13.7600 - val_rmsle: 0.2651 - learning_rate: 1.2500e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2310 - msle: 12.6178 - rmsle: 0.2060 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2378 - val_msle: 12.5175 - val_rmsle: 0.2140 - learning_rate: 1.2500e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2258 - msle: 12.5407 - rmsle: 0.2022 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2537 - val_msle: 12.8638 - val_rmsle: 0.2310 - learning_rate: 1.2500e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2212 - msle: 12.4173 - rmsle: 0.1985 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2491 - val_msle: 12.9726 - val_rmsle: 0.2272 - learning_rate: 1.2500e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2195 - msle: 12.3522 - rmsle: 0.1977 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2908 - val_msle: 13.8239 - val_rmsle: 0.2698 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2174 - msle: 12.3089 - rmsle: 0.1964 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1356 - val_msle: 10.7258 - val_rmsle: 0.1152 - learning_rate: 6.2500e-05\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2105 - msle: 12.2903 - rmsle: 0.1903 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1388 - val_msle: 10.7380 - val_rmsle: 0.1192 - learning_rate: 6.2500e-05\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2079 - msle: 12.2343 - rmsle: 0.1885 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1412 - val_msle: 10.7442 - val_rmsle: 0.1223 - learning_rate: 6.2500e-05\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2063 - msle: 12.0947 - rmsle: 0.1876 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1352 - val_msle: 10.6592 - val_rmsle: 0.1167 - learning_rate: 6.2500e-05\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2057 - msle: 12.1468 - rmsle: 0.1873 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1318 - val_msle: 10.5185 - val_rmsle: 0.1136 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2044 - msle: 12.1270 - rmsle: 0.1863 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1263 - val_msle: 10.2917 - val_rmsle: 0.1082 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2052 - msle: 12.1489 - rmsle: 0.1873 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1369 - val_msle: 10.4140 - val_rmsle: 0.1190 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2030 - msle: 12.0906 - rmsle: 0.1853 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1421 - val_msle: 10.6651 - val_rmsle: 0.1244 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2023 - msle: 12.1356 - rmsle: 0.1848 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1449 - val_msle: 10.7504 - val_rmsle: 0.1276 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1963 - msle: 12.0646 - rmsle: 0.1791 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1539 - val_msle: 11.0481 - val_rmsle: 0.1371 - learning_rate: 3.1250e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1952 - msle: 12.0194 - rmsle: 0.1786 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1505 - val_msle: 11.1278 - val_rmsle: 0.1343 - learning_rate: 3.1250e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1937 - msle: 11.9945 - rmsle: 0.1776 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1562 - val_msle: 11.0744 - val_rmsle: 0.1405 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1918 - msle: 11.8962 - rmsle: 0.1761 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1480 - val_msle: 10.9191 - val_rmsle: 0.1325 - learning_rate: 1.5625e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1914 - msle: 11.9117 - rmsle: 0.1761 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1519 - val_msle: 10.9410 - val_rmsle: 0.1367 - learning_rate: 1.5625e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1901 - msle: 11.8612 - rmsle: 0.1750 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1480 - val_msle: 10.9098 - val_rmsle: 0.1330 - learning_rate: 1.5625e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1888 - msle: 11.8593 - rmsle: 0.1738 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1321 - val_msle: 10.5389 - val_rmsle: 0.1172 - learning_rate: 7.8125e-06\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 267.50164794921875\n",
            "Fold 4 RMSLE: 0.10748063955062581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:52:04,755] Trial 45 finished with value: 0.11364067090756089 and parameters: {'units': 1024, 'last_layer': 2, 'activation': 'gelu', 'reg': 0.0006769632957612944, 'do_rate': 0.39398629748681807, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.6416 - msle: 102.3243 - rmsle: 2.6104 - val_dense_loss: 0.0000e+00 - val_loss: 1.3287 - val_msle: 87.7669 - val_rmsle: 1.3072 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 1.0764 - msle: 80.3760 - rmsle: 1.0573 - val_dense_loss: 0.0000e+00 - val_loss: 0.5484 - val_msle: 57.7252 - val_rmsle: 0.5362 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.4458 - msle: 48.5659 - rmsle: 0.4351 - val_dense_loss: 0.0000e+00 - val_loss: 0.1509 - val_msle: 20.9616 - val_rmsle: 0.1437 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1598 - msle: 16.6840 - rmsle: 0.1533 - val_dense_loss: 0.0000e+00 - val_loss: 0.0774 - val_msle: 5.9085 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1254 - msle: 10.9372 - rmsle: 0.1204 - val_dense_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.5332 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1202 - msle: 10.7858 - rmsle: 0.1159 - val_dense_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.0628 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1173 - msle: 10.6938 - rmsle: 0.1134 - val_dense_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0461 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1150 - msle: 10.5591 - rmsle: 0.1113 - val_dense_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.1378 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1134 - msle: 10.5154 - rmsle: 0.1098 - val_dense_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.0307 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1122 - msle: 10.4326 - rmsle: 0.1087 - val_dense_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.0851 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1099 - msle: 10.2999 - rmsle: 0.1065 - val_dense_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.1502 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1095 - msle: 10.2619 - rmsle: 0.1063 - val_dense_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.9460 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1087 - msle: 10.2237 - rmsle: 0.1057 - val_dense_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9496 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1082 - msle: 10.2076 - rmsle: 0.1053 - val_dense_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9919 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1074 - msle: 10.1577 - rmsle: 0.1046 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9404 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1070 - msle: 10.1128 - rmsle: 0.1042 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0682 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1064 - msle: 10.0730 - rmsle: 0.1037 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.0125 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1061 - msle: 10.0578 - rmsle: 0.1035 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9740 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1060 - msle: 10.0449 - rmsle: 0.1034 - val_dense_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9512 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1057 - msle: 10.0435 - rmsle: 0.1031 - val_dense_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.9260 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1054 - msle: 10.0021 - rmsle: 0.1029 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9652 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1050 - msle: 9.9642 - rmsle: 0.1025 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.0295 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1051 - msle: 9.9701 - rmsle: 0.1026 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9004 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1047 - msle: 9.9306 - rmsle: 0.1023 - val_dense_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9254 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1047 - msle: 9.9642 - rmsle: 0.1024 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.0369 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1044 - msle: 9.9281 - rmsle: 0.1021 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1245 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1045 - msle: 9.9066 - rmsle: 0.1022 - val_dense_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.9730 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1039 - msle: 9.9026 - rmsle: 0.1016 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8768 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1037 - msle: 9.8760 - rmsle: 0.1014 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8760 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1036 - msle: 9.8661 - rmsle: 0.1013 - val_dense_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8848 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1036 - msle: 9.8514 - rmsle: 0.1014 - val_dense_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8949 - val_rmsle: 0.0629 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.0636720853331857\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.6393 - msle: 102.2640 - rmsle: 2.6082 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.3285 - val_msle: 87.9047 - val_rmsle: 1.3069 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 1.0756 - msle: 80.3162 - rmsle: 1.0566 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.5488 - val_msle: 57.7553 - val_rmsle: 0.5366 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.4445 - msle: 48.4229 - rmsle: 0.4339 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1661 - val_msle: 22.6223 - val_rmsle: 0.1590 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1601 - msle: 16.5138 - rmsle: 0.1537 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0937 - val_msle: 7.5686 - val_rmsle: 0.0885 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1254 - msle: 10.9304 - rmsle: 0.1206 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 6.3860 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1206 - msle: 10.8474 - rmsle: 0.1164 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0755 - val_msle: 4.9927 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1175 - msle: 10.7345 - rmsle: 0.1136 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 5.3451 - val_rmsle: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1155 - msle: 10.5995 - rmsle: 0.1118 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.8593 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1136 - msle: 10.5132 - rmsle: 0.1100 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.1582 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1120 - msle: 10.4272 - rmsle: 0.1086 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 5.1591 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1112 - msle: 10.3382 - rmsle: 0.1079 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.6811 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1104 - msle: 10.2723 - rmsle: 0.1071 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.6706 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1081 - msle: 10.1018 - rmsle: 0.1050 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.0974 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1073 - msle: 10.0873 - rmsle: 0.1043 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.1854 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1069 - msle: 10.0324 - rmsle: 0.1040 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1062 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1063 - msle: 9.9928 - rmsle: 0.1035 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.0360 - val_rmsle: 0.0650 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1064 - msle: 9.9950 - rmsle: 0.1037 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.2539 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1056 - msle: 9.9347 - rmsle: 0.1029 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0644 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1055 - msle: 9.8752 - rmsle: 0.1029 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.0284 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1049 - msle: 9.8592 - rmsle: 0.1023 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.1218 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1039 - msle: 9.8157 - rmsle: 0.1015 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0662 - val_rmsle: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1036 - msle: 9.7780 - rmsle: 0.1012 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.9728 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1035 - msle: 9.7722 - rmsle: 0.1012 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0041 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1034 - msle: 9.7635 - rmsle: 0.1011 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0258 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1035 - msle: 9.7967 - rmsle: 0.1012 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.0528 - val_rmsle: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1027 - msle: 9.7476 - rmsle: 0.1004 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.0413 - val_rmsle: 0.0638 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1027 - msle: 9.7248 - rmsle: 0.1005 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.2866 - val_rmsle: 0.0643 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1027 - msle: 9.7452 - rmsle: 0.1005 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1378 - val_rmsle: 0.0639 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1024 - msle: 9.7257 - rmsle: 0.1002 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.1189 - val_rmsle: 0.0642 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1021 - msle: 9.6919 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.2560 - val_rmsle: 0.0640 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1020 - msle: 9.6981 - rmsle: 0.0999 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.4388 - val_rmsle: 0.0644 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06407906841819287\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_2_loss: 0.0000e+00 - loss: 2.6393 - msle: 102.2125 - rmsle: 2.6082 - val_dense_2_loss: 0.0000e+00 - val_loss: 1.3337 - val_msle: 88.0731 - val_rmsle: 1.3123 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 1.0770 - msle: 80.3286 - rmsle: 1.0582 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.5469 - val_msle: 57.8143 - val_rmsle: 0.5350 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.4469 - msle: 48.6732 - rmsle: 0.4365 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1560 - val_msle: 21.2165 - val_rmsle: 0.1491 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1602 - msle: 16.8698 - rmsle: 0.1539 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 5.0947 - val_rmsle: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1238 - msle: 10.9324 - rmsle: 0.1191 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.3177 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1185 - msle: 10.7997 - rmsle: 0.1144 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.4683 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1158 - msle: 10.7389 - rmsle: 0.1120 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 3.9476 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1138 - msle: 10.6287 - rmsle: 0.1101 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.7625 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1123 - msle: 10.5194 - rmsle: 0.1087 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.5968 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1108 - msle: 10.4287 - rmsle: 0.1074 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.0855 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1086 - msle: 10.2905 - rmsle: 0.1053 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.6319 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1078 - msle: 10.2337 - rmsle: 0.1047 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.1574 - val_rmsle: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1071 - msle: 10.1635 - rmsle: 0.1041 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.4761 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1063 - msle: 10.1301 - rmsle: 0.1034 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8213 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1056 - msle: 10.1011 - rmsle: 0.1028 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 3.9562 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1055 - msle: 10.0612 - rmsle: 0.1028 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.8576 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1051 - msle: 10.0736 - rmsle: 0.1024 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0337 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1044 - msle: 10.0343 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8388 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1043 - msle: 10.0136 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.7719 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1041 - msle: 9.9783 - rmsle: 0.1016 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7774 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1039 - msle: 9.9841 - rmsle: 0.1014 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8127 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1038 - msle: 9.9770 - rmsle: 0.1013 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.8006 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1036 - msle: 9.9663 - rmsle: 0.1012 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7977 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1036 - msle: 9.9753 - rmsle: 0.1012 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7707 - val_rmsle: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1032 - msle: 9.9543 - rmsle: 0.1009 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7656 - val_rmsle: 0.0634 - learning_rate: 3.1250e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1029 - msle: 9.9343 - rmsle: 0.1005 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7911 - val_rmsle: 0.0636 - learning_rate: 3.1250e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1032 - msle: 9.9351 - rmsle: 0.1008 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7935 - val_rmsle: 0.0638 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1029 - msle: 9.9140 - rmsle: 0.1006 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7774 - val_rmsle: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1027 - msle: 9.9174 - rmsle: 0.1004 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 3.7762 - val_rmsle: 0.0637 - learning_rate: 1.5625e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1029 - msle: 9.9283 - rmsle: 0.1006 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.7603 - val_rmsle: 0.0634 - learning_rate: 1.5625e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1026 - msle: 9.8755 - rmsle: 0.1004 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7641 - val_rmsle: 0.0635 - learning_rate: 1.5625e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06385229529572556\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.6391 - msle: 102.3006 - rmsle: 2.6080 - val_dense_3_loss: 0.0000e+00 - val_loss: 1.3349 - val_msle: 88.1239 - val_rmsle: 1.3135 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 1.0766 - msle: 80.3713 - rmsle: 1.0579 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.5501 - val_msle: 58.0490 - val_rmsle: 0.5381 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.4458 - msle: 48.5815 - rmsle: 0.4354 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1651 - val_msle: 23.1151 - val_rmsle: 0.1581 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1604 - msle: 16.7746 - rmsle: 0.1540 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0887 - val_msle: 7.2653 - val_rmsle: 0.0836 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1253 - msle: 10.9962 - rmsle: 0.1206 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 4.5921 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1201 - msle: 10.8259 - rmsle: 0.1160 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.4619 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1172 - msle: 10.7298 - rmsle: 0.1134 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.7334 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1151 - msle: 10.6468 - rmsle: 0.1114 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.0586 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1132 - msle: 10.5053 - rmsle: 0.1097 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.7398 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1122 - msle: 10.4304 - rmsle: 0.1089 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.4063 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1108 - msle: 10.3223 - rmsle: 0.1075 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.4414 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1092 - msle: 10.2168 - rmsle: 0.1060 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.7371 - val_rmsle: 0.0658 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1083 - msle: 10.1586 - rmsle: 0.1053 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.7656 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1079 - msle: 10.1433 - rmsle: 0.1050 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.3271 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1069 - msle: 10.0738 - rmsle: 0.1041 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.2972 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1064 - msle: 10.0322 - rmsle: 0.1036 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.9703 - val_rmsle: 0.0665 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1063 - msle: 10.0115 - rmsle: 0.1036 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.4203 - val_rmsle: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1061 - msle: 10.0385 - rmsle: 0.1035 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.3632 - val_rmsle: 0.0652 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 314.6961364746094\n",
            "Fold 3 RMSLE: 0.06494365757671418\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.6401 - msle: 102.4026 - rmsle: 2.6090 - val_dense_4_loss: 0.0000e+00 - val_loss: 1.3273 - val_msle: 87.5902 - val_rmsle: 1.3060 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 1.0753 - msle: 80.4130 - rmsle: 1.0565 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.5458 - val_msle: 57.4279 - val_rmsle: 0.5337 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.4421 - msle: 48.3391 - rmsle: 0.4316 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1649 - val_msle: 22.2412 - val_rmsle: 0.1579 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1586 - msle: 16.6627 - rmsle: 0.1522 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0898 - val_msle: 7.0218 - val_rmsle: 0.0846 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1239 - msle: 10.9492 - rmsle: 0.1190 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.6965 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1190 - msle: 10.7938 - rmsle: 0.1148 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.5815 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1160 - msle: 10.6393 - rmsle: 0.1121 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.8027 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1144 - msle: 10.5707 - rmsle: 0.1106 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.6023 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1127 - msle: 10.4964 - rmsle: 0.1091 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.1375 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1112 - msle: 10.3793 - rmsle: 0.1076 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1477 - val_rmsle: 0.0648 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1101 - msle: 10.3118 - rmsle: 0.1067 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.7451 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1097 - msle: 10.2340 - rmsle: 0.1063 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.6601 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1085 - msle: 10.1356 - rmsle: 0.1051 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.4423 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1066 - msle: 10.0120 - rmsle: 0.1034 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9090 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1060 - msle: 9.9664 - rmsle: 0.1030 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.8887 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1055 - msle: 9.9260 - rmsle: 0.1026 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9788 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1051 - msle: 9.8822 - rmsle: 0.1023 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9215 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1041 - msle: 9.8326 - rmsle: 0.1014 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8454 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1039 - msle: 9.8212 - rmsle: 0.1013 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.9002 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1037 - msle: 9.8394 - rmsle: 0.1012 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0620 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1032 - msle: 9.7928 - rmsle: 0.1008 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9513 - val_rmsle: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1028 - msle: 9.7778 - rmsle: 0.1004 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8167 - val_rmsle: 0.0634 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1027 - msle: 9.7433 - rmsle: 0.1004 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8959 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1026 - msle: 9.7942 - rmsle: 0.1003 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.8231 - val_rmsle: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1027 - msle: 9.7742 - rmsle: 0.1004 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8185 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1021 - msle: 9.7129 - rmsle: 0.0999 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8608 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1019 - msle: 9.6869 - rmsle: 0.0997 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8096 - val_rmsle: 0.0630 - learning_rate: 3.1250e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1021 - msle: 9.7302 - rmsle: 0.0999 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8241 - val_rmsle: 0.0630 - learning_rate: 3.1250e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1021 - msle: 9.7321 - rmsle: 0.0999 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8370 - val_rmsle: 0.0630 - learning_rate: 3.1250e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1017 - msle: 9.6979 - rmsle: 0.0995 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8018 - val_rmsle: 0.0628 - learning_rate: 3.1250e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1018 - msle: 9.6896 - rmsle: 0.0996 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.8546 - val_rmsle: 0.0630 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.0632577463864169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 00:58:25,972] Trial 46 finished with value: 0.06396097060204704 and parameters: {'units': 128, 'last_layer': 2, 'activation': 'relu', 'reg': 0.00021932289775685297, 'do_rate': 0.38277107119618853, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 13ms/step - dense_loss: 0.0000e+00 - loss: 2.2868 - msle: 97.3919 - rmsle: 2.0132 - val_dense_loss: 0.0000e+00 - val_loss: 0.6704 - val_msle: 65.6741 - val_rmsle: 0.5980 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.5399 - msle: 65.1966 - rmsle: 0.4755 - val_dense_loss: 0.0000e+00 - val_loss: 0.2593 - val_msle: 41.1106 - val_rmsle: 0.2151 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2826 - msle: 46.1357 - rmsle: 0.2437 - val_dense_loss: 0.0000e+00 - val_loss: 0.2433 - val_msle: 27.3876 - val_rmsle: 0.2159 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.2550 - msle: 28.6212 - rmsle: 0.2308 - val_dense_loss: 0.0000e+00 - val_loss: 0.2277 - val_msle: 14.1492 - val_rmsle: 0.2106 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2338 - msle: 15.2205 - rmsle: 0.2177 - val_dense_loss: 0.0000e+00 - val_loss: 0.1016 - val_msle: 5.3426 - val_rmsle: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1469 - msle: 9.9761 - rmsle: 0.1276 - val_dense_loss: 0.0000e+00 - val_loss: 0.0994 - val_msle: 7.7114 - val_rmsle: 0.0825 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1366 - msle: 9.7164 - rmsle: 0.1205 - val_dense_loss: 0.0000e+00 - val_loss: 0.0947 - val_msle: 5.9964 - val_rmsle: 0.0798 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1320 - msle: 9.4941 - rmsle: 0.1175 - val_dense_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 6.7938 - val_rmsle: 0.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1279 - msle: 9.3613 - rmsle: 0.1146 - val_dense_loss: 0.0000e+00 - val_loss: 0.0905 - val_msle: 6.8594 - val_rmsle: 0.0780 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1253 - msle: 9.2381 - rmsle: 0.1130 - val_dense_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 6.0182 - val_rmsle: 0.0755 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1232 - msle: 9.1435 - rmsle: 0.1114 - val_dense_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 7.1991 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1203 - msle: 8.9612 - rmsle: 0.1096 - val_dense_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 4.8325 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.1189 - msle: 8.8503 - rmsle: 0.1087 - val_dense_loss: 0.0000e+00 - val_loss: 0.0904 - val_msle: 6.1393 - val_rmsle: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1172 - msle: 8.7886 - rmsle: 0.1075 - val_dense_loss: 0.0000e+00 - val_loss: 0.0836 - val_msle: 6.2736 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1156 - msle: 8.6895 - rmsle: 0.1064 - val_dense_loss: 0.0000e+00 - val_loss: 0.0871 - val_msle: 4.8721 - val_rmsle: 0.0780 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1146 - msle: 8.5659 - rmsle: 0.1056 - val_dense_loss: 0.0000e+00 - val_loss: 0.0950 - val_msle: 4.7560 - val_rmsle: 0.0861 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1126 - msle: 8.4567 - rmsle: 0.1039 - val_dense_loss: 0.0000e+00 - val_loss: 0.0847 - val_msle: 4.5223 - val_rmsle: 0.0763 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1084 - msle: 8.2906 - rmsle: 0.1006 - val_dense_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.2156 - val_rmsle: 0.0637 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1067 - msle: 8.2126 - rmsle: 0.0999 - val_dense_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 3.8752 - val_rmsle: 0.0685 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1058 - msle: 8.2381 - rmsle: 0.0994 - val_dense_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.0056 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1056 - msle: 8.2114 - rmsle: 0.0994 - val_dense_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 3.9376 - val_rmsle: 0.0664 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1028 - msle: 8.0406 - rmsle: 0.0969 - val_dense_loss: 0.0000e+00 - val_loss: 0.0690 - val_msle: 4.2298 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1018 - msle: 8.0110 - rmsle: 0.0966 - val_dense_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.8531 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1015 - msle: 8.0200 - rmsle: 0.0964 - val_dense_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.9831 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1008 - msle: 7.9789 - rmsle: 0.0960 - val_dense_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.8543 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1006 - msle: 7.9667 - rmsle: 0.0958 - val_dense_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.1053 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1001 - msle: 7.9425 - rmsle: 0.0954 - val_dense_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.9105 - val_rmsle: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0998 - msle: 7.9032 - rmsle: 0.0952 - val_dense_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 3.7565 - val_rmsle: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0998 - msle: 7.8999 - rmsle: 0.0952 - val_dense_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 3.8578 - val_rmsle: 0.0630 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.9024 - rmsle: 0.0947 - val_dense_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.7736 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.8677 - rmsle: 0.0945 - val_dense_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.8327 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06269933265969094\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_1_loss: 0.0000e+00 - loss: 2.2857 - msle: 97.3784 - rmsle: 2.0125 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.7601 - val_msle: 68.8653 - val_rmsle: 0.6965 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.5725 - msle: 67.8760 - rmsle: 0.5116 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2743 - val_msle: 38.1966 - val_rmsle: 0.2251 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2877 - msle: 46.1330 - rmsle: 0.2447 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2313 - val_msle: 26.9276 - val_rmsle: 0.2028 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2574 - msle: 29.4100 - rmsle: 0.2320 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2235 - val_msle: 13.7062 - val_rmsle: 0.2049 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2278 - msle: 14.6689 - rmsle: 0.2099 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1043 - val_msle: 4.8232 - val_rmsle: 0.0846 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1454 - msle: 9.8513 - rmsle: 0.1268 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0917 - val_msle: 5.8214 - val_rmsle: 0.0755 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1366 - msle: 9.6898 - rmsle: 0.1208 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.2132 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1313 - msle: 9.4659 - rmsle: 0.1172 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0840 - val_msle: 4.6523 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1278 - msle: 9.3246 - rmsle: 0.1149 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 4.8501 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1246 - msle: 9.1953 - rmsle: 0.1127 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.0881 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1217 - msle: 9.0091 - rmsle: 0.1108 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.6936 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1202 - msle: 8.9356 - rmsle: 0.1099 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.1812 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1186 - msle: 8.8227 - rmsle: 0.1087 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0764 - val_msle: 4.4813 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1165 - msle: 8.7305 - rmsle: 0.1070 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 4.1519 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1158 - msle: 8.6625 - rmsle: 0.1065 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.7721 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1101 - msle: 8.3591 - rmsle: 0.1019 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0860 - val_msle: 6.0333 - val_rmsle: 0.0787 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.4066 - rmsle: 0.1016 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 6.8857 - val_rmsle: 0.0766 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1080 - msle: 8.3544 - rmsle: 0.1011 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 6.0976 - val_rmsle: 0.0737 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1050 - msle: 8.1629 - rmsle: 0.0986 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0779 - val_msle: 6.3457 - val_rmsle: 0.0720 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1042 - msle: 8.1320 - rmsle: 0.0985 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 4.9737 - val_rmsle: 0.0674 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 299.5675964355469\n",
            "Fold 1 RMSLE: 0.06469354514934862\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_2_loss: 0.0000e+00 - loss: 2.2921 - msle: 97.2796 - rmsle: 2.0184 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.7089 - val_msle: 66.6362 - val_rmsle: 0.6420 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.5429 - msle: 66.3840 - rmsle: 0.4818 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2525 - val_msle: 49.1676 - val_rmsle: 0.2108 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2810 - msle: 46.1545 - rmsle: 0.2436 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2406 - val_msle: 29.1823 - val_rmsle: 0.2154 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2470 - msle: 28.7662 - rmsle: 0.2242 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1273 - val_msle: 5.2917 - val_rmsle: 0.1048 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1535 - msle: 10.0774 - rmsle: 0.1321 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0875 - val_msle: 4.4741 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1394 - msle: 9.7637 - rmsle: 0.1219 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 4.0909 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1332 - msle: 9.5599 - rmsle: 0.1179 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0813 - val_msle: 3.8846 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1285 - msle: 9.3958 - rmsle: 0.1147 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0844 - val_msle: 5.1877 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1258 - msle: 9.2685 - rmsle: 0.1129 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0833 - val_msle: 4.0215 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1230 - msle: 9.1323 - rmsle: 0.1111 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0804 - val_msle: 4.5545 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1198 - msle: 8.9906 - rmsle: 0.1086 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 3.9182 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1184 - msle: 8.8945 - rmsle: 0.1080 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0831 - val_msle: 4.9264 - val_rmsle: 0.0734 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1158 - msle: 8.7633 - rmsle: 0.1062 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0924 - val_msle: 4.5688 - val_rmsle: 0.0831 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1117 - msle: 8.5196 - rmsle: 0.1030 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 4.7100 - val_rmsle: 0.0837 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1103 - msle: 8.5058 - rmsle: 0.1027 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 6.4772 - val_rmsle: 0.0859 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1096 - msle: 8.5017 - rmsle: 0.1024 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0882 - val_msle: 4.9162 - val_rmsle: 0.0812 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1060 - msle: 8.2941 - rmsle: 0.0992 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.8083 - val_rmsle: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1058 - msle: 8.2777 - rmsle: 0.0996 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.1170 - val_rmsle: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1047 - msle: 8.2539 - rmsle: 0.0988 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 3.9630 - val_rmsle: 0.0676 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1038 - msle: 8.1963 - rmsle: 0.0982 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 3.8274 - val_rmsle: 0.0662 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1033 - msle: 8.1837 - rmsle: 0.0979 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.8879 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.0761 - rmsle: 0.0961 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 3.7207 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1007 - msle: 8.0339 - rmsle: 0.0957 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.8841 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1000 - msle: 8.0453 - rmsle: 0.0953 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.9018 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1000 - msle: 8.0436 - rmsle: 0.0954 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 3.9441 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0997 - msle: 8.0238 - rmsle: 0.0952 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.0190 - val_rmsle: 0.0627 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.9995 - rmsle: 0.0949 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 3.7946 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.9968 - rmsle: 0.0947 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9229 - val_rmsle: 0.0625 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.9838 - rmsle: 0.0945 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0497 - val_rmsle: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.9608 - rmsle: 0.0947 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.1546 - val_rmsle: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0974 - msle: 7.9236 - rmsle: 0.0933 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.8061 - val_rmsle: 0.0630 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.3086853027344\n",
            "Fold 2 RMSLE: 0.0626055902586478\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_3_loss: 0.0000e+00 - loss: 2.2903 - msle: 97.3772 - rmsle: 2.0165 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7685 - val_msle: 69.2918 - val_rmsle: 0.7041 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5725 - msle: 68.1192 - rmsle: 0.5148 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2716 - val_msle: 40.8629 - val_rmsle: 0.2231 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2880 - msle: 47.1031 - rmsle: 0.2457 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2285 - val_msle: 30.1043 - val_rmsle: 0.2007 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2557 - msle: 31.7048 - rmsle: 0.2308 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2174 - val_msle: 15.0271 - val_rmsle: 0.1991 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2386 - msle: 16.1283 - rmsle: 0.2219 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1164 - val_msle: 8.6192 - val_rmsle: 0.0977 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1456 - msle: 9.9556 - rmsle: 0.1277 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0914 - val_msle: 4.8703 - val_rmsle: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1352 - msle: 9.6680 - rmsle: 0.1198 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1012 - val_msle: 4.7050 - val_rmsle: 0.0870 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1299 - msle: 9.4792 - rmsle: 0.1163 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 4.2137 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1262 - msle: 9.2925 - rmsle: 0.1137 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 4.4032 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1233 - msle: 9.1791 - rmsle: 0.1118 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.5436 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1216 - msle: 9.1043 - rmsle: 0.1107 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 4.5291 - val_rmsle: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1199 - msle: 9.0024 - rmsle: 0.1096 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 4.2276 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1185 - msle: 8.8767 - rmsle: 0.1086 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.4337 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1137 - msle: 8.5682 - rmsle: 0.1048 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0759 - val_msle: 4.6583 - val_rmsle: 0.0677 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1117 - msle: 8.5494 - rmsle: 0.1038 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.3509 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1104 - msle: 8.4741 - rmsle: 0.1028 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.1686 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1100 - msle: 8.4647 - rmsle: 0.1027 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0736 - val_msle: 4.8021 - val_rmsle: 0.0663 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.4012 - rmsle: 0.1017 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 3.9493 - val_rmsle: 0.0635 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1083 - msle: 8.3676 - rmsle: 0.1014 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.5272 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1075 - msle: 8.3110 - rmsle: 0.1007 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 3.9504 - val_rmsle: 0.0632 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1070 - msle: 8.2985 - rmsle: 0.1003 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 3.7469 - val_rmsle: 0.0624 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1066 - msle: 8.2521 - rmsle: 0.0999 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.1504 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.2250 - rmsle: 0.0998 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 5.4504 - val_rmsle: 0.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1064 - msle: 8.2320 - rmsle: 0.0999 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 5.2227 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1033 - msle: 8.0687 - rmsle: 0.0972 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 4.8828 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1023 - msle: 8.0590 - rmsle: 0.0969 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.4285 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1017 - msle: 8.0094 - rmsle: 0.0966 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0687 - val_msle: 4.4660 - val_rmsle: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1012 - msle: 8.0195 - rmsle: 0.0963 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.2769 - val_rmsle: 0.0635 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1010 - msle: 7.9955 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0581 - val_rmsle: 0.0628 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1003 - msle: 7.9569 - rmsle: 0.0956 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.2530 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1004 - msle: 7.9501 - rmsle: 0.0957 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.1854 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.2381286621094\n",
            "Fold 3 RMSLE: 0.06322094743454641\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 15s 12ms/step - dense_4_loss: 0.0000e+00 - loss: 2.2903 - msle: 97.5443 - rmsle: 2.0162 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7545 - val_msle: 68.0875 - val_rmsle: 0.6895 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.5635 - msle: 67.1461 - rmsle: 0.5022 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3011 - val_msle: 47.0409 - val_rmsle: 0.2529 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2881 - msle: 45.8661 - rmsle: 0.2456 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2518 - val_msle: 32.8168 - val_rmsle: 0.2240 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2545 - msle: 33.7419 - rmsle: 0.2298 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2604 - val_msle: 18.3295 - val_rmsle: 0.2396 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1602 - msle: 10.3551 - rmsle: 0.1387 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0912 - val_msle: 4.7893 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1421 - msle: 9.9156 - rmsle: 0.1238 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 4.5033 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1360 - msle: 9.7204 - rmsle: 0.1200 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0935 - val_msle: 4.6784 - val_rmsle: 0.0787 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1302 - msle: 9.4892 - rmsle: 0.1159 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0872 - val_msle: 4.1535 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1275 - msle: 9.3725 - rmsle: 0.1142 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0960 - val_msle: 4.9308 - val_rmsle: 0.0835 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1199 - msle: 8.9251 - rmsle: 0.1083 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0986 - val_msle: 7.0737 - val_rmsle: 0.0885 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1170 - msle: 8.8909 - rmsle: 0.1072 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0925 - val_msle: 6.5994 - val_rmsle: 0.0831 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.8529 - rmsle: 0.1072 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0932 - val_msle: 6.1410 - val_rmsle: 0.0842 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1118 - msle: 8.6061 - rmsle: 0.1032 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0772 - val_msle: 4.5520 - val_rmsle: 0.0693 - learning_rate: 1.2500e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1105 - msle: 8.6096 - rmsle: 0.1029 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.3988 - val_rmsle: 0.0703 - learning_rate: 1.2500e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1099 - msle: 8.5505 - rmsle: 0.1028 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0805 - val_msle: 5.0407 - val_rmsle: 0.0735 - learning_rate: 1.2500e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1093 - msle: 8.5215 - rmsle: 0.1025 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 4.4420 - val_rmsle: 0.0729 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0347002744674683\n",
            "Pred Max: 309.4903564453125\n",
            "Fold 4 RMSLE: 0.06840950813380704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 01:05:02,732] Trial 47 finished with value: 0.06432578472720817 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'mish', 'reg': 0.0003701582373943472, 'do_rate': 0.4521522960382661, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 10s 8ms/step - dense_loss: 0.0000e+00 - loss: 2.3643 - msle: 99.7575 - rmsle: 2.3614 - val_dense_loss: 0.0000e+00 - val_loss: 0.9378 - val_msle: 75.9134 - val_rmsle: 0.9341 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.7885 - msle: 68.8807 - rmsle: 0.7847 - val_dense_loss: 0.0000e+00 - val_loss: 0.3398 - val_msle: 39.9114 - val_rmsle: 0.3362 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.2799 - msle: 31.5461 - rmsle: 0.2764 - val_dense_loss: 0.0000e+00 - val_loss: 0.1033 - val_msle: 9.6966 - val_rmsle: 0.0997 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1419 - msle: 10.3541 - rmsle: 0.1384 - val_dense_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 5.9080 - val_rmsle: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1217 - msle: 9.1073 - rmsle: 0.1184 - val_dense_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 5.4002 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1132 - msle: 8.9717 - rmsle: 0.1101 - val_dense_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 5.2129 - val_rmsle: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1088 - msle: 8.9236 - rmsle: 0.1059 - val_dense_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 5.0607 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1054 - msle: 8.8462 - rmsle: 0.1026 - val_dense_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.9554 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1034 - msle: 8.7716 - rmsle: 0.1007 - val_dense_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.9193 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1016 - msle: 8.7032 - rmsle: 0.0990 - val_dense_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.8032 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.1001 - msle: 8.6331 - rmsle: 0.0977 - val_dense_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.7205 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0991 - msle: 8.5489 - rmsle: 0.0968 - val_dense_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 4.6677 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0979 - msle: 8.4646 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.6022 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0973 - msle: 8.4032 - rmsle: 0.0951 - val_dense_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.5606 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0965 - msle: 8.3366 - rmsle: 0.0944 - val_dense_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.5016 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0959 - msle: 8.2742 - rmsle: 0.0939 - val_dense_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.4580 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0952 - msle: 8.2302 - rmsle: 0.0933 - val_dense_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.4174 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0948 - msle: 8.1837 - rmsle: 0.0929 - val_dense_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.3947 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0944 - msle: 8.0984 - rmsle: 0.0925 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.3563 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0939 - msle: 8.0846 - rmsle: 0.0921 - val_dense_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.3203 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0935 - msle: 8.0573 - rmsle: 0.0918 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.3189 - val_rmsle: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0933 - msle: 8.0120 - rmsle: 0.0915 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.2750 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0929 - msle: 7.9952 - rmsle: 0.0913 - val_dense_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.2400 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.9470 - rmsle: 0.0909 - val_dense_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.2440 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.9219 - rmsle: 0.0909 - val_dense_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 4.2195 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.8594 - rmsle: 0.0902 - val_dense_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.2297 - val_rmsle: 0.0641 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.8482 - rmsle: 0.0898 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 4.2100 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.8124 - rmsle: 0.0895 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.1860 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0907 - msle: 7.7925 - rmsle: 0.0892 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 4.2005 - val_rmsle: 0.0634 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0906 - msle: 7.7899 - rmsle: 0.0892 - val_dense_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.1622 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_loss: 0.0000e+00 - loss: 0.0906 - msle: 7.8013 - rmsle: 0.0892 - val_dense_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.1704 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06412756556409858\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_1_loss: 0.0000e+00 - loss: 2.3602 - msle: 99.6605 - rmsle: 2.3573 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.9354 - val_msle: 75.8650 - val_rmsle: 0.9316 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.7833 - msle: 68.6139 - rmsle: 0.7795 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3368 - val_msle: 39.6866 - val_rmsle: 0.3333 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2761 - msle: 31.1892 - rmsle: 0.2726 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1059 - val_msle: 10.1288 - val_rmsle: 0.1024 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1407 - msle: 10.3333 - rmsle: 0.1372 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 6.0528 - val_rmsle: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1211 - msle: 9.0764 - rmsle: 0.1178 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 5.5210 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1130 - msle: 8.9763 - rmsle: 0.1100 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 5.3519 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1082 - msle: 8.9339 - rmsle: 0.1053 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 5.2077 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1052 - msle: 8.8364 - rmsle: 0.1024 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 5.1573 - val_rmsle: 0.0679 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1032 - msle: 8.7928 - rmsle: 0.1006 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 5.0550 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1014 - msle: 8.6982 - rmsle: 0.0988 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.9673 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0998 - msle: 8.5655 - rmsle: 0.0974 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.8655 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0987 - msle: 8.5373 - rmsle: 0.0964 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.8451 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0977 - msle: 8.4512 - rmsle: 0.0955 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.7646 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0971 - msle: 8.4288 - rmsle: 0.0949 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 4.6800 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0963 - msle: 8.3115 - rmsle: 0.0942 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.6337 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0957 - msle: 8.2651 - rmsle: 0.0936 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.5898 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.1830 - rmsle: 0.0930 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.5624 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0944 - msle: 8.1731 - rmsle: 0.0925 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.5094 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0941 - msle: 8.1038 - rmsle: 0.0922 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.4875 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0936 - msle: 8.0374 - rmsle: 0.0918 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 4.4285 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0931 - msle: 8.0076 - rmsle: 0.0914 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.3936 - val_rmsle: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0929 - msle: 7.9504 - rmsle: 0.0912 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.3563 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0923 - msle: 7.9329 - rmsle: 0.0907 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.3234 - val_rmsle: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0922 - msle: 7.8975 - rmsle: 0.0906 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 4.3186 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.8719 - rmsle: 0.0904 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.2982 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.8328 - rmsle: 0.0899 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.2700 - val_rmsle: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0913 - msle: 7.8171 - rmsle: 0.0898 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2520 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.7659 - rmsle: 0.0896 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.2311 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0908 - msle: 7.7536 - rmsle: 0.0894 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.2250 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.6995 - rmsle: 0.0889 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.2074 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.6937 - rmsle: 0.0891 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 4.2160 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 1 RMSLE: 0.06472805031794814\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 8ms/step - dense_2_loss: 0.0000e+00 - loss: 2.3626 - msle: 99.6109 - rmsle: 2.3597 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.9368 - val_msle: 75.9092 - val_rmsle: 0.9331 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.7839 - msle: 68.5231 - rmsle: 0.7801 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3317 - val_msle: 39.2644 - val_rmsle: 0.3282 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2765 - msle: 31.0702 - rmsle: 0.2729 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.1004 - val_msle: 9.2083 - val_rmsle: 0.0969 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1411 - msle: 10.2949 - rmsle: 0.1377 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0792 - val_msle: 5.6269 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1209 - msle: 9.0795 - rmsle: 0.1176 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0741 - val_msle: 5.3083 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1123 - msle: 8.9751 - rmsle: 0.1092 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0732 - val_msle: 5.1467 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1076 - msle: 8.9135 - rmsle: 0.1047 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0729 - val_msle: 5.0585 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1044 - msle: 8.8234 - rmsle: 0.1016 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.9900 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1022 - msle: 8.7515 - rmsle: 0.0996 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.8922 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1004 - msle: 8.6692 - rmsle: 0.0978 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 4.8447 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0989 - msle: 8.5937 - rmsle: 0.0965 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.7483 - val_rmsle: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0979 - msle: 8.5130 - rmsle: 0.0956 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.7297 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0972 - msle: 8.4410 - rmsle: 0.0949 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.6446 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0963 - msle: 8.3853 - rmsle: 0.0941 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 4.5622 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0955 - msle: 8.2992 - rmsle: 0.0934 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0714 - val_msle: 4.5308 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.2663 - rmsle: 0.0930 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.5075 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0942 - msle: 8.1690 - rmsle: 0.0923 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.4456 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0939 - msle: 8.1484 - rmsle: 0.0919 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.4062 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0930 - msle: 8.0739 - rmsle: 0.0912 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.3579 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0928 - msle: 8.0260 - rmsle: 0.0910 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.3412 - val_rmsle: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0924 - msle: 7.9834 - rmsle: 0.0906 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.3058 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.9342 - rmsle: 0.0903 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.2797 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.8782 - rmsle: 0.0894 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.1962 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0907 - msle: 7.8786 - rmsle: 0.0891 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1660 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.8523 - rmsle: 0.0887 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 4.1615 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0902 - msle: 7.8376 - rmsle: 0.0886 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1520 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0903 - msle: 7.8522 - rmsle: 0.0888 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.1404 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0900 - msle: 7.8143 - rmsle: 0.0884 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.1174 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0899 - msle: 7.7698 - rmsle: 0.0884 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 4.1163 - val_rmsle: 0.0645 - learning_rate: 2.5000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0897 - msle: 7.7865 - rmsle: 0.0882 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.1005 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0893 - msle: 7.7650 - rmsle: 0.0878 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0911 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06477912758542412\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 9s 9ms/step - dense_3_loss: 0.0000e+00 - loss: 2.3623 - msle: 99.6947 - rmsle: 2.3594 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.9368 - val_msle: 76.0555 - val_rmsle: 0.9331 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.7837 - msle: 68.6890 - rmsle: 0.7800 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3369 - val_msle: 39.4958 - val_rmsle: 0.3334 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2774 - msle: 31.3187 - rmsle: 0.2739 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.1115 - val_msle: 9.7969 - val_rmsle: 0.1080 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1424 - msle: 10.4239 - rmsle: 0.1390 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0821 - val_msle: 6.0747 - val_rmsle: 0.0787 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1224 - msle: 9.1224 - rmsle: 0.1191 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 5.5913 - val_rmsle: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1141 - msle: 9.0223 - rmsle: 0.1110 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0740 - val_msle: 5.4996 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1096 - msle: 8.9438 - rmsle: 0.1067 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0735 - val_msle: 5.2385 - val_rmsle: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1061 - msle: 8.8527 - rmsle: 0.1033 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 5.2381 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1040 - msle: 8.7874 - rmsle: 0.1014 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 5.1125 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1025 - msle: 8.7338 - rmsle: 0.0999 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 5.1310 - val_rmsle: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1010 - msle: 8.6913 - rmsle: 0.0986 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.9829 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0997 - msle: 8.5652 - rmsle: 0.0973 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.8745 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 8.5288 - rmsle: 0.0967 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.9284 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0983 - msle: 8.4541 - rmsle: 0.0961 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0704 - val_msle: 4.7863 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0974 - msle: 8.3983 - rmsle: 0.0953 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.7087 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0970 - msle: 8.3691 - rmsle: 0.0949 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.6777 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0960 - msle: 8.2611 - rmsle: 0.0940 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.6103 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0955 - msle: 8.2037 - rmsle: 0.0936 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.6062 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.1683 - rmsle: 0.0931 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0694 - val_msle: 4.5434 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0948 - msle: 8.1325 - rmsle: 0.0929 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.5315 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0943 - msle: 8.0896 - rmsle: 0.0925 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.4725 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0939 - msle: 8.0785 - rmsle: 0.0922 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.3048 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0935 - msle: 8.0083 - rmsle: 0.0918 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3919 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.9939 - rmsle: 0.0916 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.3680 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.9581 - rmsle: 0.0914 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.3323 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.8921 - rmsle: 0.0909 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 4.3313 - val_rmsle: 0.0664 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.9002 - rmsle: 0.0909 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.2875 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.8520 - rmsle: 0.0904 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2482 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.8350 - rmsle: 0.0903 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2831 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0917 - msle: 7.7913 - rmsle: 0.0902 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2556 - val_rmsle: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0907 - msle: 7.7473 - rmsle: 0.0893 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.2543 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 3 RMSLE: 0.06674079584610837\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 8s 7ms/step - dense_4_loss: 0.0000e+00 - loss: 2.3645 - msle: 99.8288 - rmsle: 2.3616 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.9364 - val_msle: 75.6754 - val_rmsle: 0.9327 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.7867 - msle: 68.8137 - rmsle: 0.7829 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3355 - val_msle: 39.3658 - val_rmsle: 0.3320 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2770 - msle: 31.2498 - rmsle: 0.2734 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1028 - val_msle: 9.3564 - val_rmsle: 0.0992 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1408 - msle: 10.3151 - rmsle: 0.1374 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0817 - val_msle: 5.9574 - val_rmsle: 0.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1209 - msle: 9.0686 - rmsle: 0.1176 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 5.3834 - val_rmsle: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1129 - msle: 8.9514 - rmsle: 0.1098 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 5.1885 - val_rmsle: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1078 - msle: 8.8877 - rmsle: 0.1049 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 5.1770 - val_rmsle: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1047 - msle: 8.7954 - rmsle: 0.1019 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 5.0475 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1024 - msle: 8.7282 - rmsle: 0.0998 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.9889 - val_rmsle: 0.0666 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1006 - msle: 8.6561 - rmsle: 0.0980 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.8794 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0993 - msle: 8.5575 - rmsle: 0.0969 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 4.7876 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0980 - msle: 8.4711 - rmsle: 0.0957 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0681 - val_msle: 4.7117 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0973 - msle: 8.4008 - rmsle: 0.0951 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.6800 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0965 - msle: 8.3458 - rmsle: 0.0943 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0675 - val_msle: 4.5803 - val_rmsle: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0957 - msle: 8.2712 - rmsle: 0.0936 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.5847 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0950 - msle: 8.2200 - rmsle: 0.0930 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.5796 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0943 - msle: 8.1419 - rmsle: 0.0924 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 4.5088 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0940 - msle: 8.1208 - rmsle: 0.0921 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 4.4838 - val_rmsle: 0.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0934 - msle: 8.0731 - rmsle: 0.0915 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0661 - val_msle: 4.4400 - val_rmsle: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0929 - msle: 8.0181 - rmsle: 0.0910 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.4027 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0925 - msle: 7.9641 - rmsle: 0.0907 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 4.3929 - val_rmsle: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0919 - msle: 7.9083 - rmsle: 0.0902 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.3354 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.8545 - rmsle: 0.0898 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.3577 - val_rmsle: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0914 - msle: 7.8401 - rmsle: 0.0898 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 4.3061 - val_rmsle: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0909 - msle: 7.7895 - rmsle: 0.0893 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 4.2677 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0906 - msle: 7.7787 - rmsle: 0.0890 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.2685 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0905 - msle: 7.7712 - rmsle: 0.0890 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 4.2235 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0900 - msle: 7.7105 - rmsle: 0.0885 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.2889 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0900 - msle: 7.6825 - rmsle: 0.0885 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 4.2422 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0896 - msle: 7.6748 - rmsle: 0.0882 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 4.2353 - val_rmsle: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0894 - msle: 7.6511 - rmsle: 0.0880 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 4.1901 - val_rmsle: 0.0629 - learning_rate: 5.0000e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06344754767843942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 01:11:24,826] Trial 48 finished with value: 0.06476461739840372 and parameters: {'units': 256, 'last_layer': 2, 'activation': 'prelu', 'reg': 0.00010472192744117036, 'do_rate': 0.40886738534711037, 'hidden_layers': 1}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 13s 11ms/step - dense_loss: 0.0000e+00 - loss: 2.1872 - msle: 97.5364 - rmsle: 2.0948 - val_dense_loss: 0.0000e+00 - val_loss: 0.8110 - val_msle: 67.8676 - val_rmsle: 0.7754 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.6526 - msle: 61.1773 - rmsle: 0.6240 - val_dense_loss: 0.0000e+00 - val_loss: 0.4502 - val_msle: 39.9591 - val_rmsle: 0.4362 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3046 - msle: 29.3040 - rmsle: 0.2898 - val_dense_loss: 0.0000e+00 - val_loss: 0.1155 - val_msle: 4.7644 - val_rmsle: 0.1012 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1388 - msle: 8.6435 - rmsle: 0.1254 - val_dense_loss: 0.0000e+00 - val_loss: 0.0838 - val_msle: 4.3122 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1299 - msle: 8.4144 - rmsle: 0.1186 - val_dense_loss: 0.0000e+00 - val_loss: 0.0782 - val_msle: 4.0912 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1247 - msle: 8.2674 - rmsle: 0.1146 - val_dense_loss: 0.0000e+00 - val_loss: 0.0785 - val_msle: 4.7633 - val_rmsle: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1196 - msle: 8.0992 - rmsle: 0.1104 - val_dense_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.1886 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1146 - msle: 7.9559 - rmsle: 0.1061 - val_dense_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 3.9006 - val_rmsle: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1118 - msle: 7.8529 - rmsle: 0.1040 - val_dense_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.3912 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1098 - msle: 7.7708 - rmsle: 0.1024 - val_dense_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.4486 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1074 - msle: 7.6713 - rmsle: 0.1004 - val_dense_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 3.9383 - val_rmsle: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1041 - msle: 7.5528 - rmsle: 0.0977 - val_dense_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.8056 - val_rmsle: 0.0621 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1031 - msle: 7.5699 - rmsle: 0.0974 - val_dense_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.9322 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1020 - msle: 7.5347 - rmsle: 0.0966 - val_dense_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1031 - val_rmsle: 0.0636 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.5071 - rmsle: 0.0956 - val_dense_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.2754 - val_rmsle: 0.0647 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0989 - msle: 7.4066 - rmsle: 0.0940 - val_dense_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.7892 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.4007 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7607 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0983 - msle: 7.3910 - rmsle: 0.0940 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.7919 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.3900 - rmsle: 0.0937 - val_dense_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.1030 - val_rmsle: 0.0632 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0969 - msle: 7.3757 - rmsle: 0.0928 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.8387 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0968 - msle: 7.3641 - rmsle: 0.0929 - val_dense_loss: 0.0000e+00 - val_loss: 0.0663 - val_msle: 3.8657 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.3727 - rmsle: 0.0928 - val_dense_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7999 - val_rmsle: 0.0620 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.3261 - rmsle: 0.0924 - val_dense_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7597 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.2907 - rmsle: 0.0912 - val_dense_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7354 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0944 - msle: 7.2895 - rmsle: 0.0908 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7761 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0945 - msle: 7.2865 - rmsle: 0.0910 - val_dense_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.7452 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0941 - msle: 7.2893 - rmsle: 0.0907 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7328 - val_rmsle: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0940 - msle: 7.2750 - rmsle: 0.0907 - val_dense_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7454 - val_rmsle: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0938 - msle: 7.2470 - rmsle: 0.0905 - val_dense_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.7530 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0936 - msle: 7.2835 - rmsle: 0.0904 - val_dense_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.7397 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2407 - rmsle: 0.0898 - val_dense_loss: 0.0000e+00 - val_loss: 0.0647 - val_msle: 3.7436 - val_rmsle: 0.0614 - learning_rate: 3.1250e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.062338577826470024\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_1_loss: 0.0000e+00 - loss: 2.1888 - msle: 97.4517 - rmsle: 2.0957 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8164 - val_msle: 68.1598 - val_rmsle: 0.7790 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.6532 - msle: 60.4830 - rmsle: 0.6235 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.1972 - val_msle: 11.7332 - val_rmsle: 0.1782 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1756 - msle: 12.7428 - rmsle: 0.1575 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0961 - val_msle: 5.7839 - val_rmsle: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1375 - msle: 8.6453 - rmsle: 0.1238 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 4.4502 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1287 - msle: 8.3886 - rmsle: 0.1173 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.4401 - val_rmsle: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1241 - msle: 8.2638 - rmsle: 0.1141 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 4.3820 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1189 - msle: 8.0992 - rmsle: 0.1099 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0743 - val_msle: 4.1836 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1151 - msle: 7.9375 - rmsle: 0.1067 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.9678 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1123 - msle: 7.8394 - rmsle: 0.1044 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.5800 - val_rmsle: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1096 - msle: 7.7934 - rmsle: 0.1023 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0717 - val_msle: 4.1384 - val_rmsle: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1073 - msle: 7.6751 - rmsle: 0.1005 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 3.9556 - val_rmsle: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1060 - msle: 7.6083 - rmsle: 0.0994 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0738 - val_msle: 4.0529 - val_rmsle: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1042 - msle: 7.5581 - rmsle: 0.0978 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.3715 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1032 - msle: 7.5093 - rmsle: 0.0971 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.7097 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1000 - msle: 7.3895 - rmsle: 0.0944 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 5.1269 - val_rmsle: 0.0691 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0992 - msle: 7.3731 - rmsle: 0.0943 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.6330 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.3442 - rmsle: 0.0935 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.3834 - val_rmsle: 0.0657 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.2916 - rmsle: 0.0918 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0666 - val_msle: 3.9727 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0952 - msle: 7.2473 - rmsle: 0.0911 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.2102 - val_rmsle: 0.0631 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0948 - msle: 7.2610 - rmsle: 0.0910 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0138 - val_rmsle: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0946 - msle: 7.2153 - rmsle: 0.0909 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.9319 - val_rmsle: 0.0622 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0942 - msle: 7.2401 - rmsle: 0.0906 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.8895 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0939 - msle: 7.2243 - rmsle: 0.0905 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0652 - val_msle: 3.8175 - val_rmsle: 0.0617 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.1991 - rmsle: 0.0900 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.9128 - val_rmsle: 0.0623 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0934 - msle: 7.1850 - rmsle: 0.0901 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 4.0038 - val_rmsle: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.2022 - rmsle: 0.0898 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.8867 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.1767 - rmsle: 0.0888 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0651 - val_msle: 3.8355 - val_rmsle: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.1656 - rmsle: 0.0887 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0657 - val_msle: 3.8369 - val_rmsle: 0.0626 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.1787 - rmsle: 0.0887 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.8196 - val_rmsle: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.1507 - rmsle: 0.0885 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.8352 - val_rmsle: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_1_loss: 0.0000e+00 - loss: 0.0911 - msle: 7.1469 - rmsle: 0.0882 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0650 - val_msle: 3.8115 - val_rmsle: 0.0620 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.6364440917969\n",
            "Fold 1 RMSLE: 0.06227456754624115\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 2.1871 - msle: 97.4128 - rmsle: 2.0949 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.8058 - val_msle: 67.5821 - val_rmsle: 0.7706 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.6452 - msle: 60.4322 - rmsle: 0.6173 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2392 - val_msle: 16.5346 - val_rmsle: 0.2227 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2460 - msle: 14.0682 - rmsle: 0.2317 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0998 - val_msle: 5.8974 - val_rmsle: 0.0873 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1383 - msle: 8.6636 - rmsle: 0.1262 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0857 - val_msle: 4.9123 - val_rmsle: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1284 - msle: 8.4600 - rmsle: 0.1178 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0859 - val_msle: 4.6282 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1226 - msle: 8.2736 - rmsle: 0.1130 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0788 - val_msle: 4.6107 - val_rmsle: 0.0697 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1181 - msle: 8.1124 - rmsle: 0.1094 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0812 - val_msle: 4.5606 - val_rmsle: 0.0728 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1142 - msle: 7.9795 - rmsle: 0.1060 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0784 - val_msle: 4.9524 - val_rmsle: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1113 - msle: 7.8945 - rmsle: 0.1036 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0853 - val_msle: 5.2339 - val_rmsle: 0.0779 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1090 - msle: 7.8255 - rmsle: 0.1018 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0829 - val_msle: 5.1945 - val_rmsle: 0.0759 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1068 - msle: 7.7238 - rmsle: 0.1000 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0803 - val_msle: 5.5293 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1033 - msle: 7.5972 - rmsle: 0.0970 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0765 - val_msle: 4.2233 - val_rmsle: 0.0709 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1017 - msle: 7.5384 - rmsle: 0.0962 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0734 - val_msle: 3.7746 - val_rmsle: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1007 - msle: 7.5087 - rmsle: 0.0955 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.4699 - val_rmsle: 0.0706 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1001 - msle: 7.4983 - rmsle: 0.0951 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0731 - val_msle: 3.9116 - val_rmsle: 0.0682 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0993 - msle: 7.4634 - rmsle: 0.0945 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.7527 - val_rmsle: 0.0656 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0988 - msle: 7.4271 - rmsle: 0.0941 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 3.6931 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0982 - msle: 7.4338 - rmsle: 0.0936 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 3.6717 - val_rmsle: 0.0660 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0976 - msle: 7.3742 - rmsle: 0.0931 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.6959 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0972 - msle: 7.3984 - rmsle: 0.0928 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.7158 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.3607 - rmsle: 0.0921 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 3.6856 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0960 - msle: 7.3519 - rmsle: 0.0918 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0680 - val_msle: 3.6704 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0955 - msle: 7.3047 - rmsle: 0.0913 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.7097 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.2842 - rmsle: 0.0909 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 3.6640 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0949 - msle: 7.2821 - rmsle: 0.0909 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.1637 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0926 - msle: 7.2032 - rmsle: 0.0887 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0659 - val_msle: 3.7270 - val_rmsle: 0.0621 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0921 - msle: 7.1882 - rmsle: 0.0885 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.7869 - val_rmsle: 0.0633 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0920 - msle: 7.2047 - rmsle: 0.0886 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.7118 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0918 - msle: 7.1882 - rmsle: 0.0885 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9496 - val_rmsle: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0915 - msle: 7.1558 - rmsle: 0.0883 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.6662 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_2_loss: 0.0000e+00 - loss: 0.0910 - msle: 7.1390 - rmsle: 0.0878 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.9954 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 2 RMSLE: 0.06194288441828796\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_3_loss: 0.0000e+00 - loss: 2.1885 - msle: 97.4589 - rmsle: 2.0959 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.8111 - val_msle: 67.8172 - val_rmsle: 0.7752 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.5848 - msle: 55.2611 - rmsle: 0.5545 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2273 - val_msle: 13.9149 - val_rmsle: 0.2101 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2400 - msle: 12.4363 - rmsle: 0.2249 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0867 - val_msle: 5.3916 - val_rmsle: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1389 - msle: 8.7720 - rmsle: 0.1261 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 4.5057 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1302 - msle: 8.5108 - rmsle: 0.1192 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0771 - val_msle: 4.2902 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1249 - msle: 8.4216 - rmsle: 0.1150 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.5042 - val_rmsle: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1214 - msle: 8.3035 - rmsle: 0.1123 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.0528 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 8.1476 - rmsle: 0.1079 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0761 - val_msle: 4.1050 - val_rmsle: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1137 - msle: 8.0281 - rmsle: 0.1057 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0797 - val_msle: 4.5209 - val_rmsle: 0.0720 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1107 - msle: 7.9325 - rmsle: 0.1031 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 4.0661 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1065 - msle: 7.7769 - rmsle: 0.0995 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0721 - val_msle: 4.8311 - val_rmsle: 0.0658 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1046 - msle: 7.7126 - rmsle: 0.0984 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 3.9934 - val_rmsle: 0.0633 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1035 - msle: 7.6662 - rmsle: 0.0977 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0700 - val_msle: 4.5083 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1026 - msle: 7.6165 - rmsle: 0.0971 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 4.4793 - val_rmsle: 0.0641 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1018 - msle: 7.5939 - rmsle: 0.0966 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.3502 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.5804 - rmsle: 0.0962 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.5984 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1004 - msle: 7.5579 - rmsle: 0.0954 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.2909 - val_rmsle: 0.0638 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0997 - msle: 7.5329 - rmsle: 0.0949 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 5.0688 - val_rmsle: 0.0666 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0990 - msle: 7.4844 - rmsle: 0.0943 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3114 - val_rmsle: 0.0640 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0985 - msle: 7.4707 - rmsle: 0.0939 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.1926 - val_rmsle: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.4482 - rmsle: 0.0926 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.7993 - val_rmsle: 0.0657 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_3_loss: 0.0000e+00 - loss: 0.0967 - msle: 7.4022 - rmsle: 0.0925 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.3861 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 314.338623046875\n",
            "Fold 3 RMSLE: 0.06413119773711051\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 12s 10ms/step - dense_4_loss: 0.0000e+00 - loss: 2.1899 - msle: 97.6007 - rmsle: 2.0974 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.8046 - val_msle: 66.8478 - val_rmsle: 0.7690 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.6538 - msle: 61.1510 - rmsle: 0.6252 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.4577 - val_msle: 42.8558 - val_rmsle: 0.4440 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2408 - msle: 22.0346 - rmsle: 0.2249 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.1127 - val_msle: 6.3388 - val_rmsle: 0.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1378 - msle: 8.5613 - rmsle: 0.1245 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0822 - val_msle: 5.2346 - val_rmsle: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1279 - msle: 8.3106 - rmsle: 0.1168 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0846 - val_msle: 6.3239 - val_rmsle: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1229 - msle: 8.1595 - rmsle: 0.1130 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0802 - val_msle: 5.6594 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1179 - msle: 8.0654 - rmsle: 0.1089 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0853 - val_msle: 5.9109 - val_rmsle: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1142 - msle: 7.9178 - rmsle: 0.1059 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0835 - val_msle: 6.1170 - val_rmsle: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1108 - msle: 7.8032 - rmsle: 0.1032 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0856 - val_msle: 6.3209 - val_rmsle: 0.0782 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1062 - msle: 7.6288 - rmsle: 0.0992 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0752 - val_msle: 5.1319 - val_rmsle: 0.0688 - learning_rate: 2.5000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1044 - msle: 7.5886 - rmsle: 0.0983 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.9602 - val_rmsle: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1030 - msle: 7.5488 - rmsle: 0.0972 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.3482 - val_rmsle: 0.0653 - learning_rate: 2.5000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1020 - msle: 7.5218 - rmsle: 0.0965 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0716 - val_msle: 4.5923 - val_rmsle: 0.0662 - learning_rate: 2.5000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1013 - msle: 7.5172 - rmsle: 0.0960 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0753 - val_msle: 4.6465 - val_rmsle: 0.0701 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1005 - msle: 7.4564 - rmsle: 0.0954 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 5.0998 - val_rmsle: 0.0672 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0987 - msle: 7.3943 - rmsle: 0.0938 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.7387 - val_rmsle: 0.0619 - learning_rate: 1.2500e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0979 - msle: 7.3319 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0660 - val_msle: 3.7281 - val_rmsle: 0.0614 - learning_rate: 1.2500e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0978 - msle: 7.3513 - rmsle: 0.0933 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_msle: 3.7083 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0971 - msle: 7.3125 - rmsle: 0.0927 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0656 - val_msle: 3.7432 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0965 - msle: 7.3369 - rmsle: 0.0923 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7093 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0964 - msle: 7.3124 - rmsle: 0.0922 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0654 - val_msle: 3.7621 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0962 - msle: 7.3121 - rmsle: 0.0922 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.6953 - val_rmsle: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0954 - msle: 7.2701 - rmsle: 0.0914 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0653 - val_msle: 3.6857 - val_rmsle: 0.0613 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0956 - msle: 7.2402 - rmsle: 0.0917 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.7071 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0950 - msle: 7.2808 - rmsle: 0.0912 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0655 - val_msle: 3.6764 - val_rmsle: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0944 - msle: 7.2029 - rmsle: 0.0905 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0648 - val_msle: 3.7033 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0939 - msle: 7.1899 - rmsle: 0.0903 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0649 - val_msle: 3.7818 - val_rmsle: 0.0613 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0935 - msle: 7.1732 - rmsle: 0.0900 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0645 - val_msle: 3.7019 - val_rmsle: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0933 - msle: 7.1917 - rmsle: 0.0899 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0646 - val_msle: 3.7110 - val_rmsle: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0930 - msle: 7.1925 - rmsle: 0.0897 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0643 - val_msle: 3.6774 - val_rmsle: 0.0608 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - dense_4_loss: 0.0000e+00 - loss: 0.0927 - msle: 7.1671 - rmsle: 0.0894 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0644 - val_msle: 3.6947 - val_rmsle: 0.0610 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 4 RMSLE: 0.06152221982456754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 01:17:54,915] Trial 49 finished with value: 0.06244188947053544 and parameters: {'units': 512, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0002212934882765353, 'do_rate': 0.3985409976038868, 'hidden_layers': 2}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold: 0\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 12ms/step - dense_loss: 0.0000e+00 - loss: 2.9455 - msle: 104.0886 - rmsle: 2.9071 - val_dense_loss: 0.0000e+00 - val_loss: 1.5482 - val_msle: 92.4224 - val_rmsle: 1.5182 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 1.3738 - msle: 90.5754 - rmsle: 1.3463 - val_dense_loss: 0.0000e+00 - val_loss: 0.7820 - val_msle: 72.6726 - val_rmsle: 0.7611 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.7045 - msle: 70.6547 - rmsle: 0.6852 - val_dense_loss: 0.0000e+00 - val_loss: 0.3780 - val_msle: 51.5044 - val_rmsle: 0.3624 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.3687 - msle: 48.4701 - rmsle: 0.3540 - val_dense_loss: 0.0000e+00 - val_loss: 0.2348 - val_msle: 24.8825 - val_rmsle: 0.2223 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.2404 - msle: 26.0931 - rmsle: 0.2283 - val_dense_loss: 0.0000e+00 - val_loss: 0.0849 - val_msle: 5.1857 - val_rmsle: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1615 - msle: 13.8897 - rmsle: 0.1509 - val_dense_loss: 0.0000e+00 - val_loss: 0.0794 - val_msle: 4.2869 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1517 - msle: 13.4782 - rmsle: 0.1426 - val_dense_loss: 0.0000e+00 - val_loss: 0.0763 - val_msle: 4.1447 - val_rmsle: 0.0681 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1460 - msle: 13.1699 - rmsle: 0.1381 - val_dense_loss: 0.0000e+00 - val_loss: 0.0748 - val_msle: 4.1347 - val_rmsle: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1413 - msle: 12.9149 - rmsle: 0.1344 - val_dense_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.2196 - val_rmsle: 0.0686 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1375 - msle: 12.7031 - rmsle: 0.1314 - val_dense_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 3.9967 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1344 - msle: 12.4826 - rmsle: 0.1289 - val_dense_loss: 0.0000e+00 - val_loss: 0.0715 - val_msle: 4.2895 - val_rmsle: 0.0663 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1318 - msle: 12.2843 - rmsle: 0.1268 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 3.9396 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1295 - msle: 12.0767 - rmsle: 0.1249 - val_dense_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 3.9551 - val_rmsle: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1273 - msle: 11.9260 - rmsle: 0.1230 - val_dense_loss: 0.0000e+00 - val_loss: 0.0718 - val_msle: 4.0264 - val_rmsle: 0.0675 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1252 - msle: 11.7391 - rmsle: 0.1211 - val_dense_loss: 0.0000e+00 - val_loss: 0.0725 - val_msle: 4.1441 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1234 - msle: 11.5845 - rmsle: 0.1195 - val_dense_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 3.9547 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1224 - msle: 11.4842 - rmsle: 0.1186 - val_dense_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 3.9658 - val_rmsle: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1212 - msle: 11.3978 - rmsle: 0.1176 - val_dense_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8459 - val_rmsle: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1200 - msle: 11.3294 - rmsle: 0.1165 - val_dense_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 3.8512 - val_rmsle: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1185 - msle: 11.1766 - rmsle: 0.1151 - val_dense_loss: 0.0000e+00 - val_loss: 0.0693 - val_msle: 4.2086 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1182 - msle: 11.0901 - rmsle: 0.1148 - val_dense_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.0507 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1163 - msle: 10.9666 - rmsle: 0.1131 - val_dense_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 4.1952 - val_rmsle: 0.0654 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1157 - msle: 10.9136 - rmsle: 0.1126 - val_dense_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.1301 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1148 - msle: 10.8497 - rmsle: 0.1118 - val_dense_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.9619 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1145 - msle: 10.8241 - rmsle: 0.1116 - val_dense_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.9913 - val_rmsle: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1143 - msle: 10.7857 - rmsle: 0.1115 - val_dense_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1152 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1139 - msle: 10.7038 - rmsle: 0.1111 - val_dense_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 4.1329 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1134 - msle: 10.7242 - rmsle: 0.1107 - val_dense_loss: 0.0000e+00 - val_loss: 0.0670 - val_msle: 4.1516 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1124 - msle: 10.6151 - rmsle: 0.1097 - val_dense_loss: 0.0000e+00 - val_loss: 0.0664 - val_msle: 4.0803 - val_rmsle: 0.0638 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1121 - msle: 10.5685 - rmsle: 0.1096 - val_dense_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 4.2302 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_loss: 0.0000e+00 - loss: 0.1116 - msle: 10.5657 - rmsle: 0.1092 - val_dense_loss: 0.0000e+00 - val_loss: 0.0662 - val_msle: 3.9287 - val_rmsle: 0.0637 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 315.0\n",
            "Fold 0 RMSLE: 0.06437403421159717\n",
            "Running Fold: 1\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_1_loss: 0.0000e+00 - loss: 2.9403 - msle: 104.0280 - rmsle: 2.9018 - val_dense_1_loss: 0.0000e+00 - val_loss: 1.5518 - val_msle: 92.7882 - val_rmsle: 1.5216 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 1.3684 - msle: 90.5257 - rmsle: 1.3408 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.8470 - val_msle: 78.9396 - val_rmsle: 0.8262 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.7044 - msle: 70.3296 - rmsle: 0.6850 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.3740 - val_msle: 50.7317 - val_rmsle: 0.3583 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.3683 - msle: 48.3351 - rmsle: 0.3535 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.2378 - val_msle: 32.2808 - val_rmsle: 0.2255 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.2644 - msle: 33.8804 - rmsle: 0.2527 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0894 - val_msle: 5.0560 - val_rmsle: 0.0789 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1626 - msle: 13.9901 - rmsle: 0.1526 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0820 - val_msle: 4.8787 - val_rmsle: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1523 - msle: 13.5027 - rmsle: 0.1438 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0815 - val_msle: 4.9985 - val_rmsle: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1454 - msle: 13.1364 - rmsle: 0.1381 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 4.7326 - val_rmsle: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1406 - msle: 12.8481 - rmsle: 0.1342 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0783 - val_msle: 4.4126 - val_rmsle: 0.0724 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1369 - msle: 12.5872 - rmsle: 0.1313 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0775 - val_msle: 5.7943 - val_rmsle: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1341 - msle: 12.4239 - rmsle: 0.1290 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0742 - val_msle: 4.6368 - val_rmsle: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1309 - msle: 12.1945 - rmsle: 0.1262 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0727 - val_msle: 4.5558 - val_rmsle: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1295 - msle: 12.0290 - rmsle: 0.1251 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.6934 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1264 - msle: 11.7509 - rmsle: 0.1223 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0724 - val_msle: 4.2694 - val_rmsle: 0.0684 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1246 - msle: 11.6446 - rmsle: 0.1207 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.0476 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1232 - msle: 11.4769 - rmsle: 0.1194 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.5972 - val_rmsle: 0.0685 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1220 - msle: 11.3874 - rmsle: 0.1184 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0710 - val_msle: 4.6236 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1207 - msle: 11.2565 - rmsle: 0.1172 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0728 - val_msle: 4.2647 - val_rmsle: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1183 - msle: 11.1336 - rmsle: 0.1150 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.2732 - val_rmsle: 0.0665 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1176 - msle: 11.0460 - rmsle: 0.1144 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0702 - val_msle: 4.0500 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1169 - msle: 10.9937 - rmsle: 0.1139 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0701 - val_msle: 4.0643 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1163 - msle: 10.9422 - rmsle: 0.1133 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.2169 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1152 - msle: 10.8589 - rmsle: 0.1124 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 4.4972 - val_rmsle: 0.0670 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1149 - msle: 10.8653 - rmsle: 0.1121 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.4376 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1144 - msle: 10.8154 - rmsle: 0.1117 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.8029 - val_rmsle: 0.0678 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1142 - msle: 10.7947 - rmsle: 0.1116 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0691 - val_msle: 4.2710 - val_rmsle: 0.0664 - learning_rate: 6.2500e-05\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1138 - msle: 10.7360 - rmsle: 0.1112 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0705 - val_msle: 4.4418 - val_rmsle: 0.0678 - learning_rate: 6.2500e-05\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1136 - msle: 10.7724 - rmsle: 0.1110 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0689 - val_msle: 4.4660 - val_rmsle: 0.0663 - learning_rate: 6.2500e-05\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1135 - msle: 10.7537 - rmsle: 0.1109 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0695 - val_msle: 4.5705 - val_rmsle: 0.0670 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1132 - msle: 10.7262 - rmsle: 0.1107 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.2698 - val_rmsle: 0.0667 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_1_loss: 0.0000e+00 - loss: 0.1132 - msle: 10.7110 - rmsle: 0.1107 - val_dense_1_loss: 0.0000e+00 - val_loss: 0.0688 - val_msle: 4.6098 - val_rmsle: 0.0663 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 295.1452941894531\n",
            "Fold 1 RMSLE: 0.0665597292341239\n",
            "Running Fold: 2\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_2_loss: 0.0000e+00 - loss: 2.9428 - msle: 103.9777 - rmsle: 2.9044 - val_dense_2_loss: 0.0000e+00 - val_loss: 1.5502 - val_msle: 92.7696 - val_rmsle: 1.5201 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 1.3723 - msle: 90.5344 - rmsle: 1.3448 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.8019 - val_msle: 75.7230 - val_rmsle: 0.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.7035 - msle: 70.4611 - rmsle: 0.6843 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.3748 - val_msle: 50.1958 - val_rmsle: 0.3593 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.3660 - msle: 48.2125 - rmsle: 0.3514 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.2329 - val_msle: 30.1384 - val_rmsle: 0.2209 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.2521 - msle: 31.7541 - rmsle: 0.2406 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0842 - val_msle: 4.8543 - val_rmsle: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1598 - msle: 13.8021 - rmsle: 0.1497 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0808 - val_msle: 4.1126 - val_rmsle: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1502 - msle: 13.4643 - rmsle: 0.1416 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.1205 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1433 - msle: 13.1429 - rmsle: 0.1359 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0754 - val_msle: 3.9165 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1393 - msle: 12.8423 - rmsle: 0.1329 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0773 - val_msle: 4.0718 - val_rmsle: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1351 - msle: 12.5970 - rmsle: 0.1294 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0726 - val_msle: 3.8377 - val_rmsle: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1322 - msle: 12.3856 - rmsle: 0.1271 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0750 - val_msle: 3.9925 - val_rmsle: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1294 - msle: 12.1261 - rmsle: 0.1247 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0746 - val_msle: 4.1019 - val_rmsle: 0.0701 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1273 - msle: 11.9578 - rmsle: 0.1229 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 3.8816 - val_rmsle: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1244 - msle: 11.7665 - rmsle: 0.1203 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2774 - val_rmsle: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1230 - msle: 11.6389 - rmsle: 0.1192 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 3.8877 - val_rmsle: 0.0674 - learning_rate: 2.5000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1223 - msle: 11.5747 - rmsle: 0.1186 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 3.8602 - val_rmsle: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1213 - msle: 11.5296 - rmsle: 0.1178 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 3.8813 - val_rmsle: 0.0675 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1202 - msle: 11.3942 - rmsle: 0.1168 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0733 - val_msle: 4.9263 - val_rmsle: 0.0700 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1194 - msle: 11.3823 - rmsle: 0.1161 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0713 - val_msle: 4.0258 - val_rmsle: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1184 - msle: 11.3114 - rmsle: 0.1152 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0686 - val_msle: 3.8865 - val_rmsle: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1175 - msle: 11.2394 - rmsle: 0.1144 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0684 - val_msle: 3.7872 - val_rmsle: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1172 - msle: 11.1861 - rmsle: 0.1142 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.7763 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1167 - msle: 11.1607 - rmsle: 0.1138 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0672 - val_msle: 3.7489 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1166 - msle: 11.1779 - rmsle: 0.1138 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 3.7933 - val_rmsle: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1163 - msle: 11.1401 - rmsle: 0.1135 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0669 - val_msle: 3.7200 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1158 - msle: 11.1394 - rmsle: 0.1131 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0682 - val_msle: 3.7340 - val_rmsle: 0.0654 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1154 - msle: 11.0717 - rmsle: 0.1128 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 3.7709 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1152 - msle: 11.0686 - rmsle: 0.1126 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 3.8110 - val_rmsle: 0.0650 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1146 - msle: 11.0154 - rmsle: 0.1120 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 3.8181 - val_rmsle: 0.0642 - learning_rate: 6.2500e-05\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1147 - msle: 10.9960 - rmsle: 0.1121 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7951 - val_rmsle: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_2_loss: 0.0000e+00 - loss: 0.1144 - msle: 10.9575 - rmsle: 0.1119 - val_dense_2_loss: 0.0000e+00 - val_loss: 0.0667 - val_msle: 3.7877 - val_rmsle: 0.0642 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 313.7419128417969\n",
            "Fold 2 RMSLE: 0.0644727690190065\n",
            "Running Fold: 3\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_3_loss: 0.0000e+00 - loss: 2.9403 - msle: 104.0618 - rmsle: 2.9019 - val_dense_3_loss: 0.0000e+00 - val_loss: 1.5526 - val_msle: 92.9493 - val_rmsle: 1.5225 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 1.3692 - msle: 90.6689 - rmsle: 1.3417 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.7860 - val_msle: 73.1932 - val_rmsle: 0.7653 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.7035 - msle: 70.6385 - rmsle: 0.6844 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.3789 - val_msle: 50.0163 - val_rmsle: 0.3637 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.3675 - msle: 48.6235 - rmsle: 0.3533 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.2371 - val_msle: 34.8217 - val_rmsle: 0.2254 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.2536 - msle: 32.8361 - rmsle: 0.2424 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0877 - val_msle: 6.1822 - val_rmsle: 0.0774 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1599 - msle: 13.7942 - rmsle: 0.1501 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0828 - val_msle: 5.0575 - val_rmsle: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1508 - msle: 13.4041 - rmsle: 0.1424 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0830 - val_msle: 5.0902 - val_rmsle: 0.0755 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1445 - msle: 13.0672 - rmsle: 0.1373 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0776 - val_msle: 4.3941 - val_rmsle: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1402 - msle: 12.7709 - rmsle: 0.1339 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0768 - val_msle: 5.0570 - val_rmsle: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1366 - msle: 12.5234 - rmsle: 0.1310 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0795 - val_msle: 4.7492 - val_rmsle: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1332 - msle: 12.2874 - rmsle: 0.1281 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0758 - val_msle: 4.8262 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1310 - msle: 12.1181 - rmsle: 0.1263 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.3128 - val_rmsle: 0.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1285 - msle: 11.9209 - rmsle: 0.1241 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0751 - val_msle: 4.7996 - val_rmsle: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1266 - msle: 11.7684 - rmsle: 0.1224 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0757 - val_msle: 4.3590 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1245 - msle: 11.5745 - rmsle: 0.1205 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0756 - val_msle: 4.3818 - val_rmsle: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1221 - msle: 11.4203 - rmsle: 0.1183 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0747 - val_msle: 4.3362 - val_rmsle: 0.0710 - learning_rate: 2.5000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1214 - msle: 11.3624 - rmsle: 0.1178 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0749 - val_msle: 4.3066 - val_rmsle: 0.0714 - learning_rate: 2.5000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1204 - msle: 11.2833 - rmsle: 0.1170 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0730 - val_msle: 4.2783 - val_rmsle: 0.0696 - learning_rate: 2.5000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1199 - msle: 11.3252 - rmsle: 0.1167 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0778 - val_msle: 4.6907 - val_rmsle: 0.0746 - learning_rate: 2.5000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1193 - msle: 11.2164 - rmsle: 0.1162 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0760 - val_msle: 4.6655 - val_rmsle: 0.0728 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1190 - msle: 11.1734 - rmsle: 0.1159 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 4.8644 - val_rmsle: 0.0714 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1174 - msle: 11.0359 - rmsle: 0.1144 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0708 - val_msle: 4.2762 - val_rmsle: 0.0678 - learning_rate: 1.2500e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1170 - msle: 11.0219 - rmsle: 0.1141 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 4.2600 - val_rmsle: 0.0682 - learning_rate: 1.2500e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1166 - msle: 11.0299 - rmsle: 0.1138 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0703 - val_msle: 4.3080 - val_rmsle: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1164 - msle: 10.9807 - rmsle: 0.1137 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0707 - val_msle: 4.1590 - val_rmsle: 0.0679 - learning_rate: 1.2500e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1162 - msle: 10.9990 - rmsle: 0.1135 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0712 - val_msle: 4.6291 - val_rmsle: 0.0685 - learning_rate: 1.2500e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1156 - msle: 10.9297 - rmsle: 0.1130 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.2998 - val_rmsle: 0.0671 - learning_rate: 1.2500e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1155 - msle: 10.9294 - rmsle: 0.1129 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.2845 - val_rmsle: 0.0672 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1151 - msle: 10.9009 - rmsle: 0.1125 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0698 - val_msle: 4.2300 - val_rmsle: 0.0672 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1149 - msle: 10.8649 - rmsle: 0.1124 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0706 - val_msle: 4.3449 - val_rmsle: 0.0681 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_3_loss: 0.0000e+00 - loss: 0.1147 - msle: 10.8418 - rmsle: 0.1123 - val_dense_3_loss: 0.0000e+00 - val_loss: 0.0683 - val_msle: 4.2323 - val_rmsle: 0.0658 - learning_rate: 6.2500e-05\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 296.99908447265625\n",
            "Fold 3 RMSLE: 0.06639755850131922\n",
            "Running Fold: 4\n",
            "Epoch 1/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 14s 11ms/step - dense_4_loss: 0.0000e+00 - loss: 2.9418 - msle: 104.1682 - rmsle: 2.9033 - val_dense_4_loss: 0.0000e+00 - val_loss: 1.5469 - val_msle: 92.2254 - val_rmsle: 1.5170 - learning_rate: 5.0000e-04\n",
            "Epoch 2/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 1.3699 - msle: 90.6565 - rmsle: 1.3423 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.7792 - val_msle: 71.8245 - val_rmsle: 0.7585 - learning_rate: 5.0000e-04\n",
            "Epoch 3/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.7028 - msle: 70.3693 - rmsle: 0.6835 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.3698 - val_msle: 45.1234 - val_rmsle: 0.3545 - learning_rate: 5.0000e-04\n",
            "Epoch 4/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.3687 - msle: 48.0516 - rmsle: 0.3543 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.2365 - val_msle: 30.1988 - val_rmsle: 0.2246 - learning_rate: 5.0000e-04\n",
            "Epoch 5/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.2431 - msle: 29.0211 - rmsle: 0.2316 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0862 - val_msle: 4.9488 - val_rmsle: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 6/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1600 - msle: 13.8592 - rmsle: 0.1500 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0789 - val_msle: 4.3456 - val_rmsle: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 7/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1499 - msle: 13.3583 - rmsle: 0.1413 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0786 - val_msle: 4.2473 - val_rmsle: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 8/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1440 - msle: 13.0235 - rmsle: 0.1366 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0745 - val_msle: 3.9731 - val_rmsle: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 9/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1393 - msle: 12.7560 - rmsle: 0.1329 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0722 - val_msle: 4.0506 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 10/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1357 - msle: 12.5080 - rmsle: 0.1299 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0723 - val_msle: 3.9158 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 11/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1330 - msle: 12.2712 - rmsle: 0.1278 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0720 - val_msle: 4.2191 - val_rmsle: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 12/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1300 - msle: 12.1265 - rmsle: 0.1251 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0719 - val_msle: 3.8411 - val_rmsle: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 13/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1281 - msle: 11.9683 - rmsle: 0.1236 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0709 - val_msle: 4.0817 - val_rmsle: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 14/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1258 - msle: 11.7301 - rmsle: 0.1215 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0711 - val_msle: 3.8744 - val_rmsle: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 15/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1232 - msle: 11.5275 - rmsle: 0.1191 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 4.1021 - val_rmsle: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 16/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1220 - msle: 11.4111 - rmsle: 0.1181 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0685 - val_msle: 3.9357 - val_rmsle: 0.0645 - learning_rate: 5.0000e-04\n",
            "Epoch 17/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1211 - msle: 11.3371 - rmsle: 0.1173 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0699 - val_msle: 3.9376 - val_rmsle: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 18/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1193 - msle: 11.1964 - rmsle: 0.1156 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0696 - val_msle: 3.8610 - val_rmsle: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 19/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1185 - msle: 11.0747 - rmsle: 0.1149 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0692 - val_msle: 3.7888 - val_rmsle: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 20/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1160 - msle: 10.8971 - rmsle: 0.1125 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0678 - val_msle: 4.0283 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 21/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1155 - msle: 10.8575 - rmsle: 0.1123 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.1911 - val_rmsle: 0.0643 - learning_rate: 2.5000e-04\n",
            "Epoch 22/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1150 - msle: 10.8305 - rmsle: 0.1119 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.0842 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 23/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1142 - msle: 10.7345 - rmsle: 0.1113 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0679 - val_msle: 4.2391 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 24/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1137 - msle: 10.7127 - rmsle: 0.1109 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0673 - val_msle: 4.2292 - val_rmsle: 0.0644 - learning_rate: 2.5000e-04\n",
            "Epoch 25/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1138 - msle: 10.6835 - rmsle: 0.1110 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0677 - val_msle: 4.3056 - val_rmsle: 0.0648 - learning_rate: 2.5000e-04\n",
            "Epoch 26/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1130 - msle: 10.6055 - rmsle: 0.1103 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.1456 - val_rmsle: 0.0646 - learning_rate: 2.5000e-04\n",
            "Epoch 27/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1125 - msle: 10.5775 - rmsle: 0.1099 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0676 - val_msle: 4.4037 - val_rmsle: 0.0649 - learning_rate: 2.5000e-04\n",
            "Epoch 28/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1115 - msle: 10.5039 - rmsle: 0.1089 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0674 - val_msle: 4.0655 - val_rmsle: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 29/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1110 - msle: 10.4714 - rmsle: 0.1085 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0668 - val_msle: 4.0803 - val_rmsle: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 30/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1109 - msle: 10.4766 - rmsle: 0.1085 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0671 - val_msle: 3.9878 - val_rmsle: 0.0646 - learning_rate: 1.2500e-04\n",
            "Epoch 31/31\n",
            "598/598 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - dense_4_loss: 0.0000e+00 - loss: 0.1106 - msle: 10.4094 - rmsle: 0.1082 - val_dense_4_loss: 0.0000e+00 - val_loss: 0.0665 - val_msle: 4.0592 - val_rmsle: 0.0641 - learning_rate: 1.2500e-04\n",
            "150/150 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
            "Pred Min: 1.0\n",
            "Pred Max: 312.2402038574219\n",
            "Fold 4 RMSLE: 0.06441022357705799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-08 01:25:10,709] Trial 50 finished with value: 0.06524286290862095 and parameters: {'units': 128, 'last_layer': 2, 'activation': 'silu', 'reg': 0.0001433447813483603, 'do_rate': 0.4227286017634942, 'hidden_layers': 3}. Best is trial 18 with value: 0.06211038027842043.\n"
          ]
        }
      ],
      "source": [
        "nn0_study = tune_hyperparameters(X_fin, y_fin, model_class=wide_deep, n_trials=51, n_splits_ = 5 ,n_repeats_=3, use_gpu=True)\n",
        "\n",
        "cat_params = nn0_study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCXgnVWW7_0h",
        "outputId": "4690cae5-4ebb-43e1-c4ee-48388effeda2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 512,\n",
              " 'last_layer': 2,\n",
              " 'activation': 'silu',\n",
              " 'reg': 0.0001004170129215336,\n",
              " 'do_rate': 0.41356627172269655,\n",
              " 'hidden_layers': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 Train Model:"
      ],
      "metadata": {
        "id": "oUmQ2LeBOMjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'units': 512, 'last_layer': 1, 'activation': 'relu', 'reg': 0.00012466698516071345, 'do_rate': 0.32329936440008156}\n",
        "TM = TrainModels(X=data.X, y=data.y, X_test=data.X_test, test_finc_target=y_test_fic, X_original=None, y_original=None, model_=build_model, parameters=param)"
      ],
      "metadata": {
        "id": "P0TZ7C9ZOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TM.fit_model(name=\"NN_exp_00\")"
      ],
      "metadata": {
        "id": "4NQhOfOpOMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 Store Results:"
      ],
      "metadata": {
        "id": "O2653MGROMjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = TM.OOF_train\n",
        "test_pred = TM.OOF_test\n",
        "train_pred = pd.DataFrame(data = train_pred, columns = [\"NN_exp_00\"])\n",
        "\n",
        "\n",
        "sub = pd.read_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/sample_submission.csv\",index_col=0)\n",
        "\n",
        "sub[\"Calories\"] =  test_pred.values\n",
        "\n",
        "sub.to_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/submission_NN_exp_00.csv\")\n",
        "train_pred.to_csv(\"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S5E5/train_pred_NN_exp_00.csv\")"
      ],
      "metadata": {
        "id": "P-llnneROMjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.min(), test_pred.max()"
      ],
      "metadata": {
        "id": "fAkI6ulSOMjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred"
      ],
      "metadata": {
        "id": "9dYagSFaOMjR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}